# 統合運用ガイド

## 📋 このファイルの目的

**対象読者**:
- **AI（Claude Code等）**: 自律的にデプロイ・検証を実行
- **開発者**: 手動実行時のリファレンス
- **運用担当者**: 日常監視・緊急対応のガイド

**使用場面**:
- **デプロイ前準備**: ML学習・パラメータ最適化・品質確認
- **ローカル検証**: ペーパートレード・バックテスト実行
- **本番デプロイ**: CI/CD実行・環境構築
- **日常運用**: 監視・メンテナンス・緊急対応

**ガイドの特徴**:
- ✅ **明確な手順**: 各ステップで実行コマンド・期待結果を明示
- ✅ **最新状態反映**: 1,117テスト・68.32%カバレッジ達成済み（Phase 49完了）
- ✅ **AI可読性**: コマンド・出力例・確認項目を構造化
- ✅ **実測値記載**: 実行時間・モデルサイズ等の実際の値を記載

---

# 第1部: デプロイ前準備

## 🚀 デプロイ前チェックリスト（必須実行順序）

### Step 1: ML学習実行（新機能開発後・定期再学習時必須）

#### 🎯 **標準ML学習コマンド**（推奨）

```bash
# ========================================
# 標準ML学習（約4分・50 trials）
# ========================================
python3 scripts/ml/create_ml_models.py \
  --n-classes 3 \
  --threshold 0.005 \
  --optimize \
  --n-trials 50 \
  --verbose

# 実行時間: 約4分（50 trials）
# 学習データ: 180日分・1,032サンプル・55特徴量（50基本+5戦略信号）
# モデル: LightGBM・XGBoost・RandomForest アンサンブル
# 分類: 3クラス（SELL/HOLD/BUY）・閾値±0.5%
# 最適化: Optuna TPESampler・TimeSeriesSplit n_splits=5

# ========================================
# 高精度版（100 trials・推奨しない）
# ========================================
# python3 scripts/ml/create_ml_models.py \
#   --n-classes 3 \
#   --threshold 0.005 \
#   --optimize \
#   --n-trials 100 \
#   --verbose
#
# 実行時間: 約8分（100 trials）
# 効果: +1-3%改善のみ（50 trials比）・コスパ悪い
```

#### 📊 **オプション一覧**（標準コマンドで全て有効）

| オプション | 説明 | 標準で有効 |
|-----------|------|----------|
| `--n-classes 3` | 3クラス分類（SELL/HOLD/BUY） | ✅ 推奨 |
| `--threshold 0.005` | 閾値±0.5%（ノイズ削減） | ✅ 推奨 |
| `--optimize` | Optunaハイパーパラメータ最適化 | ✅ 推奨 |
| `--n-trials 50` | 最適化試行回数50（コスパ最良） | ✅ 推奨 |
| `--verbose` | 詳細ログ出力 | ✅ 推奨 |
| `--use-smote` | SMOTE（2クラス専用・非推奨） | ❌ 使用しない |
| `--feature-engineering` | Feature Engineering（未実装） | ⏳ 将来実装 |

**補足**:
- 実データ学習: デフォルトで有効
- 定期再学習: 週次（日曜18:00 JST）自動実行
- 手動再学習タイミング: 新機能追加後・市況急変時

#### 🔍 **モデル学習完了後の確認**

```bash
# 1. モデルファイル保存確認
ls -lh models/production/production_ensemble.pkl
# 期待: 8.6M（8,607,520 bytes）

# 2. メタデータ確認
cat models/production/production_model_metadata.json | python3 -m json.tool
# 期待出力:
# {
#   "created_at": "2025-10-14T20:14:00.978257",
#   "model_type": "ProductionEnsemble",
#   "status": "production_ready",
#   "model_weights": {
#     "lightgbm": 0.4,
#     "xgboost": 0.4,
#     "random_forest": 0.2
#   }
# }

# 3. パフォーマンスメトリクス確認
cat models/production/production_model_metadata.json | jq '.performance_metrics'
# 期待: F1スコア 0.46-0.61 範囲（3クラス分類として良好）

# 4. 旧モデル自動バックアップ確認
ls -lt models/archive/ | head -3
# 期待: production_ensemble_YYYYMMDD_HHMMSS.pkl存在

# 5. Optuna最適化結果確認
cat models/optuna/phase39_5_results.json | python3 -m json.tool
# 期待: best_score 0.48-0.57 範囲
```

#### ✅ **期待される学習結果**（実測値）

```bash
# ログ出力例（標準コマンド実行時・約4分）:
# 🚀 ML実データ学習システム開始
# ✅ 実データ読み込み完了: 1,032サンプル (180日分)
# 📊 3クラス分布: SELL 15.4%, HOLD 65.9%, BUY 18.7%
# 📊 Train/Val/Test split: 722/155/155 (70%/15%/15%)
# 🔬 Optuna最適化開始（50試行・約3分）
#
# lightgbm:
#   Test F1: 0.466, CV F1: 0.427±0.074
#   Best params: learning_rate=0.170, max_depth=12, n_estimators=186
#
# xgboost:
#   Test F1: 0.611, CV F1: 0.525±0.081
#   Best params: learning_rate=0.016, max_depth=5, n_estimators=71
#
# random_forest:
#   Test F1: 0.614, CV F1: 0.522±0.076
#   Best params: n_estimators=279, max_depth=14, min_samples_split=3
#
# ✅ アンサンブルモデル保存完了: models/production/production_ensemble.pkl (8.6M)
# ✅ メタデータ保存: production_model_metadata.json
# 🎉 ML学習完了 - 実取引準備完了
#
# 実行時間: 約4分（50 trials）
# F1スコア: 0.56-0.59（55特徴量対応・3クラス分類として良好）
```

### Step 1.5: Meta-Learning学習実行（オプション・将来の改善）

#### 🎯 **Meta-Learning概要**

**目的**: 市場状況に応じてML/戦略重みを動的最適化（トレンド市場ではML重視・レンジ市場では戦略重視）

**機能概要**: ML/戦略重みの動的最適化システム

**機能**:
- 13特徴量入力（11市場特徴量 + 2パフォーマンス特徴量）
- LightGBM回帰モデルによる最適重み予測
- 動的重み調整（ml_weight・strategy_weight）

**現状**:
- ✅ システム実装完了
- ⏸️ デフォルト無効（enabled: false）
- 🔮 将来有効化時の期待効果: シャープレシオ+30-50%向上

#### ⚙️ **実行コマンド**（データ収集後）

```bash
# ========================================
# Meta-ML学習データ生成・モデル学習
# ========================================
PYTHONPATH=/Users/nao/Desktop/bot:$PYTHONPATH python3 scripts/ml/train_meta_learning_model.py

# 実行時間: 約10-20分（データ量による）
# 学習データ: 180日分15m足データ
# 入力特徴量: 13特徴量（11市場 + 2パフォーマンス）
# 出力: ml_weight, strategy_weight（合計1.0正規化）
# モデル: LightGBM回帰（n_estimators=100, learning_rate=0.05）

# ========================================
# DRY RUNモード（事前確認）
# ========================================
PYTHONPATH=/Users/nao/Desktop/bot:$PYTHONPATH python3 scripts/ml/train_meta_learning_model.py --dry-run

# モデル保存はスキップ・学習プロセスのみ確認
```

#### 🔍 **学習完了後の確認**

```bash
# 1. モデルファイル保存確認
ls -lh models/meta_learning/meta_model.pkl
# 期待: 数KB〜数MB（LightGBMモデル）

# 2. パフォーマンス履歴確認
ls -lh src/core/state/performance_history.json
# 期待: JSON形式のパフォーマンストラッキングデータ

# 3. 設定有効化（学習完了後）
# config/core/thresholds.yaml を編集:
# ml.meta_learning.enabled: false → true

# 4. 有効化後のシステム再起動
bash scripts/management/run_safe.sh local paper
```

#### ⚠️ **実行時の注意**

- 📊 **データ要件**: 過去180日分の15m足データ必要
- ⏰ **実行タイミング**: 十分なデータ収集後（本番運用後推奨）
- 🔄 **再学習頻度**: 月次または市況急変時
- 💾 **バックアップ**: 既存モデルは自動的にarchive/に保存
- 🧪 **検証推奨**: バックテストでパフォーマンス確認後に有効化

#### ✅ **期待される学習結果**

```bash
# ログ出力例:
# 📊 Meta-ML学習データ生成開始（過去180日間）
# 📈 価格データ取得: 17,271件
# 🔧 特徴量生成中...
# 🧠 ML予測生成中...
# 📊 戦略シグナル生成中...
# 🎯 最適重み計算中...
# 🎓 LightGBMモデル学習中...
# ✅ モデル保存完了: models/meta_learning/meta_model.pkl
# 📊 最適重み統計:
#    ML重み平均: 0.420 ± 0.180
#    戦略重み平均: 0.580 ± 0.180
# ✅ Meta-ML学習パイプライン完了
```

### Step 1.6: Optunaハイブリッド最適化実行（デプロイ前推奨・約8時間）

#### 🎯 **ハイブリッド最適化概要**

**目的**: 79パラメータ自動最適化（リスク管理・戦略・ML統合・MLハイパーパラメータ）

**3段階最適化プロセス**:
- **Stage 1**: シミュレーションベース最適化（750試行・高速・約11秒）
- **Stage 2**: 軽量バックテスト検証（上位50候補・30日・10%サンプリング・約37.5分）
- **Stage 3**: 完全バックテスト検証（上位10候補・180日・100%データ・約7.5時間）

**最適化パラメータ**:
- リスク管理パラメータ（12パラメータ）
- 戦略パラメータ（30パラメータ）
- ML統合パラメータ（7パラメータ）
- MLハイパーパラメータ（30パラメータ）
- 統合デプロイ（即座）

**期待効果**: +50-70%の収益向上・シャープレシオ最大化

**実行時間**:
- 🚀 **ハイブリッド最適化**: 約8時間（Stage 1 + Stage 2 + Stage 3）
- 📊 **従来型最適化**: 13-19時間（シミュレーションのみ）
- ⚡ **高速化**: 約40-60%短縮（3段階バックテスト検証実装）

**実行推奨タイミング**:
- ✅ **デプロイ前**: ML学習後・品質チェック前
- ✅ **定期再最適化**: 四半期（3ヶ月）ごと
- ✅ **市況急変時**: 取引パフォーマンス悪化時
- ✅ **大幅な戦略変更後**: 新戦略追加・既存戦略大幅変更時

**注意**:
- ⏰ 実行時間: 約8時間（夜間・週末推奨）
- 💾 自動バックアップ: thresholds.yaml自動バックアップ
- 🔄 中断・再開可能: チェックポイント機能利用
- 📋 詳細ドキュメント: `scripts/optimization/README.md`

#### ⚙️ **実行コマンド**（ハイブリッド最適化推奨）

```bash
# ========================================
# 🚀 ハイブリッド最適化（推奨・約8時間）
# ========================================
python3 scripts/optimization/run_phase40_optimization.py --all --use-hybrid-backtest

# 実行内容:
#   Stage 1: シミュレーション（750試行・11秒）
#   Stage 2: 軽量バックテスト（上位50候補・37.5分）
#   Stage 3: 完全バックテスト（上位10候補・7.5時間）
#   → 統合デプロイ
# 合計: 79パラメータ最適化・約8時間

# ========================================
# 📊 従来型最適化（シミュレーションのみ・13-19時間）
# ========================================
# python3 scripts/optimization/run_phase40_optimization.py --all
# 注: ハイブリッド最適化推奨（実バックテストによる精度向上）

# ========================================
# 対話式メニュー実行（段階的実行）
# ========================================
python3 scripts/optimization/run_phase40_optimization.py

# メニュー選択:
#   [1] 全Phase一括実行（ハイブリッド: --use-hybrid-backtest追加で約8時間）
#   [2-6] 個別Phase実行
#   [7] チェックポイントから再開
#   [0] 終了

# ========================================
# DRY RUNモード（事前確認）
# ========================================
python3 scripts/optimization/run_phase40_optimization.py --all --use-hybrid-backtest --dry-run

# 確認後、実際に適用:
python3 scripts/optimization/run_phase40_optimization.py --all --use-hybrid-backtest
```

#### 🔧 **ハイブリッド最適化パラメータ調整**（高度な使い方）

```bash
# デフォルト設定
python3 scripts/optimization/run_phase40_optimization.py --all --use-hybrid-backtest

# カスタム設定
python3 scripts/optimization/run_phase40_optimization.py --all --use-hybrid-backtest \
  --n-simulation-trials 1000 \      # Stage 1試行数（デフォルト: 750）
  --n-lightweight-candidates 75 \   # Stage 2候補数（デフォルト: 50）
  --n-full-candidates 15            # Stage 3候補数（デフォルト: 10）

# 実行時間調整:
#   - simulation-trials増: Stage 1時間増・精度向上（+10秒/250試行）
#   - lightweight-candidates増: Stage 2時間増・精度向上（+18.75分/25候補）
#   - full-candidates増: Stage 3時間増・精度向上（+3.75時間/5候補）
```

#### 🔍 **最適化完了後の確認**

```bash
# 1. 最適化結果ファイル確認
ls -lh config/optimization/results/
# 期待: phase40_*_hybrid.json（4ファイル）

# 2. thresholds.yaml更新確認
git diff config/core/thresholds.yaml
# 期待: 79パラメータの変更

# 3. バックアップ確認
ls -lt config/core/backups/ | head -1
# 期待: thresholds_backup_YYYYMMDD_HHMMSS.yaml存在

# 4. 最終シャープレシオ確認
cat config/optimization/results/phase40_*_hybrid.json | jq '.best_value'
# 期待: 0.8以上（シャープレシオ）

# 5. チェックポイントファイル確認（中断時のみ）
ls -lh config/optimization/checkpoints/
# 期待: phase40_*_stage*.json（中断時のみ存在）
```

#### ✅ **期待される最適化結果**（実測値）

```bash
# ログ出力例（ハイブリッド最適化実行時・約8時間）:
# 🎯 リスク管理パラメータ ハイブリッド最適化開始
#
# 📊 Stage 1: シミュレーションベース最適化
# [I 2025-10-18 12:00:15,123] Trial 750 finished with value: 0.95 and parameters: {...}
# ✅ Stage 1完了: 750試行・11秒・最高スコア=0.95
#
# 🔬 Stage 2: 軽量バックテスト検証（上位50候補）
# 🔬 軽量バックテスト 1/50 (シミュレーションスコア: 0.9500)
#   シャープレシオ: 0.8234
# ...
# ✅ Stage 2完了: 50候補検証・37.5分・最高シャープレシオ=0.8234
#
# 🏆 Stage 3: 完全バックテスト検証（上位10候補）
# 🏆 完全バックテスト 1/10 (Stage2シャープレシオ: 0.8234)
#   最終シャープレシオ: 0.8567
# ...
# ✅ Stage 3完了: 10候補検証・7.5時間・最終シャープレシオ=0.8567
#
# 🎉 リスク管理パラメータ ハイブリッド最適化完了
# ⏱️  総実行時間: 8.12時間
# 📊 最終シャープレシオ: 0.8567
#
# 合計実行時間: 約8時間（79パラメータ統合最適化）
# 精度: シミュレーション → 実バックテスト検証の段階的絞り込み
```

#### ⚠️ **実行時の注意**

- ⏰ **実行時間**: 約8時間（夜間・週末推奨）
- 💾 **自動バックアップ**: thresholds.yaml自動バックアップ
- 🔄 **中断・再開可能**: チェックポイント機能利用（config/optimization/checkpoints/）
- 📋 **詳細ドキュメント**: `scripts/optimization/README.md`参照
- 🚀 **ハイブリッド推奨**: `--use-hybrid-backtest`フラグで実バックテスト精度向上

---

### Step 2: 品質チェック実行（必須・約80秒）

**注**: Step 1.5のOptuna最適化は任意実行（デプロイ前推奨）。品質チェックは必須実行。

```bash
# 統一品質チェック実行
bash scripts/testing/checks.sh

# 期待結果:
# ✅ 1,117テスト100%成功
# ✅ 68.32%カバレッジ達成
# ✅ flake8・black・isort通過
# ✅ MLモデル整合性確認
```

**役割**: ML学習・パラメータ最適化後のシステム全体の健全性確認

---

### Step 3: ペーパーテスト実行（安全性確認・5-10分）

```bash
# ペーパートレード起動
bash scripts/management/run_safe.sh local paper

# 確認項目（5-10分実行）:
# ✅ 55特徴量生成成功（50基本+5戦略信号）
# ✅ 5戦略統合動作
# ✅ ML予測機能
# ✅ リスク管理システム
# ✅ Discord通知機能

# 停止
bash scripts/management/run_safe.sh stop
```

**役割**: 本番デプロイ前の実動作確認・各コンポーネント正常性確認

---

### Step 4: バックテスト実行（戦略検証・45分）

#### 📊 **Step 4.1: データ存在確認（必須）**

```bash
# 180日分のデータ存在確認
ls -lh src/backtest/data/historical/btc_jpy_4h.csv
ls -lh src/backtest/data/historical/btc_jpy_15m.csv

# データ件数確認（期待値）
# 4h足: 約1,080件（180日 × 6件/日）
# 15m足: 約17,271件（180日 × 96件/日）

wc -l src/backtest/data/historical/btc_jpy_4h.csv
wc -l src/backtest/data/historical/btc_jpy_15m.csv

# 期待出力例:
#     1081 src/backtest/data/historical/btc_jpy_4h.csv   (ヘッダー含む)
#    17272 src/backtest/data/historical/btc_jpy_15m.csv  (ヘッダー含む)
```

**役割**: バックテスト実行前のデータ確認・不足時のエラー防止

#### 📥 **Step 4.2: データ収集（データが不足している場合）**

```bash
# 過去180日データ収集
python src/backtest/scripts/collect_historical_csv.py --days 180

# 実行時間: 約5-10分（API制限による）
# 期待結果:
# ✅ 4時間足: 1,080件
# ✅ 15分足: 17,271件
# ✅ CSV保存: src/backtest/data/historical/

# データ収集完了後、再度確認
wc -l src/backtest/data/historical/btc_jpy_*.csv
```

**注意**: データ収集はBitbank Public APIを使用するため、API制限（35秒間隔）により時間がかかります

#### 🚀 **Step 4.3: バックテスト実行**

```bash
# バックテスト実行
bash scripts/management/run_backtest.sh

# 確認項目:
# ✅ 過去180日データで戦略パフォーマンス検証
# ✅ リスク・リターン分析
# ✅ ドローダウン評価（20%以内）
# ✅ 取引頻度・勝率確認

# 結果確認
ls -t logs/backtest_reports/ | head -1 | xargs cat
```

**役割**: 最適化後のパラメータが過去データで期待通りの性能を出すか検証

---

### Step 5: 最終品質確認（デプロイ直前・約80秒）

```bash
# デプロイ前最終確認
bash scripts/testing/checks.sh

# 期待結果:
# ✅ 1,117テスト100%維持
# ✅ 68.32%カバレッジ維持
# ✅ MLモデル準備完了
```

**役割**: デプロイ直前の最終チェック・全システムの健全性確認

---

### Step 6: コミット・プッシュ・デプロイ実行

```bash
# 変更内容確認・コミット
git add -A
git commit -m "feat: ML学習・パラメータ最適化・品質保証完了

🤖 Generated with [Claude Code](https://claude.ai/code)
Co-Authored-By: Claude <noreply@anthropic.com>"

# GitHub プッシュ（CI/CD自動実行）
git push origin main

# デプロイ状況確認
gh run list --limit 5
gh run view --log

# 期待結果:
# ✅ CI/CDパイプライン成功
# ✅ 1,117テスト自動実行通過
# ✅ Cloud Run自動デプロイ成功
```

**役割**: GitHub CI/CD経由で本番環境へ自動デプロイ・品質ゲート適用

---

# 第2部: ペーパーテスト詳細手順

## ペーパートレード完全検証フロー

**目的**: 本番デプロイ前の実動作確認・各コンポーネント正常性検証

```bash
# 1. 品質事前確認
bash scripts/testing/checks.sh

# 2. ペーパートレード起動
bash scripts/management/run_safe.sh local paper

# 3. 検証項目チェック（5-10分実行）
# ✅ MLモデル初期化: ProductionEnsemble読み込み成功（55特徴量対応）
# ✅ 55特徴量生成: 基本50（ATR・EMA・RSI・MACD・BB・Donchian・ADX・ラグ・移動統計・交互作用・時間等） + 戦略信号5
# ✅ 5戦略実行: ATR・MochiPoy・MultiTimeframe・Donchian・ADX統合判定
# ✅ ML予測: アンサンブル予測実行（信頼度45%閾値・60%高信頼度）
# ✅ リスク管理: Kelly基準・ドローダウン制限・ポジションサイジング
# ✅ 取引機能: BUY/SELL/HOLD判定・TP/SL自動配置・トレーリングストップ
# ✅ Discord通知: 3階層通知（Critical/Warning/Info）
# ✅ 統一設定: unified.yaml・thresholds.yaml設定適用

# 4. ログ確認（期待出力）
# [INFO] 🤖 MLモデル初期化成功: ProductionEnsemble (8.6M・55特徴量対応)
# [INFO] 📊 55特徴量完全生成成功
# [INFO] 🎯 5戦略統合判定: 信頼度XX%・シグナル=HOLD/BUY/SELL
# [INFO] 💰 ペーパーモード残高: 10,000円 → XX,XXX円

# 5. 停止
bash scripts/management/run_safe.sh stop
```

---

# 第3部: バックテスト詳細手順

## バックテスト実行

**目的**: 最適化後のパラメータが過去データで期待通りの性能を出すか検証

**システム概要**:
- ライブモード完全一致（実戦略シグナル実行・TP/SL決済ロジック実装）
- TradeTracker損益計算（エントリー/エグジットペアリング）
- matplotlib可視化（エクイティカーブ・損益分布・ドローダウン・価格チャート）
- 信頼性100%達成（バックテスト完全改修完了）

### 標準実行フロー（推奨）

#### 📊 **Step 1: データ存在確認（必須）**

```bash
# 180日分のデータ存在確認
ls -lh src/backtest/data/historical/btc_jpy_4h.csv
ls -lh src/backtest/data/historical/btc_jpy_15m.csv

# データ件数確認
wc -l src/backtest/data/historical/btc_jpy_4h.csv
wc -l src/backtest/data/historical/btc_jpy_15m.csv

# 期待出力:
#     1081 src/backtest/data/historical/btc_jpy_4h.csv   (ヘッダー含む・約1,080件)
#    17272 src/backtest/data/historical/btc_jpy_15m.csv  (ヘッダー含む・約17,271件)
```

**データが存在しない、または不足している場合**: Step 2でデータ収集を実施

#### 📥 **Step 2: データ収集（初回のみ・データ不足時）**

```bash
# 過去180日データ収集
python src/backtest/scripts/collect_historical_csv.py --days 180

# 実行時間: 約5-10分（API制限による）
# 期待結果:
# ✅ 4時間足: 1,080件（180日 × 6件/日）
# ✅ 15分足: 17,271件（180日 × 96件/日）
# ✅ CSV保存: src/backtest/data/historical/

# データ収集完了後、再度確認
wc -l src/backtest/data/historical/btc_jpy_*.csv
```

**注意**: Bitbank Public API使用・API制限（35秒間隔）により時間がかかる

#### 🚀 **Step 3: バックテスト実行**

```bash
# バックテスト実行（本番と完全同一ロジック）
python main.py --mode backtest

# 実行内容:
# ✅ 戦略シグナル事前計算（look-ahead bias防止）
# ✅ TP/SLトリガー・決済ロジック実行
# ✅ エントリー/エグジットペアリング・損益計算
# ✅ matplotlib可視化（4種類グラフ生成）

# 結果確認
ls -t src/backtest/logs/backtest_*.txt | head -1 | xargs cat
ls -t src/backtest/logs/graphs_* | head -1
```

### 実行確認項目（Step 3バックテスト実行時）

```bash
# データ確認完了後、バックテスト実行
python main.py --mode backtest

# 確認項目:
# ✅ 過去データ読み込み: 1,080件（4h）、17,271件（15m）
# ✅ 戦略シグナル事前計算: look-ahead bias防止実装
# ✅ TP/SLトリガー: ロング/ショート別判定・決済注文シミュレーション
# ✅ TradeTracker: エントリー/エグジットペアリング・損益計算
# ✅ matplotlib可視化: 4種類グラフ生成（equity_curve.png等）
# ✅ パフォーマンス指標: 勝率・プロフィットファクター・最大ドローダウン

# 結果確認（実行後）
# テキストレポート
ls -t src/backtest/logs/backtest_*.txt | head -1 | xargs cat

# グラフ確認
open $(ls -t src/backtest/logs/graphs_*/equity_curve.png | head -1)

# 評価基準:
# ✅ 実行時間: 45分以内
# ✅ 年間収益率: 10%以上（目標）
# ✅ 最大ドローダウン: 20%以内
# ✅ 勝率: 55%以上（期待）
# ✅ 取引回数: 月100-200回
# ✅ BUY/SELL判定正常化（SELL注文生成確認）
```

### データ不足時のエラー例

```bash
# データが不足している場合のエラー出力例:
# FileNotFoundError: [Errno 2] No such file or directory: 'src/backtest/data/historical/btc_jpy_4h.csv'

# 対処方法: Step 2でデータ収集を実施
python src/backtest/scripts/collect_historical_csv.py --days 180
```

---

# 第4部: 環境構築・初期セットアップ

## システム要件

- **Python**: 3.13
- **Node.js**: 18+（GitHub CLI用）
- **Docker**: 20.10+
- **Git**: 2.30+

## 権限要件

- **GCP**: Editor/Owner権限
- **GitHub**: Admin権限
- **Bitbank API**: 信用取引対応APIキー
- **Discord**: Webhook URL設定権限

## 初回セットアップ

```bash
# リポジトリクローン
git clone <repository-url>
cd crypto-bot

# 依存関係インストール
pip install -r requirements.txt

# 環境確認
python3 --version  # 3.13.x
gcloud --version
docker --version
gh --version
```

## GCP環境構築

```bash
# 自動環境構築（推奨）
bash scripts/deployment/setup_gcp_environment.sh --full

# 設定内容:
# - GCP Project ID設定
# - API有効化（Cloud Run・Artifact Registry・Secret Manager）
# - サービスアカウント作成・権限付与
# - Workload Identity設定（GitHub Actions用）
# - Secret Manager設定（Bitbank API・Discord Webhook）

# 環境検証
bash scripts/deployment/verify_gcp_setup.sh --full
```

---

# 第5部: ローカル開発環境

## 実行クイックリファレンス

### ペーパートレード実行

```bash
# 起動
bash scripts/management/run_safe.sh local paper

# 状況確認
bash scripts/management/run_safe.sh status

# 停止
bash scripts/management/run_safe.sh stop

# 強制停止（Discord通知が止まらない場合）
bash scripts/management/bot_manager.sh stop
```

### バックテスト実行

```bash
# 起動
bash scripts/management/run_safe.sh local backtest

# 結果確認
ls -t logs/backtest_reports/ | head -1 | xargs cat
```

### 品質チェック

```bash
# 統一品質チェック（約80秒）
bash scripts/testing/checks.sh

# 期待: 1,117テスト100%・68.32%カバレッジ
```

## モード別実行

```bash
# ペーパーモード（推奨）
bash scripts/management/run_safe.sh local paper

# ライブモード（本番取引）
bash scripts/management/run_safe.sh local live

# バックテストモード
bash scripts/management/run_safe.sh local backtest
```

## 初期残高設定変更

`config/core/unified.yaml`の`mode_balances`セクションを編集

```yaml
mode_balances:
  paper:
    initial_balance: 100000.0    # 10,000 → 100,000
  live:
    initial_balance: 100000.0
  backtest:
    initial_balance: 100000.0
```

**変更後**:
1. 品質チェック実行: `bash scripts/testing/checks.sh`
2. ペーパーテストで動作確認
3. 停止

## 戦略パラメータ変更

`config/core/thresholds.yaml`の`dynamic_confidence.strategies.*`セクションを編集

**注意事項**:
- 元値の±20%程度の変更に留める
- 品質チェック必須
- ペーパーテストで確認後、本番適用

---

# 第6部: デプロイメント

## CI/CDパイプライン

```bash
# ローカル品質チェック
bash scripts/testing/checks.sh

# コード変更プッシュ（CI/CD自動実行）
git add -A
git commit -m "feat: ML学習・パラメータ最適化完了"
git push origin main

# デプロイ状況確認
gh run list --limit 5
gh run view --log
```

## デプロイモード制御

```bash
# ペーパーモード（推奨）
gh secret set DEPLOY_MODE --body "paper"

# 本番モード
gh secret set DEPLOY_MODE --body "live"
```

---

# 第7部: 日常運用・監視

## 日常確認（毎日推奨）

```bash
# 品質チェック
bash scripts/testing/checks.sh

# 本番環境確認
gcloud run services describe crypto-bot-service-prod --region=asia-northeast1

# 最新ログ確認
gcloud logging read "resource.type=cloud_run_revision" --limit=10

# エラーログ確認
gcloud logging read 'resource.type="cloud_run_revision" AND severity>=WARNING' --limit=10
```

## Discord監視

- **Critical**: システム停止・緊急対応必要
- **Warning**: 残高不足・API異常等
- **Info**: 通常取引・システム状態

---

# 第8部: 緊急時対応

## Critical対応（5分以内）

**症状**: システム完全停止・データ損失

```bash
# ロールバック
gh workflow run ci.yml --ref <安定版コミット>
gcloud run services update-traffic crypto-bot-service-prod \
  --to-revisions=<安定リビジョン>=100 \
  --region=asia-northeast1

# 緊急停止（最終手段）
gcloud run services update crypto-bot-service-prod \
  --min-instances=0 \
  --region=asia-northeast1
```

## 主なトラブルシューティング

### Discord通知が止まらない

```bash
# 強制停止
bash scripts/management/bot_manager.sh stop

# 停止確認
bash scripts/management/run_safe.sh status
```

### プロセス重複エラー

```bash
# 完全停止後、再実行
bash scripts/management/bot_manager.sh stop
bash scripts/management/run_safe.sh local paper
```

### ドローダウン状態リセット

```bash
# 状態ファイル削除
rm -f src/core/state/drawdown_state.json

# 再起動
bash scripts/management/run_safe.sh local paper
```

## 診断コマンド

```bash
# 品質診断
bash scripts/testing/checks.sh

# 環境診断
bash scripts/deployment/verify_gcp_setup.sh --full

# プロセス診断
bash scripts/management/run_safe.sh status
```

---

# 付録: 主要スクリプトリファレンス

## スクリプト一覧

```
scripts/
├── management/
│   ├── run_safe.sh           # 安全実行（プロセス管理）
│   ├── bot_manager.sh        # 強制停止（Discord問題解決）
│   └── run_backtest.sh       # バックテスト実行
├── ml/
│   └── create_ml_models.py   # ML学習
├── optimization/
│   └── run_phase40_optimization.py  # パラメータ最適化
├── testing/
│   └── checks.sh             # 品質チェック
└── deployment/
    ├── setup_gcp_environment.sh     # GCP環境構築
    └── verify_gcp_setup.sh          # GCP環境検証
```

## 主要コマンド

### プロセス管理

```bash
# 起動
bash scripts/management/run_safe.sh local paper

# 停止
bash scripts/management/run_safe.sh stop

# 強制停止（Discord通知問題対応）
bash scripts/management/bot_manager.sh stop
```

### 品質チェック

```bash
# 統一品質チェック（1,117テスト・68.32%カバレッジ）
bash scripts/testing/checks.sh
```

### ML学習・最適化

```bash
# ML学習（約4分・50 trials）
python3 scripts/ml/create_ml_models.py --n-classes 3 --threshold 0.005 --optimize --n-trials 50 --verbose

# パラメータ最適化（約8時間・79パラメータ・ハイブリッド最適化推奨）
python3 scripts/optimization/run_phase40_optimization.py --all --use-hybrid-backtest
```

### バックテスト実行

```bash
# バックテスト実行（本番と完全同一ロジック）
python main.py --mode backtest

# 実行内容:
# - 戦略シグナル事前計算（look-ahead bias防止）
# - TP/SLトリガー・決済ロジック実行
# - エントリー/エグジットペアリング・損益計算
# - matplotlib可視化（4種類グラフ生成）
```

---

**📅 最終更新**: 2025年10月25日 - デプロイ・検証・運用ガイド（実装履歴は開発履歴ドキュメント参照）
