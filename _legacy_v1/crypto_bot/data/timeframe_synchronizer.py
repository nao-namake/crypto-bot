# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«å: crypto_bot/data/timeframe_synchronizer.py
# èª¬æ˜:
# ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿åŒæœŸãƒ»çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
# ãƒ»æ™‚åˆ»ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»æ¬ æãƒ‡ãƒ¼ã‚¿è£œå®Œãƒ»æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
# ãƒ»ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸãƒ»ã‚¯ãƒ­ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œè¨¼
# ãƒ»Phase 2.2: ãƒ‡ãƒ¼ã‚¿åŒæœŸãƒ»çµ±åˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…
# =============================================================================

import logging
from datetime import datetime, timedelta
from typing import Dict, List

import numpy as np
import pandas as pd
from scipy import stats

logger = logging.getLogger(__name__)


class TimeframeSynchronizer:
    """ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿åŒæœŸãƒ»çµ±åˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self,
        timeframes: List[str] = None,
        base_timeframe: str = "1h",
        sync_tolerance: timedelta = None,
        missing_data_threshold: float = 0.1,
        consistency_check_enabled: bool = True,
    ):
        """
        åˆæœŸåŒ–

        Args:
            timeframes: å¯¾è±¡ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ 
            base_timeframe: ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ 
            sync_tolerance: åŒæœŸè¨±å®¹èª¤å·®
            missing_data_threshold: æ¬ æãƒ‡ãƒ¼ã‚¿è¨±å®¹ç‡
            consistency_check_enabled: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯æœ‰åŠ¹åŒ–
        """
        self.timeframes = timeframes or ["15m", "1h", "4h"]
        self.base_timeframe = base_timeframe
        self.sync_tolerance = sync_tolerance or timedelta(minutes=1)
        self.missing_data_threshold = missing_data_threshold
        self.consistency_check_enabled = consistency_check_enabled

        # åŒæœŸçµ±è¨ˆ
        self.sync_stats = {
            "sync_operations": 0,
            "alignment_corrections": 0,
            "missing_data_filled": 0,
            "consistency_violations": 0,
            "quality_improvements": 0,
        }

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æœŸé–“ãƒãƒƒãƒ”ãƒ³ã‚°
        self.timeframe_periods = {
            "1m": timedelta(minutes=1),
            "5m": timedelta(minutes=5),
            "15m": timedelta(minutes=15),
            "30m": timedelta(minutes=30),
            "1h": timedelta(hours=1),
            "2h": timedelta(hours=2),
            "4h": timedelta(hours=4),
            "8h": timedelta(hours=8),
            "12h": timedelta(hours=12),
            "1d": timedelta(days=1),
        }

        logger.info("ğŸ”„ TimeframeSynchronizer initialized")
        logger.info(f"  - Timeframes: {self.timeframes}")
        logger.info(f"  - Base timeframe: {self.base_timeframe}")
        logger.info(f"  - Sync tolerance: {self.sync_tolerance}")

    def synchronize_multi_timeframe_data(
        self, multi_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """
        ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®åŒæœŸãƒ»çµ±åˆ

        Args:
            multi_data: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿è¾æ›¸

        Returns:
            Dict[str, pd.DataFrame]: åŒæœŸæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info("ğŸ”„ Starting multi-timeframe synchronization")
            self.sync_stats["sync_operations"] += 1

            if not multi_data:
                logger.warning("âš ï¸ No data to synchronize")
                return {}

            # 1. æ™‚åˆ»ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ
            aligned_data = self._align_timeframes(multi_data)

            # 2. æ¬ æãƒ‡ãƒ¼ã‚¿è£œå®Œ
            filled_data = self._fill_missing_data(aligned_data)

            # 3. æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£
            if self.consistency_check_enabled:
                consistent_data = self._ensure_consistency(filled_data)
            else:
                consistent_data = filled_data

            # 4. å“è³ªå‘ä¸Š
            improved_data = self._improve_data_quality(consistent_data)

            logger.info("âœ… Multi-timeframe synchronization complete")
            logger.info(f"  - Processed {len(improved_data)} timeframes")

            return improved_data

        except Exception as e:
            logger.error(f"âŒ Multi-timeframe synchronization failed: {e}")
            return multi_data

    def _align_timeframes(
        self, multi_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚åˆ»ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ"""
        try:
            logger.debug("ğŸ”„ Aligning timeframes")
            aligned_data = {}

            # ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ™‚åˆ»ç¯„å›²ã‚’å–å¾—
            base_data = multi_data.get(self.base_timeframe)
            if base_data is None or base_data.empty:
                logger.warning(f"âš ï¸ Base timeframe {self.base_timeframe} not available")
                return multi_data

            base_start = base_data.index.min()
            base_end = base_data.index.max()

            for timeframe, data in multi_data.items():
                if data.empty:
                    aligned_data[timeframe] = data
                    continue

                try:
                    # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æœŸé–“ã‚’å–å¾—
                    period = self.timeframe_periods.get(timeframe)
                    if period is None:
                        logger.warning(f"âš ï¸ Unknown timeframe period: {timeframe}")
                        aligned_data[timeframe] = data
                        continue

                    # æ¨™æº–çš„ãªæ™‚åˆ»ã‚°ãƒªãƒƒãƒ‰ã‚’ç”Ÿæˆ
                    aligned_index = self._generate_aligned_index(
                        base_start, base_end, period, timeframe
                    )

                    # ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–ã‚°ãƒªãƒƒãƒ‰ã«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ
                    aligned_data[timeframe] = self._align_to_index(
                        data, aligned_index, timeframe
                    )

                    logger.debug(
                        f"âœ… Aligned {timeframe}: {len(data)} -> {len(aligned_data[timeframe])} records"
                    )

                except Exception as e:
                    logger.error(f"âŒ Failed to align {timeframe}: {e}")
                    aligned_data[timeframe] = data

            self.sync_stats["alignment_corrections"] += len(multi_data)
            return aligned_data

        except Exception as e:
            logger.error(f"âŒ Timeframe alignment failed: {e}")
            return multi_data

    def _generate_aligned_index(
        self,
        start_time: datetime,
        end_time: datetime,
        period: timedelta,
        timeframe: str,
    ) -> pd.DatetimeIndex:
        """æ¨™æº–æ™‚åˆ»ã‚°ãƒªãƒƒãƒ‰ç”Ÿæˆ"""
        try:
            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¿œã˜ãŸé–‹å§‹æ™‚åˆ»èª¿æ•´
            if timeframe in ["4h", "8h", "12h"]:
                # 4æ™‚é–“ãƒ»8æ™‚é–“ãƒ»12æ™‚é–“è¶³ã¯00:00UTCã‹ã‚‰é–‹å§‹
                # âœ… Phase H.14ä¿®æ­£: period.total_seconds()ã‚’int()ã§æ˜ç¤ºçš„å‹å¤‰æ›
                hours_per_period = int(period.total_seconds() // 3600)
                aligned_hour = (start_time.hour // hours_per_period) * hours_per_period
                aligned_start = start_time.replace(
                    hour=aligned_hour,
                    minute=0,
                    second=0,
                    microsecond=0,
                )
            elif timeframe in ["1d"]:
                # æ—¥è¶³ã¯00:00UTCã‹ã‚‰é–‹å§‹
                aligned_start = start_time.replace(
                    hour=0, minute=0, second=0, microsecond=0
                )
            else:
                # åˆ†è¶³ãƒ»æ™‚é–“è¶³ã¯é©åˆ‡ãªå¢ƒç•Œã«èª¿æ•´
                if period.total_seconds() >= 3600:  # 1æ™‚é–“ä»¥ä¸Š
                    aligned_start = start_time.replace(
                        minute=0, second=0, microsecond=0
                    )
                else:  # 1æ™‚é–“æœªæº€
                    minute_period = int(period.total_seconds() // 60)
                    aligned_minute = (
                        start_time.minute // minute_period
                    ) * minute_period
                    aligned_start = start_time.replace(
                        minute=aligned_minute, second=0, microsecond=0
                    )

            # æ¨™æº–ã‚°ãƒªãƒƒãƒ‰ç”Ÿæˆ
            freq_str = self._period_to_freq_string(period, timeframe)
            return pd.date_range(start=aligned_start, end=end_time, freq=freq_str)

        except Exception as e:
            logger.error(f"âŒ Failed to generate aligned index: {e}")
            return pd.date_range(start=start_time, end=end_time, freq="1h")

    def _period_to_freq_string(self, period: timedelta, timeframe: str) -> str:
        """timedelta ã‚’ pandas frequency string ã«å¤‰æ›"""
        total_seconds = period.total_seconds()

        if total_seconds < 3600:  # 1æ™‚é–“æœªæº€
            minutes = int(total_seconds // 60)
            return f"{minutes}T"
        elif total_seconds < 86400:  # 1æ—¥æœªæº€
            hours = int(total_seconds // 3600)
            return f"{hours}h"
        else:  # 1æ—¥ä»¥ä¸Š
            days = int(total_seconds // 86400)
            return f"{days}D"

    def _align_to_index(
        self, data: pd.DataFrame, target_index: pd.DatetimeIndex, timeframe: str
    ) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ"""
        try:
            # æœ€è¿‘å‚æ™‚åˆ»ãƒãƒƒãƒ”ãƒ³ã‚°
            aligned_data = pd.DataFrame(index=target_index, columns=data.columns)

            for target_time in target_index:
                # è¨±å®¹èª¤å·®å†…ã®æœ€è¿‘å‚ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
                time_diff = np.abs(data.index - target_time)
                # âœ… Phase H.14ä¿®æ­£: TimedeltaIndexã‚¨ãƒ©ãƒ¼å®Œå…¨è§£æ±ºãƒ»argmin()ã§intå–å¾—ãƒ»ç›´æ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨
                min_diff_argmin = time_diff.argmin()
                min_diff_idx = data.index[min_diff_argmin]
                min_diff = time_diff[
                    min_diff_argmin
                ]  # TimedeltaIndexã¯ç›´æ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¢ã‚¯ã‚»ã‚¹

                if min_diff <= self.sync_tolerance:
                    aligned_data.loc[target_time] = data.loc[min_diff_idx]

            # æ¬ æãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¯
            missing_count = aligned_data.isnull().all(axis=1).sum()
            if missing_count > 0:
                logger.debug(
                    f"ğŸ“Š {timeframe}: {missing_count} missing records after alignment"
                )

            return aligned_data

        except Exception as e:
            logger.error(f"âŒ Failed to align data to index: {e}")
            return data

    def _fill_missing_data(
        self, multi_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """æ¬ æãƒ‡ãƒ¼ã‚¿è£œå®Œ"""
        try:
            logger.debug("ğŸ”„ Filling missing data")
            filled_data = {}

            for timeframe, data in multi_data.items():
                if data.empty:
                    filled_data[timeframe] = data
                    continue

                try:
                    # æ¬ æç‡ãƒã‚§ãƒƒã‚¯
                    missing_ratio = data.isnull().all(axis=1).mean()
                    if missing_ratio > self.missing_data_threshold:
                        logger.warning(
                            f"âš ï¸ {timeframe}: High missing ratio " f"{missing_ratio:.2f}"
                        )

                    # æ¬ æãƒ‡ãƒ¼ã‚¿è£œå®Œ
                    filled = self._intelligent_fill_missing(data, timeframe)
                    filled_data[timeframe] = filled

                    fill_count = data.isnull().sum().sum() - filled.isnull().sum().sum()
                    if fill_count > 0:
                        logger.debug(
                            f"âœ… {timeframe}: Filled {fill_count} missing values"
                        )
                        self.sync_stats["missing_data_filled"] += fill_count

                except Exception as e:
                    logger.error(f"âŒ Failed to fill missing data for {timeframe}: {e}")
                    filled_data[timeframe] = data

            return filled_data

        except Exception as e:
            logger.error(f"âŒ Missing data filling failed: {e}")
            return multi_data

    def _intelligent_fill_missing(
        self, data: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """é«˜åº¦ãªæ¬ æãƒ‡ãƒ¼ã‚¿è£œå®Œ"""
        try:
            filled = data.copy()

            # OHLCVã®å„åˆ—ã«å¯¾ã—ã¦é©åˆ‡ãªè£œå®Œã‚’å®Ÿè¡Œ
            for col in data.columns:
                if col in ["open", "high", "low", "close"]:
                    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿: æ™‚é–“åŠ é‡è£œé–“
                    filled[col] = self._time_weighted_interpolation(data[col])
                elif col == "volume":
                    # ãƒœãƒªãƒ¥ãƒ¼ãƒ : ã‚¼ãƒ­åŸ‹ã‚å¾Œã«ç§»å‹•å¹³å‡è£œé–“
                    filled[col] = self._volume_interpolation(data[col])
                else:
                    # ãã®ä»–: ç·šå½¢è£œé–“
                    filled[col] = data[col].interpolate(method="linear")

            # OHLCæ•´åˆæ€§ã®ç¢ºä¿
            if all(col in filled.columns for col in ["open", "high", "low", "close"]):
                filled = self._ensure_ohlc_consistency(filled)

            return filled

        except Exception as e:
            logger.error(f"âŒ Intelligent fill failed: {e}")
            return data

    def _time_weighted_interpolation(self, series: pd.Series) -> pd.Series:
        """æ™‚é–“åŠ é‡è£œé–“"""
        try:
            # åŸºæœ¬ç·šå½¢è£œé–“
            interpolated = series.interpolate(method="linear")

            # é•·æœŸé–“ã®æ¬ æã«å¯¾ã—ã¦ã¯ãƒˆãƒ¬ãƒ³ãƒ‰è€ƒæ…®è£œé–“
            missing_mask = series.isnull()
            if missing_mask.any():
                # å‰å¾Œã®æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ³ãƒ‰è£œé–“
                interpolated = series.interpolate(method="cubic")

            return interpolated

        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç·šå½¢è£œé–“
            return series.interpolate(method="linear")

    def _volume_interpolation(self, volume_series: pd.Series) -> pd.Series:
        """ãƒœãƒªãƒ¥ãƒ¼ãƒ è£œé–“"""
        try:
            filled = volume_series.copy()

            # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ã‚¼ãƒ­å€¤ã‚’ä¸€æ™‚çš„ã«æ¬ æã¨ã—ã¦æ‰±ã†
            zero_mask = filled == 0
            filled[zero_mask] = np.nan

            # ç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ã®è£œé–“
            ma_7 = filled.rolling(window=7, min_periods=3).mean()
            ma_24 = filled.rolling(window=24, min_periods=12).mean()

            # æ¬ æç®‡æ‰€ã‚’ç§»å‹•å¹³å‡ã§åŸ‹ã‚ã‚‹
            filled = filled.fillna(ma_7).fillna(ma_24)

            # å…ƒã®ã‚¼ãƒ­å€¤ã¯ä¿æŒ
            filled[zero_mask] = 0

            # è² å€¤ã®é™¤å»
            filled = np.maximum(filled, 0)

            return filled

        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç·šå½¢è£œé–“
            return volume_series.interpolate(method="linear").fillna(0)

    def _ensure_consistency(
        self, multi_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """ã‚¯ãƒ­ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ•´åˆæ€§ç¢ºä¿"""
        try:
            logger.debug("ğŸ”„ Ensuring cross-timeframe consistency")
            consistent_data = multi_data.copy()

            # ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŸºæº–ã¨ã—ãŸæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            base_data = consistent_data.get(self.base_timeframe)
            if base_data is None or base_data.empty:
                return consistent_data

            for timeframe, data in consistent_data.items():
                if timeframe == self.base_timeframe or data.empty:
                    continue

                try:
                    # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£
                    corrected = self._cross_timeframe_validation(
                        data, base_data, timeframe
                    )
                    consistent_data[timeframe] = corrected

                except Exception as e:
                    logger.error(f"âŒ Consistency check failed for {timeframe}: {e}")

            return consistent_data

        except Exception as e:
            logger.error(f"âŒ Consistency ensuring failed: {e}")
            return multi_data

    def _cross_timeframe_validation(
        self, data: pd.DataFrame, base_data: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """ã‚¯ãƒ­ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œè¨¼ãƒ»ä¿®æ­£"""
        try:
            corrected = data.copy()
            period = self.timeframe_periods.get(timeframe)

            if period is None or "close" not in data.columns:
                return corrected

            # ä¾¡æ ¼ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            violations = 0
            for timestamp, row in data.iterrows():
                if pd.isnull(row["close"]):
                    continue

                # å¯¾å¿œã™ã‚‹ãƒ™ãƒ¼ã‚¹æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                base_period_data = self._get_base_period_data(
                    base_data, timestamp, period
                )

                if base_period_data.empty:
                    continue

                # ä¾¡æ ¼ç¯„å›²ãƒã‚§ãƒƒã‚¯
                base_min = base_period_data["low"].min()
                base_max = base_period_data["high"].max()

                # ç•°å¸¸å€¤æ¤œå‡ºãƒ»ä¿®æ­£
                if row["close"] < base_min * 0.95 or row["close"] > base_max * 1.05:
                    # 5%ã‚’è¶…ãˆã‚‹ä¹–é›¢ã¯ç•°å¸¸å€¤ã¨ã—ã¦ä¿®æ­£
                    corrected.loc[timestamp, "close"] = base_period_data["close"].iloc[
                        -1
                    ]
                    violations += 1

            if violations > 0:
                logger.debug(
                    f"ğŸ”§ {timeframe}: Corrected {violations} consistency violations"
                )
                self.sync_stats["consistency_violations"] += violations

            return corrected

        except Exception as e:
            logger.error(f"âŒ Cross-timeframe validation failed: {e}")
            return data

    def _get_base_period_data(
        self, base_data: pd.DataFrame, timestamp: datetime, period: timedelta
    ) -> pd.DataFrame:
        """æŒ‡å®šæœŸé–“ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            start_time = timestamp - period
            end_time = timestamp

            return base_data.loc[
                (base_data.index >= start_time) & (base_data.index <= end_time)
            ]

        except Exception:
            return pd.DataFrame()

    def _improve_data_quality(
        self, multi_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Š"""
        try:
            logger.debug("ğŸ”„ Improving data quality")
            improved_data = {}

            for timeframe, data in multi_data.items():
                if data.empty:
                    improved_data[timeframe] = data
                    continue

                try:
                    improved = data.copy()

                    # OHLCæ•´åˆæ€§ç¢ºä¿
                    if all(
                        col in improved.columns
                        for col in ["open", "high", "low", "close"]
                    ):
                        improved = self._ensure_ohlc_consistency(improved)

                    # å¤–ã‚Œå€¤ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
                    improved = self._smooth_outliers(improved, timeframe)

                    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®æ­£è¦åŒ–
                    if "volume" in improved.columns:
                        improved["volume"] = np.maximum(improved["volume"], 0)

                    improved_data[timeframe] = improved
                    self.sync_stats["quality_improvements"] += 1

                except Exception as e:
                    logger.error(f"âŒ Quality improvement failed for {timeframe}: {e}")
                    improved_data[timeframe] = data

            return improved_data

        except Exception as e:
            logger.error(f"âŒ Data quality improvement failed: {e}")
            return multi_data

    def _ensure_ohlc_consistency(self, data: pd.DataFrame) -> pd.DataFrame:
        """OHLCæ•´åˆæ€§ç¢ºä¿"""
        try:
            corrected = data.copy()

            # High >= max(Open, Close), Low <= min(Open, Close)
            corrected["high"] = np.maximum(
                corrected["high"], np.maximum(corrected["open"], corrected["close"])
            )
            corrected["low"] = np.minimum(
                corrected["low"], np.minimum(corrected["open"], corrected["close"])
            )

            # High >= Low
            corrected["high"] = np.maximum(corrected["high"], corrected["low"])

            return corrected

        except Exception as e:
            logger.error(f"âŒ OHLC consistency ensuring failed: {e}")
            return data

    def _smooth_outliers(
        self, data: pd.DataFrame, timeframe: str, threshold: float = 3.0
    ) -> pd.DataFrame:
        """å¤–ã‚Œå€¤ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°"""
        try:
            smoothed = data.copy()

            for col in ["open", "high", "low", "close"]:
                if col not in data.columns:
                    continue

                try:
                    # Phase H.16.2: numpy/pandasäº’æ›æ€§ä¿®å¾©ãƒ»ãƒ‡ãƒ¼ã‚¿å‹å®‰å…¨æ€§ç¢ºä¿
                    col_data = data[col].dropna()

                    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨å¤‰æ›
                    if len(col_data) == 0:
                        continue

                    # float64ã«æ˜ç¤ºçš„å¤‰æ›ï¼ˆnumpyäº’æ›æ€§ç¢ºä¿ï¼‰
                    col_data = pd.to_numeric(col_data, errors="coerce").astype(
                        np.float64
                    )

                    # NaNå‰Šé™¤å¾Œã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯
                    col_data = col_data.dropna()
                    if len(col_data) < 3:  # æœ€å°ãƒ‡ãƒ¼ã‚¿è¦ä»¶
                        continue

                    # Z-scoreè¨ˆç®—ï¼ˆå‹å®‰å…¨ï¼‰
                    z_scores = np.abs(stats.zscore(col_data.values))
                    outliers_mask = z_scores > threshold

                    if np.any(outliers_mask):
                        # å¤–ã‚Œå€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
                        outlier_indices = col_data.index[outliers_mask]

                        # ç§»å‹•å¹³å‡ã§ç½®æ›
                        window = 5 if timeframe in ["15m", "1h"] else 3
                        ma = data[col].rolling(window=window, center=True).mean()
                        smoothed.loc[outlier_indices, col] = ma.loc[outlier_indices]

                except Exception as e:
                    logger.debug(f"âš ï¸ Outlier smoothing failed for {col}: {e}")
                    continue

            return smoothed

        except Exception as e:
            logger.error(f"âŒ Outlier smoothing failed: {e}")
            return data

    def get_synchronization_stats(self) -> Dict:
        """åŒæœŸçµ±è¨ˆæƒ…å ±å–å¾—"""
        return {
            "sync_stats": self.sync_stats.copy(),
            "timeframes": self.timeframes,
            "base_timeframe": self.base_timeframe,
            "sync_tolerance_seconds": self.sync_tolerance.total_seconds(),
            "missing_data_threshold": self.missing_data_threshold,
            "consistency_check_enabled": self.consistency_check_enabled,
        }

    def reset_stats(self) -> None:
        """çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"""
        self.sync_stats = {
            "sync_operations": 0,
            "alignment_corrections": 0,
            "missing_data_filled": 0,
            "consistency_violations": 0,
            "quality_improvements": 0,
        }
        logger.info("ğŸ”„ Synchronization stats reset")
