"""
ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
Phase 2: å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–å®Ÿè£…

æ©Ÿèƒ½:
- 30%ãƒ«ãƒ¼ãƒ«å®Ÿè£…ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤æ¯”ç‡ç›£è¦–ï¼‰
- å–å¼•è¦‹é€ã‚Šåˆ¤å®š
- å“è³ªé–¾å€¤è¶…éæ™‚è‡ªå‹•åœæ­¢
- å›å¾©åˆ¤å®š
- å“è³ªçµ±è¨ˆãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
"""

import logging
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class QualityStatus(Enum):
    """å“è³ªçŠ¶æ…‹ç®¡ç†"""

    HEALTHY = "healthy"
    WARNING = "warning"
    DEGRADED = "degraded"
    FAILED = "failed"
    EMERGENCY_STOP = "emergency_stop"


@dataclass
class QualityMetrics:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    timestamp: datetime
    source_type: str
    source_name: str
    quality_score: float
    default_ratio: float
    success_rate: float
    latency_ms: float
    error_count: int
    status: QualityStatus

    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "timestamp": self.timestamp.isoformat(),
            "source_type": self.source_type,
            "source_name": self.source_name,
            "quality_score": self.quality_score,
            "default_ratio": self.default_ratio,
            "success_rate": self.success_rate,
            "latency_ms": self.latency_ms,
            "error_count": self.error_count,
            "status": self.status.value,
        }


@dataclass
class QualityThresholds:
    """å“è³ªé–¾å€¤è¨­å®š"""

    # 30%ãƒ«ãƒ¼ãƒ«é–¢é€£
    default_ratio_warning: float = 0.20  # 20%ã§Warning
    default_ratio_degraded: float = 0.30  # 30%ã§Degraded
    default_ratio_failed: float = 0.50  # 50%ã§Failed

    # å“è³ªã‚¹ã‚³ã‚¢é–¢é€£
    quality_score_warning: float = 0.80  # 80%æœªæº€ã§Warning
    quality_score_degraded: float = 0.70  # 70%æœªæº€ã§Degraded
    quality_score_failed: float = 0.50  # 50%æœªæº€ã§Failed

    # æˆåŠŸç‡é–¢é€£
    success_rate_warning: float = 0.90  # 90%æœªæº€ã§Warning
    success_rate_degraded: float = 0.80  # 80%æœªæº€ã§Degraded
    success_rate_failed: float = 0.70  # 70%æœªæº€ã§Failed

    # é€£ç¶šå¤±æ•—å›æ•°
    consecutive_failures_warning: int = 3  # 3å›é€£ç¶šå¤±æ•—ã§Warning
    consecutive_failures_degraded: int = 5  # 5å›é€£ç¶šå¤±æ•—ã§Degraded
    consecutive_failures_emergency: int = 10  # 10å›é€£ç¶šå¤±æ•—ã§ç·Šæ€¥åœæ­¢

    # å›å¾©åˆ¤å®š
    recovery_observation_minutes: int = 30  # 30åˆ†é–“ã®è¦³å¯ŸæœŸé–“
    recovery_success_rate: float = 0.85  # 85%ä»¥ä¸Šã§å›å¾©
    recovery_default_ratio: float = 0.25  # 25%ä»¥ä¸‹ã§å›å¾©


@dataclass
class QualityAlert:
    """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆ"""

    timestamp: datetime
    source_type: str
    source_name: str
    alert_type: str
    severity: str
    message: str
    metrics: QualityMetrics
    resolved: bool = False
    resolved_at: Optional[datetime] = None


class DataQualityMonitor:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.thresholds = QualityThresholds()

        # å“è³ªçµ±è¨ˆç®¡ç†
        self.quality_history: List[QualityMetrics] = []
        self.source_statistics: Dict[str, Dict[str, Any]] = {}
        self.active_alerts: List[QualityAlert] = []

        # çŠ¶æ…‹ç®¡ç†
        self.emergency_stop_active = False
        self.emergency_stop_sources: List[str] = []
        self.recovery_mode_sources: List[str] = []

        # çµ±è¨ˆè¨­å®š
        self.history_retention_hours = self.config.get("history_retention_hours", 24)
        self.statistics_window_minutes = self.config.get(
            "statistics_window_minutes", 60
        )

        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.enable_alerts = self.config.get("enable_alerts", True)
        self.alert_channels = self.config.get("alert_channels", ["log"])

        # Phase H.19: ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ãƒ‡ã‚°ãƒ¬ãƒ¼ãƒ‰è¨­å®š
        self.graceful_degradation_enabled = self.config.get(
            "graceful_degradation", True
        )
        self.partial_data_acceptance = self.config.get("partial_data_acceptance", True)
        self.quality_improvement_factor = self.config.get(
            "quality_improvement_factor", 1.1
        )  # 10%æ”¹å–„

        logger.info("ğŸ”§ DataQualityMonitor initialized")
        logger.info(
            f"  - Default ratio thresholds: "
            f"{self.thresholds.default_ratio_warning}/"
            f"{self.thresholds.default_ratio_degraded}/"
            f"{self.thresholds.default_ratio_failed}"
        )
        logger.info(
            f"  - Quality score thresholds: "
            f"{self.thresholds.quality_score_warning}/"
            f"{self.thresholds.quality_score_degraded}/"
            f"{self.thresholds.quality_score_failed}"
        )
        logger.info(
            f"  - Success rate thresholds: "
            f"{self.thresholds.success_rate_warning}/"
            f"{self.thresholds.success_rate_degraded}/"
            f"{self.thresholds.success_rate_failed}"
        )

    def record_quality_metrics(
        self,
        source_type: str,
        source_name: str,
        quality_score: float,
        default_ratio: float,
        success: bool,
        latency_ms: float = 0.0,
        error_count: int = 0,
    ) -> QualityMetrics:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        try:
            # æˆåŠŸç‡è¨ˆç®—
            success_rate = self._calculate_success_rate(
                source_type, source_name, success
            )

            # å“è³ªçŠ¶æ…‹åˆ¤å®š
            status = self._determine_quality_status(
                quality_score, default_ratio, success_rate, source_type, source_name
            )

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ
            metrics = QualityMetrics(
                timestamp=datetime.now(),
                source_type=source_type,
                source_name=source_name,
                quality_score=quality_score,
                default_ratio=default_ratio,
                success_rate=success_rate,
                latency_ms=latency_ms,
                error_count=error_count,
                status=status,
            )

            # å±¥æ­´ã«è¿½åŠ 
            self.quality_history.append(metrics)

            # çµ±è¨ˆæ›´æ–°
            self._update_source_statistics(metrics)

            # ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†
            self._process_quality_alerts(metrics)

            # ç·Šæ€¥åœæ­¢åˆ¤å®š
            self._check_emergency_stop(metrics)

            # å›å¾©åˆ¤å®š
            self._check_recovery(metrics)

            # å¤ã„å±¥æ­´å‰Šé™¤
            self._cleanup_history()

            return metrics

        except Exception as e:
            logger.error(f"âŒ Failed to record quality metrics: {e}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿”å´
            return QualityMetrics(
                timestamp=datetime.now(),
                source_type=source_type,
                source_name=source_name,
                quality_score=0.0,
                default_ratio=1.0,
                success_rate=0.0,
                latency_ms=0.0,
                error_count=1,
                status=QualityStatus.FAILED,
            )

    def _calculate_success_rate(
        self, source_type: str, source_name: str, success: bool
    ) -> float:
        """æˆåŠŸç‡è¨ˆç®—"""
        source_key = f"{source_type}_{source_name}"

        if source_key not in self.source_statistics:
            self.source_statistics[source_key] = {
                "total_requests": 0,
                "successful_requests": 0,
                "consecutive_failures": 0,
                "last_success": None,
                "last_failure": None,
            }

        stats = self.source_statistics[source_key]
        stats["total_requests"] += 1

        if success:
            stats["successful_requests"] += 1
            stats["consecutive_failures"] = 0
            stats["last_success"] = datetime.now()
        else:
            stats["consecutive_failures"] += 1
            stats["last_failure"] = datetime.now()

        return stats["successful_requests"] / stats["total_requests"]

    def _determine_quality_status(
        self,
        quality_score: float,
        default_ratio: float,
        success_rate: float,
        source_type: str,
        source_name: str,
    ) -> QualityStatus:
        """å“è³ªçŠ¶æ…‹åˆ¤å®š"""
        source_key = f"{source_type}_{source_name}"

        # ç·Šæ€¥åœæ­¢ä¸­ãƒã‚§ãƒƒã‚¯
        if self.emergency_stop_active and source_key in self.emergency_stop_sources:
            return QualityStatus.EMERGENCY_STOP

        # é€£ç¶šå¤±æ•—å›æ•°ãƒã‚§ãƒƒã‚¯
        consecutive_failures = self.source_statistics.get(source_key, {}).get(
            "consecutive_failures", 0
        )
        if consecutive_failures >= self.thresholds.consecutive_failures_emergency:
            return QualityStatus.EMERGENCY_STOP

        # å“è³ªè©•ä¾¡ï¼ˆæœ€ã‚‚å³ã—ã„æ¡ä»¶ã‚’é©ç”¨ï¼‰
        status_scores = []

        # 30%ãƒ«ãƒ¼ãƒ«è©•ä¾¡
        if default_ratio >= self.thresholds.default_ratio_failed:
            status_scores.append(QualityStatus.FAILED)
        elif default_ratio >= self.thresholds.default_ratio_degraded:
            status_scores.append(QualityStatus.DEGRADED)
        elif default_ratio >= self.thresholds.default_ratio_warning:
            status_scores.append(QualityStatus.WARNING)
        else:
            status_scores.append(QualityStatus.HEALTHY)

        # å“è³ªã‚¹ã‚³ã‚¢è©•ä¾¡
        if quality_score < self.thresholds.quality_score_failed:
            status_scores.append(QualityStatus.FAILED)
        elif quality_score < self.thresholds.quality_score_degraded:
            status_scores.append(QualityStatus.DEGRADED)
        elif quality_score < self.thresholds.quality_score_warning:
            status_scores.append(QualityStatus.WARNING)
        else:
            status_scores.append(QualityStatus.HEALTHY)

        # æˆåŠŸç‡è©•ä¾¡
        if success_rate < self.thresholds.success_rate_failed:
            status_scores.append(QualityStatus.FAILED)
        elif success_rate < self.thresholds.success_rate_degraded:
            status_scores.append(QualityStatus.DEGRADED)
        elif success_rate < self.thresholds.success_rate_warning:
            status_scores.append(QualityStatus.WARNING)
        else:
            status_scores.append(QualityStatus.HEALTHY)

        # æœ€ã‚‚å³ã—ã„çŠ¶æ…‹ã‚’è¿”ã™
        status_priority = {
            QualityStatus.EMERGENCY_STOP: 5,
            QualityStatus.FAILED: 4,
            QualityStatus.DEGRADED: 3,
            QualityStatus.WARNING: 2,
            QualityStatus.HEALTHY: 1,
        }

        return max(status_scores, key=lambda s: status_priority[s])

    def _update_source_statistics(self, metrics: QualityMetrics) -> None:
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±è¨ˆæ›´æ–°"""
        source_key = f"{metrics.source_type}_{metrics.source_name}"

        if source_key not in self.source_statistics:
            self.source_statistics[source_key] = {}

        stats = self.source_statistics[source_key]

        # æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        stats["last_quality_score"] = metrics.quality_score
        stats["last_default_ratio"] = metrics.default_ratio
        stats["last_success_rate"] = metrics.success_rate
        stats["last_status"] = metrics.status.value
        stats["last_update"] = metrics.timestamp

        # å¹³å‡å€¤è¨ˆç®—ï¼ˆéå»1æ™‚é–“ï¼‰
        window_start = datetime.now() - timedelta(
            minutes=self.statistics_window_minutes
        )
        recent_metrics = [
            m
            for m in self.quality_history
            if m.source_type == metrics.source_type
            and m.source_name == metrics.source_name
            and m.timestamp >= window_start
        ]

        if recent_metrics:
            stats["avg_quality_score"] = sum(
                m.quality_score for m in recent_metrics
            ) / len(recent_metrics)
            stats["avg_default_ratio"] = sum(
                m.default_ratio for m in recent_metrics
            ) / len(recent_metrics)
            stats["avg_latency_ms"] = sum(m.latency_ms for m in recent_metrics) / len(
                recent_metrics
            )
            stats["error_count_1h"] = sum(m.error_count for m in recent_metrics)

    def _process_quality_alerts(self, metrics: QualityMetrics) -> None:
        """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†"""
        if not self.enable_alerts:
            return

        # æ–°ã—ã„ã‚¢ãƒ©ãƒ¼ãƒˆãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
        alert_needed = False
        alert_message = ""
        severity = "info"

        if metrics.status == QualityStatus.EMERGENCY_STOP:
            alert_needed = True
            alert_message = (
                f"EMERGENCY STOP: {metrics.source_type}/{metrics.source_name} - "
                f"Quality critically degraded"
            )
            severity = "critical"
        elif metrics.status == QualityStatus.FAILED:
            alert_needed = True
            alert_message = (
                f"FAILED: {metrics.source_type}/{metrics.source_name} - "
                f"Quality: {metrics.quality_score:.2f}, "
                f"Default ratio: {metrics.default_ratio:.2f}"
            )
            severity = "error"
        elif metrics.status == QualityStatus.DEGRADED:
            alert_needed = True
            alert_message = (
                f"DEGRADED: {metrics.source_type}/{metrics.source_name} - "
                f"Quality: {metrics.quality_score:.2f}, "
                f"Default ratio: {metrics.default_ratio:.2f}"
            )
            severity = "warning"
        elif metrics.status == QualityStatus.WARNING:
            alert_needed = True
            alert_message = (
                f"WARNING: {metrics.source_type}/{metrics.source_name} - "
                f"Quality: {metrics.quality_score:.2f}, "
                f"Default ratio: {metrics.default_ratio:.2f}"
            )
            severity = "warning"

        if alert_needed:
            # é‡è¤‡ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
            existing_alert = None
            for alert in self.active_alerts:
                if (
                    alert.source_type == metrics.source_type
                    and alert.source_name == metrics.source_name
                    and alert.severity == severity
                    and not alert.resolved
                ):
                    existing_alert = alert
                    break

            if existing_alert is None:
                # æ–°ã—ã„ã‚¢ãƒ©ãƒ¼ãƒˆä½œæˆ
                alert = QualityAlert(
                    timestamp=datetime.now(),
                    source_type=metrics.source_type,
                    source_name=metrics.source_name,
                    alert_type="quality_degradation",
                    severity=severity,
                    message=alert_message,
                    metrics=metrics,
                )

                self.active_alerts.append(alert)
                self._send_alert(alert)

    def _check_emergency_stop(self, metrics: QualityMetrics) -> None:
        """ç·Šæ€¥åœæ­¢åˆ¤å®š"""
        source_key = f"{metrics.source_type}_{metrics.source_name}"

        if metrics.status == QualityStatus.EMERGENCY_STOP:
            if not self.emergency_stop_active:
                self.emergency_stop_active = True
                logger.critical(
                    "ğŸš¨ EMERGENCY STOP ACTIVATED: Data quality critically degraded"
                )

            if source_key not in self.emergency_stop_sources:
                self.emergency_stop_sources.append(source_key)
                logger.critical(f"ğŸš¨ Emergency stop source added: {source_key}")

    def _check_recovery(self, metrics: QualityMetrics) -> None:
        """å›å¾©åˆ¤å®š"""
        source_key = f"{metrics.source_type}_{metrics.source_name}"

        # å›å¾©è¦³å¯ŸæœŸé–“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        window_start = datetime.now() - timedelta(
            minutes=self.thresholds.recovery_observation_minutes
        )
        recent_metrics = [
            m
            for m in self.quality_history
            if m.source_type == metrics.source_type
            and m.source_name == metrics.source_name
            and m.timestamp >= window_start
        ]

        if len(recent_metrics) >= 3:  # æœ€ä½3å›ã®è¦³å¯Ÿ
            avg_success_rate = sum(m.success_rate for m in recent_metrics) / len(
                recent_metrics
            )
            avg_default_ratio = sum(m.default_ratio for m in recent_metrics) / len(
                recent_metrics
            )

            # å›å¾©æ¡ä»¶ãƒã‚§ãƒƒã‚¯
            if (
                avg_success_rate >= self.thresholds.recovery_success_rate
                and avg_default_ratio <= self.thresholds.recovery_default_ratio
            ):

                # ç·Šæ€¥åœæ­¢è§£é™¤
                if source_key in self.emergency_stop_sources:
                    self.emergency_stop_sources.remove(source_key)
                    logger.info(
                        f"âœ… Recovery detected: {source_key} - Emergency stop removed"
                    )

                    # å…¨ã¦ã®ç·Šæ€¥åœæ­¢ãŒè§£é™¤ã•ã‚ŒãŸã‹ç¢ºèª
                    if not self.emergency_stop_sources:
                        self.emergency_stop_active = False
                        logger.info(
                            "âœ… EMERGENCY STOP DEACTIVATED: All sources recovered"
                        )

                # å›å¾©ã‚¢ãƒ©ãƒ¼ãƒˆ
                if source_key not in self.recovery_mode_sources:
                    self.recovery_mode_sources.append(source_key)

                    recovery_alert = QualityAlert(
                        timestamp=datetime.now(),
                        source_type=metrics.source_type,
                        source_name=metrics.source_name,
                        alert_type="quality_recovery",
                        severity="info",
                        message=(
                            f"RECOVERY: {metrics.source_type}/{metrics.source_name} - "
                            f"Quality recovered (Success rate: {avg_success_rate:.2f}, "
                            f"Default ratio: {avg_default_ratio:.2f})"
                        ),
                        metrics=metrics,
                    )

                    self.active_alerts.append(recovery_alert)
                    self._send_alert(recovery_alert)

    def _send_alert(self, alert: QualityAlert) -> None:
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        for channel in self.alert_channels:
            if channel == "log":
                if alert.severity == "critical":
                    logger.critical(alert.message)
                elif alert.severity == "error":
                    logger.error(alert.message)
                elif alert.severity == "warning":
                    logger.warning(alert.message)
                else:
                    logger.info(alert.message)
            # ä»–ã®ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆSlackã€Emailç­‰ï¼‰ã¯ä»Šå¾Œå®Ÿè£…

    def _cleanup_history(self) -> None:
        """å¤ã„å±¥æ­´å‰Šé™¤"""
        cutoff_time = datetime.now() - timedelta(hours=self.history_retention_hours)
        self.quality_history = [
            m for m in self.quality_history if m.timestamp >= cutoff_time
        ]

    def should_allow_trading(self, source_type: str, source_name: str) -> bool:
        """å–å¼•å®Ÿè¡Œè¨±å¯åˆ¤å®š"""
        # ç·Šæ€¥åœæ­¢ä¸­ã¯å–å¼•åœæ­¢
        if self.emergency_stop_active:
            return False

        # ç‰¹å®šã‚½ãƒ¼ã‚¹ã®çŠ¶æ…‹ç¢ºèª
        source_key = f"{source_type}_{source_name}"
        if source_key in self.emergency_stop_sources:
            return False

        # æœ€æ–°ã®å“è³ªçŠ¶æ…‹ç¢ºèª
        latest_metrics = self._get_latest_metrics(source_type, source_name)
        if latest_metrics and latest_metrics.status in [
            QualityStatus.FAILED,
            QualityStatus.EMERGENCY_STOP,
        ]:
            return False

        return True

    def _get_latest_metrics(
        self, source_type: str, source_name: str
    ) -> Optional[QualityMetrics]:
        """æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        for metrics in reversed(self.quality_history):
            if (
                metrics.source_type == source_type
                and metrics.source_name == source_name
            ):
                return metrics
        return None

    def get_quality_summary(self) -> Dict[str, Any]:
        """å“è³ªã‚µãƒãƒªãƒ¼å–å¾—"""
        summary = {
            "emergency_stop_active": self.emergency_stop_active,
            "emergency_stop_sources": self.emergency_stop_sources,
            "recovery_mode_sources": self.recovery_mode_sources,
            "active_alerts": len(self.active_alerts),
            "total_metrics": len(self.quality_history),
            "source_statistics": {},
        }

        # ã‚½ãƒ¼ã‚¹åˆ¥çµ±è¨ˆ
        for source_key, stats in self.source_statistics.items():
            summary["source_statistics"][source_key] = {
                "last_status": stats.get("last_status", "unknown"),
                "last_quality_score": stats.get("last_quality_score", 0.0),
                "last_default_ratio": stats.get("last_default_ratio", 1.0),
                "success_rate": stats.get("last_success_rate", 0.0),
                "consecutive_failures": stats.get("consecutive_failures", 0),
                "total_requests": stats.get("total_requests", 0),
            }

        return summary

    def get_quality_report(self) -> Dict[str, Any]:
        """è©³ç´°å“è³ªãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": self.get_quality_summary(),
            "recent_metrics": [
                m.to_dict() for m in self.quality_history[-20:]  # æœ€æ–°20ä»¶
            ],
            "active_alerts": [
                {
                    "timestamp": alert.timestamp.isoformat(),
                    "source": f"{alert.source_type}/{alert.source_name}",
                    "severity": alert.severity,
                    "message": alert.message,
                    "resolved": alert.resolved,
                }
                for alert in self.active_alerts
            ],
            "thresholds": {
                "default_ratio_warning": self.thresholds.default_ratio_warning,
                "default_ratio_degraded": self.thresholds.default_ratio_degraded,
                "default_ratio_failed": self.thresholds.default_ratio_failed,
                "quality_score_warning": self.thresholds.quality_score_warning,
                "quality_score_degraded": self.thresholds.quality_score_degraded,
                "quality_score_failed": self.thresholds.quality_score_failed,
            },
        }

        return report

    def improve_data_quality(self, current_quality: float, source_type: str) -> float:
        """Phase H.19: ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’æ”¹å–„ã™ã‚‹è©¦ã¿

        Args:
            current_quality: ç¾åœ¨ã®å“è³ªã‚¹ã‚³ã‚¢
            source_type: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—

        Returns:
            æ”¹å–„ã•ã‚ŒãŸå“è³ªã‚¹ã‚³ã‚¢
        """
        if not self.graceful_degradation_enabled:
            return current_quality

        # ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ãƒ‡ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼šéƒ¨åˆ†çš„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚æ´»ç”¨
        improved_quality = current_quality

        # 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã«ã‚ˆã‚‹å“è³ªæ”¹å–„
        if self.partial_data_acceptance and current_quality > 0.4:
            # 40%ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã§è£œå®Œå¯èƒ½ã¨åˆ¤æ–­
            improved_quality = min(
                current_quality * self.quality_improvement_factor, 0.65
            )
            logger.info(
                f"ğŸ“ˆ Quality improved by cache supplementation: "
                f"{current_quality:.2f} â†’ {improved_quality:.2f}"
            )

        # 2. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®éƒ¨åˆ†çš„æˆåŠŸã‚’è€ƒæ…®
        recent_metrics = [
            m
            for m in self.quality_history[-10:]
            if m.source_type == source_type and m.success_rate > 0
        ]

        if recent_metrics:
            # æœ€è¿‘ã®æˆåŠŸç‡ã‚’è€ƒæ…®
            avg_success_rate = sum(m.success_rate for m in recent_metrics) / len(
                recent_metrics
            )
            if avg_success_rate > 0.5:  # 50%ä»¥ä¸ŠæˆåŠŸã—ã¦ã„ã‚Œã°
                quality_boost = avg_success_rate * 0.1  # æœ€å¤§10%ã®ãƒ–ãƒ¼ã‚¹ãƒˆ
                improved_quality = min(improved_quality + quality_boost, 0.7)
                logger.info(
                    f"ğŸ“Š Quality boosted by historical success rate: "
                    f"+{quality_boost:.2f} (total: {improved_quality:.2f})"
                )

        # 3. è¤‡æ•°ã‚½ãƒ¼ã‚¹ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹å“è³ªå‘ä¸Š
        if source_type in ["external_data", "multi_source"]:
            # è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ç›¸äº’è£œå®Œ
            other_sources = [
                m
                for m in self.quality_history[-5:]
                if m.source_type != source_type and m.quality_score > 0.5
            ]

            if len(other_sources) >= 2:
                # ä»–ã®ã‚½ãƒ¼ã‚¹ãŒå¥å…¨ãªã‚‰å“è³ªã‚’å‘ä¸Š
                improved_quality = min(improved_quality + 0.05, 0.65)
                logger.info(
                    f"ğŸ”„ Quality improved by multi-source validation: "
                    f"{improved_quality:.2f}"
                )

        return improved_quality

    def get_adjusted_quality_threshold(self, base_threshold: float) -> float:
        """Phase H.19: å‹•çš„å“è³ªé–¾å€¤ã®èª¿æ•´

        Args:
            base_threshold: åŸºæœ¬å“è³ªé–¾å€¤

        Returns:
            èª¿æ•´ã•ã‚ŒãŸå“è³ªé–¾å€¤
        """
        if not self.graceful_degradation_enabled:
            return base_threshold

        # å…¨ä½“çš„ãªå“è³ªçŠ¶æ³ã‚’è©•ä¾¡
        recent_metrics = self.quality_history[-30:]  # æœ€æ–°30ä»¶
        if not recent_metrics:
            return base_threshold

        # å¹³å‡å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        avg_quality = sum(m.quality_score for m in recent_metrics) / len(recent_metrics)

        # å“è³ªãŒå…¨ä½“çš„ã«ä½ã„å ´åˆã€é–¾å€¤ã‚’å°‘ã—ç·©å’Œ
        if avg_quality < 0.6:
            # æœ€å¤§10%ã¾ã§é–¾å€¤ã‚’ä¸‹ã’ã‚‹
            adjustment = max(0.9, avg_quality / 0.6)
            adjusted_threshold = base_threshold * adjustment

            logger.info(
                f"ğŸ¯ Quality threshold adjusted: {base_threshold:.2f} â†’ "
                f"{adjusted_threshold:.2f} (avg quality: {avg_quality:.2f})"
            )

            return adjusted_threshold

        return base_threshold

    def calculate_composite_quality(self, metrics_dict: Dict[str, float]) -> float:
        """Phase H.19: è¤‡åˆå“è³ªã‚¹ã‚³ã‚¢ã®è¨ˆç®—

        Args:
            metrics_dict: å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¾æ›¸

        Returns:
            è¤‡åˆå“è³ªã‚¹ã‚³ã‚¢
        """
        # é‡ã¿ä»˜ã‘è¨­å®š
        weights = {
            "price_data": 0.4,  # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒæœ€é‡è¦
            "technical": 0.3,  # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
            "external": 0.2,  # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿
            "market": 0.1,  # å¸‚å ´ãƒ‡ãƒ¼ã‚¿
        }

        composite_score = 0.0
        total_weight = 0.0

        for category, weight in weights.items():
            if category in metrics_dict:
                score = metrics_dict[category]
                # ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ãƒ‡ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼šéƒ¨åˆ†çš„ãªæˆåŠŸã‚‚è€ƒæ…®
                if self.partial_data_acceptance and score > 0:
                    composite_score += score * weight
                    total_weight += weight

        # æ­£è¦åŒ–
        if total_weight > 0:
            composite_score = composite_score / total_weight

        # æœ€ä½å“è³ªä¿è¨¼ï¼ˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°æœ€ä½40%ï¼‰
        if "price_data" in metrics_dict and metrics_dict["price_data"] > 0.8:
            composite_score = max(composite_score, 0.4)

        return composite_score


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_quality_monitor = None


def get_quality_monitor(config: Optional[Dict[str, Any]] = None) -> DataQualityMonitor:
    """å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
    global _quality_monitor
    if _quality_monitor is None:
        _quality_monitor = DataQualityMonitor(config)
    return _quality_monitor
