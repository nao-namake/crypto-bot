# =============================================================================
# .github/workflows/ci.yml
#   - Push / PR 時に Lint・Format・UnitTest（coverage）を実行
#   - Bybit Testnet 用 E2E テスト（API キーが無ければスキップ）
#   - Docker イメージのビルド & Artifact Registry へのプッシュ
#   - GCP Cloud Run への自動デプロイ（Terraform使用）
# =============================================================================
name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

# ──────────────────────────────────────────────────────────────────────────────
jobs:
  # ────────────────────────────────────────────────────────────────────────────
  test:
    name: Unit Tests
    runs-on: ubuntu-latest

    # Bitbank本番運用に最適化 - Python 3.11のみでテスト実行
    strategy:
      matrix:
        python-version: ['3.11']

    # Codecov 用のトークンを事前に環境変数へ流し込んでおく
    env:
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

    steps:
      - uses: actions/checkout@v4
        # リポジトリをチェックアウト

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements/*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
        # Phase 12.5: 統一依存関係管理・requirements/フォルダ対応

      - name: Restore data cache (168-hour)
        uses: actions/cache/restore@v4
        with:
          path: |
            cache/initial_data_168h.pkl
            cache/initial_features_168h.pkl
          key: data-cache-168h-${{ github.run_number }}-${{ github.sha }}
          restore-keys: |
            data-cache-168h-
        # 事前取得された168時間データキャッシュを復元

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
        # matrix で指定した Python バージョンをセットアップ

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements/dev.txt
        # Phase 12.5: 統一依存関係管理・requirements/dev.txt使用

      - name: Run quality checks & tests
        run: |
          echo ">>> Running full quality checks"
          bash scripts/ci_tools/checks.sh
        # scripts/checks.sh に書かれた flake8/isort/black/pytest＋coverage コマンドを一括実行

      - name: Generate pre-computed cache
        run: |
          echo ">>> Phase 12.3: Generating pre-computed cache"
          python scripts/data_tools/pre_compute_data.py || echo "⚠️ Pre-computation failed but continuing"
          if [ -d "cache" ]; then
            echo "✅ Cache generated successfully: $(ls -la cache/)"
          else
            echo "⚠️ Cache directory not found"
          fi
        # Phase 12.3: 事前計算キャッシュ生成（失敗してもCIを停止しない）

      - name: Validate production environment dependencies
        run: |
          echo ">>> Phase 12.5: Validating production dependencies"
          echo "📋 Testing production base dependencies import"
          python -c "
          import sys
          failed_imports = []
          base_modules = ['numpy', 'pandas', 'sklearn', 'joblib', 'requests', 'ccxt', 'dotenv', 'fastapi', 'uvicorn', 'yaml', 'tenacity']
          for module in base_modules:
              try:
                  __import__(module)
                  print(f'✅ {module}')
              except ImportError as e:
                  failed_imports.append(f'{module}: {e}')
                  print(f'❌ {module}: {e}')
          if failed_imports:
              print(f'\\n🚨 Failed imports: {len(failed_imports)}')
              for failure in failed_imports:
                  print(f'   - {failure}')
              sys.exit(1)
          else:
              print(f'\\n🎉 All {len(base_modules)} base dependencies imported successfully')
          "
        # Phase 12.5: 本番環境依存関係検証・import失敗早期検出

      - name: Prepare cache directory for Docker build
        run: |
          echo ">>> Phase 18: Preparing cache directory for Docker build"
          mkdir -p cache
          echo "# Cache directory for CI environment" > cache/README.md
          echo "✅ Cache directory created for Docker build"
        # Phase 18: CI環境でDockerビルド用のcache/ディレクトリを作成

      - name: Test production Docker environment
        run: |
          echo ">>> Phase 12.5: Testing production Docker build and import"
          echo "🐳 Building production Docker image..."
          docker build -f docker/Dockerfile -t crypto-bot-prod-test .
          echo "📦 Testing production environment import..."
          docker run --rm crypto-bot-prod-test python -c "
          import crypto_bot
          print('✅ Production Docker import test passed')
          print('🎯 Environment parity verified: Local ≈ CI ≈ Production')
          "
        # Phase 12.5: 本番Docker環境テスト・tenacityモジュール問題類似エラー防止

      - name: Run Phase C1 integration tests
        run: |
          echo ">>> Running Phase C1 integration tests"
          if [ -f "tests/integration/test_phase_c1_integration.py" ]; then
            python tests/integration/test_phase_c1_integration.py || echo "⚠️ Phase C1 integration tests failed but continuing"
          else
            echo "⚠️ Phase C1 integration tests not found - skipping"
          fi
        # Phase C1統合テスト実行（失敗してもCIを停止しない）

      - name: Run Phase C2 integration tests
        run: |
          echo ">>> Running Phase C2 integration tests"
          if [ -f "tests/integration/test_phase_c2_integration.py" ]; then
            python tests/integration/test_phase_c2_integration.py || echo "⚠️ Phase C2 integration tests failed but continuing"
          else
            echo "⚠️ Phase C2 integration tests not found - skipping"
          fi
        # Phase C2統合テスト実行（失敗してもCIを停止しない）

      - name: Upload coverage to Codecov
        if: ${{ env.CODECOV_TOKEN != '' }}
        uses: codecov/codecov-action@v4.5.0
        with:
          token: ${{ env.CODECOV_TOKEN }}
        # CODECOV_TOKEN が設定されていれば coverage を Codecov へアップロード

  # ────────────────────────────────────────────────────────────────────────────
  # Bybit Testnet E2E テスト - Bitbank本番運用のため除外
  # 必要に応じて手動実行可能
  # ────────────────────────────────────────────────────────────────────────────

  # ────────────────────────────────────────────────────────────────────────────
  docker-build:
    name: Build & Test Docker Image
    needs: test
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'push' && github.ref == 'refs/heads/main') ||
      startsWith(github.ref, 'refs/tags/v') ||
      (github.event_name == 'workflow_dispatch')
    permissions:
      contents: read
      id-token: write

    # Docker build and test environment
    env:
      IMAGE_NAME: crypto-bot

    steps:
      - uses: actions/checkout@v4
        # コードをチェックアウト

      - name: Create CI cache directory with minimal data
        run: |
          echo "🔧 Creating cache directory with minimal initial data for CI..."
          # Use lightweight bash script that doesn't require Python dependencies
          bash scripts/data_tools/create_ci_cache.sh
        # CI環境用の初期データキャッシュ作成

      - name: Prepare model files for CI
        run: |
          echo "🤖 Preparing model files for CI environment..."
          mkdir -p models/production
          
          # モデルファイルが存在しない場合、本番用モデルを生成
          if [ ! -f "models/production/model.pkl" ]; then
            echo "⚠️ Model file not found, creating production model for CI..."
            # 本番用モデル作成を試みる
            python scripts/model_tools/create_production_model.py || {
              echo "⚠️ Production model creation failed, falling back to CI model..."
              python scripts/model_tools/create_ci_model.py || echo "⚠️ CI model creation also failed, but continuing"
            }
          else
            echo "✅ Model file already exists"
          fi
          
          # メタデータファイルも作成
          if [ ! -f "models/production/model_metadata.json" ]; then
            echo '{"version": "CI", "features": 97, "created": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}' > models/production/model_metadata.json
          fi
          
          echo "📊 Model files prepared:"
          ls -la models/production/
        # CI環境用のモデルファイル準備

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          platforms: linux/amd64
        # Docker Buildx をセットアップ (AMD64専用)

      # ---------- Authenticate to GCP for Artifact Registry ----------
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_DEPLOYER_SA }}
          access_token_lifetime: 7200s
          access_token_scopes: |
            https://www.googleapis.com/auth/cloud-platform
            https://www.googleapis.com/auth/devstorage.read_write
            https://www.googleapis.com/auth/artifactregistry.repositories.uploadArtifacts

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure docker for Artifact Registry
        run: gcloud --quiet auth configure-docker asia-northeast1-docker.pkg.dev

      - name: Create Artifact Registry repository if not exists
        run: |
          echo "Checking if Artifact Registry repository exists..."
          if ! gcloud artifacts repositories describe crypto-bot-repo --location=asia-northeast1 --format="value(name)" 2>/dev/null; then
            echo "Creating Artifact Registry repository..."
            gcloud artifacts repositories create crypto-bot-repo \
              --repository-format=docker \
              --location=asia-northeast1 \
              --description="Docker repository for crypto-bot application"
          else
            echo "Artifact Registry repository already exists"
          fi

      # ---------- Build & push to Artifact Registry ----------
      - name: Set build timestamp
        id: timestamp
        run: echo "BUILD_TIME=$(date +%Y%m%d-%H%M%S)" >> $GITHUB_OUTPUT
      
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/Dockerfile
          push: true
          load: false
          platforms: linux/amd64
          provenance: false
          tags: |
            asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:latest
            asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:${{ github.sha }}
            asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:${{ steps.timestamp.outputs.BUILD_TIME }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1
      
      - name: Test Docker image
        run: |
          IMAGE_TAG="asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:${{ github.sha }}"
          docker pull "${IMAGE_TAG}"
          docker run --rm "${IMAGE_TAG}" python -c "import crypto_bot; print('Docker import test passed')"
          
          # Test API server only mode for CI (no live trading due to missing model)
          docker run -d --name test-container -p 8080:8080 -e CI=true -e API_ONLY_MODE=true "${IMAGE_TAG}"
          echo "Waiting for API server to start..."
          sleep 15
          
          # Test API server health
          if curl -f http://localhost:8080/health; then
            echo "✅ API server health check passed"
          else
            echo "❌ API server health check failed"
            echo "Container logs:"
            docker logs test-container
            exit 1
          fi
          
          # Test additional endpoints
          if curl -f http://localhost:8080/healthz; then
            echo "✅ Healthz endpoint check passed"
          else
            echo "❌ Healthz endpoint check failed"
            docker logs test-container
            exit 1
          fi
          
          docker stop test-container
          docker rm test-container
          echo "✅ Docker image tests passed successfully"
          echo "📋 Note: Live trading mode requires trained ML model (not available in CI)"


  # ────────────────────────────────────────────────────────────────────────────
  # Production Environment Deploy (main branch only)
  # ────────────────────────────────────────────────────────────────────────────
  terraform-deploy-prod:
    name: Deploy to Production
    needs: docker-build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    permissions:
      contents: read
      id-token: write
    env:
      # Docker image pushed in the previous job
      IMAGE_NAME: ghcr.io/${{ github.repository_owner }}/crypto-bot
      # GCP project (secret)
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}

      # Production environment specific settings
      TF_VAR_artifact_registry_repo: "crypto-bot-repo"
      TF_VAR_service_name: "crypto-bot-service-prod"
      TF_VAR_image_name: "crypto-bot"
      TF_VAR_mode: "live"
      TF_VAR_discord_webhook_url: ${{ secrets.DISCORD_WEBHOOK_URL }}
      TF_VAR_github_repo: "nao-namake/crypto-bot"
      TF_VAR_project_number: ${{ secrets.GCP_PROJECT_NUMBER }}
      TF_VAR_deployer_sa: ${{ secrets.GCP_DEPLOYER_SA }}

      # ----- Terraform variables -----
      TF_VAR_project_id: ${{ secrets.GCP_PROJECT_ID }}
      TF_VAR_region: "asia-northeast1"
      TF_VAR_image_tag: "${{ github.sha }}"
      TF_VAR_bitbank_api_key: ${{ secrets.BITBANK_API_KEY }}
      TF_VAR_bitbank_api_secret: ${{ secrets.BITBANK_API_SECRET }}
      TF_ENV_DIR: "infra/envs/prod"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---------- Authenticate to GCP via Workload Identity Federation ----------
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_DEPLOYER_SA }}
          access_token_lifetime: 7200s
          access_token_scopes: |
            https://www.googleapis.com/auth/cloud-platform
            https://www.googleapis.com/auth/devstorage.read_write
            https://www.googleapis.com/auth/artifactregistry.repositories.uploadArtifacts

      - name: Set up gcloud for Production
        uses: google-github-actions/setup-gcloud@v2

      # ---------- Terraform ----------
      - name: Set up Terraform for Production
        uses: hashicorp/setup-terraform@v3.1.1
        with:
          terraform_version: 1.8.5

      - name: Clear Terraform state lock if exists
        run: |
          echo "🔒 Checking for existing Terraform state lock..."
          if gsutil ls gs://my-crypto-bot-terraform-state/prod/default.tflock 2>/dev/null; then
            echo "⚠️ Found existing lock file, removing it..."
            gsutil rm gs://my-crypto-bot-terraform-state/prod/default.tflock || echo "Failed to remove lock, but continuing"
          else
            echo "✅ No existing lock file found"
          fi

      - name: Prepare Production Data Cache
        run: |
          echo "📊 Preparing production data cache for CI environment..."
          # Use lightweight bash script that doesn't require Python dependencies
          bash scripts/data_tools/create_ci_cache.sh
          echo "✅ Cache preparation complete"

      - name: Terraform Init (Production)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} init -upgrade -lock-timeout=5m

      - name: Terraform Plan (Production)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} plan -input=false -lock-timeout=5m

      - name: Terraform Apply (Production)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} apply -auto-approve -input=false -lock-timeout=5m

      # ---------- Post-deployment verification ----------
      - name: Verify Production Deployment
        run: |
          echo "🔍 Verifying production deployment..."
          sleep 30  # Wait for service to fully start
          
          # Check service health
          echo "📊 Checking service health..."
          HEALTH_RESPONSE=$(curl -s https://crypto-bot-service-prod-lufv3saz7q-an.a.run.app/health || echo "failed")
          
          if [[ "$HEALTH_RESPONSE" == *"healthy"* ]]; then
            echo "✅ Service is healthy: $HEALTH_RESPONSE"
          else
            echo "⚠️ Service health check failed or returned unexpected response"
            echo "Response: $HEALTH_RESPONSE"
          fi
          
          # Check for critical errors in logs
          echo "📝 Checking for critical errors in recent logs..."
          gcloud logging read "resource.type=cloud_run_revision AND severity>=ERROR AND timestamp>=\"$(date -u -d '5 minutes ago' '+%Y-%m-%dT%H:%M:%S')Z\"" --limit=10 --format=json | jq -r '.[] | "\(.timestamp): \(.textPayload // .jsonPayload.message)"' || echo "No recent errors found"
          
          # Verify main loop is running
          echo "🔄 Checking if main trading loop started..."
          LOOP_CHECK=$(gcloud logging read "resource.type=cloud_run_revision AND textPayload:\"LOOP-ITER\" AND timestamp>=\"$(date -u -d '5 minutes ago' '+%Y-%m-%dT%H:%M:%S')Z\"" --limit=1 --format=json | jq -r '.[] | .textPayload' || echo "")
          
          if [[ -n "$LOOP_CHECK" ]]; then
            echo "✅ Main trading loop is running"
          else
            echo "⚠️ Main trading loop not detected yet (this may be normal if deployment just completed)"
          fi
          
          echo "📊 Deployment verification complete"

