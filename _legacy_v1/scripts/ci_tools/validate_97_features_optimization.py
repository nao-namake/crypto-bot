#!/usr/bin/env python3
"""
97ç‰¹å¾´é‡æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åŠ¹æœæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase 2: 127â†’97ç‰¹å¾´é‡æœ€é©åŒ–ã®åŠ¹æœæ¸¬å®šãƒ»æ€§èƒ½æ¯”è¼ƒ

å®Ÿè¡Œå†…å®¹:
1. 97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§ç¢ºèª
2. 97ç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç¢ºèª
3. åŠ¹ç‡åŒ–åŠ¹æœæ¸¬å®šï¼ˆæ¨å®šï¼‰
4. ã‚·ã‚¹ãƒ†ãƒ æº–å‚™çŠ¶æ³ç¢ºèª
"""

import json
import logging
import sys
import time
from pathlib import Path

import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from crypto_bot.ml.feature_defaults import FeatureDefaults
from crypto_bot.ml.feature_order_manager import FeatureOrderManager

logging.basicConfig(level=logging.INFO, format="%(levelname)s:%(name)s:%(message)s")
logger = logging.getLogger(__name__)


def validate_system_integration():
    """97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§ç¢ºèª"""
    print("ğŸ” === 97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§ç¢ºèª ===")

    # FeatureOrderManagerç¢ºèª
    fom = FeatureOrderManager()
    defaults = FeatureDefaults()

    print(f"âœ… FeatureOrderManager: {len(fom.FEATURE_ORDER_97)} ç‰¹å¾´é‡")
    print(f"âœ… FeatureDefaults target_count: {defaults.target_count}")

    # feature_order.jsonç¢ºèª
    feature_order_path = Path("config/core/feature_order.json")
    if feature_order_path.exists():
        with open(feature_order_path, "r") as f:
            data = json.load(f)

        feature_order_json = data["feature_order"]
        print(f"âœ… feature_order.json: {len(feature_order_json)} ç‰¹å¾´é‡")
        print(
            f"   å‰Šé™¤ã•ã‚ŒãŸç‰¹å¾´é‡: {len(data['optimization_info']['deleted_features'])} å€‹"
        )

        # é †åºä¸€è‡´ç¢ºèª
        full_match = feature_order_json == fom.FEATURE_ORDER_97
        print(f"âœ… ç‰¹å¾´é‡é †åºä¸€è‡´: {full_match}")

        if full_match:
            print("ğŸŠ 97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§: å®Œå…¨ä¸€è‡´")
            return True
        else:
            print("âŒ 97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§: ä¸ä¸€è‡´")
            return False
    else:
        print("âŒ feature_order.json: ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        return False


def validate_model_performance():
    """97ç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç¢ºèª"""
    print("\nğŸ” === 97ç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç¢ºèª ===")

    model_dir = Path("models/production")
    models = ["lgbm_97_features.pkl", "xgb_97_features.pkl", "rf_97_features.pkl"]

    model_results = {}

    for model_file in models:
        model_path = model_dir / model_file
        if model_path.exists():
            size_kb = model_path.stat().st_size / 1024
            print(f"âœ… {model_file}: {size_kb:.1f} KB")

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
            metadata_file = model_file.replace(".pkl", "_metadata.json")
            metadata_path = model_dir / metadata_file
            if metadata_path.exists():
                with open(metadata_path, "r") as f:
                    meta = json.load(f)

                accuracy = meta.get("train_accuracy", 0)
                f1_score = meta.get("train_f1", 0)
                print(f"   å­¦ç¿’ç²¾åº¦: {accuracy:.3f}")
                print(f"   F1ã‚¹ã‚³ã‚¢: {f1_score:.3f}")

                model_results[model_file] = {
                    "size_kb": size_kb,
                    "accuracy": accuracy,
                    "f1_score": f1_score,
                }
            else:
                print(f"   âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—")
                model_results[model_file] = {
                    "size_kb": size_kb,
                    "accuracy": 0,
                    "f1_score": 0,
                }
        else:
            print(f"âŒ {model_file}: ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
            model_results[model_file] = None

    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    ensemble_meta_path = model_dir / "ensemble_97_features_metadata.json"
    if ensemble_meta_path.exists():
        print(f"\nâœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
        with open(ensemble_meta_path, "r") as f:
            ensemble_meta = json.load(f)
        print(f"   å­¦ç¿’æ—¥æ™‚: {ensemble_meta.get('training_timestamp', 'N/A')}")
        print(f"   æ§‹æˆãƒ¢ãƒ‡ãƒ«: {list(ensemble_meta.get('models', {}).keys())}")

    return model_results


def estimate_efficiency_gains():
    """åŠ¹ç‡åŒ–åŠ¹æœæ¨å®š"""
    print("\nğŸ” === åŠ¹ç‡åŒ–åŠ¹æœæ¨å®š ===")

    # ç†è«–çš„åŠ¹ç‡åŒ–åŠ¹æœ
    original_features = 127
    optimized_features = 97
    deleted_features = 30

    # è¨ˆç®—åŠ¹ç‡å‘ä¸Šæ¨å®š
    efficiency_gain = (deleted_features / original_features) * 100
    processing_improvement = (1 - (optimized_features / original_features)) * 100

    print(f"ğŸ“Š ç‰¹å¾´é‡æœ€é©åŒ–åŠ¹æœ:")
    print(f"   å…ƒç‰¹å¾´é‡æ•°: {original_features}")
    print(f"   æœ€é©åŒ–å¾Œ: {optimized_features}")
    print(f"   å‰Šé™¤ç‰¹å¾´é‡: {deleted_features} å€‹")
    print(f"   å‰Šæ¸›ç‡: {efficiency_gain:.1f}%")
    print(f"   å‡¦ç†åŠ¹ç‡å‘ä¸Š: {processing_improvement:.1f}%")

    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ¨å®š
    feature_memory_per_sample = 8  # bytes (float64)
    sample_count = 8000  # æ¨å®š

    original_memory = (
        original_features * feature_memory_per_sample * sample_count / 1024 / 1024
    )  # MB
    optimized_memory = (
        optimized_features * feature_memory_per_sample * sample_count / 1024 / 1024
    )  # MB
    memory_saved = original_memory - optimized_memory

    print(f"\nğŸ“Š ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–æ¨å®š:")
    print(f"   å…ƒãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {original_memory:.2f} MB")
    print(f"   æœ€é©åŒ–å¾Œ: {optimized_memory:.2f} MB")
    print(
        f"   ãƒ¡ãƒ¢ãƒªç¯€ç´„: {memory_saved:.2f} MB ({memory_saved/original_memory*100:.1f}%)"
    )

    # å‰Šé™¤ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥åŠ¹æœ
    deleted_categories = {
        "SMAç³»ç§»å‹•å¹³å‡": 6,
        "ATRè¤‡æ•°æœŸé–“": 2,
        "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é‡è¤‡": 4,
        "RSIè¤‡æ•°æœŸé–“": 2,
        "å¯¾æ•°ãƒªã‚¿ãƒ¼ãƒ³": 5,
        "éå‰°ãƒ©ã‚°ç‰¹å¾´é‡": 5,
        "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“é‡è¤‡": 1,
        "çµ±è¨ˆæŒ‡æ¨™é‡è¤‡": 5,
    }

    print(f"\nğŸ“Š å‰Šé™¤ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥å†…è¨³:")
    for category, count in deleted_categories.items():
        print(f"   {category}: {count} å€‹")

    return {
        "efficiency_gain": efficiency_gain,
        "processing_improvement": processing_improvement,
        "memory_saved_mb": memory_saved,
        "memory_saved_percent": memory_saved / original_memory * 100,
    }


def check_system_readiness():
    """ã‚·ã‚¹ãƒ†ãƒ æº–å‚™çŠ¶æ³ç¢ºèª"""
    print("\nğŸ” === ã‚·ã‚¹ãƒ†ãƒ æº–å‚™çŠ¶æ³ç¢ºèª ===")

    checks = {
        "feature_order_manager": False,
        "feature_defaults": False,
        "feature_order_json": False,
        "97_models": False,
        "backtest_config": False,
        "metadata": False,
    }

    # FeatureOrderManagerç¢ºèª
    try:
        fom = FeatureOrderManager()
        if len(fom.FEATURE_ORDER_97) == 97:
            checks["feature_order_manager"] = True
    except Exception:
        pass

    # FeatureDefaultsç¢ºèª
    try:
        defaults = FeatureDefaults()
        if defaults.target_count == 97:
            checks["feature_defaults"] = True
    except Exception:
        pass

    # feature_order.jsonç¢ºèª
    feature_order_path = Path("config/core/feature_order.json")
    if feature_order_path.exists():
        try:
            with open(feature_order_path, "r") as f:
                data = json.load(f)
            if data.get("num_features") == 97:
                checks["feature_order_json"] = True
        except Exception:
            pass

    # 97ç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«ç¢ºèª
    model_dir = Path("models/production")
    model_files = ["lgbm_97_features.pkl", "xgb_97_features.pkl", "rf_97_features.pkl"]
    if all((model_dir / f).exists() for f in model_files):
        checks["97_models"] = True

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šç¢ºèª
    backtest_config = Path("config/validation/unified_97_features_backtest.yml")
    if backtest_config.exists():
        checks["backtest_config"] = True

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    metadata_file = Path("models/production/model_metadata_97.yaml")
    if metadata_file.exists():
        checks["metadata"] = True

    # çµæœè¡¨ç¤º
    print("ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ æº–å‚™çŠ¶æ³:")
    for check, status in checks.items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"   {status_icon} {check}: {'æº–å‚™å®Œäº†' if status else 'æœªå®Œäº†'}")

    readiness_score = sum(checks.values()) / len(checks) * 100
    print(f"\nğŸ¯ ã‚·ã‚¹ãƒ†ãƒ æº–å‚™ç‡: {readiness_score:.1f}%")

    return checks, readiness_score


def generate_optimization_report():
    """97ç‰¹å¾´é‡æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    print("\nğŸŠ === 97ç‰¹å¾´é‡æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Œæˆãƒ¬ãƒãƒ¼ãƒˆ ===")

    # çµ±åˆæ€§ç¢ºèª
    integration_ok = validate_system_integration()

    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç¢ºèª
    model_results = validate_model_performance()

    # åŠ¹ç‡åŒ–åŠ¹æœæ¨å®š
    efficiency_results = estimate_efficiency_gains()

    # ã‚·ã‚¹ãƒ†ãƒ æº–å‚™çŠ¶æ³ç¢ºèª
    checks, readiness_score = check_system_readiness()

    # ç·åˆè©•ä¾¡
    print(f"\nğŸ† === 97ç‰¹å¾´é‡æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ç·åˆè©•ä¾¡ ===")
    print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ€§: {'å®Œç’§' if integration_ok else 'è¦ä¿®æ­£'}")
    print(
        f"âœ… ãƒ¢ãƒ‡ãƒ«æº–å‚™çŠ¶æ³: {sum(1 for r in model_results.values() if r is not None)}/3 ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†"
    )
    print(
        f"âœ… åŠ¹ç‡åŒ–åŠ¹æœ: {efficiency_results['processing_improvement']:.1f}% å‡¦ç†åŠ¹ç‡å‘ä¸Š"
    )
    print(
        f"âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–: {efficiency_results['memory_saved_percent']:.1f}% ãƒ¡ãƒ¢ãƒªå‰Šæ¸›"
    )
    print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ æº–å‚™ç‡: {readiness_score:.1f}%")

    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
    print(f"\nğŸš€ === æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ ===")
    if readiness_score >= 80:
        print("ğŸŠ Phase 2å®Œå…¨å®Ÿè£…é”æˆï¼97ç‰¹å¾´é‡æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åŸºç›¤æ§‹ç¯‰å®Œäº†")
        print("ğŸ”„ æ¨å¥¨æ¬¡ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   1. Phase 4.3: æ€§èƒ½æ¯”è¼ƒãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        print("   2. Phase 4.4: æœ¬ç•ªã‚·ã‚¹ãƒ†ãƒ ç§»è¡Œæº–å‚™")
        print("   3. åŠ¹ç‡åŒ–åŠ¹æœå®Ÿæ¸¬ãƒ»æ¤œè¨¼")
    else:
        print("âš ï¸ ã‚·ã‚¹ãƒ†ãƒ æº–å‚™ä¸å®Œå…¨ãƒ»è¿½åŠ ä½œæ¥­å¿…è¦")
        print("ğŸ”§ è¦å¯¾å¿œé …ç›®:")
        for check, status in checks.items():
            if not status:
                print(f"   - {check}")

    return {
        "integration_ok": integration_ok,
        "model_results": model_results,
        "efficiency_results": efficiency_results,
        "readiness_score": readiness_score,
        "checks": checks,
    }


if __name__ == "__main__":
    print("ğŸŠ 97ç‰¹å¾´é‡æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åŠ¹æœæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)

    try:
        report = generate_optimization_report()

        print("\n" + "=" * 60)
        print("ğŸŠ 97ç‰¹å¾´é‡æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å®Œäº†ï¼")

        if report["readiness_score"] >= 80:
            print("âœ… Phase 2: 97ç‰¹å¾´é‡æœ€é©åŒ–åŸºç›¤æ§‹ç¯‰ - å®Œå…¨å®Ÿè£…é”æˆ")
        else:
            print("âš ï¸ Phase 2: è¿½åŠ ä½œæ¥­ãŒå¿…è¦ã§ã™")

    except Exception as e:
        logger.error(f"æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
