#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ¯”è¼ƒ
127ç‰¹å¾´é‡ vs 97ç‰¹å¾´é‡ vs 26ç‰¹å¾´é‡ã®ç›´æ¥æ¯”è¼ƒ
"""

import json
import logging
import os
import sys
from pathlib import Path

import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.model_selection import train_test_split

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def create_simple_test_data():
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
    np.random.seed(42)
    n_samples = 2000

    # ã‚ˆã‚Šç¾å®Ÿçš„ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    returns = np.random.normal(0, 0.02, n_samples)
    returns[500:600] += 0.03  # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
    returns[1200:1300] -= 0.03  # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰

    prices = 45000 * np.exp(np.cumsum(returns))

    data = pd.DataFrame(
        {
            "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1H"),
            "open": np.roll(prices, 1),
            "high": prices * (1 + np.abs(np.random.normal(0, 0.01, n_samples))),
            "low": prices * (1 - np.abs(np.random.normal(0, 0.01, n_samples))),
            "close": prices,
            "volume": np.random.lognormal(6, 0.3, n_samples),
        }
    )

    data["open"].iloc[0] = data["close"].iloc[0]

    return data


def create_features_manual(data, feature_set):
    """æ‰‹å‹•ç‰¹å¾´é‡ä½œæˆï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰"""
    df = data.copy()
    features = pd.DataFrame()

    # åŸºæœ¬ä¾¡æ ¼ç‰¹å¾´é‡
    if "close" in feature_set:
        features["close"] = df["close"]
    if "volume" in feature_set:
        features["volume"] = df["volume"]
    if "high" in feature_set:
        features["high"] = df["high"]
    if "low" in feature_set:
        features["low"] = df["low"]

    # ãƒªã‚¿ãƒ¼ãƒ³
    if "returns_1" in feature_set:
        features["returns_1"] = df["close"].pct_change().fillna(0)

    # ãƒ©ã‚°ç‰¹å¾´é‡
    if "close_lag_1" in feature_set:
        features["close_lag_1"] = df["close"].shift(1).fillna(df["close"].iloc[0])

    # SMA
    if "sma_20" in feature_set:
        features["sma_20"] = df["close"].rolling(20).mean().fillna(df["close"])

    # EMA
    if "ema_50" in feature_set:
        features["ema_50"] = df["close"].ewm(span=50).mean()

    # RSIï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if "rsi_14" in feature_set:
        delta = df["close"].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / (loss + 1e-8)
        rsi = 100 - (100 / (1 + rs))
        features["rsi_14"] = rsi.fillna(50)

    # MACDï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if "macd" in feature_set:
        ema12 = df["close"].ewm(span=12).mean()
        ema26 = df["close"].ewm(span=26).mean()
        features["macd"] = ema12 - ema26

    if "macd_signal" in feature_set:
        macd = features.get(
            "macd", df["close"].ewm(span=12).mean() - df["close"].ewm(span=26).mean()
        )
        features["macd_signal"] = macd.ewm(span=9).mean()

    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    if (
        "bb_upper" in feature_set
        or "bb_lower" in feature_set
        or "bb_width" in feature_set
    ):
        sma = df["close"].rolling(20).mean()
        std = df["close"].rolling(20).std()

        if "bb_upper" in feature_set:
            features["bb_upper"] = sma + (2 * std)
        if "bb_lower" in feature_set:
            features["bb_lower"] = sma - (2 * std)
        if "bb_width" in feature_set:
            features["bb_width"] = (4 * std).fillna(0)

    # ãƒœãƒªãƒ¥ãƒ¼ãƒ æŒ‡æ¨™
    if "volume_ratio" in feature_set:
        vol_avg = df["volume"].rolling(20).mean()
        features["volume_ratio"] = (df["volume"] / vol_avg).fillna(1)

    if "vwap" in feature_set:
        vwap = (df["close"] * df["volume"]).rolling(20).sum() / df["volume"].rolling(
            20
        ).sum()
        features["vwap"] = vwap.fillna(df["close"])

    if "obv" in feature_set:
        obv = np.where(
            df["close"] > df["close"].shift(1),
            df["volume"],
            np.where(df["close"] < df["close"].shift(1), -df["volume"], 0),
        )
        features["obv"] = pd.Series(obv).cumsum()

    # ATRï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if "atr_14" in feature_set:
        tr1 = df["high"] - df["low"]
        tr2 = np.abs(df["high"] - df["close"].shift(1))
        tr3 = np.abs(df["low"] - df["close"].shift(1))
        tr = np.maximum(tr1, np.maximum(tr2, tr3))
        features["atr_14"] = pd.Series(tr).rolling(14).mean().fillna(tr1.mean())

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    if "volatility_20" in feature_set:
        returns = df["close"].pct_change()
        features["volatility_20"] = returns.rolling(20).std().fillna(0.02)

    # ä¾¡æ ¼ãƒã‚¸ã‚·ãƒ§ãƒ³
    if "price_vs_sma20" in feature_set:
        sma = df["close"].rolling(20).mean()
        features["price_vs_sma20"] = ((df["close"] - sma) / sma).fillna(0)

    # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
    if "stoch_k" in feature_set:
        low_14 = df["low"].rolling(14).min()
        high_14 = df["high"].rolling(14).max()
        k_percent = 100 * ((df["close"] - low_14) / (high_14 - low_14 + 1e-8))
        features["stoch_k"] = k_percent.fillna(50)

    # Williams %R
    if "williams_r" in feature_set:
        high_14 = df["high"].rolling(14).max()
        low_14 = df["low"].rolling(14).min()
        wr = -100 * ((high_14 - df["close"]) / (high_14 - low_14 + 1e-8))
        features["williams_r"] = wr.fillna(-50)

    # ADXï¼ˆè¶…ç°¡æ˜“ç‰ˆï¼‰
    if "adx_14" in feature_set:
        features["adx_14"] = (
            np.abs(features.get("returns_1", df["close"].pct_change()))
            .rolling(14)
            .mean()
            .fillna(0.02)
            * 100
        )

    # æ™‚é–“ç‰¹å¾´é‡
    if "hour" in feature_set:
        features["hour"] = df["timestamp"].dt.hour

    if "is_us_session" in feature_set:
        hour = df["timestamp"].dt.hour
        features["is_us_session"] = ((hour >= 14) & (hour <= 21)).astype(int)

    # ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if "support_distance" in feature_set:
        low_20 = df["low"].rolling(20).min()
        features["support_distance"] = ((df["close"] - low_20) / df["close"]).fillna(0)

    # ä¸è¶³ç‰¹å¾´é‡ã‚’ãƒ€ãƒŸãƒ¼ã§è£œå®Œ
    target_count = len(feature_set)
    while len(features.columns) < target_count:
        dummy_name = f"dummy_{len(features.columns)}"
        features[dummy_name] = np.random.normal(0, 0.01, len(features))

    # éå‰°åˆ†å‰Šé™¤
    if len(features.columns) > target_count:
        features = features.iloc[:, :target_count]

    return features


def test_feature_set(data, feature_set, set_name):
    """ç‰¹å¾´é‡ã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
    logger.info(f"\n{set_name}ãƒ†ã‚¹ãƒˆé–‹å§‹ ({len(feature_set)}ç‰¹å¾´é‡)")

    # ç‰¹å¾´é‡ä½œæˆ
    X = create_features_manual(data, feature_set)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
    returns = data["close"].pct_change().fillna(0)
    buy_threshold = returns.quantile(0.7)
    sell_threshold = returns.quantile(0.3)

    y = np.where(returns > buy_threshold, 1, np.where(returns < sell_threshold, 0, -1))

    # æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«
    valid_mask = y != -1
    X_valid = X[valid_mask].fillna(0)
    y_valid = y[valid_mask]

    if len(X_valid) < 100:
        logger.warning(f"{set_name}: ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³")
        return None

    logger.info(f"æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«: {len(X_valid)}")
    logger.info(f"BUY: {np.sum(y_valid==1)}, SELL: {np.sum(y_valid==0)}")

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X_valid, y_valid, test_size=0.3, random_state=42, stratify=y_valid
    )

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = lgb.LGBMClassifier(
        objective="binary",
        n_estimators=50,
        max_depth=5,
        learning_rate=0.1,
        random_state=42,
        verbose=-1,
    )

    model.fit(X_train, y_train)

    # äºˆæ¸¬ãƒ»è©•ä¾¡
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    accuracy = accuracy_score(y_test, y_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_test, y_pred, average="binary"
    )

    # äºˆæ¸¬å¤šæ§˜æ€§
    pred_std = np.std(y_pred_proba)

    # ç°¡æ˜“å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    strong_signals = (y_pred_proba > 0.7) | (y_pred_proba < 0.3)
    correct_strong = ((y_pred_proba > 0.7) & (y_test == 1)) | (
        (y_pred_proba < 0.3) & (y_test == 0)
    )

    trading_accuracy = (
        correct_strong.sum() / strong_signals.sum() if strong_signals.sum() > 0 else 0
    )
    trade_count = strong_signals.sum()

    result = {
        "set_name": set_name,
        "n_features": len(feature_set),
        "n_samples": len(X_valid),
        "accuracy": accuracy,
        "f1_score": f1,
        "pred_std": pred_std,
        "trading_accuracy": trading_accuracy,
        "trade_count": trade_count,
    }

    logger.info(
        f"çµæœ: ç²¾åº¦={accuracy:.1%}, F1={f1:.1%}, äºˆæ¸¬å¤šæ§˜æ€§={pred_std:.3f}, å–å¼•ç²¾åº¦={trading_accuracy:.1%}"
    )

    return result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("=" * 60)
    logger.info("ç‰¹å¾´é‡ã‚»ãƒƒãƒˆç°¡æ˜“æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 60)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    data = create_simple_test_data()
    logger.info(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(data)}è¡Œ")

    # ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå®šç¾©
    feature_sets = {
        "essential_26": [
            "close",
            "volume",
            "high",
            "low",
            "sma_20",
            "ema_50",
            "price_vs_sma20",
            "rsi_14",
            "macd",
            "macd_signal",
            "atr_14",
            "volatility_20",
            "bb_width",
            "volume_ratio",
            "vwap",
            "obv",
            "returns_1",
            "close_lag_1",
            "bb_upper",
            "bb_lower",
            "support_distance",
            "hour",
            "is_us_session",
            "adx_14",
            "stoch_k",
            "williams_r",
        ],
        "medium_50": [
            # åŸºæœ¬ä¾¡æ ¼
            "close",
            "volume",
            "high",
            "low",
            # ç§»å‹•å¹³å‡
            "sma_20",
            "ema_50",
            # ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼
            "rsi_14",
            "macd",
            "macd_signal",
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            "atr_14",
            "volatility_20",
            "bb_width",
            "bb_upper",
            "bb_lower",
            # ãƒœãƒªãƒ¥ãƒ¼ãƒ 
            "volume_ratio",
            "vwap",
            "obv",
            # ãã®ä»–
            "returns_1",
            "close_lag_1",
            "price_vs_sma20",
            "support_distance",
            "hour",
            "is_us_session",
            "adx_14",
            "stoch_k",
            "williams_r",
        ]
        + [f"dummy_{i}" for i in range(25)],  # 50å€‹ã¾ã§åŸ‹ã‚ã‚‹
        "large_100": [
            # åŸºæœ¬+æ‹¡å¼µã‚»ãƒƒãƒˆ
            "close",
            "volume",
            "high",
            "low",
            "sma_20",
            "ema_50",
            "rsi_14",
            "macd",
            "macd_signal",
            "atr_14",
            "volatility_20",
            "bb_width",
            "bb_upper",
            "bb_lower",
            "volume_ratio",
            "vwap",
            "obv",
            "returns_1",
            "close_lag_1",
            "price_vs_sma20",
            "support_distance",
            "hour",
            "is_us_session",
            "adx_14",
            "stoch_k",
            "williams_r",
        ]
        + [f"dummy_{i}" for i in range(74)],  # 100å€‹ã¾ã§åŸ‹ã‚ã‚‹
    }

    # å„ã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
    results = []
    for set_name, feature_list in feature_sets.items():
        result = test_feature_set(data, feature_list, set_name)
        if result:
            results.append(result)

    # çµæœæ¯”è¼ƒ
    logger.info("\n" + "=" * 60)
    logger.info("æ¯”è¼ƒçµæœ")
    logger.info("=" * 60)

    for result in results:
        print(f"\nğŸ” {result['set_name'].upper()}:")
        print(f"  ç‰¹å¾´é‡æ•°: {result['n_features']}")
        print(f"  ç²¾åº¦: {result['accuracy']:.1%}")
        print(f"  F1ã‚¹ã‚³ã‚¢: {result['f1_score']:.1%}")
        print(f"  äºˆæ¸¬å¤šæ§˜æ€§: {result['pred_std']:.3f}")
        print(f"  å–å¼•ç²¾åº¦: {result['trading_accuracy']:.1%}")
        print(f"  å–å¼•æ•°: {result['trade_count']}")

    # æ¨å¥¨æ±ºå®š
    if results:
        # ç·åˆã‚¹ã‚³ã‚¢ = F1 * 0.5 + å–å¼•ç²¾åº¦ * 0.3 + äºˆæ¸¬å¤šæ§˜æ€§ * 0.2
        for result in results:
            result["composite_score"] = (
                result["f1_score"] * 0.5
                + result["trading_accuracy"] * 0.3
                + result["pred_std"] * 0.2
            )

        best = max(results, key=lambda x: x["composite_score"])

        print(f"\nğŸ† æ¨å¥¨: {best['set_name'].upper()}")
        print(f"   ç‰¹å¾´é‡æ•°: {best['n_features']}")
        print(f"   ç·åˆã‚¹ã‚³ã‚¢: {best['composite_score']:.3f}")

    print("\n" + "=" * 60)
    print("ğŸ“‹ çµè«–")
    print("=" * 60)
    print("1. 26ç‰¹å¾´é‡ï¼ˆessentialï¼‰ã¯åŠ¹ç‡æ€§é‡è¦–")
    print("2. 50ç‰¹å¾´é‡ï¼ˆmediumï¼‰ã¯ãƒãƒ©ãƒ³ã‚¹å‹")
    print("3. 100ç‰¹å¾´é‡ï¼ˆlargeï¼‰ã¯åŒ…æ‹¬æ€§é‡è¦–")
    print("æ¨å¥¨: å–å¼•ç²¾åº¦ã¨è¨ˆç®—åŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦é¸æŠ")


if __name__ == "__main__":
    main()
