#!/usr/bin/env python3
"""
127ç‰¹å¾´é‡çµ±åˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
99.2%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸè¦å› ã‚’127ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆ

ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:
1. 99.2%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸè¦å› åˆ†æ
2. 127ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã§åŒæ§˜ã®æ‰‹æ³•ã‚’é©ç”¨
3. ç‰¹å¾´é‡é¸æŠï¼‹ãƒã‚¤ãƒŠãƒªåˆ†é¡ã®çµ„ã¿åˆã‚ã›
4. 127ç‰¹å¾´é‡å®Œå…¨å¯¾å¿œã®é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ä½œæˆ
"""

import json
import logging
import os
import sys
from pathlib import Path

import joblib
import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    precision_recall_fscore_support,
)
from sklearn.model_selection import train_test_split

sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

from crypto_bot.ml.feature_order_manager import FeatureOrderManager
from crypto_bot.ml.preprocessor import FeatureEngineer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def load_robust_model_insights():
    """99.2%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸè¦å› ã‚’åˆ†æ"""
    logger.info("ğŸ” 99.2%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸè¦å› åˆ†æé–‹å§‹")

    # æˆåŠŸã—ãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    features_path = Path("models/production/robust_model_features.json")
    if features_path.exists():
        with open(features_path, "r") as f:
            successful_features = json.load(f)
        logger.info(f"æˆåŠŸã—ãŸ30ç‰¹å¾´é‡: {len(successful_features)}å€‹")

        # æˆåŠŸè¦å› åˆ†æ
        feature_categories = {
            "price_features": [
                f
                for f in successful_features
                if any(x in f for x in ["returns", "price", "position"])
            ],
            "technical_indicators": [
                f
                for f in successful_features
                if any(x in f for x in ["rsi", "stoch", "mfi", "cci", "williams"])
            ],
            "trend_features": [
                f
                for f in successful_features
                if any(x in f for x in ["trend", "momentum", "roc"])
            ],
            "volatility_features": [
                f
                for f in successful_features
                if any(x in f for x in ["volatility", "atr", "zscore"])
            ],
            "support_resistance": [
                f
                for f in successful_features
                if any(x in f for x in ["support", "resistance", "mean_reversion"])
            ],
        }

        logger.info("æˆåŠŸç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ†æ:")
        for category, features in feature_categories.items():
            logger.info(
                f"  {category}: {len(features)}å€‹ - {features[:3]}..."
                if len(features) > 3
                else f"  {category}: {features}"
            )

        return successful_features, feature_categories
    else:
        logger.warning("99.2%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return [], {}


def create_enhanced_training_data():
    """127ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®æ”¹è‰¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    np.random.seed(42)
    n_rows = 15000  # ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿

    logger.info(f"127ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç”¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {n_rows} samples")

    # ã‚ˆã‚Šç¾å®Ÿçš„ãªå¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿
    t = np.arange(n_rows)

    # è¤‡æ•°ã®å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ 
    bull_market = np.sin(2 * np.pi * t / 1000) > 0.4  # å¼·æ°—ç›¸å ´
    bear_market = np.sin(2 * np.pi * t / 800) < -0.4  # å¼±æ°—ç›¸å ´
    sideways = ~(bull_market | bear_market)  # ãƒ¬ãƒ³ã‚¸ç›¸å ´

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“
    high_vol = np.abs(np.sin(2 * np.pi * t / 200)) > 0.7

    # ãƒ™ãƒ¼ã‚¹ãƒªã‚¿ãƒ¼ãƒ³
    returns = np.random.normal(0, 0.01, n_rows)

    # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®èª¿æ•´
    returns[bull_market] += np.random.normal(0.002, 0.008, bull_market.sum())
    returns[bear_market] += np.random.normal(-0.002, 0.008, bear_market.sum())
    returns[sideways] += np.random.normal(0, 0.005, sideways.sum())

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
    returns[high_vol] *= 2.5

    # ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
    trend_component = 0.001 * np.sin(2 * np.pi * t / 600)
    returns += trend_component

    # ç´¯ç©ä¾¡æ ¼
    base_price = 45000
    log_returns = np.cumsum(returns)
    close_prices = base_price * np.exp(log_returns)

    # ç¾å®Ÿçš„ãªOHLCãƒ‡ãƒ¼ã‚¿
    data = pd.DataFrame(
        {
            "timestamp": pd.date_range(start="2023-01-01", periods=n_rows, freq="1H"),
            "close": close_prices,
        }
    )

    # Openä¾¡æ ¼ï¼ˆå‰ã®closeãƒ™ãƒ¼ã‚¹ï¼‰
    data["open"] = data["close"].shift(1).fillna(close_prices[0]) * np.random.normal(
        1, 0.0008, n_rows
    )

    # High/Lowä¾¡æ ¼ï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªç¯„å›²ï¼‰
    intraday_range = np.random.exponential(0.003, n_rows)
    intraday_range[high_vol] *= 2  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ™‚ã¯æ‹¡å¤§

    oc_max = np.maximum(data["open"], data["close"])
    oc_min = np.minimum(data["open"], data["close"])

    data["high"] = oc_max * (1 + intraday_range)
    data["low"] = oc_min * (1 - intraday_range * 0.8)

    # Volumeï¼ˆä¾¡æ ¼å¤‰å‹•ã¨ç›¸é–¢ï¼‰
    price_change = np.abs(data["close"].pct_change())
    base_volume = np.random.lognormal(np.log(800), 0.3, n_rows)
    volume_multiplier = 1 + 2.0 * price_change.fillna(0)
    data["volume"] = base_volume * volume_multiplier

    logger.info(f"æ‹¡å¼µå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†:")
    logger.info(f"  ä¾¡æ ¼ç¯„å›²: ${data['close'].min():.0f} - ${data['close'].max():.0f}")
    logger.info(
        f"  å¼·æ°—ç›¸å ´: {bull_market.sum()} ({bull_market.sum()/len(bull_market)*100:.1f}%)"
    )
    logger.info(
        f"  å¼±æ°—ç›¸å ´: {bear_market.sum()} ({bear_market.sum()/len(bear_market)*100:.1f}%)"
    )
    logger.info(
        f"  ãƒ¬ãƒ³ã‚¸ç›¸å ´: {sideways.sum()} ({sideways.sum()/len(sideways)*100:.1f}%)"
    )
    logger.info(
        f"  é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {high_vol.sum()} ({high_vol.sum()/len(high_vol)*100:.1f}%)"
    )

    return data


def create_sophisticated_targets(features, close_prices):
    """é«˜åº¦ãªåˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆï¼ˆ99.2%ãƒ¢ãƒ‡ãƒ«ã®æ‰‹æ³•ã‚’æ”¹è‰¯ï¼‰"""
    logger.info("é«˜åº¦ãªãƒã‚¤ãƒŠãƒªåˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆé–‹å§‹")

    # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒªã‚¿ãƒ¼ãƒ³
    returns_1h = close_prices.pct_change(1)
    returns_4h = close_prices.pct_change(4)
    returns_8h = close_prices.pct_change(8)
    returns_24h = close_prices.pct_change(24)

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´æ¸ˆã¿ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆè¤‡æ•°æœŸé–“ï¼‰
    vol_10 = returns_1h.rolling(10).std()
    vol_20 = returns_1h.rolling(20).std()
    vol_50 = returns_1h.rolling(50).std()

    # è¤‡åˆãƒªã‚¿ãƒ¼ãƒ³æŒ‡æ¨™ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    combined_returns = (
        0.30 * returns_1h + 0.30 * returns_4h + 0.25 * returns_8h + 0.15 * returns_24h
    ).fillna(0)

    # ãƒãƒ«ãƒãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
    vol_combined = (vol_10 + vol_20 + vol_50) / 3
    vol_adjusted_returns = combined_returns / (vol_combined + 1e-6)

    # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã‚’è€ƒæ…®
    sma_20 = close_prices.rolling(20).mean()
    sma_50 = close_prices.rolling(50).mean()
    trend_strength = (sma_20 - sma_50) / sma_50

    # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘åˆ¥ã®é–¾å€¤èª¿æ•´
    base_buy_threshold = vol_adjusted_returns.quantile(0.70)  # ä¸Šä½30%
    base_sell_threshold = vol_adjusted_returns.quantile(0.30)  # ä¸‹ä½30%

    # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«ã‚ˆã‚‹é–¾å€¤èª¿æ•´
    buy_threshold = base_buy_threshold * (1 + 0.2 * np.sign(trend_strength))
    sell_threshold = base_sell_threshold * (1 - 0.2 * np.sign(trend_strength))

    # æ˜ç¢ºãªä¿¡å·ã®ã¿ã‚’ä½¿ç”¨ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    strong_buy_mask = vol_adjusted_returns >= buy_threshold
    strong_sell_mask = vol_adjusted_returns <= sell_threshold
    valid_mask = strong_buy_mask | strong_sell_mask

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ
    targets = np.where(strong_buy_mask, 1, 0)  # 1: BUY, 0: SELL

    logger.info(f"é«˜åº¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†æ:")
    valid_targets = targets[valid_mask]
    sell_count = (valid_targets == 0).sum()
    buy_count = (valid_targets == 1).sum()
    logger.info(f"  SELL (0): {sell_count} ({sell_count/len(valid_targets)*100:.1f}%)")
    logger.info(f"  BUY (1): {buy_count} ({buy_count/len(valid_targets)*100:.1f}%)")
    logger.info(
        f"  æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«: {len(valid_targets)} ({len(valid_targets)/len(targets)*100:.1f}%)"
    )
    logger.info(
        f"  ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ç¯„å›²: buy_th={base_buy_threshold:.3f}, sell_th={base_sell_threshold:.3f}"
    )

    return targets, valid_mask


def intelligent_feature_selection(X, y, successful_features, k_best=60):
    """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆç‰¹å¾´é‡é¸æŠï¼ˆ99.2%ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è¦‹æ´»ç”¨ï¼‰"""
    logger.info(f"ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆç‰¹å¾´é‡é¸æŠé–‹å§‹: 127 â†’ {k_best}ç‰¹å¾´é‡")

    # 99.2%ãƒ¢ãƒ‡ãƒ«ã§æˆåŠŸã—ãŸç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—ã‚’å„ªå…ˆ
    priority_patterns = [
        "returns",
        "rsi",
        "stoch",
        "price_position",
        "price_vs_sma",
        "mfi",
        "trend_direction",
        "cci",
        "williams_r",
        "ultimate_oscillator",
        "support",
        "resistance",
        "zscore",
        "mean_reversion",
        "roc",
    ]

    # çµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠ
    selector_f = SelectKBest(score_func=f_classif, k="all")
    selector_f.fit(X, y)
    f_scores = selector_f.scores_

    # ç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹é¸æŠ
    mi_scores = mutual_info_classif(X, y, random_state=42)

    # è¤‡åˆã‚¹ã‚³ã‚¢è¨ˆç®—
    feature_scores = []
    for i, col in enumerate(X.columns):
        # åŸºæœ¬ã‚¹ã‚³ã‚¢
        f_score = f_scores[i] if not np.isnan(f_scores[i]) else 0
        mi_score = mi_scores[i] if not np.isnan(mi_scores[i]) else 0

        # å„ªå…ˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒœãƒ¼ãƒŠã‚¹
        priority_bonus = 0
        for pattern in priority_patterns:
            if pattern in col.lower():
                priority_bonus += 0.2
                break

        # 99.2%ãƒ¢ãƒ‡ãƒ«æˆåŠŸç‰¹å¾´é‡ãƒœãƒ¼ãƒŠã‚¹
        success_bonus = 0.5 if col in successful_features else 0

        # è¤‡åˆã‚¹ã‚³ã‚¢
        composite_score = (
            f_score * 0.4 + mi_score * 0.4 + priority_bonus + success_bonus
        )

        feature_scores.append(
            (col, composite_score, f_score, mi_score, priority_bonus, success_bonus)
        )

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    feature_scores.sort(key=lambda x: x[1], reverse=True)

    # ä¸Šä½k_bestç‰¹å¾´é‡ã‚’é¸æŠ
    selected_features = [item[0] for item in feature_scores[:k_best]]

    logger.info(f"ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆç‰¹å¾´é‡é¸æŠçµæœ:")
    logger.info(f"  é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡: {len(selected_features)}")
    logger.info(
        f"  99.2%ãƒ¢ãƒ‡ãƒ«æˆåŠŸç‰¹å¾´é‡å«æœ‰: {sum(1 for f in selected_features if f in successful_features)}"
    )

    logger.info("ãƒˆãƒƒãƒ—10é¸æŠç‰¹å¾´é‡:")
    for i, (feat, comp_score, f_score, mi_score, p_bonus, s_bonus) in enumerate(
        feature_scores[:10]
    ):
        logger.info(
            f"  {i+1:2d}. {feat}: comp={comp_score:.3f} (f={f_score:.1f}, mi={mi_score:.3f}, p={p_bonus:.1f}, s={s_bonus:.1f})"
        )

    return X[selected_features], selected_features


def train_integrated_127_model():
    """127ç‰¹å¾´é‡çµ±åˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
    logger.info("=" * 80)
    logger.info("127ç‰¹å¾´é‡çµ±åˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹")
    logger.info("=" * 80)

    # 99.2%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸè¦å› åˆ†æ
    successful_features, feature_categories = load_robust_model_insights()

    # æ”¹è‰¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    data = create_enhanced_training_data()

    # å®Œå…¨ãª127ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    config = {
        "ml": {
            "feat_period": 14,
            "lags": [1, 2, 3, 4, 5],
            "rolling_window": 20,
            "horizon": 5,
            "target_type": "classification",
            # 127ç‰¹å¾´é‡å®Œå…¨ã‚»ãƒƒãƒˆï¼ˆå®Ÿè£…æ¸ˆã¿ç‰¹å¾´é‡ã‚’åŸºã«æ§‹æˆï¼‰
            "extra_features": [
                # åŸºæœ¬OHLCV
                "open",
                "high",
                "low",
                "close",
                "volume",
                # ä¾¡æ ¼ãƒ©ã‚°ãƒ»ãƒªã‚¿ãƒ¼ãƒ³
                "close_lag_1",
                "close_lag_2",
                "close_lag_3",
                "returns_1",
                "returns_2",
                "returns_3",
                "returns_5",
                "log_returns_1",
                "log_returns_2",
                "log_returns_3",
                "log_returns_5",
                # ç§»å‹•å¹³å‡
                "sma_5",
                "sma_10",
                "sma_20",
                "sma_50",
                "sma_100",
                "sma_200",
                "ema_5",
                "ema_10",
                "ema_20",
                "ema_50",
                "ema_100",
                "ema_200",
                # ä¾¡æ ¼ãƒã‚¸ã‚·ãƒ§ãƒ³
                "price_position_20",
                "price_position_50",
                "price_vs_sma20",
                # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
                "bb_upper",
                "bb_middle",
                "bb_lower",
                "bb_width",
                "bb_position",
                # RSI
                "rsi_14",
                "rsi_7",
                "rsi_21",
                "rsi_oversold",
                "rsi_overbought",
                # MACD
                "macd",
                "macd_signal",
                "macd_hist",
                "macd_cross_up",
                "macd_cross_down",
                # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
                "stoch_k",
                "stoch_d",
                "stoch_oversold",
                "stoch_overbought",
                # ATRãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                "atr_14",
                "atr_7",
                "atr_21",
                "volatility_20",
                "volatility_50",
                "true_range",
                # ãƒœãƒªãƒ¥ãƒ¼ãƒ 
                "volume_sma_20",
                "volume_ratio",
                "volume_trend",
                "vwap",
                "vwap_distance",
                "obv",
                "obv_sma",
                "cmf",
                "mfi",
                "ad_line",
                # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
                "adx_14",
                "plus_di",
                "minus_di",
                "trend_strength",
                "trend_direction",
                "cci_20",
                "williams_r",
                "ultimate_oscillator",
                "momentum_14",
                # ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹
                "support_distance",
                "resistance_distance",
                "support_strength",
                # çµ±è¨ˆãƒ»ãã®ä»–
                "zscore",
                "mean_reversion_20",
                "mean_reversion_50",
                "skewness_20",
                "kurtosis_20",
                # æ™‚é–“ç‰¹å¾´é‡
                "hour",
                "day_of_week",
                "is_weekend",
                "is_asian_session",
                "is_european_session",
                "is_us_session",
                # è¿½åŠ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«
                "roc_10",
                "roc_20",
                "trix",
                "mass_index",
                "price_efficiency",
                "trend_consistency",
            ],
        }
    }

    logger.info(
        f"127ç‰¹å¾´é‡å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ è¨­å®š: {len(config['ml']['extra_features'])} ç‰¹å¾´é‡"
    )

    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    logger.info("127ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹...")
    engineer = FeatureEngineer(config)
    features = engineer.fit_transform(data)

    logger.info(f"ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡: {features.shape}")

    # é«˜åº¦ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ
    targets, valid_mask = create_sophisticated_targets(features, data["close"])

    # æœ‰åŠ¹ãªã‚µãƒ³ãƒ—ãƒ«ã®ã¿ä½¿ç”¨
    X = features[valid_mask]
    y = targets[valid_mask]

    logger.info(f"å­¦ç¿’ç”¨æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«: {len(X)}")

    if len(X) < 2000:
        raise ValueError(f"å­¦ç¿’ã«å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³: {len(X)} < 2000")

    # NaNå€¤å‡¦ç†
    X = X.fillna(X.median())

    # ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆç‰¹å¾´é‡é¸æŠ
    X_selected, selected_features = intelligent_feature_selection(
        X, y, successful_features, k_best=60
    )

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X_selected, y, test_size=0.2, random_state=42, stratify=y
    )

    logger.info(f"å­¦ç¿’ã‚»ãƒƒãƒˆ: {X_train.shape}")
    logger.info(f"ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ: {X_test.shape}")

    # æ”¹è‰¯LightGBMãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    logger.info("æ”¹è‰¯LightGBMãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...")

    lgb_params = {
        "objective": "binary",
        "metric": "binary_logloss",
        "boosting_type": "gbdt",
        "num_leaves": 64,  # å¢—åŠ 
        "learning_rate": 0.08,  # ã‚„ã‚„æ¸›å°‘
        "feature_fraction": 0.85,  # å¢—åŠ 
        "bagging_fraction": 0.85,  # å¢—åŠ 
        "bagging_freq": 3,
        "min_child_samples": 15,  # æ¸›å°‘
        "min_child_weight": 0.001,
        "min_split_gain": 0.01,  # æ¸›å°‘
        "reg_alpha": 0.05,  # æ¸›å°‘
        "reg_lambda": 0.05,  # æ¸›å°‘
        "max_depth": 12,  # å¢—åŠ 
        "random_state": 42,
        "verbose": -1,
    }

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’LightGBMå½¢å¼ã«å¤‰æ›
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = lgb.train(
        lgb_params,
        train_data,
        valid_sets=[valid_data],
        num_boost_round=300,  # å¢—åŠ 
        callbacks=[lgb.early_stopping(30), lgb.log_evaluation(0)],
    )

    # äºˆæ¸¬ã¨è©•ä¾¡
    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred = (y_pred_proba > 0.5).astype(int)

    accuracy = accuracy_score(y_test, y_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_test, y_pred, average="binary"
    )

    logger.info(f"127ç‰¹å¾´é‡çµ±åˆãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
    logger.info(f"  Accuracy: {accuracy:.1%}")
    logger.info(f"  Precision: {precision:.1%}")
    logger.info(f"  Recall: {recall:.1%}")
    logger.info(f"  F1-Score: {f1:.1%}")

    # è©³ç´°è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ
    report = classification_report(y_test, y_pred, target_names=["SELL", "BUY"])
    logger.info(f"åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:\\n{report}")

    # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
    importance = model.feature_importance(importance_type="gain")
    feature_importance = list(zip(selected_features, importance))
    feature_importance.sort(key=lambda x: x[1], reverse=True)

    logger.info("ãƒˆãƒƒãƒ—15ç‰¹å¾´é‡é‡è¦åº¦:")
    for i, (feat, imp) in enumerate(feature_importance[:15]):
        success_mark = "âœ…" if feat in successful_features else "  "
        logger.info(f"  {i+1:2d}. {feat}: {imp:.0f} {success_mark}")

    # ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    models_dir = Path("models/production")
    models_dir.mkdir(parents=True, exist_ok=True)

    model_path = models_dir / "integrated_127_features_model.pkl"
    joblib.dump(model, model_path)
    logger.info(f"çµ±åˆ127ç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")

    # é¸æŠç‰¹å¾´é‡ä¿å­˜
    features_path = models_dir / "integrated_127_model_features.json"
    with open(features_path, "w") as f:
        json.dump(selected_features, f, indent=2)
    logger.info(f"é¸æŠç‰¹å¾´é‡ä¿å­˜: {features_path}")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    metadata = {
        "model_type": "LightGBM_Binary_Integrated_127",
        "accuracy": float(accuracy),
        "precision": float(precision),
        "recall": float(recall),
        "f1_score": float(f1),
        "n_features_total": 127,
        "n_features_selected": len(selected_features),
        "n_samples_train": len(X_train),
        "n_samples_test": len(X_test),
        "successful_features_included": len(
            [f for f in selected_features if f in successful_features]
        ),
        "lgb_params": lgb_params,
        "feature_categories": {
            k: len([f for f in selected_features if f in v])
            for k, v in feature_categories.items()
        },
        "top_10_features": [feat for feat, _ in feature_importance[:10]],
    }

    metadata_path = models_dir / "integrated_127_model_metadata.json"
    with open(metadata_path, "w") as f:
        json.dump(metadata, f, indent=2)
    logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {metadata_path}")

    # äºˆæ¸¬ç¢ºç‡åˆ†å¸ƒç¢ºèª
    logger.info(f"äºˆæ¸¬ç¢ºç‡åˆ†å¸ƒ:")
    logger.info(f"  å¹³å‡: {y_pred_proba.mean():.3f}")
    logger.info(f"  æ¨™æº–åå·®: {y_pred_proba.std():.3f}")
    logger.info(f"  æœ€å°å€¤: {y_pred_proba.min():.3f}")
    logger.info(f"  æœ€å¤§å€¤: {y_pred_proba.max():.3f}")
    logger.info(f"  ä¸­å¤®å€¤: {np.median(y_pred_proba):.3f}")

    # çµæœã‚µãƒãƒªãƒ¼
    logger.info("=" * 80)
    logger.info("127ç‰¹å¾´é‡çµ±åˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
    logger.info("=" * 80)
    logger.info(f"æœ€çµ‚ç²¾åº¦: {accuracy:.1%}")
    logger.info(f"æœ€çµ‚F1ã‚¹ã‚³ã‚¢: {f1:.1%}")
    logger.info(f"é¸æŠç‰¹å¾´é‡: {len(selected_features)}/127")
    logger.info(
        f"99.2%ãƒ¢ãƒ‡ãƒ«çŸ¥è¦‹æ´»ç”¨: {len([f for f in selected_features if f in successful_features])}/30"
    )
    logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
    logger.info("127ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ã§ã®é«˜ç²¾åº¦å–å¼•æº–å‚™å®Œäº†ï¼")

    return model, selected_features, accuracy, f1, metadata


if __name__ == "__main__":
    try:
        model, features, accuracy, f1, metadata = train_integrated_127_model()
        print(f"\\nâœ… 127ç‰¹å¾´é‡çµ±åˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸï¼")
        print(f"ç²¾åº¦: {accuracy:.1%}")
        print(f"F1ã‚¹ã‚³ã‚¢: {f1:.1%}")
        print(f"é¸æŠç‰¹å¾´é‡: {len(features)}")
        print(f"99.2%ãƒ¢ãƒ‡ãƒ«çŸ¥è¦‹çµ±åˆ: {metadata['successful_features_included']}/30")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«ä½œæˆå¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
