#!/usr/bin/env python3
"""
Phase H.25: 125ç‰¹å¾´é‡å¯¾å¿œã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å¤–éƒ¨APIç‰¹å¾´é‡ã‚’é™¤å¤–ã—ãŸ125ç‰¹å¾´é‡ã§LGBM/XGBoost/RandomForestã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
"""

import logging
import os
import pickle
import sys
from datetime import datetime

import joblib
import numpy as np
import pandas as pd

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from crypto_bot.ml.ensemble import TradingEnsembleClassifier
from crypto_bot.ml.feature_order_manager import FeatureOrderManager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_dummy_data(n_samples=1000, n_features=125):
    """125ç‰¹å¾´é‡ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    np.random.seed(42)

    # FeatureOrderManagerã‹ã‚‰ç‰¹å¾´é‡é †åºã‚’å–å¾—
    fom = FeatureOrderManager()
    feature_order_125 = fom.FEATURE_ORDER_125

    # FEATURE_ORDER_125ã®é †åºã§ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features), columns=feature_order_125[:n_features]
    )

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆãƒã‚¤ãƒŠãƒªåˆ†é¡ï¼‰
    y = np.random.randint(0, 2, size=n_samples)

    return X, y


def main():
    logger.info("ğŸš€ Phase H.25: Creating 125-feature ensemble model...")

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    X, y = create_dummy_data(n_samples=1000, n_features=125)
    logger.info(f"âœ… Created dummy data: {X.shape}")

    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«è¨­å®š
    ensemble_config = {
        "models": ["lgbm", "xgb", "rf"],
        "model_weights": [0.5, 0.3, 0.2],
        "lgbm_params": {
            "n_estimators": 100,
            "max_depth": 5,
            "learning_rate": 0.1,
            "num_leaves": 31,
            "random_state": 42,
            "n_jobs": -1,
            "verbosity": -1,
        },
        "xgb_params": {
            "n_estimators": 100,
            "max_depth": 5,
            "learning_rate": 0.1,
            "random_state": 42,
            "n_jobs": -1,
            "verbosity": 0,
        },
        "rf_params": {
            "n_estimators": 100,
            "max_depth": 5,
            "random_state": 42,
            "n_jobs": -1,
        },
        "use_calibration": False,
        "cv_folds": 3,
    }

    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    ensemble_model = TradingEnsembleClassifier(ensemble_config)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    logger.info("ğŸ”§ Training ensemble model...")
    ensemble_model.fit(X, y)

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_dir = "models/production"
    os.makedirs(model_dir, exist_ok=True)

    # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    model_path = os.path.join(model_dir, "model.pkl")
    if os.path.exists(model_path):
        backup_path = os.path.join(
            model_dir, f"model_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        )
        os.rename(model_path, backup_path)
        logger.info(f"ğŸ“¦ Backed up existing model to: {backup_path}")

    # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    joblib.dump(ensemble_model, model_path)
    logger.info(f"ğŸ’¾ Saved ensemble model to: {model_path}")

    # feature_order.jsonã‚‚æ›´æ–°
    fom = FeatureOrderManager()
    fom.save_feature_order(fom.FEATURE_ORDER_125)
    logger.info("âœ… Updated feature_order.json with 125 features")

    # æ¤œè¨¼
    logger.info("\nğŸ” Model validation:")
    predictions = ensemble_model.predict_proba(X[:10])
    logger.info(f"Sample predictions shape: {predictions.shape}")
    logger.info(f"Sample predictions: {predictions[:3]}")

    logger.info("\nâœ… Phase H.25: Ensemble model creation completed!")
    logger.info(f"Model features: {len(fom.FEATURE_ORDER_125)} features")
    logger.info(f"Model type: TradingEnsembleClassifier with LGBM/XGBoost/RandomForest")


if __name__ == "__main__":
    main()
