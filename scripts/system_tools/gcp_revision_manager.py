#!/usr/bin/env python3
"""
Phase H.28.4: GCPé‹ç”¨ç’°å¢ƒå®Œå…¨æœ€é©åŒ–ãƒ»ãƒªãƒ“ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
Cloud Runãƒªãƒ“ã‚¸ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†ãƒ»ç¾åœ¨ç¨¼åƒãƒªãƒ“ã‚¸ãƒ§ãƒ³é™å®šç›£è¦–
"""

import json
import logging
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class GCPRevisionManager:
    """GCP Cloud Runãƒªãƒ“ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self,
        service_name: str = "crypto-bot-service-prod",
        region: str = "asia-northeast1",
    ):
        """
        GCPãƒªãƒ“ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–

        Args:
            service_name: Cloud Runã‚µãƒ¼ãƒ“ã‚¹å
            region: GCPãƒªãƒ¼ã‚¸ãƒ§ãƒ³
        """
        self.service_name = service_name
        self.region = region
        self.max_revisions = 3  # Phase H.28.4: æœ€æ–°3ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã¾ã§ä¿æŒ

        logger.info(f"GCP Revision Manager initialized: {service_name} in {region}")

    def get_current_revision_info(self) -> Dict:
        """ç¾åœ¨ç¨¼åƒä¸­ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³æƒ…å ±å–å¾—"""
        try:
            cmd = [
                "gcloud",
                "run",
                "services",
                "describe",
                self.service_name,
                "--region",
                self.region,
                "--format",
                "json",
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            service_info = json.loads(result.stdout)

            # ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯æƒ…å ±ã‹ã‚‰ç¾åœ¨ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç‰¹å®š
            current_revision = None
            for traffic in service_info.get("status", {}).get("traffic", []):
                if traffic.get("percent", 0) > 0:
                    current_revision = traffic.get("revisionName")
                    break

            revision_info = {
                "current_revision": current_revision,
                "service_url": service_info.get("status", {}).get("url"),
                "last_modified": service_info.get("metadata", {})
                .get("annotations", {})
                .get("serving.knative.dev/lastModifier"),
                "traffic_allocation": service_info.get("status", {}).get("traffic", []),
            }

            logger.info(f"Current revision: {current_revision}")
            return revision_info

        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to get current revision info: {e}")
            return {}
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse service info JSON: {e}")
            return {}

    def list_all_revisions(self) -> List[Dict]:
        """å…¨ãƒªãƒ“ã‚¸ãƒ§ãƒ³ä¸€è¦§å–å¾—"""
        try:
            cmd = [
                "gcloud",
                "run",
                "revisions",
                "list",
                "--service",
                self.service_name,
                "--region",
                self.region,
                "--format",
                "json",
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            revisions = json.loads(result.stdout)

            # ä½œæˆæ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
            revisions.sort(
                key=lambda x: x.get("metadata", {}).get("creationTimestamp", ""),
                reverse=True,
            )

            revision_list = []
            for rev in revisions:
                metadata = rev.get("metadata", {})
                status = rev.get("status", {})

                revision_info = {
                    "name": metadata.get("name"),
                    "creation_time": metadata.get("creationTimestamp"),
                    "ready": any(
                        c.get("status") == "True" for c in status.get("conditions", [])
                    ),
                    "serving": metadata.get("labels", {}).get(
                        "serving.knative.dev/service"
                    )
                    == self.service_name,
                    "age_hours": self._calculate_age_hours(
                        metadata.get("creationTimestamp")
                    ),
                }
                revision_list.append(revision_info)

            logger.info(f"Found {len(revision_list)} revisions")
            return revision_list

        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to list revisions: {e}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse revisions JSON: {e}")
            return []

    def cleanup_old_revisions(self) -> Tuple[int, List[str]]:
        """
        Phase H.28.4: å¤ã„ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        æœ€æ–°3ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚’é™¤ã„ã¦å¤ã„ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚’å‰Šé™¤

        Returns:
            Tuple[å‰Šé™¤ã•ã‚ŒãŸãƒªãƒ“ã‚¸ãƒ§ãƒ³æ•°, å‰Šé™¤ã•ã‚ŒãŸãƒªãƒ“ã‚¸ãƒ§ãƒ³åãƒªã‚¹ãƒˆ]
        """
        logger.info("Starting revision cleanup...")

        revisions = self.list_all_revisions()
        current_info = self.get_current_revision_info()
        current_revision = current_info.get("current_revision")

        if not revisions:
            logger.warning("No revisions found")
            return 0, []

        # ç¾åœ¨ç¨¼åƒä¸­ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚’ä¿è­·
        protected_revisions = {current_revision} if current_revision else set()

        # æœ€æ–°ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚‚ä¿è­·ï¼ˆä¸Šä½max_revisionsã¾ã§ï¼‰
        for i, rev in enumerate(revisions[: self.max_revisions]):
            protected_revisions.add(rev["name"])

        # å‰Šé™¤å¯¾è±¡ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç‰¹å®š
        revisions_to_delete = []
        for rev in revisions[self.max_revisions :]:
            if rev["name"] not in protected_revisions:
                # 24æ™‚é–“ä»¥ä¸Šå‰ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã®ã¿å‰Šé™¤ï¼ˆå®‰å…¨æ€§ç¢ºä¿ï¼‰
                if rev["age_hours"] >= 24:
                    revisions_to_delete.append(rev["name"])

        logger.info(f"Revisions to delete: {len(revisions_to_delete)}")
        logger.info(f"Protected revisions: {protected_revisions}")

        deleted_revisions = []
        for revision_name in revisions_to_delete:
            if self._delete_revision(revision_name):
                deleted_revisions.append(revision_name)

        logger.info(f"Successfully deleted {len(deleted_revisions)} old revisions")
        return len(deleted_revisions), deleted_revisions

    def _delete_revision(self, revision_name: str) -> bool:
        """å€‹åˆ¥ãƒªãƒ“ã‚¸ãƒ§ãƒ³å‰Šé™¤"""
        try:
            cmd = [
                "gcloud",
                "run",
                "revisions",
                "delete",
                revision_name,
                "--region",
                self.region,
                "--quiet",
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info(f"Deleted revision: {revision_name}")
            return True

        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to delete revision {revision_name}: {e}")
            return False

    def _calculate_age_hours(self, creation_timestamp: str) -> float:
        """ãƒªãƒ“ã‚¸ãƒ§ãƒ³ä½œæˆã‹ã‚‰ã®çµŒéæ™‚é–“è¨ˆç®—ï¼ˆæ™‚é–“å˜ä½ï¼‰"""
        try:
            # ISOå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
            creation_time = datetime.fromisoformat(
                creation_timestamp.replace("Z", "+00:00")
            )
            now = datetime.now(creation_time.tzinfo)
            age = now - creation_time
            return age.total_seconds() / 3600
        except Exception as e:
            logger.warning(
                f"Failed to calculate age for timestamp {creation_timestamp}: {e}"
            )
            return 0

    def get_active_revision_metrics(self) -> Dict:
        """
        Phase H.28.4: ç¾åœ¨ç¨¼åƒãƒªãƒ“ã‚¸ãƒ§ãƒ³é™å®šç›£è¦–
        ç¾åœ¨ç¨¼åƒä¸­ã®ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã®ã¿ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        """
        current_info = self.get_current_revision_info()
        current_revision = current_info.get("current_revision")

        if not current_revision:
            logger.error("No current revision found")
            return {}

        try:
            # Cloud Run ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ï¼ˆéå»1æ™‚é–“ï¼‰
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=1)

            metrics_data = {
                "revision_name": current_revision,
                "service_url": current_info.get("service_url"),
                "monitoring_period": f"{start_time.isoformat()} to {end_time.isoformat()}",
                "health_check_url": f"{current_info.get('service_url', '')}/health",
                "detailed_health_url": f"{current_info.get('service_url', '')}/health/detailed",
                "resilience_health_url": f"{current_info.get('service_url', '')}/health/resilience",
            }

            logger.info(f"Active revision metrics for: {current_revision}")
            return metrics_data

        except Exception as e:
            logger.error(f"Failed to get active revision metrics: {e}")
            return {}

    def verify_deployment_health(self, timeout_minutes: int = 5) -> Dict:
        """
        Phase H.28.4: ãƒ‡ãƒ—ãƒ­ã‚¤æ¤œè¨¼ãƒ•ãƒ­ãƒ¼
        æ–°ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®è‡ªå‹•ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ»ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®š
        """
        logger.info("Starting deployment health verification...")

        current_info = self.get_current_revision_info()
        current_revision = current_info.get("current_revision")
        service_url = current_info.get("service_url")

        if not service_url:
            return {"status": "FAILED", "reason": "No service URL found"}

        health_checks = {
            "basic_health": f"{service_url}/health",
            "detailed_health": f"{service_url}/health/detailed",
            "resilience_health": f"{service_url}/health/resilience",
        }

        verification_results = {
            "revision_name": current_revision,
            "verification_time": datetime.now().isoformat(),
            "overall_status": "PASSED",
            "health_checks": {},
            "deployment_recommendation": "KEEP",
        }

        failed_checks = 0

        for check_name, check_url in health_checks.items():
            try:
                import requests

                response = requests.get(check_url, timeout=30)

                check_result = {
                    "url": check_url,
                    "status_code": response.status_code,
                    "response_time_ms": response.elapsed.total_seconds() * 1000,
                    "status": "PASSED" if response.status_code == 200 else "FAILED",
                }

                if response.status_code != 200:
                    failed_checks += 1
                    check_result["error"] = f"HTTP {response.status_code}"

                verification_results["health_checks"][check_name] = check_result

            except Exception as e:
                failed_checks += 1
                verification_results["health_checks"][check_name] = {
                    "url": check_url,
                    "status": "FAILED",
                    "error": str(e),
                }

        # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        if failed_checks == 0:
            verification_results["overall_status"] = "PASSED"
            verification_results["deployment_recommendation"] = "KEEP"
        elif failed_checks <= 1:
            verification_results["overall_status"] = "WARNING"
            verification_results["deployment_recommendation"] = "MONITOR"
        else:
            verification_results["overall_status"] = "FAILED"
            verification_results["deployment_recommendation"] = "ROLLBACK"

        logger.info(
            f"Deployment verification: {verification_results['overall_status']}"
        )
        logger.info(
            f"Recommendation: {verification_results['deployment_recommendation']}"
        )

        return verification_results

    def generate_operational_dashboard(self) -> Dict:
        """
        Phase H.28.4: çµ±åˆè¨ºæ–­ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é‹ç”¨çŠ¶æ³ãƒ»åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å¯è¦–åŒ–
        """
        logger.info("Generating operational dashboard...")

        try:
            # å„ç¨®æƒ…å ±ã‚’çµ±åˆ
            current_info = self.get_current_revision_info()
            revisions = self.list_all_revisions()
            metrics = self.get_active_revision_metrics()
            health_status = self.verify_deployment_health()

            dashboard_data = {
                "generated_at": datetime.now().isoformat(),
                "service_name": self.service_name,
                "region": self.region,
                # ç¾åœ¨ã®ç¨¼åƒçŠ¶æ³
                "current_status": {
                    "active_revision": current_info.get("current_revision"),
                    "service_url": current_info.get("service_url"),
                    "health_status": health_status.get("overall_status", "UNKNOWN"),
                    "deployment_recommendation": health_status.get(
                        "deployment_recommendation", "UNKNOWN"
                    ),
                },
                # ãƒªãƒ“ã‚¸ãƒ§ãƒ³ç®¡ç†çŠ¶æ³
                "revision_management": {
                    "total_revisions": len(revisions),
                    "latest_revisions": [rev["name"] for rev in revisions[:3]],
                    "oldest_revision_age_hours": (
                        revisions[-1]["age_hours"] if revisions else 0
                    ),
                    "cleanup_needed": len(revisions) > self.max_revisions,
                },
                # ç›£è¦–ãƒ»ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
                "monitoring": {
                    "health_check_endpoints": metrics.get("health_check_url"),
                    "detailed_health": metrics.get("detailed_health_url"),
                    "resilience_check": metrics.get("resilience_health_url"),
                    "monitoring_period": metrics.get("monitoring_period"),
                },
                # é‹ç”¨æ¨å¥¨äº‹é …
                "operational_recommendations": self._generate_operational_recommendations(
                    current_info, revisions, health_status
                ),
            }

            logger.info("Operational dashboard generated successfully")
            return dashboard_data

        except Exception as e:
            logger.error(f"Failed to generate operational dashboard: {e}")
            return {"error": str(e), "generated_at": datetime.now().isoformat()}

    def _generate_operational_recommendations(
        self, current_info: Dict, revisions: List[Dict], health_status: Dict
    ) -> List[str]:
        """é‹ç”¨æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []

        # ãƒªãƒ“ã‚¸ãƒ§ãƒ³ç®¡ç†æ¨å¥¨
        if len(revisions) > self.max_revisions:
            recommendations.append(
                f"å¤ã„ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ¨å¥¨: {len(revisions) - self.max_revisions}å€‹ã®å¤ã„ãƒªãƒ“ã‚¸ãƒ§ãƒ³ãŒå­˜åœ¨"
            )

        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ¨å¥¨
        if health_status.get("overall_status") == "FAILED":
            recommendations.append("ç·Šæ€¥å¯¾å¿œå¿…è¦: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œè¨")
        elif health_status.get("overall_status") == "WARNING":
            recommendations.append("æ³¨æ„ç›£è¦–å¿…è¦: ä¸€éƒ¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç•°å¸¸ã€ç¶™ç¶šç›£è¦–æ¨å¥¨")

        # é‹ç”¨åŠ¹ç‡æ¨å¥¨
        if not recommendations:
            recommendations.append("ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸ç¨¼åƒä¸­: å®šæœŸçš„ãªç›£è¦–ç¶™ç¶šæ¨å¥¨")

        return recommendations

    def run_comprehensive_optimization(self) -> Dict:
        """
        Phase H.28.4: åŒ…æ‹¬çš„GCPé‹ç”¨ç’°å¢ƒæœ€é©åŒ–å®Ÿè¡Œ
        ãƒªãƒ“ã‚¸ãƒ§ãƒ³ç®¡ç†ãƒ»ç›£è¦–ãƒ»è¨ºæ–­ã®çµ±åˆå®Ÿè¡Œ
        """
        logger.info("ğŸš€ Phase H.28.4: GCPé‹ç”¨ç’°å¢ƒå®Œå…¨æœ€é©åŒ–é–‹å§‹")
        logger.info("=" * 70)

        optimization_results = {
            "phase": "H.28.4",
            "start_time": datetime.now().isoformat(),
            "service_name": self.service_name,
            "region": self.region,
        }

        try:
            # Step 1: ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            logger.info("ğŸ“‹ Step 1: ãƒªãƒ“ã‚¸ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†")
            deleted_count, deleted_revisions = self.cleanup_old_revisions()
            optimization_results["revision_cleanup"] = {
                "deleted_count": deleted_count,
                "deleted_revisions": deleted_revisions,
                "status": "SUCCESS",
            }

            # Step 2: ç¾åœ¨ç¨¼åƒãƒªãƒ“ã‚¸ãƒ§ãƒ³ç›£è¦–
            logger.info("ğŸ” Step 2: ç¾åœ¨ç¨¼åƒãƒªãƒ“ã‚¸ãƒ§ãƒ³é™å®šç›£è¦–")
            active_metrics = self.get_active_revision_metrics()
            optimization_results["active_monitoring"] = {
                "metrics": active_metrics,
                "status": "SUCCESS" if active_metrics else "FAILED",
            }

            # Step 3: ãƒ‡ãƒ—ãƒ­ã‚¤æ¤œè¨¼
            logger.info("âœ… Step 3: ãƒ‡ãƒ—ãƒ­ã‚¤æ¤œè¨¼ãƒ•ãƒ­ãƒ¼")
            health_verification = self.verify_deployment_health()
            optimization_results["deployment_verification"] = health_verification

            # Step 4: çµ±åˆè¨ºæ–­ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
            logger.info("ğŸ“Š Step 4: çµ±åˆè¨ºæ–­ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ")
            dashboard = self.generate_operational_dashboard()
            optimization_results["operational_dashboard"] = dashboard

            # ç·åˆè©•ä¾¡
            optimization_results["end_time"] = datetime.now().isoformat()
            optimization_results["overall_status"] = (
                self._evaluate_optimization_success(optimization_results)
            )

            logger.info("=" * 70)
            logger.info(
                f"âœ… Phase H.28.4å®Œäº†: {optimization_results['overall_status']}"
            )

            return optimization_results

        except Exception as e:
            logger.error(f"âŒ Phase H.28.4å¤±æ•—: {e}")
            optimization_results["error"] = str(e)
            optimization_results["overall_status"] = "FAILED"
            return optimization_results

    def _evaluate_optimization_success(self, results: Dict) -> str:
        """æœ€é©åŒ–æˆåŠŸè©•ä¾¡"""
        success_indicators = [
            results.get("revision_cleanup", {}).get("status") == "SUCCESS",
            results.get("active_monitoring", {}).get("status") == "SUCCESS",
            results.get("deployment_verification", {}).get("overall_status")
            in ["PASSED", "WARNING"],
            "operational_dashboard" in results
            and "error" not in results.get("operational_dashboard", {}),
        ]

        success_count = sum(success_indicators)

        if success_count == 4:
            return "COMPLETE_SUCCESS"
        elif success_count >= 3:
            return "PARTIAL_SUCCESS"
        else:
            return "FAILED"


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info("ğŸš€ GCP Revision Manager starting...")

        manager = GCPRevisionManager()
        results = manager.run_comprehensive_optimization()

        # çµæœä¿å­˜
        output_dir = Path(project_root / "results" / "gcp_optimization")
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = output_dir / f"gcp_optimization_{timestamp}.json"

        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"ğŸ“ çµæœä¿å­˜: {results_file}")

        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\nğŸ“Š GCPé‹ç”¨ç’°å¢ƒæœ€é©åŒ–çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 50)
        print(f"ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {results['overall_status']}")

        if results.get("revision_cleanup"):
            cleanup = results["revision_cleanup"]
            print(f"ãƒªãƒ“ã‚¸ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {cleanup['deleted_count']}å€‹å‰Šé™¤")

        if results.get("deployment_verification"):
            health = results["deployment_verification"]
            print(f"ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ˜ãƒ«ã‚¹: {health['overall_status']}")
            print(f"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {health['deployment_recommendation']}")

        if results.get("operational_dashboard"):
            dashboard = results["operational_dashboard"]
            if "current_status" in dashboard:
                current = dashboard["current_status"]
                print(f"ç¾åœ¨ç¨¼åƒ: {current.get('active_revision', 'Unknown')}")
                print(f"ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹: {current.get('health_status', 'Unknown')}")

        return (
            0
            if results["overall_status"] in ["COMPLETE_SUCCESS", "PARTIAL_SUCCESS"]
            else 1
        )

    except Exception as e:
        logger.error(f"GCP Revision Manager failed: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
