#!/usr/bin/env python3
"""
Phase 1è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: hourãƒ»day_of_weekç‰¹å¾´é‡enhanced_defaultæ±šæŸ“å•é¡Œç‰¹å®š

ç›®çš„:
- 125ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ã§hourãƒ»day_of_weekç‰¹å¾´é‡ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
- enhanced_defaultæ±šæŸ“ã®åŸå› ç‰¹å®š
- ç‰¹å¾´é‡ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
"""

import logging
import os
import sys
from datetime import datetime, timezone

import numpy as np
import pandas as pd
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append("/Users/nao/Desktop/bot")

from crypto_bot.ml.feature_engines.batch_calculator import BatchFeatureCalculator
from crypto_bot.ml.feature_engines.technical_engine import TechnicalFeatureEngine

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


def create_test_data_with_datetime_index(num_rows=100):
    """DatetimeIndexã‚’æŒã¤ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
    # ç¾åœ¨æ™‚åˆ»ã‹ã‚‰é¡ã£ã¦æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    end_time = datetime.now(timezone.utc)
    timestamps = pd.date_range(end=end_time, periods=num_rows, freq="H")  # 1æ™‚é–“é–“éš”

    # Bitcoinä¾¡æ ¼é¢¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    base_price = 50000
    price_changes = np.random.normal(0, 0.02, num_rows)  # 2%å¤‰å‹•
    prices = [base_price]

    for change in price_changes[1:]:
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)

    # OHLCV ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    data = {
        "open": [p * np.random.uniform(0.998, 1.002) for p in prices],
        "high": [p * np.random.uniform(1.001, 1.020) for p in prices],
        "low": [p * np.random.uniform(0.980, 0.999) for p in prices],
        "close": prices,
        "volume": np.random.uniform(100, 1000, num_rows),
    }

    df = pd.DataFrame(data, index=timestamps)
    df.index.name = "timestamp"

    logger.info(f"âœ… Test data created: {len(df)} rows")
    logger.info(f"   Index type: {type(df.index)}")
    logger.info(f"   Index has hour attr: {hasattr(df.index, 'hour')}")
    logger.info(f"   Index name: {df.index.name}")
    logger.info(f"   Date range: {df.index[0]} to {df.index[-1]}")

    return df


def diagnose_time_features():
    """æ™‚é–“ç‰¹å¾´é‡ç”Ÿæˆè¨ºæ–­"""
    logger.info("ğŸ” Phase 1è¨ºæ–­é–‹å§‹: hourãƒ»day_of_weekç‰¹å¾´é‡enhanced_defaultæ±šæŸ“å•é¡Œ")

    try:
        # 1. è¨­å®šãƒ­ãƒ¼ãƒ‰
        config_path = "/Users/nao/Desktop/bot/config/production/production.yml"
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        logger.info("âœ… Production config loaded")

        # 2. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        test_df = create_test_data_with_datetime_index(50)

        # 3. ãƒãƒƒãƒè¨ˆç®—æ©ŸåˆæœŸåŒ–
        batch_calc = BatchFeatureCalculator(config)

        # 4. ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        tech_engine = TechnicalFeatureEngine(config, batch_calc)
        logger.info("âœ… TechnicalFeatureEngine initialized")

        # 5. æ™‚é–“ç‰¹å¾´é‡ã®ã¿è¨ˆç®—ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ§ª Testing missing_features_batch calculation...")
        missing_batch = tech_engine.calculate_missing_features_batch(test_df)

        # 6. çµæœåˆ†æ
        logger.info(f"ğŸ“Š Missing features batch results:")
        logger.info(f"   Total features generated: {len(missing_batch.features)}")

        # æ™‚é–“é–¢é€£ç‰¹å¾´é‡ãƒã‚§ãƒƒã‚¯
        time_features = [
            "hour",
            "day_of_week",
            "is_weekend",
            "is_asian_session",
            "is_european_session",
            "is_us_session",
        ]

        for feature in time_features:
            if feature in missing_batch.features:
                values = missing_batch.features[feature]
                logger.info(
                    f"   âœ… {feature}: Generated - Type: {type(values)} - Sample: {values.iloc[:5].tolist()}"
                )

                # enhanced_defaultãƒã‚§ãƒƒã‚¯
                if hasattr(values, "dtype") and "object" in str(values.dtype):
                    unique_vals = (
                        values.unique() if hasattr(values, "unique") else [str(values)]
                    )
                    if any("enhanced_default" in str(val) for val in unique_vals):
                        logger.error(
                            f"   âŒ {feature}: ENHANCED_DEFAULT contamination detected!"
                        )
                        logger.error(f"      Unique values: {unique_vals}")
                    else:
                        logger.info(
                            f"   âœ… {feature}: No enhanced_default contamination"
                        )

            else:
                logger.error(f"   âŒ {feature}: NOT GENERATED")

        # 7. ç‰¹å¾´é‡é †åºç¢ºèª
        feature_order_path = "/Users/nao/Desktop/bot/config/core/feature_order.json"
        if os.path.exists(feature_order_path):
            import json

            with open(feature_order_path, "r") as f:
                feature_order = json.load(f)

            logger.info(f"ğŸ“‹ Feature order analysis:")
            logger.info(f"   Expected features: {feature_order['num_features']}")

            # æ™‚é–“ç‰¹å¾´é‡ãŒæ­£ã—ã„é †åºã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            expected_order = feature_order["feature_order"]
            for feature in time_features:
                if feature in expected_order:
                    position = expected_order.index(feature) + 1
                    logger.info(
                        f"   âœ… {feature}: Position {position} in feature order"
                    )
                else:
                    logger.error(f"   âŒ {feature}: Missing from feature order!")

        # 8. è¨ºæ–­ã‚µãƒãƒª
        logger.info("ğŸ¯ è¨ºæ–­çµæœã‚µãƒãƒª:")
        generated_time_features = [
            f for f in time_features if f in missing_batch.features
        ]
        missing_time_features = [
            f for f in time_features if f not in missing_batch.features
        ]

        logger.info(f"   Generated time features: {len(generated_time_features)}/6")
        logger.info(f"   Generated: {generated_time_features}")
        if missing_time_features:
            logger.error(f"   Missing: {missing_time_features}")

        # 9. å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿å€¤ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        if "hour" in missing_batch.features and "day_of_week" in missing_batch.features:
            sample_df = pd.DataFrame(
                {
                    "timestamp": test_df.index[:10],
                    "hour": missing_batch.features["hour"].iloc[:10],
                    "day_of_week": missing_batch.features["day_of_week"].iloc[:10],
                    "expected_hour": test_df.index[:10].hour,
                    "expected_dow": test_df.index[:10].dayofweek,
                }
            )
            logger.info("ğŸ“Š Sample time feature comparison:")
            logger.info(f"\n{sample_df.to_string()}")

            # å€¤ã®ä¸€è‡´ç¢ºèª
            hour_match = (sample_df["hour"] == sample_df["expected_hour"]).all()
            dow_match = (sample_df["day_of_week"] == sample_df["expected_dow"]).all()

            logger.info(f"   Hour values match: {hour_match}")
            logger.info(f"   Day of week values match: {dow_match}")

            if not hour_match or not dow_match:
                logger.error("âŒ Time feature values do not match expected values!")
                return False
            else:
                logger.info("âœ… Time feature values match expected values!")

        return True

    except Exception as e:
        logger.error(f"âŒ Diagnosis failed: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = diagnose_time_features()
    if success:
        print("\nğŸ‰ Diagnosis completed successfully!")
        print("âœ… Time features appear to be working correctly")
        print(
            "ğŸ”„ Next step: Check if the issue is in the ML pipeline or feature integration"
        )
    else:
        print("\nâŒ Diagnosis revealed issues!")
        print("ğŸ”§ Time features need to be fixed before proceeding")

    sys.exit(0 if success else 1)
