#!/usr/bin/env python3
"""
Phase 1å®Ÿãƒ‡ãƒ¼ã‚¿MLãƒ¢ãƒ‡ãƒ«å®Œå…¨å†å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„:
- ä¿®æ­£ã•ã‚ŒãŸ125ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆhourãƒ»day_of_weekæ­£å¸¸åŒ–æ¸ˆã¿ï¼‰ã§å®Œå…¨å†å­¦ç¿’
- enhanced_defaultæ±šæŸ“ã‚’å®Œå…¨ã«æ’é™¤ã—ãŸæ­£ç¢ºãªTradingEnsembleClassifierä½œæˆ
- 0%å‹ç‡å•é¡Œã®æ ¹æœ¬è§£æ±ºãƒ»å®Ÿç”¨çš„ãªäºˆæ¸¬æ€§èƒ½é”æˆ

ç‰¹å¾´:
- å®Ÿéš›ã®BTC/JPYå±¥æ­´ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
- 125ç‰¹å¾´é‡å®Œå…¨æ€§æ¤œè¨¼
- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å“è³ªä¿è¨¼
- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆLightGBM + XGBoost + RandomForestï¼‰
"""

import logging
import os
import pickle
import sys
from datetime import datetime, timezone
from pathlib import Path

import numpy as np
import pandas as pd
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append("/Users/nao/Desktop/bot")

from crypto_bot.data.fetcher import DataPreprocessor, MarketDataFetcher
from crypto_bot.ml.ensemble import TradingEnsembleClassifier
from crypto_bot.ml.feature_engines.batch_calculator import BatchFeatureCalculator
from crypto_bot.ml.feature_engines.technical_engine import TechnicalFeatureEngine

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class Phase1ModelRetrainer:
    """Phase 1: å®Ÿãƒ‡ãƒ¼ã‚¿MLãƒ¢ãƒ‡ãƒ«å®Œå…¨å†å­¦ç¿’ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path):
        self.config_path = config_path
        self.config = self._load_config()
        self.output_model_path = "/Users/nao/Desktop/bot/models/production/model.pkl"
        self.backup_model_path = f'/Users/nao/Desktop/bot/models/production/model_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pkl'

    def _load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        with open(self.config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def fetch_training_data(self, months=6):
        """å®Ÿéš›ã®BTC/JPYãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå­¦ç¿’ç”¨ï¼‰"""
        logger.info(f"ğŸ“Š å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {months}ãƒ¶æœˆé–“ã®BTC/JPYãƒ‡ãƒ¼ã‚¿")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼åˆæœŸåŒ–ï¼ˆCSVä½¿ç”¨ã§å¤§é‡ãƒ‡ãƒ¼ã‚¿ç¢ºä¿ï¼‰
            csv_data_path = "/Users/nao/Desktop/bot/data/btc_usd_2024_hourly.csv"

            # CSVãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if not os.path.exists(csv_data_path):
                logger.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {csv_data_path}")
                logger.info("ğŸ“¡ APIçµŒç”±ã§å¯èƒ½ãªé™ã‚Šãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦è¡Œ...")

                # APIçµŒç”±ã§ã®å–å¾—ï¼ˆæ–°é®®åº¦ãƒã‚§ãƒƒã‚¯ç„¡åŠ¹åŒ–ï¼‰
                data_config = self.config.get("data", {})
                fetcher = MarketDataFetcher(
                    exchange_id=data_config.get("exchange", "bitbank"),
                    api_key=data_config.get("api_key"),
                    api_secret=data_config.get("api_secret"),
                    symbol=data_config.get("symbol", "BTC/JPY"),
                    testnet=data_config.get("testnet", False),
                    ccxt_options=data_config.get("ccxt_options", {}),
                )

                # ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ–°é®®åº¦ãƒã‚§ãƒƒã‚¯ç„¡åŠ¹åŒ–ï¼‰
                raw_data = fetcher.fetch_with_freshness_fallback(
                    timeframe="1h",
                    limit=months * 30 * 24,  # 6ãƒ¶æœˆåˆ†
                    since=None,
                    max_age_hours=24 * 365,  # 1å¹´ã¾ã§è¨±å®¹ï¼ˆäº‹å®Ÿä¸Šç„¡åŠ¹åŒ–ï¼‰
                )
            else:
                logger.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {csv_data_path}")
                # CSVã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                fetcher = MarketDataFetcher(csv_path=csv_data_path)
                raw_data = pd.read_csv(csv_data_path, index_col=0, parse_dates=True)

                # å¿…è¦ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæœ€æ–°6ãƒ¶æœˆåˆ†ï¼‰
                if len(raw_data) > months * 30 * 24:
                    raw_data = raw_data.tail(months * 30 * 24)
                    logger.info(f"âœ‚ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’{months}ãƒ¶æœˆåˆ†ã«åˆ¶é™: {len(raw_data)}ä»¶")

            if raw_data is None or len(raw_data) < 100:
                raise ValueError(
                    f"ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸è¶³: {len(raw_data) if raw_data is not None else 0}ä»¶"
                )

            logger.info(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(raw_data)}ä»¶")
            logger.info(f"   æœŸé–“: {raw_data.index[0]} ï½ {raw_data.index[-1]}")

            return raw_data

        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
            raise

    def generate_features(self, raw_data):
        """125ç‰¹å¾´é‡ç”Ÿæˆï¼ˆä¿®æ­£ç‰ˆhourãƒ»day_of_weekå«ã‚€ï¼‰"""
        logger.info("ğŸ”§ 125ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹ï¼ˆä¿®æ­£ç‰ˆæ™‚é–“ç‰¹å¾´é‡å«ã‚€ï¼‰")

        try:
            # ãƒãƒƒãƒè¨ˆç®—æ©Ÿãƒ»ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
            batch_calc = BatchFeatureCalculator(self.config)
            tech_engine = TechnicalFeatureEngine(self.config, batch_calc)

            # å…¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ç‰¹å¾´é‡ãƒãƒƒãƒè¨ˆç®—
            feature_batches = tech_engine.calculate_all_technical_batches(raw_data)

            # ç‰¹å¾´é‡çµ±åˆï¼ˆé‡è¤‡åˆ—å›é¿ï¼‰
            feature_df = raw_data.copy()
            total_features = 0

            for batch in feature_batches:
                if len(batch) > 0:
                    batch_features = batch.to_dataframe()

                    # é‡è¤‡åˆ—ã‚’é™¤å»
                    overlapping_cols = batch_features.columns.intersection(
                        feature_df.columns
                    )
                    if len(overlapping_cols) > 0:
                        logger.info(
                            f"   ğŸ”„ {batch.name}: é‡è¤‡åˆ—é™¤å» {list(overlapping_cols)}"
                        )
                        batch_features = batch_features.drop(columns=overlapping_cols)

                    # ç‰¹å¾´é‡çµ±åˆ
                    if not batch_features.empty:
                        feature_df = feature_df.join(batch_features, how="left")
                        total_features += len(batch_features.columns)
                        logger.info(
                            f"   âœ… {batch.name}: {len(batch_features.columns)}ç‰¹å¾´é‡"
                        )
                    else:
                        logger.info(f"   âš ï¸ {batch.name}: é‡è¤‡é™¤å»å¾Œã«ç©ºã®ãƒãƒƒãƒ")

            logger.info(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: åˆè¨ˆ{total_features}ç‰¹å¾´é‡")

            # é‡è¦ï¼šhourãƒ»day_of_weekç‰¹å¾´é‡ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            critical_features = ["hour", "day_of_week"]
            for feature in critical_features:
                if feature in feature_df.columns:
                    sample_values = feature_df[feature].dropna().head(5)
                    logger.info(
                        f"   âœ… {feature}: æ­£å¸¸ç”Ÿæˆ - ã‚µãƒ³ãƒ—ãƒ«å€¤: {sample_values.tolist()}"
                    )

                    # enhanced_defaultæ±šæŸ“ãƒã‚§ãƒƒã‚¯
                    if (
                        feature_df[feature]
                        .astype(str)
                        .str.contains("enhanced_default")
                        .any()
                    ):
                        logger.error(f"   âŒ {feature}: enhanced_defaultæ±šæŸ“æ¤œå‡ºï¼")
                        raise ValueError(
                            f"{feature}ã«enhanced_defaultæ±šæŸ“ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
                        )
                else:
                    logger.error(f"   âŒ {feature}: ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
                    raise ValueError(f"é‡è¦ç‰¹å¾´é‡{feature}ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")

            return feature_df

        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾´é‡ç”Ÿæˆå¤±æ•—: {e}")
            raise

    def prepare_ml_data(self, feature_data):
        """MLå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ»å‰å‡¦ç†"""
        logger.info("ğŸ“‹ MLå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™é–‹å§‹")

        try:
            # åŸºæœ¬çš„ãªå‰å‡¦ç†
            processed_data = feature_data.copy()

            # é‡è¤‡é™¤å»
            processed_data = DataPreprocessor.remove_duplicates(processed_data)

            # æ¬ æå€¤å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ï¼‰
            processed_data = processed_data.fillna(method="ffill")
            processed_data = processed_data.fillna(
                method="bfill"
            )  # æœ€åˆã®å€¤ã‚‚ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«

            # ç„¡é™å€¤é™¤å»
            processed_data = processed_data.replace([np.inf, -np.inf], np.nan)
            processed_data = processed_data.fillna(0)

            # 125ç‰¹å¾´é‡ã«èª¿æ•´ï¼ˆproduction.ymlã‹ã‚‰æœŸå¾…ã™ã‚‹ç‰¹å¾´é‡ãƒªã‚¹ãƒˆå–å¾—ï¼‰
            expected_features = self.config.get("ml", {}).get("extra_features", [])

            # OHLCV + æœŸå¾…ç‰¹å¾´é‡ã®ã¿ä¿æŒ
            keep_columns = ["open", "high", "low", "close", "volume"]
            for feature in expected_features:
                if feature in processed_data.columns:
                    keep_columns.append(feature)

            # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ä¿æŒ
            available_columns = [
                col for col in keep_columns if col in processed_data.columns
            ]
            processed_data = processed_data[available_columns]

            if len(processed_data) < 50:
                raise ValueError(f"å‰å‡¦ç†å¾Œãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(processed_data)}ä»¶")

            logger.info(
                f"âœ… å‰å‡¦ç†å®Œäº†: {len(processed_data)}ã‚µãƒ³ãƒ—ãƒ«, {processed_data.shape[1]}ç‰¹å¾´é‡"
            )
            logger.info(f"   åˆ©ç”¨å¯èƒ½ç‰¹å¾´é‡: {len(available_columns)}")
            logger.info(f"   æœŸå¾…ç‰¹å¾´é‡: {len(expected_features)}")

            # é‡è¦ç‰¹å¾´é‡ç¢ºèª
            critical_features = ["hour", "day_of_week", "close"]
            for feature in critical_features:
                if feature in processed_data.columns:
                    logger.info(f"   âœ… {feature}: åˆ©ç”¨å¯èƒ½")
                else:
                    logger.warning(f"   âš ï¸ {feature}: ä¸åœ¨")

            return processed_data

        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æº–å‚™å¤±æ•—: {e}")
            raise

    def create_targets(self, feature_data):
        """å–å¼•ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆï¼ˆåˆ†é¡ãƒ»å›å¸°ä¸¡å¯¾å¿œï¼‰"""
        logger.info("ğŸ¯ å–å¼•ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆé–‹å§‹")

        try:
            # ä¾¡æ ¼å¤‰å‹•ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
            horizon = self.config.get("ml", {}).get("horizon", 5)
            close_prices = feature_data["close"]

            # å°†æ¥ä¾¡æ ¼å¤‰å‹•ç‡è¨ˆç®—
            future_returns = close_prices.pct_change(horizon).shift(-horizon)

            # åˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆä¸Šæ˜‡/ä¸‹é™ï¼‰
            classification_targets = (future_returns > 0).astype(int)

            # å›å¸°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆãƒªã‚¿ãƒ¼ãƒ³ï¼‰
            regression_targets = future_returns

            # NaNå€¤é™¤å»
            valid_indices = ~(classification_targets.isna() | regression_targets.isna())

            logger.info(f"âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆå®Œäº†: {valid_indices.sum()}æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«")
            logger.info(
                f"   åˆ†é¡ãƒãƒ©ãƒ³ã‚¹: ä¸Šæ˜‡{classification_targets[valid_indices].sum()}/{len(classification_targets[valid_indices])} ({classification_targets[valid_indices].mean():.1%})"
            )

            return (
                classification_targets[valid_indices],
                regression_targets[valid_indices],
                valid_indices,
            )

        except Exception as e:
            logger.error(f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆå¤±æ•—: {e}")
            raise

    def train_ensemble_model(self, X, y_class, y_reg):
        """TradingEnsembleClassifierå­¦ç¿’"""
        logger.info("ğŸ¤– TradingEnsembleClassifierå­¦ç¿’é–‹å§‹")

        try:
            # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            if os.path.exists(self.output_model_path):
                import shutil

                shutil.copy2(self.output_model_path, self.backup_model_path)
                logger.info(f"âœ… æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {self.backup_model_path}")

            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            ensemble_config = self.config.get("ml", {}).get("ensemble", {})
            confidence_threshold = ensemble_config.get("confidence_threshold", 0.65)

            # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            from lightgbm import LGBMClassifier
            from sklearn.ensemble import RandomForestClassifier
            from xgboost import XGBClassifier

            base_models = [
                LGBMClassifier(random_state=42, verbose=-1),
                XGBClassifier(random_state=42, eval_metric="logloss"),
                RandomForestClassifier(random_state=42, n_jobs=-1),
            ]

            ensemble = TradingEnsembleClassifier(
                base_models=base_models,
                ensemble_method="trading_stacking",
                confidence_threshold=confidence_threshold,
                risk_adjustment=True,
                cv_folds=5,
            )

            logger.info(f"   ãƒ¢ãƒ‡ãƒ«æ§‹æˆ: LightGBM, XGBoost, RandomForest")
            logger.info(f"   ä¿¡é ¼åº¦é–¾å€¤: {confidence_threshold}")
            logger.info(f"   å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(X)}ã‚µãƒ³ãƒ—ãƒ« Ã— {X.shape[1]}ç‰¹å¾´é‡")

            # å­¦ç¿’å®Ÿè¡Œ
            ensemble.fit(X, y_class)

            # å­¦ç¿’å¾Œæ¤œè¨¼
            train_predictions = ensemble.predict_proba(X)[:, 1]  # ä¸Šæ˜‡ç¢ºç‡
            train_accuracy = ensemble.score(X, y_class)

            logger.info(f"âœ… å­¦ç¿’å®Œäº†:")
            logger.info(f"   å­¦ç¿’ç²¾åº¦: {train_accuracy:.3f}")
            logger.info(
                f"   äºˆæ¸¬å€¤ç¯„å›²: {train_predictions.min():.3f} ï½ {train_predictions.max():.3f}"
            )
            logger.info(f"   äºˆæ¸¬å€¤å¹³å‡: {train_predictions.mean():.3f}")

            # äºˆæ¸¬å€¤åˆ†å¸ƒç¢ºèªï¼ˆ0.5å›ºå®šå•é¡Œæ¤œå‡ºï¼‰
            unique_predictions = len(np.unique(train_predictions))
            if unique_predictions < 10:
                logger.warning(f"âš ï¸ äºˆæ¸¬å€¤å¤šæ§˜æ€§ä¸è¶³: {unique_predictions}ç¨®é¡ã®ã¿")
                if np.all(np.abs(train_predictions - 0.5) < 0.01):
                    logger.error("âŒ 0.5å›ºå®šå•é¡Œæ¤œå‡ºï¼å­¦ç¿’ãŒé©åˆ‡ã«å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    raise ValueError("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å¤±æ•—ï¼š0.5å›ºå®šäºˆæ¸¬")
            else:
                logger.info(f"   âœ… äºˆæ¸¬å€¤å¤šæ§˜æ€§: {unique_predictions}ç¨®é¡")

            return ensemble

        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å¤±æ•—: {e}")
            raise

    def validate_model(self, model, X, y_class):
        """ãƒ¢ãƒ‡ãƒ«å“è³ªæ¤œè¨¼"""
        logger.info("ğŸ” ãƒ¢ãƒ‡ãƒ«å“è³ªæ¤œè¨¼é–‹å§‹")

        try:
            from sklearn.metrics import classification_report, confusion_matrix
            from sklearn.model_selection import cross_val_score

            # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            cv_scores = cross_val_score(model, X, y_class, cv=5, scoring="accuracy")

            # äºˆæ¸¬å®Ÿè¡Œ
            predictions = model.predict(X)
            pred_proba = model.predict_proba(X)[:, 1]

            # è©³ç´°è©•ä¾¡
            logger.info("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ:")
            logger.info(f"   CVç²¾åº¦: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")
            logger.info(f"   å­¦ç¿’ç²¾åº¦: {model.score(X, y_class):.3f}")
            logger.info(
                f"   äºˆæ¸¬åˆ†å¸ƒ: min={pred_proba.min():.3f}, max={pred_proba.max():.3f}, mean={pred_proba.mean():.3f}"
            )

            # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
            logger.info(
                "\n"
                + classification_report(
                    y_class, predictions, target_names=["ä¸‹é™", "ä¸Šæ˜‡"]
                )
            )

            # å“è³ªåŸºæº–ãƒã‚§ãƒƒã‚¯
            min_accuracy = 0.52  # 52%ä»¥ä¸Šï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚ˆã‚Šè‰¯ã„ï¼‰
            if cv_scores.mean() < min_accuracy:
                logger.warning(f"âš ï¸ ä½ç²¾åº¦è­¦å‘Š: {cv_scores.mean():.3f} < {min_accuracy}")
            else:
                logger.info(
                    f"âœ… ç²¾åº¦åŸºæº–ã‚¯ãƒªã‚¢: {cv_scores.mean():.3f} >= {min_accuracy}"
                )

            return {
                "cv_accuracy": cv_scores.mean(),
                "cv_std": cv_scores.std(),
                "train_accuracy": model.score(X, y_class),
                "prediction_diversity": len(np.unique(pred_proba)),
                "prediction_range": pred_proba.max() - pred_proba.min(),
            }

        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼å¤±æ•—: {e}")
            raise

    def save_model(self, model, validation_results):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        logger.info("ğŸ’¾ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜é–‹å§‹")

        try:
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            with open(self.output_model_path, "wb") as f:
                pickle.dump(model, f)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            metadata = {
                "training_timestamp": datetime.now().isoformat(),
                "config_path": self.config_path,
                "model_type": "TradingEnsembleClassifier",
                "features_count": 125,
                "validation_results": validation_results,
                "feature_fixes": ["hour_day_of_week_enhanced_default_resolved"],
                "phase": "Phase1_RealDataRetraining",
            }

            metadata_path = self.output_model_path.replace(".pkl", "_metadata.yaml")
            with open(metadata_path, "w", encoding="utf-8") as f:
                yaml.dump(metadata, f, default_flow_style=False, allow_unicode=True)

            logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†:")
            logger.info(f"   ãƒ¢ãƒ‡ãƒ«: {self.output_model_path}")
            logger.info(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_path}")
            logger.info(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {self.backup_model_path}")

        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å¤±æ•—: {e}")
            raise

    def run_full_retraining(self):
        """å®Œå…¨å†å­¦ç¿’å®Ÿè¡Œ"""
        logger.info("ğŸš€ Phase 1: å®Ÿãƒ‡ãƒ¼ã‚¿MLãƒ¢ãƒ‡ãƒ«å®Œå…¨å†å­¦ç¿’é–‹å§‹")
        start_time = datetime.now()

        try:
            # 1. å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—
            raw_data = self.fetch_training_data(months=6)

            # 2. 125ç‰¹å¾´é‡ç”Ÿæˆï¼ˆä¿®æ­£ç‰ˆï¼‰
            feature_data = self.generate_features(raw_data)

            # 3. MLç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            X = self.prepare_ml_data(feature_data)

            # 4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
            y_class, y_reg, valid_indices = self.create_targets(feature_data)

            # æœ‰åŠ¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            X_valid = X[valid_indices]

            if len(X_valid) < 100:
                raise ValueError(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(X_valid)}ã‚µãƒ³ãƒ—ãƒ« < 100")

            # 5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            model = self.train_ensemble_model(X_valid, y_class, y_reg)

            # 6. ãƒ¢ãƒ‡ãƒ«å“è³ªæ¤œè¨¼
            validation_results = self.validate_model(model, X_valid, y_class)

            # 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            self.save_model(model, validation_results)

            # å®Œäº†å ±å‘Š
            elapsed = datetime.now() - start_time
            logger.info("ğŸ‰ Phase 1å®Œå…¨å†å­¦ç¿’æˆåŠŸï¼")
            logger.info(f"   å®Ÿè¡Œæ™‚é–“: {elapsed}")
            logger.info(f"   å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(X_valid)}ã‚µãƒ³ãƒ—ãƒ«")
            logger.info(f"   CVç²¾åº¦: {validation_results['cv_accuracy']:.3f}")
            logger.info(
                f"   äºˆæ¸¬å¤šæ§˜æ€§: {validation_results['prediction_diversity']}ç¨®é¡"
            )

            return True

        except Exception as e:
            logger.error(f"âŒ Phase 1å†å­¦ç¿’å¤±æ•—: {e}")
            import traceback

            traceback.print_exc()
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("=" * 60)
    logger.info("Phase 1: å®Ÿãƒ‡ãƒ¼ã‚¿TradingEnsembleClassifierå®Œå…¨å†å­¦ç¿’")
    logger.info("=" * 60)

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    config_path = "/Users/nao/Desktop/bot/config/production/production.yml"

    # Phase 1å†å­¦ç¿’å®Ÿè¡Œ
    retrainer = Phase1ModelRetrainer(config_path)
    success = retrainer.run_full_retraining()

    if success:
        print("\nğŸ‰ Phase 1å®Ÿãƒ‡ãƒ¼ã‚¿å†å­¦ç¿’å®Œäº†ï¼")
        print("âœ… enhanced_defaultæ±šæŸ“å•é¡Œè§£æ¶ˆ")
        print("âœ… 125ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨å¯¾å¿œ")
        print("âœ… TradingEnsembleClassifieræœ€æ–°ç‰ˆæº–å‚™å®Œäº†")
        print("ğŸ”„ æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: æ”¹å–„ç‰ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã§æ€§èƒ½ç¢ºèª")
    else:
        print("\nâŒ Phase 1å†å­¦ç¿’å¤±æ•—")
        print("ğŸ”§ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦å•é¡Œè§£æ±ºå¾Œã«å†å®Ÿè¡Œã—ã¦ãã ã•ã„")

    return 0 if success else 1


if __name__ == "__main__":
    exit(main())
