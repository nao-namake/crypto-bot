#!/usr/bin/env python3
"""
è»½é‡ç‰ˆç‰¹å¾´é‡æ¯”è¼ƒãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
127ç‰¹å¾´é‡ vs 26ç‰¹å¾´é‡ã®ç¾å®Ÿçš„æ€§èƒ½æ¯”è¼ƒ
"""

import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.model_selection import TimeSeriesSplit

sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def load_latest_data():
    """æœ€æ–°6ãƒ¶æœˆã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    data_path = Path("data/btc_usd_2024_hourly.csv")

    if not data_path.exists():
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
        return None

    df = pd.read_csv(data_path)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df = df.sort_values("timestamp").reset_index(drop=True)

    # æœ€æ–°3ãƒ¶æœˆã®ãƒ‡ãƒ¼ã‚¿ã«åˆ¶é™
    cutoff_date = df["timestamp"].max() - timedelta(days=90)
    df = df[df["timestamp"] >= cutoff_date].reset_index(drop=True)

    logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œï¼ˆæœ€æ–°3ãƒ¶æœˆï¼‰")
    logger.info(f"æœŸé–“: {df['timestamp'].min()} - {df['timestamp'].max()}")

    return df


def create_simple_features(df, feature_type="full"):
    """è»½é‡ç‰¹å¾´é‡ç”Ÿæˆ"""
    features = pd.DataFrame()

    # åŸºæœ¬ä¾¡æ ¼ç‰¹å¾´é‡
    features["open"] = df["open"]
    features["high"] = df["high"]
    features["low"] = df["low"]
    features["close"] = df["close"]
    features["volume"] = df["volume"]

    # åŸºæœ¬ãƒªã‚¿ãƒ¼ãƒ³
    features["returns_1"] = df["close"].pct_change().fillna(0)
    features["returns_5"] = df["close"].pct_change(5).fillna(0)

    # ãƒ©ã‚°ç‰¹å¾´é‡
    features["close_lag_1"] = df["close"].shift(1).fillna(df["close"])

    if feature_type == "essential":
        # 26å€‹ã®å³é¸ç‰¹å¾´é‡
        # ç§»å‹•å¹³å‡
        features["sma_20"] = df["close"].rolling(20).mean().fillna(df["close"])
        features["ema_50"] = df["close"].ewm(span=50).mean()
        features["price_vs_sma20"] = (
            (df["close"] - features["sma_20"]) / features["sma_20"]
        ).fillna(0)

        # RSI
        delta = df["close"].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / (loss + 1e-8)
        features["rsi_14"] = (100 - (100 / (1 + rs))).fillna(50)

        # MACD
        ema12 = df["close"].ewm(span=12).mean()
        ema26 = df["close"].ewm(span=26).mean()
        features["macd"] = ema12 - ema26
        features["macd_signal"] = features["macd"].ewm(span=9).mean()

        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        sma = df["close"].rolling(20).mean()
        std = df["close"].rolling(20).std()
        features["bb_upper"] = sma + (2 * std)
        features["bb_lower"] = sma - (2 * std)
        features["bb_width"] = (4 * std).fillna(0)

        # ATR
        tr1 = df["high"] - df["low"]
        tr2 = np.abs(df["high"] - df["close"].shift(1))
        tr3 = np.abs(df["low"] - df["close"].shift(1))
        tr = np.maximum(tr1, np.maximum(tr2, tr3))
        features["atr_14"] = pd.Series(tr).rolling(14).mean().fillna(tr1.mean())

        # ãƒœãƒªãƒ¥ãƒ¼ãƒ æŒ‡æ¨™
        vol_avg = df["volume"].rolling(20).mean()
        features["volume_ratio"] = (df["volume"] / vol_avg).fillna(1)

        vwap = (df["close"] * df["volume"]).rolling(20).sum() / df["volume"].rolling(
            20
        ).sum()
        features["vwap"] = vwap.fillna(df["close"])

        obv = np.where(
            df["close"] > df["close"].shift(1),
            df["volume"],
            np.where(df["close"] < df["close"].shift(1), -df["volume"], 0),
        )
        features["obv"] = pd.Series(obv).cumsum()

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        returns = df["close"].pct_change()
        features["volatility_20"] = returns.rolling(20).std().fillna(0.02)

        # ãã®ä»–ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
        features["stoch_k"] = (
            (df["close"] - df["low"].rolling(14).min())
            / (df["high"].rolling(14).max() - df["low"].rolling(14).min() + 1e-8)
            * 100
        ).fillna(50)

        features["williams_r"] = (
            -(df["high"].rolling(14).max() - df["close"])
            / (df["high"].rolling(14).max() - df["low"].rolling(14).min() + 1e-8)
            * 100
        ).fillna(-50)

        features["adx_14"] = (
            np.abs(features["returns_1"]).rolling(14).mean().fillna(0.02) * 100
        )

        # ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹
        low_20 = df["low"].rolling(20).min()
        features["support_distance"] = ((df["close"] - low_20) / df["close"]).fillna(0)

        # æ™‚é–“ç‰¹å¾´é‡
        features["hour"] = df["timestamp"].dt.hour
        features["is_us_session"] = (
            (features["hour"] >= 14) & (features["hour"] <= 21)
        ).astype(int)

    elif feature_type == "full":
        # 127å€‹ã®å®Œå…¨ç‰¹å¾´é‡ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        # ã¾ãšåŸºæœ¬æ™‚é–“ç‰¹å¾´é‡ã‚’ä½œæˆ
        features["hour"] = df["timestamp"].dt.hour
        features["day_of_week"] = df["timestamp"].dt.dayofweek
        features["is_weekend"] = (features["day_of_week"] >= 5).astype(int)
        features["is_us_session"] = (
            (features["hour"] >= 14) & (features["hour"] <= 21)
        ).astype(int)
        features["is_asian_session"] = (
            (features["hour"] >= 0) & (features["hour"] <= 8)
        ).astype(int)
        features["is_european_session"] = (
            (features["hour"] >= 8) & (features["hour"] <= 16)
        ).astype(int)

        # 26å€‹ã®åŸºæœ¬ç‰¹å¾´é‡ã‚’å«ã‚ã‚‹ï¼ˆæ™‚é–“ç‰¹å¾´é‡ä»¥å¤–ï¼‰
        essential_features = create_simple_features(df, "essential")
        for col in essential_features.columns:
            if col not in features.columns and not col.startswith(("hour", "is_")):
                features[col] = essential_features[col]

        # è¿½åŠ ã®ç§»å‹•å¹³å‡
        for period in [5, 10, 50, 100, 200]:
            features[f"sma_{period}"] = (
                df["close"].rolling(period).mean().fillna(df["close"])
            )
            features[f"ema_{period}"] = df["close"].ewm(span=period).mean()

        # è¿½åŠ ã®ãƒ©ã‚°ç‰¹å¾´é‡
        for lag in [2, 3, 4, 5]:
            features[f"close_lag_{lag}"] = df["close"].shift(lag).fillna(df["close"])
            if lag <= 3:
                features[f"volume_lag_{lag}"] = (
                    df["volume"].shift(lag).fillna(df["volume"])
                )
                features[f"returns_{lag}"] = df["close"].pct_change(lag).fillna(0)

        # è¿½åŠ ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
        for period in [7, 21]:
            delta = df["close"].diff()
            gain = (delta.where(delta > 0, 0)).rolling(period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
            rs = gain / (loss + 1e-8)
            features[f"rsi_{period}"] = (100 - (100 / (1 + rs))).fillna(50)

        # è¿½åŠ ã®ATR
        for period in [7, 21]:
            tr1 = df["high"] - df["low"]
            tr2 = np.abs(df["high"] - df["close"].shift(1))
            tr3 = np.abs(df["low"] - df["close"].shift(1))
            tr = np.maximum(tr1, np.maximum(tr2, tr3))
            features[f"atr_{period}"] = (
                pd.Series(tr).rolling(period).mean().fillna(tr1.mean())
            )

        # ä¾¡æ ¼ãƒã‚¸ã‚·ãƒ§ãƒ³
        for period in [20, 50]:
            sma = df["close"].rolling(period).mean()
            features[f"price_position_{period}"] = ((df["close"] - sma) / sma).fillna(0)

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™
        returns = df["close"].pct_change()
        for period in [10, 50]:
            features[f"volatility_{period}"] = (
                returns.rolling(period).std().fillna(0.02)
            )

        # çµ±è¨ˆçš„ç‰¹å¾´é‡
        for period in [20]:
            features[f"skewness_{period}"] = returns.rolling(period).skew().fillna(0)
            features[f"kurtosis_{period}"] = returns.rolling(period).kurt().fillna(0)
            features[f"close_mean_{period}"] = (
                df["close"].rolling(period).mean().fillna(df["close"])
            )
            features[f"close_std_{period}"] = (
                df["close"].rolling(period).std().fillna(0)
            )

        # è¿½åŠ æ™‚é–“ç‰¹å¾´é‡
        features["day_of_week"] = df["timestamp"].dt.dayofweek
        features["is_weekend"] = (features["day_of_week"] >= 5).astype(int)
        features["is_asian_session"] = (
            (features["hour"] >= 0) & (features["hour"] <= 8)
        ).astype(int)
        features["is_european_session"] = (
            (features["hour"] >= 8) & (features["hour"] <= 16)
        ).astype(int)

    # NaNå€¤ã‚’å®‰å…¨ãªå€¤ã§åŸ‹ã‚ã‚‹
    features = features.fillna(0)

    # ç›®æ¨™ç‰¹å¾´é‡æ•°ã«èª¿æ•´
    target_count = 127 if feature_type == "full" else 26
    current_count = len(features.columns)

    if current_count < target_count:
        # ä¸è¶³åˆ†ã‚’ãƒ€ãƒŸãƒ¼ç‰¹å¾´é‡ã§è£œå®Œ
        for i in range(target_count - current_count):
            features[f"dummy_{i}"] = np.random.normal(0, 0.01, len(features))
    elif current_count > target_count:
        # éå‰°åˆ†ã‚’å‰Šé™¤
        features = features.iloc[:, :target_count]

    logger.info(f"{feature_type}ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {features.shape}")
    return features


def create_realistic_targets(df):
    """ç¾å®Ÿçš„ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ"""
    returns = df["close"].pct_change().fillna(0)

    # å‹•çš„é–¾å€¤ï¼ˆãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ï¼‰
    vol = returns.rolling(24 * 3).std().fillna(returns.std())  # 3æ—¥é–“ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    buy_threshold = 0.5 * vol  # ã‚ˆã‚Šæ§ãˆã‚ãªé–¾å€¤
    sell_threshold = -0.5 * vol

    targets = np.where(
        returns > buy_threshold, 1, np.where(returns < sell_threshold, 0, -1)
    )

    valid_mask = targets != -1
    return targets, valid_mask


def run_time_series_split_test(df, n_splits=3):
    """æ™‚ç³»åˆ—åˆ†å‰²ã§ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== è»½é‡ç‰ˆç‰¹å¾´é‡æ¯”è¼ƒãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
    targets, valid_mask = create_realistic_targets(df)

    results = {"full_127": [], "essential_26": []}

    # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
    df_valid = df[valid_mask].reset_index(drop=True)
    targets_valid = targets[valid_mask]

    # æ™‚ç³»åˆ—åˆ†å‰²
    tscv = TimeSeriesSplit(n_splits=n_splits)

    for split_idx, (train_idx, test_idx) in enumerate(tscv.split(df_valid)):
        logger.info(f"\n=== åˆ†å‰² {split_idx + 1}/{n_splits} ===")

        train_data = df_valid.iloc[train_idx]
        test_data = df_valid.iloc[test_idx]
        y_train = targets_valid[train_idx]
        y_test = targets_valid[test_idx]

        logger.info(
            f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_data)}ä»¶, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_data)}ä»¶"
        )
        logger.info(
            f"å­¦ç¿’æœŸé–“: {train_data['timestamp'].min()} - {train_data['timestamp'].max()}"
        )
        logger.info(
            f"ãƒ†ã‚¹ãƒˆæœŸé–“: {test_data['timestamp'].min()} - {test_data['timestamp'].max()}"
        )

        # å„ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆ
        for feature_type in ["full", "essential"]:
            set_name = "full_127" if feature_type == "full" else "essential_26"
            logger.info(f"\n{set_name}ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå‡¦ç†ä¸­...")

            # ç‰¹å¾´é‡ç”Ÿæˆ
            X_train = create_simple_features(train_data, feature_type)
            X_test = create_simple_features(test_data, feature_type)

            if len(np.unique(y_train)) < 2:
                logger.warning(f"{set_name}: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¹ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                continue

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            model = lgb.LGBMClassifier(
                objective="binary",
                n_estimators=50,
                max_depth=5,
                learning_rate=0.1,
                random_state=42,
                verbose=-1,
            )

            model.fit(X_train, y_train)

            # äºˆæ¸¬ãƒ»è©•ä¾¡
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]

            accuracy = accuracy_score(y_test, y_pred)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_test, y_pred, average="binary"
            )

            # äºˆæ¸¬å¤šæ§˜æ€§
            pred_std = np.std(y_pred_proba)
            pred_min = np.min(y_pred_proba)
            pred_max = np.max(y_pred_proba)

            # å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            trades = 0
            wins = 0
            total_return = 0

            for i in range(len(y_test)):
                if y_pred_proba[i] > 0.7 or y_pred_proba[i] < 0.3:
                    trades += 1
                    if (y_pred_proba[i] > 0.7 and y_test[i] == 1) or (
                        y_pred_proba[i] < 0.3 and y_test[i] == 0
                    ):
                        wins += 1
                        total_return += 0.015  # 1.5%åˆ©ç›Š
                    else:
                        total_return -= 0.01  # 1%æå¤±

            win_rate = wins / trades if trades > 0 else 0

            result = {
                "split": split_idx,
                "feature_count": X_train.shape[1],
                "train_size": len(X_train),
                "test_size": len(X_test),
                "accuracy": accuracy,
                "precision": precision,
                "recall": recall,
                "f1_score": f1,
                "pred_std": pred_std,
                "pred_min": pred_min,
                "pred_max": pred_max,
                "total_return": total_return,
                "trades": trades,
                "wins": wins,
                "win_rate": win_rate,
                "buy_signals": np.sum(y_pred_proba > 0.7),
                "sell_signals": np.sum(y_pred_proba < 0.3),
                "top_features": sorted(
                    zip(X_train.columns, model.feature_importances_),
                    key=lambda x: x[1],
                    reverse=True,
                )[:10],
            }

            results[set_name].append(result)

            logger.info(f"  ç²¾åº¦: {accuracy:.1%}")
            logger.info(f"  F1ã‚¹ã‚³ã‚¢: {f1:.1%}")
            logger.info(f"  äºˆæ¸¬ç¯„å›²: {pred_min:.3f} - {pred_max:.3f}")
            logger.info(f"  å–å¼•åç›Š: {total_return:.1%}")
            logger.info(f"  å‹ç‡: {win_rate:.1%} ({wins}/{trades})")

    return results


def analyze_results(results):
    """çµæœåˆ†æ"""
    logger.info("\n" + "=" * 80)
    logger.info("è»½é‡ç‰ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœåˆ†æ")
    logger.info("=" * 80)

    summary = {}

    for set_name, set_results in results.items():
        if not set_results:
            continue

        df_results = pd.DataFrame(set_results)

        summary[set_name] = {
            "avg_accuracy": df_results["accuracy"].mean(),
            "std_accuracy": df_results["accuracy"].std(),
            "avg_f1": df_results["f1_score"].mean(),
            "std_f1": df_results["f1_score"].std(),
            "avg_return": df_results["total_return"].mean(),
            "std_return": df_results["total_return"].std(),
            "avg_win_rate": df_results["win_rate"].mean(),
            "avg_pred_std": df_results["pred_std"].mean(),
            "avg_trades": df_results["trades"].mean(),
            "consistent_profitable": (
                (df_results["total_return"] > 0).sum() / len(df_results)
                if len(df_results) > 0
                else 0
            ),
        }

    # çµæœè¡¨ç¤º
    print(f"\n{'='*60}")
    print("ğŸ“Š ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ€§èƒ½æ¯”è¼ƒï¼ˆè»½é‡ç‰ˆï¼‰")
    print(f"{'='*60}")

    for set_name, stats in summary.items():
        display_name = (
            "127ç‰¹å¾´é‡ï¼ˆå®Œå…¨ç‰ˆï¼‰" if set_name == "full_127" else "26ç‰¹å¾´é‡ï¼ˆå³é¸ç‰ˆï¼‰"
        )
        print(f"\nğŸ” {display_name}:")
        print(f"  å¹³å‡ç²¾åº¦: {stats['avg_accuracy']:.1%} (Â±{stats['std_accuracy']:.1%})")
        print(f"  å¹³å‡F1ã‚¹ã‚³ã‚¢: {stats['avg_f1']:.1%} (Â±{stats['std_f1']:.1%})")
        print(f"  å¹³å‡åç›Šç‡: {stats['avg_return']:.1%} (Â±{stats['std_return']:.1%})")
        print(f"  å¹³å‡å‹ç‡: {stats['avg_win_rate']:.1%}")
        print(f"  å¹³å‡å–å¼•æ•°: {stats['avg_trades']:.0f}å›")
        print(f"  äºˆæ¸¬å¤šæ§˜æ€§: {stats['avg_pred_std']:.3f}")
        print(f"  åˆ©ç›Šä¸€è²«æ€§: {stats['consistent_profitable']:.1%}")

    # æ¨å¥¨æ±ºå®š
    if len(summary) >= 2:
        sets = list(summary.keys())
        full_stats = summary[sets[0]] if "full" in sets[0] else summary[sets[1]]
        essential_stats = (
            summary[sets[1]] if "essential" in sets[1] else summary[sets[0]]
        )

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        full_score = (
            full_stats["avg_f1"] * 0.4
            + full_stats["avg_return"] * 0.4
            + full_stats["avg_pred_std"] * 0.2
        )
        essential_score = (
            essential_stats["avg_f1"] * 0.4
            + essential_stats["avg_return"] * 0.4
            + essential_stats["avg_pred_std"] * 0.2
        )

        if essential_score > full_score:
            winner = "26ç‰¹å¾´é‡ï¼ˆå³é¸ç‰ˆï¼‰"
            reason = "åŠ¹ç‡æ€§ã¨æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹"
        else:
            winner = "127ç‰¹å¾´é‡ï¼ˆå®Œå…¨ç‰ˆï¼‰"
            reason = "ç·åˆæ€§èƒ½ã®å„ªä½æ€§"

        print(f"\nğŸ† æ¨å¥¨: {winner}")
        print(f"   ç†ç”±: {reason}")
        print(f"   127ç‰¹å¾´é‡ã‚¹ã‚³ã‚¢: {full_score:.3f}")
        print(f"   26ç‰¹å¾´é‡ã‚¹ã‚³ã‚¢: {essential_score:.3f}")

    return summary


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_latest_data()
    if df is None:
        return

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = run_time_series_split_test(df, n_splits=3)

    # çµæœåˆ†æ
    summary = analyze_results(results)

    # çµæœä¿å­˜
    results_dir = Path("results/lightweight_backtest")
    results_dir.mkdir(parents=True, exist_ok=True)

    results_path = results_dir / "lightweight_comparison_results.json"
    with open(results_path, "w") as f:
        json.dump(results, f, indent=2, default=str)

    summary_path = results_dir / "performance_summary.json"
    with open(summary_path, "w") as f:
        json.dump(summary, f, indent=2)

    logger.info(f"\nçµæœä¿å­˜å®Œäº†:")
    logger.info(f"  è©³ç´°: {results_path}")
    logger.info(f"  ã‚µãƒãƒªãƒ¼: {summary_path}")

    print(f"\n{'='*60}")
    print("ğŸ¯ çµè«–")
    print(f"{'='*60}")
    print("1. ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å•é¡Œã¯æ™‚ç³»åˆ—åˆ†å‰²ã§å›é¿")
    print("2. ç¾å®Ÿçš„ãªé–¾å€¤è¨­å®šã§éåº¦ãªæ¥½è¦³è«–ã‚’æ’é™¤")
    print("3. 127ç‰¹å¾´é‡ vs 26ç‰¹å¾´é‡ã®å®Ÿéš›ã®æ€§èƒ½å·®ã‚’ç¢ºèª")
    print("4. æ¬¡å…ƒã®å‘ªã„ã®å½±éŸ¿ã‚’å®šé‡çš„ã«è©•ä¾¡")


if __name__ == "__main__":
    main()
