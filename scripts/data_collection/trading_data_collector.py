#!/usr/bin/env python3
"""
Phase 12-2: å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼TradingStatisticsManageræ”¹è‰¯ç‰ˆï¼‰

Cloud Runãƒ­ã‚°ã‹ã‚‰å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ãƒ»åˆ†æã—ã€ä½“ç³»çš„ãªçµ±è¨ˆç®¡ç†ã‚’å®Ÿç¾ã€‚
ã‚·ãƒ³ãƒ—ãƒ«ã•ã¨å®Ÿç”¨æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’é‡è¦–ã—ãŸå€‹äººé–‹ç™ºæœ€é©åŒ–ç‰ˆã€‚

ãƒ¬ã‚¬ã‚¸ãƒ¼ã®è‰¯ã„éƒ¨åˆ†ã‚’æ´»ç”¨:
- TradingStatisticsManager: åŒ…æ‹¬çš„çµ±è¨ˆç®¡ç†ãƒ»ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ
- TradeRecordãƒ»DailyStatistics: å®Ÿç¸¾ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹è¨­è¨ˆ
- PerformanceMetrics: åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™å®šç¾©
"""

import argparse
import csv
import json
import logging
import subprocess
import sys
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd

# base_analyzer.pyæ´»ç”¨
sys.path.append(str(Path(__file__).parent.parent / "analytics"))
from base_analyzer import BaseAnalyzer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


@dataclass
class TradeRecord:
    """å€‹åˆ¥å–å¼•è¨˜éŒ²ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""

    trade_id: str
    timestamp: str
    symbol: str = "BTC_JPY"
    side: str = "unknown"  # 'buy', 'sell', 'hold'
    signal_confidence: float = 0.0
    entry_price: Optional[float] = None
    quantity: float = 0.0
    strategy_type: str = "unknown"
    status: str = "detected"  # 'detected', 'executed', 'completed'

    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return asdict(self)


@dataclass
class DailyStatistics:
    """æ—¥æ¬¡çµ±è¨ˆï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼æº–æ‹ ãƒ»ç°¡ç´ åŒ–ç‰ˆï¼‰"""

    date: str
    total_signals: int = 0
    buy_signals: int = 0
    sell_signals: int = 0
    hold_signals: int = 0
    signal_frequency: float = 0.0  # signals per hour
    avg_confidence: float = 0.0
    total_entries: int = 0
    total_logs: int = 0
    system_uptime_hours: float = 0.0

    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return asdict(self)


@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ç°¡ç´ ç‰ˆï¼‰"""

    # åŸºæœ¬çµ±è¨ˆ
    total_signals: int = 0
    total_buy: int = 0
    total_sell: int = 0
    total_hold: int = 0

    # é »åº¦åˆ†æ
    signals_per_hour: float = 0.0
    signals_per_day: float = 0.0

    # ä¿¡é ¼åº¦åˆ†æ
    avg_confidence: float = 0.0
    high_confidence_signals: int = 0  # confidence > 0.7

    # æ™‚é–“åŠ¹ç‡
    analysis_period_hours: float = 0.0
    data_collection_success_rate: float = 0.0

    # ã‚·ã‚¹ãƒ†ãƒ æŒ‡æ¨™
    log_entries_processed: int = 0
    error_rate: float = 0.0

    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return asdict(self)


class TradingDataCollector(BaseAnalyzer):
    """å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ï¼ˆPhase 12-2ç‰ˆãƒ»base_analyzer.pyæ´»ç”¨ï¼‰"""

    def __init__(
        self,
        project_id: str = "my-crypto-bot-project",
        service_name: str = "crypto-bot-service",
        region: str = "asia-northeast1",
        output_dir: str = "logs/data_collection",
    ):
        # base_analyzer.pyåˆæœŸåŒ–
        super().__init__(project_id, service_name, region)

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
        timestamp = datetime.now().strftime("%Y%m%d")
        self.trades_file = self.output_dir / f"trades_{timestamp}.csv"
        self.daily_stats_file = self.output_dir / f"daily_stats_{timestamp}.csv"
        self.performance_file = self.output_dir / f"performance_metrics_{timestamp}.json"

        # ãƒ‡ãƒ¼ã‚¿æ ¼ç´
        self.trades: List[TradeRecord] = []
        self.daily_stats: Dict[str, DailyStatistics] = {}
        self.performance_metrics = PerformanceMetrics()

        logger.info(f"TradingDataCollectoråˆæœŸåŒ–å®Œäº†ï¼ˆbase_analyzer.pyæ´»ç”¨ç‰ˆï¼‰: {output_dir}")

    def collect_trading_logs(self, hours: int = 24) -> Tuple[bool, int]:
        """Cloud Runãƒ­ã‚°ã‹ã‚‰å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆbase_analyzer.pyæ´»ç”¨ç‰ˆï¼‰"""
        logger.info(f"å–å¼•ãƒ­ã‚°åé›†é–‹å§‹ï¼ˆéå»{hours}æ™‚é–“ï¼‰")

        try:
            # base_analyzer.pyã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ´»ç”¨ï¼ˆé‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šé™¤ï¼‰
            success, logs = self.fetch_trading_logs(hours=hours, limit=500)

            if not success:
                logger.error("ãƒ­ã‚°å–å¾—å¤±æ•—")
                return False, 0

            logger.info(f"ãƒ­ã‚°å–å¾—æˆåŠŸ: {len(logs)}ä»¶")

            # ãƒ­ã‚°è§£æãƒ»TradeRecordç”Ÿæˆ
            processed_count = 0
            for log_entry in logs:
                trade_record = self._parse_log_entry(log_entry)
                if trade_record:
                    self.trades.append(trade_record)
                    processed_count += 1

            logger.info(f"å–å¼•ãƒ¬ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ: {processed_count}ä»¶")
            return True, processed_count

        except Exception as e:
            logger.error(f"ãƒ­ã‚°åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return False, 0

    def _convert_to_trade_record(self, log_entry: Dict, parsed_log: Dict) -> Optional[TradeRecord]:
        """è§£ææ¸ˆã¿ãƒ­ã‚°ã‚’TradeRecordã«å¤‰æ›ï¼ˆbase_analyzer.pyæ´»ç”¨ç‰ˆï¼‰"""
        try:
            # base_analyzer.pyã§è§£ææ¸ˆã¿ã®æƒ…å ±ã‚’æ´»ç”¨
            timestamp = parsed_log.get("timestamp", "")
            side = parsed_log.get("signal_type", "unknown")
            confidence = parsed_log.get("confidence", 0.0)
            strategy_type = parsed_log.get("strategy_type", "unknown")

            if side == "unknown" and confidence == 0.0:
                return None  # æœ‰åŠ¹ãªã‚·ã‚°ãƒŠãƒ«ã§ã¯ãªã„

            # TradeRecordç”Ÿæˆ
            trade_id = f"{timestamp.replace(':', '').replace('-', '').replace('T', '').replace('Z', '')}_{side}"

            return TradeRecord(
                trade_id=trade_id,
                timestamp=timestamp,
                side=side,
                signal_confidence=confidence,
                strategy_type=strategy_type,
                status="detected",
            )

        except Exception as e:
            logger.warning(f"ãƒ­ã‚°è§£æå¤±æ•—: {e}")
            return None

    def calculate_daily_statistics(self) -> Dict[str, DailyStatistics]:
        """æ—¥æ¬¡çµ±è¨ˆã‚’è¨ˆç®—"""
        logger.info("æ—¥æ¬¡çµ±è¨ˆè¨ˆç®—é–‹å§‹")

        # æ—¥ä»˜åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        daily_groups = {}
        for trade in self.trades:
            try:
                date = trade.timestamp[:10]  # YYYY-MM-DD
                if date not in daily_groups:
                    daily_groups[date] = []
                daily_groups[date].append(trade)
            except Exception:
                continue

        # å„æ—¥ã®çµ±è¨ˆè¨ˆç®—
        for date, trades in daily_groups.items():
            stats = DailyStatistics(date=date)

            stats.total_signals = len(trades)
            stats.buy_signals = len([t for t in trades if t.side == "buy"])
            stats.sell_signals = len([t for t in trades if t.side == "sell"])
            stats.hold_signals = len([t for t in trades if t.side == "hold"])

            # ä¿¡é ¼åº¦å¹³å‡
            confidences = [t.signal_confidence for t in trades if t.signal_confidence > 0]
            stats.avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

            # 1æ—¥ã‚’24æ™‚é–“ã¨ã—ã¦é »åº¦è¨ˆç®—
            stats.signal_frequency = stats.total_signals / 24.0
            stats.system_uptime_hours = 24.0  # ç°¡æ˜“å®Ÿè£…

            self.daily_stats[date] = stats

        logger.info(f"æ—¥æ¬¡çµ±è¨ˆè¨ˆç®—å®Œäº†: {len(self.daily_stats)}æ—¥åˆ†")
        return self.daily_stats

    def calculate_performance_metrics(self, hours: int = 24) -> PerformanceMetrics:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’è¨ˆç®—"""
        logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—é–‹å§‹")

        self.performance_metrics.total_signals = len(self.trades)
        self.performance_metrics.total_buy = len([t for t in self.trades if t.side == "buy"])
        self.performance_metrics.total_sell = len([t for t in self.trades if t.side == "sell"])
        self.performance_metrics.total_hold = len([t for t in self.trades if t.side == "hold"])

        # é »åº¦åˆ†æ
        self.performance_metrics.analysis_period_hours = hours
        self.performance_metrics.signals_per_hour = (
            self.performance_metrics.total_signals / hours if hours > 0 else 0
        )
        self.performance_metrics.signals_per_day = self.performance_metrics.signals_per_hour * 24

        # ä¿¡é ¼åº¦åˆ†æ
        confidences = [t.signal_confidence for t in self.trades if t.signal_confidence > 0]
        if confidences:
            self.performance_metrics.avg_confidence = sum(confidences) / len(confidences)
            self.performance_metrics.high_confidence_signals = len(
                [c for c in confidences if c > 0.7]
            )

        # ãƒ‡ãƒ¼ã‚¿åé›†æˆåŠŸç‡
        self.performance_metrics.log_entries_processed = len(self.trades)
        self.performance_metrics.data_collection_success_rate = 100.0 if self.trades else 0.0

        logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—å®Œäº†: {self.performance_metrics.total_signals}ã‚·ã‚°ãƒŠãƒ«")
        return self.performance_metrics

    def export_to_csv(self) -> Tuple[str, str]:
        """CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        logger.info("CSVå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–‹å§‹")

        # å–å¼•ãƒ‡ãƒ¼ã‚¿CSV
        with open(self.trades_file, "w", newline="", encoding="utf-8") as f:
            if self.trades:
                writer = csv.DictWriter(f, fieldnames=self.trades[0].to_dict().keys())
                writer.writeheader()
                for trade in self.trades:
                    writer.writerow(trade.to_dict())

        # æ—¥æ¬¡çµ±è¨ˆCSV
        with open(self.daily_stats_file, "w", newline="", encoding="utf-8") as f:
            if self.daily_stats:
                first_stat = next(iter(self.daily_stats.values()))
                writer = csv.DictWriter(f, fieldnames=first_stat.to_dict().keys())
                writer.writeheader()
                for stats in self.daily_stats.values():
                    writer.writerow(stats.to_dict())

        logger.info(f"CSVä¿å­˜å®Œäº†: {self.trades_file}, {self.daily_stats_file}")
        return str(self.trades_file), str(self.daily_stats_file)

    def export_performance_json(self) -> str:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™JSONä¿å­˜é–‹å§‹")

        report_data = {
            "timestamp": datetime.now().isoformat(),
            "collection_period_hours": self.performance_metrics.analysis_period_hours,
            "performance_metrics": self.performance_metrics.to_dict(),
            "daily_stats_summary": {
                "total_days": len(self.daily_stats),
                "avg_signals_per_day": (
                    sum(stats.total_signals for stats in self.daily_stats.values())
                    / len(self.daily_stats)
                    if self.daily_stats
                    else 0
                ),
            },
            "data_files": {
                "trades_csv": str(self.trades_file),
                "daily_stats_csv": str(self.daily_stats_file),
            },
        }

        with open(self.performance_file, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ä¿å­˜å®Œäº†: {self.performance_file}")
        return str(self.performance_file)

    def generate_summary_report(self) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

        report = []
        report.append("=" * 60)
        report.append("Phase 12-2 å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 60)
        report.append(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"åˆ†ææœŸé–“: {self.performance_metrics.analysis_period_hours}æ™‚é–“")
        report.append("")

        # åŸºæœ¬çµ±è¨ˆ
        report.append("ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        report.append(f"  ç·ã‚·ã‚°ãƒŠãƒ«æ•°: {self.performance_metrics.total_signals}")
        report.append(f"  BUYã‚·ã‚°ãƒŠãƒ«: {self.performance_metrics.total_buy}")
        report.append(f"  SELLã‚·ã‚°ãƒŠãƒ«: {self.performance_metrics.total_sell}")
        report.append(f"  HOLDã‚·ã‚°ãƒŠãƒ«: {self.performance_metrics.total_hold}")
        report.append("")

        # é »åº¦åˆ†æ
        report.append("ğŸ“ˆ é »åº¦åˆ†æ:")
        report.append(f"  ã‚·ã‚°ãƒŠãƒ«é »åº¦: {self.performance_metrics.signals_per_hour:.2f}/æ™‚é–“")
        report.append(f"  æ—¥æ¬¡æ¨å®š: {self.performance_metrics.signals_per_day:.1f}/æ—¥")
        report.append("")

        # ä¿¡é ¼åº¦åˆ†æ
        report.append("ğŸ¯ ä¿¡é ¼åº¦åˆ†æ:")
        report.append(f"  å¹³å‡ä¿¡é ¼åº¦: {self.performance_metrics.avg_confidence:.3f}")
        report.append(
            f"  é«˜ä¿¡é ¼ã‚·ã‚°ãƒŠãƒ«: {self.performance_metrics.high_confidence_signals}ä»¶ (>0.7)"
        )
        report.append("")

        # ãƒ‡ãƒ¼ã‚¿å“è³ª
        report.append("âœ… ãƒ‡ãƒ¼ã‚¿å“è³ª:")
        report.append(f"  å‡¦ç†æˆåŠŸç‡: {self.performance_metrics.data_collection_success_rate:.1f}%")
        report.append(f"  æ—¥æ¬¡çµ±è¨ˆ: {len(self.daily_stats)}æ—¥åˆ†")
        report.append("")

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        report.append("ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        report.append(f"  å–å¼•ãƒ‡ãƒ¼ã‚¿: {self.trades_file}")
        report.append(f"  æ—¥æ¬¡çµ±è¨ˆ: {self.daily_stats_file}")
        report.append(f"  æ€§èƒ½æŒ‡æ¨™: {self.performance_file}")
        report.append("=" * 60)

        return "\n".join(report)

    def run_collection(self, hours: int = 24) -> bool:
        """å®Œå…¨ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œï¼ˆbase_analyzer.pyæ´»ç”¨ç‰ˆï¼‰"""
        logger.info(f"Phase 12-2å®Ÿãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ï¼ˆæœŸé–“: {hours}æ™‚é–“ï¼‰")

        try:
            # 1. ãƒ­ã‚°åé›†ï¼ˆbase_analyzer.pyæ´»ç”¨ï¼‰
            success, count = self.collect_trading_logs(hours)
            if not success:
                logger.error("ãƒ­ã‚°åé›†å¤±æ•—")
                return False

            # 2. çµ±è¨ˆè¨ˆç®—
            self.calculate_daily_statistics()
            self.calculate_performance_metrics(hours)

            # 3. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆbase_analyzer.pyãƒ¡ã‚½ãƒƒãƒ‰æ´»ç”¨ï¼‰
            self.export_to_csv()
            self.export_performance_json()

            # 4. ã‚µãƒãƒªãƒ¼å‡ºåŠ›
            summary = self.generate_summary_report()
            print(summary)

            logger.info("Phase 12-2å®Ÿãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
            return True

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    # ===== base_analyzer.pyæŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£… =====

    def run_analysis(self, hours: int = 24) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿åé›†åˆ†æå®Ÿè¡Œï¼ˆbase_analyzer.pyè¦æ±‚ï¼‰"""
        success = self.run_collection(hours)
        return {
            "success": success,
            "trade_count": len(self.trades),
            "daily_stats_count": len(self.daily_stats),
            "analysis_period_hours": hours,
            "performance_metrics": self.performance_metrics.to_dict(),
        }

    def generate_report(self, analysis_result: Dict) -> str:
        """ãƒ‡ãƒ¼ã‚¿åé›†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆbase_analyzer.pyè¦æ±‚ï¼‰"""
        if analysis_result.get("success"):
            return f"""
=== Phase 12-2 ãƒ‡ãƒ¼ã‚¿åé›†ãƒ¬ãƒãƒ¼ãƒˆ ===
å–å¼•ä»¶æ•°: {analysis_result.get('trade_count', 0)}
çµ±è¨ˆæ—¥æ•°: {analysis_result.get('daily_stats_count', 0)}
åˆ†ææœŸé–“: {analysis_result.get('analysis_period_hours', 0)}æ™‚é–“
ã‚·ã‚°ãƒŠãƒ«é »åº¦: {analysis_result.get('performance_metrics', {}).get('signals_per_hour', 0):.2f}/h
==================================="""
        else:
            return "ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—"


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="Phase 12-2 å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--hours", type=int, default=24, help="åé›†æœŸé–“ï¼ˆæ™‚é–“ï¼‰")
    parser.add_argument("--service", default="crypto-bot-service", help="Cloud Runã‚µãƒ¼ãƒ“ã‚¹å")
    parser.add_argument("--project", default="my-crypto-bot-project", help="GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID")
    parser.add_argument("--region", default="asia-northeast1", help="GCPãƒªãƒ¼ã‚¸ãƒ§ãƒ³")
    parser.add_argument("--output", default="logs/data_collection", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")

    args = parser.parse_args()

    try:
        collector = TradingDataCollector(
            project_id=args.project,
            service_name=args.service,
            region=args.region,
            output_dir=args.output,
        )

        success = collector.run_collection(args.hours)

        if success:
            print("\\nğŸ‰ Phase 12-2å®Ÿãƒ‡ãƒ¼ã‚¿åé›†æˆåŠŸï¼")
            print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»A/Bãƒ†ã‚¹ãƒˆãƒ»ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ´»ç”¨ãŒå¯èƒ½ã§ã™")
        else:
            print("\\nâŒ ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("ãƒ‡ãƒ¼ã‚¿åé›†ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
