#!/usr/bin/env python3
"""
Phase 54.7: MLãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„:
- è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æ€§èƒ½ã‚’æ¤œè¨¼
- ç²¾åº¦ãƒ»F1ã‚¹ã‚³ã‚¢ãƒ»ä¿¡é ¼åº¦åˆ†å¸ƒã‚’ç¢ºèª
- ãƒ‡ãƒ—ãƒ­ã‚¤å‰ã®ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼

ä½¿ç”¨æ–¹æ³•:
    python scripts/ml/validate_model_performance.py
"""

import json
import pickle
import sys
from pathlib import Path

import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))


class ModelPerformanceValidator:
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.project_root = project_root
        self.model = None
        self.metadata = None

    def load_model(self) -> bool:
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        print("=" * 60)
        print("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
        print("=" * 60)

        model_path = self.project_root / "models/production/ensemble_full.pkl"
        metadata_path = self.project_root / "models/production/production_model_metadata.json"

        try:
            with open(model_path, "rb") as f:
                self.model = pickle.load(f)
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {model_path.name}")
            print(f"   ã‚¿ã‚¤ãƒ—: {type(self.model).__name__}")

            with open(metadata_path, "r") as f:
                self.metadata = json.load(f)
            print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ")
            print(f"   ä½œæˆæ—¥æ™‚: {self.metadata.get('created_at', 'unknown')}")
            print(
                f"   ç‰¹å¾´é‡æ•°: {self.metadata.get('training_info', {}).get('feature_count', 'unknown')}"
            )
            return True
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def load_test_data(self) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
        print("=" * 60)

        # 4hè¶³ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        data_path = self.project_root / "src/backtest/data/historical/btc_jpy_4h.csv"

        try:
            df = pd.read_csv(data_path)
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {data_path.name}")
            print(f"   è¡Œæ•°: {len(df)}")
            print(f"   æœŸé–“: {df['timestamp'].iloc[0]} ã€œ {df['timestamp'].iloc[-1]}")
            return df
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def generate_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾´é‡ç”Ÿæˆ"""
        print("\n" + "=" * 60)
        print("ğŸ”§ ç‰¹å¾´é‡ç”Ÿæˆ")
        print("=" * 60)

        try:
            from src.features.feature_generator import FeatureGenerator

            generator = FeatureGenerator()
            features_df = generator.generate_features_sync(df)
            print(f"âœ… ç‰¹å¾´é‡ç”ŸæˆæˆåŠŸ: {len(features_df.columns)}åˆ—")
            return features_df
        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def validate_predictions(self, features_df: pd.DataFrame) -> dict:
        """äºˆæ¸¬æ¤œè¨¼"""
        print("\n" + "=" * 60)
        print("ğŸ¯ äºˆæ¸¬æ¤œè¨¼")
        print("=" * 60)

        # ãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã™ã‚‹ç‰¹å¾´é‡ã‚’å–å¾—
        expected_features = self.metadata.get("feature_names", [])
        print(f"   æœŸå¾…ç‰¹å¾´é‡æ•°: {len(expected_features)}")

        # æˆ¦ç•¥ä¿¡å·ä»¥å¤–ã®ç‰¹å¾´é‡ã§ãƒ†ã‚¹ãƒˆï¼ˆæˆ¦ç•¥ä¿¡å·ã¯ãƒ€ãƒŸãƒ¼å€¤ã§è£œå®Œï¼‰
        base_features = [f for f in expected_features if not f.startswith("strategy_signal_")]
        strategy_features = [f for f in expected_features if f.startswith("strategy_signal_")]

        print(f"   åŸºæœ¬ç‰¹å¾´é‡: {len(base_features)}")
        print(f"   æˆ¦ç•¥ä¿¡å·: {len(strategy_features)}")

        # åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡ã‚’ç¢ºèª
        available = [f for f in base_features if f in features_df.columns]
        missing = [f for f in base_features if f not in features_df.columns]

        print(f"\n   åˆ©ç”¨å¯èƒ½: {len(available)}/{len(base_features)}")
        if missing:
            print(f"   ä¸è¶³: {missing[:5]}...")

        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆæœ€æ–°100ä»¶ï¼‰
        test_size = min(100, len(features_df))
        test_df = features_df.tail(test_size).copy()

        # ä¸è¶³ç‰¹å¾´é‡ã¯ãƒ€ãƒŸãƒ¼å€¤ï¼ˆ0ï¼‰ã§è£œå®Œ
        for f in expected_features:
            if f not in test_df.columns:
                test_df[f] = 0.0

        # ç‰¹å¾´é‡ã‚’æ­£ã—ã„é †åºã§æŠ½å‡º
        X_test = test_df[expected_features].values

        # NaNã‚’0ã§ç½®æ›
        X_test = np.nan_to_num(X_test, nan=0.0)

        print(f"\n   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_test.shape}")

        # äºˆæ¸¬å®Ÿè¡Œ
        try:
            predictions = self.model.predict(X_test)
            probabilities = self.model.predict_proba(X_test)

            # çµæœé›†è¨ˆ
            unique, counts = np.unique(predictions, return_counts=True)
            pred_dist = dict(zip(unique, counts))

            print(f"\nâœ… äºˆæ¸¬æˆåŠŸ")
            print(f"   äºˆæ¸¬åˆ†å¸ƒ:")
            for label, count in sorted(pred_dist.items()):
                pct = count / len(predictions) * 100
                label_name = {0: "SELL", 1: "HOLD", 2: "BUY"}.get(label, str(label))
                print(f"     {label_name}: {count}ä»¶ ({pct:.1f}%)")

            # ä¿¡é ¼åº¦åˆ†æ
            max_probs = np.max(probabilities, axis=1)
            print(f"\n   ä¿¡é ¼åº¦çµ±è¨ˆ:")
            print(f"     å¹³å‡: {np.mean(max_probs):.3f}")
            print(f"     æœ€å°: {np.min(max_probs):.3f}")
            print(f"     æœ€å¤§: {np.max(max_probs):.3f}")
            print(f"     æ¨™æº–åå·®: {np.std(max_probs):.3f}")

            # é«˜ä¿¡é ¼åº¦ï¼ˆ>0.6ï¼‰ã®å‰²åˆ
            high_conf = np.sum(max_probs > 0.6) / len(max_probs) * 100
            print(f"     é«˜ä¿¡é ¼åº¦(>60%): {high_conf:.1f}%")

            return {
                "success": True,
                "test_size": test_size,
                "predictions": pred_dist,
                "confidence_mean": float(np.mean(max_probs)),
                "confidence_std": float(np.std(max_probs)),
                "high_confidence_ratio": high_conf,
            }

        except Exception as e:
            print(f"âŒ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            traceback.print_exc()
            return {"success": False, "error": str(e)}

    def validate_individual_models(self) -> dict:
        """å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼"""
        print("\n" + "=" * 60)
        print("ğŸ” å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼")
        print("=" * 60)

        if not hasattr(self.model, "models"):
            print("âš ï¸ å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯")
            return {}

        results = {}
        for name, model in self.model.models.items():
            print(f"\nğŸ“Š {name}:")
            print(f"   ã‚¿ã‚¤ãƒ—: {type(model).__name__}")

            if hasattr(model, "n_estimators"):
                print(f"   n_estimators: {model.n_estimators}")
            if hasattr(model, "n_features_in_"):
                print(f"   n_features_in_: {model.n_features_in_}")
            if hasattr(model, "classes_"):
                print(f"   classes_: {model.classes_}")

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ€§èƒ½ã‚’å–å¾—
            perf = self.metadata.get("performance_metrics", {}).get(name, {})
            if perf:
                print(f"   è¨“ç·´æ™‚æ€§èƒ½:")
                print(f"     Accuracy: {perf.get('accuracy', 'N/A'):.3f}")
                print(f"     F1 Score: {perf.get('f1_score', 'N/A'):.3f}")
                print(f"     CV F1 Mean: {perf.get('cv_f1_mean', 'N/A'):.3f}")

            results[name] = {
                "type": type(model).__name__,
                "n_features": getattr(model, "n_features_in_", None),
                "performance": perf,
            }

        return results

    def run_validation(self) -> bool:
        """å…¨æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        print("\n" + "=" * 60)
        print("ğŸš€ Phase 54.7: MLãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¤œè¨¼é–‹å§‹")
        print("=" * 60)

        # 1. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        if not self.load_model():
            return False

        # 2. å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼
        individual_results = self.validate_individual_models()

        # 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = self.load_test_data()
        if df is None:
            return False

        # 4. ç‰¹å¾´é‡ç”Ÿæˆ
        features_df = self.generate_features(df)
        if features_df is None:
            return False

        # 5. äºˆæ¸¬æ¤œè¨¼
        pred_results = self.validate_predictions(features_df)

        # 6. çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 60)
        print("ğŸ“‹ æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)

        if pred_results.get("success"):
            print("\nâœ… ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¤œè¨¼æˆåŠŸ")
            print(f"   ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {pred_results.get('test_size')}")
            print(f"   ä¿¡é ¼åº¦å¹³å‡: {pred_results.get('confidence_mean', 0):.3f}")
            print(f"   é«˜ä¿¡é ¼åº¦æ¯”ç‡: {pred_results.get('high_confidence_ratio', 0):.1f}%")

            # äºˆæ¸¬ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
            preds = pred_results.get("predictions", {})
            total = sum(preds.values())
            if total > 0:
                buy_ratio = preds.get(2, 0) / total * 100
                sell_ratio = preds.get(0, 0) / total * 100
                hold_ratio = preds.get(1, 0) / total * 100

                print(f"\n   äºˆæ¸¬ãƒãƒ©ãƒ³ã‚¹:")
                print(f"     BUY: {buy_ratio:.1f}%")
                print(f"     HOLD: {hold_ratio:.1f}%")
                print(f"     SELL: {sell_ratio:.1f}%")

                # ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
                if abs(buy_ratio - sell_ratio) > 30:
                    print("\nâš ï¸ è­¦å‘Š: BUY/SELLã®åã‚ŠãŒå¤§ãã„")
                elif hold_ratio > 80:
                    print("\nâš ï¸ è­¦å‘Š: HOLDæ¯”ç‡ãŒé«˜ã™ãã‚‹")
                else:
                    print("\nâœ… äºˆæ¸¬ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½")

            return True
        else:
            print(f"\nâŒ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¤œè¨¼å¤±æ•—: {pred_results.get('error')}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    validator = ModelPerformanceValidator()
    success = validator.run_validation()
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
