#!/usr/bin/env python3
"""
ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰çµ±åˆè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - Phase 62.10

ç›®çš„:
  ãƒ©ã‚¤ãƒ–é‹ç”¨ã®æ¨™æº–åŒ–ã•ã‚ŒãŸåˆ†æã¨ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»Botæ©Ÿèƒ½è¨ºæ–­ã‚’
  çµ±åˆã—ã€å˜ä¸€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å®Œå…¨ãªè¨ºæ–­ã‚’å®Ÿç¾ã€‚

æ©Ÿèƒ½:
  - 39é …ç›®ã®å›ºå®šæŒ‡æ¨™è¨ˆç®—ï¼ˆLiveAnalyzerï¼‰
  - ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­ï¼ˆInfrastructureCheckerï¼‰
    - Cloud Runç¨¼åƒçŠ¶æ³
    - Secret Manageræ¨©é™ç¢ºèª
    - Containerå®‰å®šæ€§
    - Discordé€šçŸ¥ç¢ºèª
    - APIæ®‹é«˜å–å¾—ç¢ºèª
    - ãƒã‚¸ã‚·ãƒ§ãƒ³å¾©å…ƒç¢ºèª
    - å–å¼•é˜»å®³ã‚¨ãƒ©ãƒ¼æ¤œå‡º
  - Botæ©Ÿèƒ½è¨ºæ–­ï¼ˆBotFunctionCheckerï¼‰
    - 55ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª
    - Silent Failureæ¤œå‡º
    - 6æˆ¦ç•¥å‹•ä½œç¢ºèª
    - MLäºˆæ¸¬ç¢ºèª
    - ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥TP/SLç¢ºèª
    - KellyåŸºæº–ç¢ºèª
    - Atomic Entry Patternç¢ºèª
    - Phase 62.9-62.10: Makeræˆ¦ç•¥ç¢ºèªï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼/TPæ±ºæ¸ˆï¼‰
  - JSON/Markdown/CSVå‡ºåŠ›
  - çµ‚äº†ã‚³ãƒ¼ãƒ‰å¯¾å¿œï¼ˆCI/CDé€£æºç”¨ï¼‰

ä½¿ã„æ–¹:
  # åŸºæœ¬å®Ÿè¡Œï¼ˆå…¨è¨ºæ–­ + 39æŒ‡æ¨™ï¼‰
  python3 scripts/live/standard_analysis.py

  # æœŸé–“æŒ‡å®šï¼ˆ48æ™‚é–“ï¼‰
  python3 scripts/live/standard_analysis.py --hours 48

  # å‡ºåŠ›å…ˆæŒ‡å®š
  python3 scripts/live/standard_analysis.py --output results/live/

  # CI/CDé€£æºï¼ˆçµ‚äº†ã‚³ãƒ¼ãƒ‰è¿”å´ï¼‰
  python3 scripts/live/standard_analysis.py --exit-code

  # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆGCPãƒ­ã‚°ã®ã¿ã€APIå‘¼ã³å‡ºã—ãªã—ï¼‰
  python3 scripts/live/standard_analysis.py --quick

çµ‚äº†ã‚³ãƒ¼ãƒ‰:
  0: æ­£å¸¸
  1: è‡´å‘½çš„å•é¡Œï¼ˆå³åº§å¯¾å¿œå¿…é ˆï¼‰
  2: è¦æ³¨æ„ï¼ˆè©³ç´°è¨ºæ–­æ¨å¥¨ï¼‰
  3: ç›£è¦–ç¶™ç¶šï¼ˆè»½å¾®ãªå•é¡Œï¼‰
"""

import argparse
import asyncio
import csv
import json
import os
import subprocess
import sys
import time
from dataclasses import asdict, dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ï¼‰
from dotenv import load_dotenv

env_path = PROJECT_ROOT / "config" / "secrets" / ".env"
if env_path.exists():
    load_dotenv(env_path, override=True)
    # èª­ã¿è¾¼ã¿ç¢ºèªç”¨ãƒ­ã‚°ã¯å¾Œã§å‡ºåŠ›ï¼ˆloggeråˆæœŸåŒ–å¾Œï¼‰

from src.core.logger import get_logger
from src.data.bitbank_client import BitbankClient

# =============================================================================
# ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­ï¼ˆcheck_infrastructure.sh ç§»æ¤ï¼‰
# =============================================================================


@dataclass
class InfrastructureCheckResult:
    """ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­çµæœ"""

    # Cloud RunçŠ¶æ…‹
    cloud_run_status: str = ""  # True/False/Unknown
    latest_revisions: List[str] = field(default_factory=list)

    # Secret Manager
    service_account: str = ""
    bitbank_key_ok: bool = False
    bitbank_secret_ok: bool = False
    discord_ok: bool = False

    # Containerå®‰å®šæ€§
    container_exit_count: int = 0
    runtime_warning_count: int = 0

    # Discordé€šçŸ¥
    discord_error_count: int = 0

    # APIæ®‹é«˜å–å¾—
    api_balance_count: int = 0
    fallback_count: int = 0

    # ãƒã‚¸ã‚·ãƒ§ãƒ³å¾©å…ƒ
    position_restore_count: int = 0

    # å–å¼•é˜»å®³ã‚¨ãƒ©ãƒ¼
    nonetype_error_count: int = 0
    api_error_count: int = 0

    # ã‚¹ã‚³ã‚¢
    normal_checks: int = 0
    warning_issues: int = 0
    critical_issues: int = 0
    total_score: int = 0


class InfrastructureChecker:
    """ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­ã‚¯ãƒ©ã‚¹"""

    def __init__(self, logger):
        self.logger = logger
        self.result = InfrastructureCheckResult()
        self.deploy_time = self._get_deploy_time()

    def _get_deploy_time(self) -> str:
        """æœ€æ–°CIæ™‚åˆ»ã¾ãŸã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚åˆ»ã‚’å–å¾—"""
        try:
            result = subprocess.run(
                [
                    "gh",
                    "run",
                    "list",
                    "--limit=1",
                    "--workflow=CI/CD Pipeline",
                    "--status=success",
                    "--json=createdAt",
                    "--jq=.[0].createdAt",
                ],
                capture_output=True,
                text=True,
                timeout=30,
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
        except Exception:
            pass

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éå»24æ™‚é–“
        from datetime import timezone

        utc_time = datetime.now(timezone.utc) - timedelta(days=1)
        return utc_time.strftime("%Y-%m-%dT%H:%M:%S.%fZ")

    def _count_gcp_logs(self, query: str, limit: int = 50) -> int:
        """GCPãƒ­ã‚°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        if not self.deploy_time:
            return 0

        try:
            full_query = (
                f'resource.type="cloud_run_revision" AND '
                f'resource.labels.service_name="crypto-bot-service-prod" AND '
                f"({query}) AND "
                f'timestamp>="{self.deploy_time}"'
            )
            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    full_query,
                    f"--limit={limit}",
                    "--format=value(textPayload)",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )
            if result.returncode == 0:
                lines = [line for line in result.stdout.strip().split("\n") if line]
                return len(lines)
        except Exception:
            pass
        return 0

    def _fetch_gcp_logs(self, query: str, limit: int = 5) -> List[str]:
        """GCPãƒ­ã‚°ã‚’å–å¾—"""
        if not self.deploy_time:
            return []

        try:
            full_query = (
                f'resource.type="cloud_run_revision" AND '
                f'resource.labels.service_name="crypto-bot-service-prod" AND '
                f"({query}) AND "
                f'timestamp>="{self.deploy_time}"'
            )
            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    full_query,
                    f"--limit={limit}",
                    "--format=value(timestamp.date(tz='Asia/Tokyo'),textPayload)",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )
            if result.returncode == 0:
                return [line for line in result.stdout.strip().split("\n") if line]
        except Exception:
            pass
        return []

    def check(self) -> InfrastructureCheckResult:
        """ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­å®Ÿè¡Œ"""
        self.logger.info("ğŸš€ ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­é–‹å§‹")

        self._check_cloud_run()
        self._check_secret_manager()
        self._check_container_stability()
        self._check_discord()
        self._check_api_balance()
        self._check_position_restore()
        self._check_trade_blocking_errors()

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        self.result.total_score = (
            self.result.normal_checks * 10
            - self.result.warning_issues * 3
            - self.result.critical_issues * 20
        )

        self.logger.info(
            f"ğŸ“Š ã‚¤ãƒ³ãƒ•ãƒ©è¨ºæ–­å®Œäº† - æ­£å¸¸:{self.result.normal_checks} "
            f"è­¦å‘Š:{self.result.warning_issues} è‡´å‘½çš„:{self.result.critical_issues}"
        )
        return self.result

    def _check_cloud_run(self):
        """Cloud Runã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒç¢ºèª"""
        self.logger.info("ğŸ”§ Cloud Run ã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒç¢ºèª")
        try:
            result = subprocess.run(
                [
                    "gcloud",
                    "run",
                    "services",
                    "describe",
                    "crypto-bot-service-prod",
                    "--region=asia-northeast1",
                    "--format=value(status.conditions[0].status)",
                ],
                capture_output=True,
                text=True,
                timeout=30,
            )
            self.result.cloud_run_status = (
                result.stdout.strip() if result.returncode == 0 else "Unknown"
            )
            if self.result.cloud_run_status == "True":
                self.result.normal_checks += 1
            else:
                self.result.critical_issues += 2
        except Exception as e:
            self.logger.warning(f"Cloud Runç¢ºèªå¤±æ•—: {e}")
            self.result.cloud_run_status = "Error"

    def _check_secret_manager(self):
        """Secret Manageræ¨©é™ç¢ºèª"""
        self.logger.info("ğŸ” Secret Manager æ¨©é™ç¢ºèª")
        try:
            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
            result = subprocess.run(
                [
                    "gcloud",
                    "run",
                    "services",
                    "describe",
                    "crypto-bot-service-prod",
                    "--region=asia-northeast1",
                    "--format=value(spec.template.spec.serviceAccountName)",
                ],
                capture_output=True,
                text=True,
                timeout=30,
            )
            self.result.service_account = result.stdout.strip() if result.returncode == 0 else ""

            if self.result.service_account:
                # å„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®æ¨©é™ç¢ºèª
                for secret, attr in [
                    ("bitbank-api-key", "bitbank_key_ok"),
                    ("bitbank-api-secret", "bitbank_secret_ok"),
                    ("discord-webhook-url", "discord_ok"),
                ]:
                    check = subprocess.run(
                        [
                            "gcloud",
                            "secrets",
                            "get-iam-policy",
                            secret,
                            "--format=value(bindings[].members)",
                        ],
                        capture_output=True,
                        text=True,
                        timeout=30,
                    )
                    if check.returncode == 0 and self.result.service_account in check.stdout:
                        setattr(self.result, attr, True)

                if (
                    self.result.bitbank_key_ok
                    and self.result.bitbank_secret_ok
                    and self.result.discord_ok
                ):
                    self.result.normal_checks += 1
                else:
                    self.result.critical_issues += 2
        except Exception as e:
            self.logger.warning(f"Secret Managerç¢ºèªå¤±æ•—: {e}")

    def _check_container_stability(self):
        """Containerå®‰å®šæ€§ç¢ºèª"""
        self.logger.info("ğŸ”¥ Container å®‰å®šæ€§ç¢ºèª")
        self.result.container_exit_count = self._count_gcp_logs(
            'textPayload:"Container called exit(1)"', 20
        )
        self.result.runtime_warning_count = self._count_gcp_logs(
            'textPayload:"RuntimeWarning" AND textPayload:"never awaited"', 20
        )

        if self.result.container_exit_count < 5 and self.result.runtime_warning_count == 0:
            self.result.normal_checks += 1
        elif self.result.container_exit_count < 10 and self.result.runtime_warning_count < 5:
            self.result.warning_issues += 1
        else:
            self.result.critical_issues += 1

    def _check_discord(self):
        """Discordé€šçŸ¥ç¢ºèª"""
        self.logger.info("ğŸ“¨ Discord é€šçŸ¥ç¢ºèª")
        self.result.discord_error_count = self._count_gcp_logs(
            'textPayload:"code: 50027" OR textPayload:"Invalid Webhook Token"', 5
        )
        if self.result.discord_error_count == 0:
            self.result.normal_checks += 1
        else:
            self.result.critical_issues += 1

    def _check_api_balance(self):
        """APIæ®‹é«˜å–å¾—ç¢ºèª"""
        self.logger.info("ğŸ’° API æ®‹é«˜å–å¾—ç¢ºèª")
        self.result.api_balance_count = self._count_gcp_logs('textPayload:"æ®‹é«˜"', 15)
        self.result.fallback_count = self._count_gcp_logs('textPayload:"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"', 15)

        if self.result.api_balance_count > 0 and self.result.fallback_count < 3:
            self.result.normal_checks += 1
        elif self.result.fallback_count > 5:
            self.result.warning_issues += 1
        else:
            self.result.warning_issues += 1

    def _check_position_restore(self):
        """ãƒã‚¸ã‚·ãƒ§ãƒ³å¾©å…ƒç¢ºèª"""
        self.logger.info("ğŸ“Š ãƒã‚¸ã‚·ãƒ§ãƒ³å¾©å…ƒç¢ºèª")
        self.result.position_restore_count = self._count_gcp_logs(
            'textPayload:"ãƒã‚¸ã‚·ãƒ§ãƒ³å¾©å…ƒ" OR textPayload:"Position restored"', 10
        )
        if self.result.position_restore_count > 0:
            self.result.normal_checks += 1

    def _check_trade_blocking_errors(self):
        """å–å¼•é˜»å®³ã‚¨ãƒ©ãƒ¼æ¤œå‡º"""
        self.logger.info("ğŸ›¡ï¸ å–å¼•é˜»å®³ã‚¨ãƒ©ãƒ¼æ¤œå‡º")
        self.result.nonetype_error_count = self._count_gcp_logs('textPayload:"NoneType"', 20)
        self.result.api_error_count = self._count_gcp_logs(
            'textPayload:"bitbank API ã‚¨ãƒ©ãƒ¼" OR textPayload:"API.*ã‚¨ãƒ©ãƒ¼.*20"', 20
        )

        if self.result.nonetype_error_count == 0 and self.result.api_error_count < 3:
            self.result.normal_checks += 1
        elif self.result.nonetype_error_count < 5 and self.result.api_error_count < 10:
            self.result.warning_issues += 1
        else:
            self.result.critical_issues += 1


# =============================================================================
# Botæ©Ÿèƒ½è¨ºæ–­ï¼ˆcheck_bot_functions.sh ç§»æ¤ï¼‰
# =============================================================================


@dataclass
class BotFunctionCheckResult:
    """Botæ©Ÿèƒ½è¨ºæ–­çµæœ"""

    # 55ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ 
    feature_55_count: int = 0
    feature_49_count: int = 0
    dummy_model_count: int = 0

    # Silent Failure
    signal_count: int = 0
    order_count: int = 0
    success_rate: int = 0

    # 6æˆ¦ç•¥å‹•ä½œ
    strategy_counts: Dict[str, int] = field(default_factory=dict)
    active_strategy_count: int = 0

    # MLäºˆæ¸¬
    ml_prediction_count: int = 0

    # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥TP/SL
    regime_count: int = 0
    tight_range_count: int = 0
    normal_range_count: int = 0
    trending_count: int = 0

    # KellyåŸºæº–
    kelly_count: int = 0

    # Atomic Entry Pattern
    atomic_success_count: int = 0
    atomic_rollback_count: int = 0

    # Phase 62.9-62.10: Makeræˆ¦ç•¥
    entry_maker_success_count: int = 0
    entry_maker_fallback_count: int = 0
    entry_post_only_cancelled_count: int = 0
    tp_maker_success_count: int = 0
    tp_maker_fallback_count: int = 0
    tp_post_only_cancelled_count: int = 0

    # Phase 62.13: ATRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œçŸ¥
    atr_success_count: int = 0  # ATRå–å¾—æˆåŠŸæ•°
    atr_fallback_count: int = 0  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ATRä½¿ç”¨æ•°

    # ã‚¹ã‚³ã‚¢
    normal_checks: int = 0
    warning_issues: int = 0
    critical_issues: int = 0
    total_score: int = 0


class BotFunctionChecker:
    """Botæ©Ÿèƒ½è¨ºæ–­ã‚¯ãƒ©ã‚¹"""

    STRATEGIES = [
        "ATRBased",
        "BBReversal",
        "StochasticReversal",
        "DonchianChannel",
        "ADXTrendStrength",
        "MACDEMACrossover",
    ]

    def __init__(self, logger, infra_checker: InfrastructureChecker):
        self.logger = logger
        self.infra_checker = infra_checker
        self.result = BotFunctionCheckResult()

    def check(self) -> BotFunctionCheckResult:
        """Botæ©Ÿèƒ½è¨ºæ–­å®Ÿè¡Œ"""
        self.logger.info("ğŸ¤– Botæ©Ÿèƒ½è¨ºæ–­é–‹å§‹")

        self._check_feature_system()
        self._detect_silent_failure()
        self._check_strategy_activation()
        self._check_ml_prediction()
        self._check_regime_tp_sl()
        self._check_kelly_criterion()
        self._check_atomic_entry()
        self._check_maker_strategy()  # Phase 62.9-62.10
        self._check_atr_fallback()  # Phase 62.13

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        self.result.total_score = (
            self.result.normal_checks * 10
            - self.result.warning_issues * 3
            - self.result.critical_issues * 20
        )

        self.logger.info(
            f"ğŸ“Š Botæ©Ÿèƒ½è¨ºæ–­å®Œäº† - æ­£å¸¸:{self.result.normal_checks} "
            f"è­¦å‘Š:{self.result.warning_issues} è‡´å‘½çš„:{self.result.critical_issues}"
        )
        return self.result

    def _count_logs(self, query: str, limit: int = 50) -> int:
        """GCPãƒ­ã‚°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆInfrastructureCheckerã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å†åˆ©ç”¨ï¼‰"""
        return self.infra_checker._count_gcp_logs(query, limit)

    def _check_feature_system(self):
        """55ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª"""
        self.logger.info("ğŸ“Š 55ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª")
        self.result.feature_55_count = self._count_logs(
            'textPayload:"55ç‰¹å¾´é‡" OR textPayload:"55å€‹ã®ç‰¹å¾´é‡"', 15
        )
        self.result.feature_49_count = self._count_logs(
            'textPayload:"49ç‰¹å¾´é‡" OR textPayload:"åŸºæœ¬ç‰¹å¾´é‡ã®ã¿"', 15
        )
        self.result.dummy_model_count = self._count_logs('textPayload:"DummyModel"', 15)

        if self.result.feature_55_count > 0 and self.result.dummy_model_count == 0:
            self.result.normal_checks += 1
        elif self.result.feature_49_count > 0 and self.result.dummy_model_count == 0:
            self.result.warning_issues += 1
        elif self.result.dummy_model_count > 0:
            self.result.critical_issues += 2

    def _detect_silent_failure(self):
        """Silent Failureæ¤œå‡º"""
        self.logger.info("ğŸ” Silent Failure æ¤œå‡º")
        self.result.signal_count = self._count_logs(
            'textPayload:"çµ±åˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ: buy" OR textPayload:"çµ±åˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ: sell"',
            30,
        )
        self.result.order_count = self._count_logs(
            'textPayload:"æ³¨æ–‡å®Ÿè¡Œ" OR textPayload:"order_executed" OR textPayload:"create_order"',
            30,
        )

        if self.result.signal_count == 0:
            self.result.warning_issues += 1
        elif self.result.signal_count > 0 and self.result.order_count == 0:
            # å®Œå…¨Silent Failure
            self.result.critical_issues += 3
        else:
            self.result.success_rate = int(
                (self.result.order_count / self.result.signal_count) * 100
            )
            if self.result.success_rate >= 40:
                self.result.normal_checks += 1
            elif self.result.success_rate >= 20:
                self.result.warning_issues += 1
            else:
                self.result.critical_issues += 1

    def _check_strategy_activation(self):
        """6æˆ¦ç•¥å‹•ä½œç¢ºèª"""
        self.logger.info("ğŸ¯ 6æˆ¦ç•¥å‹•ä½œç¢ºèª")
        for strategy in self.STRATEGIES:
            count = self._count_logs(f'textPayload:"{strategy}"', 10)
            self.result.strategy_counts[strategy] = count
            if count > 0:
                self.result.active_strategy_count += 1

        if self.result.active_strategy_count == 6:
            self.result.normal_checks += 1
        elif self.result.active_strategy_count >= 4:
            self.result.warning_issues += 1
        else:
            self.result.critical_issues += 1

    def _check_ml_prediction(self):
        """MLäºˆæ¸¬ç¢ºèª"""
        self.logger.info("ğŸ¤– MLäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª")
        self.result.ml_prediction_count = self._count_logs(
            'textPayload:"ProductionEnsemble" OR textPayload:"MLäºˆæ¸¬" OR textPayload:"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬"',
            20,
        )

        if self.result.ml_prediction_count > 0:
            self.result.normal_checks += 1
        else:
            self.result.critical_issues += 1

    def _check_regime_tp_sl(self):
        """ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥TP/SLç¢ºèª"""
        self.logger.info("ğŸ“ˆ ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥TP/SLç¢ºèª")
        self.result.regime_count = self._count_logs(
            'textPayload:"å¸‚å ´çŠ¶æ³:" OR textPayload:"RegimeType" OR textPayload:"ãƒ¬ã‚¸ãƒ¼ãƒ "',
            10,
        )
        self.result.tight_range_count = self._count_logs(
            'textPayload:"TIGHT_RANGE" OR textPayload:"tight_range"', 10
        )
        self.result.normal_range_count = self._count_logs(
            'textPayload:"NORMAL_RANGE" OR textPayload:"normal_range"', 10
        )
        self.result.trending_count = self._count_logs(
            'textPayload:"TRENDING" OR textPayload:"trending"', 10
        )

        total = (
            self.result.tight_range_count
            + self.result.normal_range_count
            + self.result.trending_count
        )
        if total > 0:
            self.result.normal_checks += 1

    def _check_kelly_criterion(self):
        """KellyåŸºæº–ç¢ºèª"""
        self.logger.info("ğŸ’± KellyåŸºæº–ç¢ºèª")
        self.result.kelly_count = self._count_logs(
            'textPayload:"Kellyè¨ˆç®—" OR textPayload:"Kellyå±¥æ­´"', 15
        )
        if self.result.kelly_count > 0:
            self.result.normal_checks += 1

    def _check_atomic_entry(self):
        """Atomic Entry Patternç¢ºèª"""
        self.logger.info("ğŸ¯ Atomic Entry Patternç¢ºèª")
        self.result.atomic_success_count = self._count_logs('textPayload:"Atomic Entryå®Œäº†"', 10)
        self.result.atomic_rollback_count = self._count_logs(
            'textPayload:"ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ" OR textPayload:"Atomic Entry rollback"', 10
        )

        if self.result.atomic_success_count > 0 and self.result.atomic_rollback_count <= 2:
            self.result.normal_checks += 1
        elif self.result.atomic_rollback_count > 5:
            self.result.critical_issues += 1

    def _check_maker_strategy(self):
        """Phase 62.9-62.10: Makeræˆ¦ç•¥ç¢ºèª"""
        self.logger.info("ğŸ’° Phase 62.9-62.10: Makeræˆ¦ç•¥ç¢ºèª")

        # Phase 62.9: ã‚¨ãƒ³ãƒˆãƒªãƒ¼Makeræˆ¦ç•¥
        self.result.entry_maker_success_count = self._count_logs(
            'textPayload:"Phase 62.9: Makeræ³¨æ–‡é…ç½®æˆåŠŸ"', 20
        )
        self.result.entry_maker_fallback_count = self._count_logs(
            'textPayload:"Phase 62.9: Makerå¤±æ•—" OR textPayload:"Phase 62.9: Takerãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"',
            20,
        )
        self.result.entry_post_only_cancelled_count = self._count_logs(
            'textPayload:"Phase 62.9: post_onlyã‚­ãƒ£ãƒ³ã‚»ãƒ«"', 20
        )

        # Phase 62.10: TP Makeræˆ¦ç•¥
        self.result.tp_maker_success_count = self._count_logs(
            'textPayload:"Phase 62.10: TP Makeré…ç½®æˆåŠŸ"', 20
        )
        self.result.tp_maker_fallback_count = self._count_logs(
            'textPayload:"Phase 62.10: TP Makerå¤±æ•—" OR textPayload:"take_profitãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"',
            20,
        )
        self.result.tp_post_only_cancelled_count = self._count_logs(
            'textPayload:"Phase 62.10: TP post_onlyã‚­ãƒ£ãƒ³ã‚»ãƒ«"', 20
        )

        # è©•ä¾¡: Makeræˆ¦ç•¥ãŒå‹•ä½œã—ã¦ã„ã‚Œã°æ­£å¸¸
        total_entry = self.result.entry_maker_success_count + self.result.entry_maker_fallback_count
        total_tp = self.result.tp_maker_success_count + self.result.tp_maker_fallback_count

        if total_entry > 0 or total_tp > 0:
            # Makeræˆ¦ç•¥ãŒå‹•ä½œä¸­
            entry_success_rate = (
                self.result.entry_maker_success_count / total_entry * 100 if total_entry > 0 else 0
            )
            tp_success_rate = (
                self.result.tp_maker_success_count / total_tp * 100 if total_tp > 0 else 0
            )

            self.logger.info(
                f"ğŸ“Š Makeræˆ¦ç•¥çµ±è¨ˆ - ã‚¨ãƒ³ãƒˆãƒªãƒ¼: {self.result.entry_maker_success_count}æˆåŠŸ/"
                f"{self.result.entry_maker_fallback_count}FB ({entry_success_rate:.0f}%), "
                f"TP: {self.result.tp_maker_success_count}æˆåŠŸ/"
                f"{self.result.tp_maker_fallback_count}FB ({tp_success_rate:.0f}%)"
            )

            # æˆåŠŸç‡80%ä»¥ä¸Šãªã‚‰æ­£å¸¸
            if entry_success_rate >= 80 or tp_success_rate >= 80:
                self.result.normal_checks += 1
            elif entry_success_rate >= 50 or tp_success_rate >= 50:
                # 50%ä»¥ä¸Šãªã‚‰è­¦å‘Šã®ã¿
                pass
            else:
                # 50%æœªæº€ãªã‚‰è­¦å‘Š
                self.result.warning_issues += 1
        else:
            # Makeræˆ¦ç•¥ã®å‹•ä½œè¨˜éŒ²ãªã—ï¼ˆã¾ã å–å¼•ãŒãªã„å¯èƒ½æ€§ï¼‰
            self.logger.info("â„¹ï¸ Makeræˆ¦ç•¥: å‹•ä½œè¨˜éŒ²ãªã—ï¼ˆå–å¼•ãªã— or æœªæœ‰åŠ¹åŒ–ï¼‰")

    def _check_atr_fallback(self):
        """Phase 62.13: ATRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œçŸ¥"""
        self.logger.info("ğŸ“Š Phase 62.13: ATRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œçŸ¥")

        # ATRå–å¾—æˆåŠŸæ•°ï¼ˆPhase 62.13ã®æ–°ãƒ­ã‚°ï¼‰
        self.result.atr_success_count = self._count_logs(
            'textPayload:"Phase 62.13: ATRå–å¾—æˆåŠŸ"', 20
        )

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ATRä½¿ç”¨æ•°ï¼ˆæ—¢å­˜ã®ãƒ­ã‚°ï¼‰
        self.result.atr_fallback_count = self._count_logs(
            'textPayload:"Phase 51.5-C: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ATRä½¿ç”¨"', 20
        )

        total = self.result.atr_success_count + self.result.atr_fallback_count
        if total > 0:
            success_rate = self.result.atr_success_count / total * 100
            self.logger.info(
                f"ğŸ“Š ATRå–å¾—çµ±è¨ˆ - æˆåŠŸ: {self.result.atr_success_count}å›, "
                f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {self.result.atr_fallback_count}å› ({success_rate:.0f}%æˆåŠŸ)"
            )

            # 100%æˆåŠŸãªã‚‰æ­£å¸¸
            if success_rate == 100:
                self.result.normal_checks += 1
            # 80%ä»¥ä¸Šãªã‚‰è­¦å‘Š
            elif success_rate >= 80:
                self.result.warning_issues += 1
            # 80%æœªæº€ãªã‚‰è‡´å‘½çš„
            else:
                self.result.critical_issues += 1
                self.logger.warning(f"âš ï¸ ATRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤šç™º: {self.result.atr_fallback_count}å›")
        else:
            # è¨˜éŒ²ãªã—ï¼ˆã¾ã TP/SLå†è¨ˆç®—ãŒç™ºç”Ÿã—ã¦ã„ãªã„ï¼‰
            self.logger.info("â„¹ï¸ ATRå–å¾—: è¨˜éŒ²ãªã—ï¼ˆTP/SLå†è¨ˆç®—æœªç™ºç”Ÿï¼‰")


@dataclass
class LiveAnalysisResult:
    """ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰åˆ†æçµæœï¼ˆ35æŒ‡æ¨™ï¼‰"""

    # ãƒ¡ã‚¿æƒ…å ±
    timestamp: str = ""
    analysis_period_hours: int = 24

    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ…‹ï¼ˆ5æŒ‡æ¨™ï¼‰
    margin_ratio: float = 0.0
    available_balance: float = 0.0
    used_margin: float = 0.0
    unrealized_pnl: float = 0.0
    margin_call_status: str = ""

    # ãƒã‚¸ã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆ5æŒ‡æ¨™ï¼‰
    open_position_count: int = 0
    position_details: List[Dict[str, Any]] = field(default_factory=list)
    pending_order_count: int = 0
    order_breakdown: Dict[str, int] = field(default_factory=dict)
    losscut_price: Optional[float] = None

    # å–å¼•å±¥æ­´åˆ†æï¼ˆ12æŒ‡æ¨™ï¼‰
    trades_count: int = 0
    win_rate: float = 0.0
    total_pnl: float = 0.0
    avg_pnl: float = 0.0
    max_profit: float = 0.0
    max_loss: float = 0.0
    strategy_stats: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    tp_triggered_count: int = 0
    sl_triggered_count: int = 0

    # ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ï¼ˆ6æŒ‡æ¨™ï¼‰
    api_response_time_ms: float = 0.0
    recent_error_count: int = 0
    last_trade_time: Optional[str] = None
    service_status: str = ""
    last_deploy_time: Optional[str] = None
    container_restart_count: int = 0

    # TP/SLé©åˆ‡æ€§ï¼ˆ4æŒ‡æ¨™ï¼‰
    tp_distance_pct: Optional[float] = None
    sl_distance_pct: Optional[float] = None
    tp_sl_placement_ok: bool = True
    tp_sl_config_deviation: Optional[float] = None

    # Phase 58.8: å­¤å…æ³¨æ–‡æ¤œå‡ºï¼ˆ2æŒ‡æ¨™ï¼‰
    orphan_sl_detected: bool = False
    orphan_order_count: int = 0

    # ç¨¼åƒç‡ï¼ˆ5æŒ‡æ¨™ï¼‰
    uptime_rate: float = 0.0
    total_downtime_minutes: float = 0.0
    last_incident_time: Optional[str] = None
    actual_cycle_count: int = 0
    expected_cycle_count: int = 0

    # MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ï¼ˆ4æŒ‡æ¨™ï¼‰- Phase 59.8è¿½åŠ 
    ml_model_type: str = ""  # StackingEnsemble / ProductionEnsemble / DummyModel
    ml_model_level: int = -1  # 0=Stacking, 1=Full, 2=Basic, 3=Dummy
    ml_feature_count: int = 0  # 55 / 49 / 0
    stacking_enabled: bool = False  # thresholds.yamlè¨­å®šå€¤

    # Phase 62.16: ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸åˆ†æï¼ˆ6æŒ‡æ¨™ï¼‰
    slippage_avg: float = 0.0  # å¹³å‡ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ï¼ˆå††ï¼‰
    slippage_max: float = 0.0  # æœ€å¤§ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ï¼ˆå††ï¼‰
    slippage_min: float = 0.0  # æœ€å°ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ï¼ˆå††ï¼‰
    slippage_count: int = 0  # ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸è¨˜éŒ²æ•°
    slippage_entry_avg: float = 0.0  # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚å¹³å‡ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸
    slippage_exit_avg: float = 0.0  # æ±ºæ¸ˆæ™‚å¹³å‡ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸

    # Phase 62.18: SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆGCPãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ï¼‰
    sl_pattern_total_executions: int = 0
    sl_pattern_tp_count: int = 0
    sl_pattern_sl_count: int = 0
    sl_pattern_sl_pnl_total: float = 0.0
    sl_pattern_sl_pnl_avg: float = 0.0
    sl_pattern_tp_pnl_total: float = 0.0
    sl_pattern_tp_pnl_avg: float = 0.0
    sl_pattern_strategy_stats: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    sl_pattern_hourly_stats: Dict[int, int] = field(default_factory=dict)
    sl_pattern_weekday_stats: Dict[str, int] = field(default_factory=dict)


class LiveAnalyzer:
    """ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰æ¨™æº–åˆ†æ"""

    STRATEGIES = [
        "ATRBased",
        "BBReversal",
        "DonchianChannel",
        "StochasticReversal",
        "ADXTrendStrength",
        "MACDEMACrossover",
    ]

    def __init__(self, period_hours: int = 24):
        self.period_hours = period_hours
        self.logger = get_logger()
        self.result = LiveAnalysisResult(analysis_period_hours=period_hours)
        self.bitbank_client: Optional[BitbankClient] = None
        self.current_price: float = 0.0
        # Phase 59.5: æ³¨æ–‡ãƒ•ã‚§ãƒƒãƒä¸€å…ƒåŒ–ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°å·®ã«ã‚ˆã‚‹ä¸æ•´åˆé˜²æ­¢ï¼‰
        self._cached_active_orders: List[Dict[str, Any]] = []

    async def analyze(self) -> LiveAnalysisResult:
        """åˆ†æå®Ÿè¡Œ"""
        self.result.timestamp = datetime.now().isoformat()
        self.logger.info(f"ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰åˆ†æé–‹å§‹ - å¯¾è±¡æœŸé–“: {self.period_hours}æ™‚é–“")

        # .envèª­ã¿è¾¼ã¿ç¢ºèª
        if env_path.exists():
            api_key = os.getenv("BITBANK_API_KEY", "")
            if api_key and len(api_key) > 8:
                self.logger.info(f"âœ… .envã‹ã‚‰APIã‚­ãƒ¼èª­ã¿è¾¼ã¿æˆåŠŸ: {api_key[:8]}...")
            else:
                self.logger.warning("âš ï¸ .envãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã™ã‚‹ãŒAPIã‚­ãƒ¼ãŒç©º")

        try:
            # bitbankã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            self.bitbank_client = BitbankClient()

            # ç¾åœ¨ä¾¡æ ¼å–å¾—
            await self._fetch_current_price()

            # å„åˆ†æå®Ÿè¡Œ
            await self._fetch_account_status()
            await self._fetch_position_status()
            await self._fetch_trade_history()
            await self._check_system_health()
            await self._check_tp_sl_placement()
            await self._calculate_uptime()
            await self._check_ml_model_status()
            # Phase 62.18: SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            await self._analyze_sl_patterns()

        except Exception as e:
            self.logger.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            raise

        self.logger.info("ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰åˆ†æå®Œäº†")
        return self.result

    def _count_logs(self, query: str, limit: int = 50) -> int:
        """GCPãƒ­ã‚°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆPhase 61.11è¿½åŠ ï¼‰"""
        try:
            # ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚åˆ»ã‚’å–å¾—
            from datetime import timezone

            utc_now = datetime.now(timezone.utc)
            since_time = (utc_now - timedelta(hours=self.period_hours)).strftime(
                "%Y-%m-%dT%H:%M:%SZ"
            )

            full_query = (
                f'resource.type="cloud_run_revision" AND '
                f'resource.labels.service_name="crypto-bot-service-prod" AND '
                f"({query}) AND "
                f'timestamp>="{since_time}"'
            )
            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    full_query,
                    f"--limit={limit}",
                    "--format=value(textPayload)",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )
            if result.returncode == 0:
                lines = [line for line in result.stdout.strip().split("\n") if line]
                return len(lines)
        except FileNotFoundError:
            # ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ï¼ˆgcloudã‚³ãƒãƒ³ãƒ‰ãªã—ï¼‰
            self.logger.debug("GCPãƒ­ã‚°ã‚«ã‚¦ãƒ³ãƒˆã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼‰")
        except Exception as e:
            self.logger.debug(f"GCPãƒ­ã‚°ã‚«ã‚¦ãƒ³ãƒˆå¤±æ•—: {e}")
        return 0

    async def _fetch_current_price(self):
        """ç¾åœ¨ä¾¡æ ¼å–å¾—"""
        try:
            ticker = self.bitbank_client.fetch_ticker("BTC/JPY")
            self.current_price = ticker.get("last", 0)
            self.logger.info(f"ç¾åœ¨ä¾¡æ ¼: Â¥{self.current_price:,.0f}")
        except Exception as e:
            self.logger.warning(f"ä¾¡æ ¼å–å¾—å¤±æ•—: {e}")
            self.current_price = 0

    async def _fetch_account_status(self):
        """ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ…‹å–å¾—ï¼ˆ5æŒ‡æ¨™ï¼‰"""
        try:
            start_time = time.time()
            margin_status = await self.bitbank_client.fetch_margin_status()
            self.result.api_response_time_ms = (time.time() - start_time) * 1000

            self.result.margin_ratio = margin_status.get("margin_ratio", 0.0)
            self.result.available_balance = margin_status.get("available_balance", 0.0)
            self.result.used_margin = margin_status.get("used_margin", 0.0)
            self.result.unrealized_pnl = margin_status.get("unrealized_pnl", 0.0)
            self.result.margin_call_status = margin_status.get("margin_call_status", "unknown")

            self.logger.info(f"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ…‹å–å¾—å®Œäº† - ç¶­æŒç‡: {self.result.margin_ratio:.1f}%")
        except Exception as e:
            self.logger.error(f"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ…‹å–å¾—å¤±æ•—: {e}")
            self.result.margin_call_status = "error"

    async def _fetch_position_status(self):
        """ãƒã‚¸ã‚·ãƒ§ãƒ³çŠ¶æ…‹å–å¾—ï¼ˆ5æŒ‡æ¨™ï¼‰"""
        try:
            # ãƒã‚¸ã‚·ãƒ§ãƒ³å–å¾—ï¼ˆPhase 58.4: fetch_margin_positionsä½¿ç”¨ï¼‰
            positions = await self.bitbank_client.fetch_margin_positions("BTC/JPY")

            # Phase 58.8: æœ‰åŠ¹ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆBTC/JPY + Amount > 0ï¼‰
            # bitbank APIã¯å…¨é€šè²¨ãƒšã‚¢ã®ã‚¹ãƒ­ãƒƒãƒˆã‚’è¿”å´ã™ã‚‹ãŸã‚ã€ãƒ•ã‚£ãƒ«ã‚¿å¿…é ˆ
            active_positions = [
                p
                for p in positions
                if p.get("amount", 0) > 0
                and p.get("symbol", "").lower().replace("/", "_") == "btc_jpy"
            ]
            self.result.open_position_count = len(active_positions)

            # ãƒã‚¸ã‚·ãƒ§ãƒ³è©³ç´°ï¼ˆæœ‰åŠ¹ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ã¿ï¼‰
            self.result.position_details = []
            for pos in active_positions:
                detail = {
                    "side": pos.get("side", "unknown"),
                    "amount": pos.get("amount", 0),
                    "avg_price": pos.get("average_price", 0),
                    "unrealized_pnl": pos.get("unrealized_pnl", 0),
                }
                self.result.position_details.append(detail)

                # ãƒ­ã‚¹ã‚«ãƒƒãƒˆä¾¡æ ¼
                if pos.get("losscut_price"):
                    self.result.losscut_price = pos.get("losscut_price")

            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ³¨æ–‡å–å¾—ï¼ˆPhase 59.5: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼‰
            active_orders = self.bitbank_client.fetch_active_orders("BTC/JPY")
            self._cached_active_orders = active_orders  # ä»–ãƒ¡ã‚½ãƒƒãƒ‰ã§å†åˆ©ç”¨
            self.result.pending_order_count = len(active_orders)

            # æ³¨æ–‡å†…è¨³
            breakdown = {"limit": 0, "stop": 0, "stop_limit": 0}
            for order in active_orders:
                order_type = order.get("type", "limit")
                if order_type in breakdown:
                    breakdown[order_type] += 1
                else:
                    breakdown["limit"] += 1
            self.result.order_breakdown = breakdown

            # Phase 58.8: å­¤å…SL/TPæ¤œå‡º
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ãŒãªã„ã®ã«stop/stop_limitæ³¨æ–‡ãŒã‚ã‚‹å ´åˆã¯å­¤å…
            sl_tp_count = breakdown.get("stop", 0) + breakdown.get("stop_limit", 0)
            if self.result.open_position_count == 0 and sl_tp_count > 0:
                self.result.orphan_sl_detected = True
                self.result.orphan_order_count = sl_tp_count
                self.logger.warning(
                    f"âš ï¸ Phase 58.8: å­¤å…SL/TPæ³¨æ–‡æ¤œå‡º - {sl_tp_count}ä»¶ "
                    "(ãƒã‚¸ã‚·ãƒ§ãƒ³ãªã—ã§SL/TPæ³¨æ–‡ãŒæ®‹å­˜)"
                )

            self.logger.info(
                f"ãƒã‚¸ã‚·ãƒ§ãƒ³çŠ¶æ…‹å–å¾—å®Œäº† - ãƒã‚¸ã‚·ãƒ§ãƒ³: {self.result.open_position_count}ä»¶, "
                f"æœªç´„å®šæ³¨æ–‡: {self.result.pending_order_count}ä»¶"
            )
        except Exception as e:
            self.logger.error(f"ãƒã‚¸ã‚·ãƒ§ãƒ³çŠ¶æ…‹å–å¾—å¤±æ•—: {e}")

    async def _fetch_trade_history(self):
        """å–å¼•å±¥æ­´åˆ†æï¼ˆ12æŒ‡æ¨™ï¼‰"""
        try:
            # SQLiteã‹ã‚‰å–å¼•å±¥æ­´å–å¾—
            db_path = Path("tax/trade_history.db")
            if not db_path.exists():
                self.logger.warning("å–å¼•å±¥æ­´DBãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return

            import sqlite3

            conn = sqlite3.connect(db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # å¯¾è±¡æœŸé–“ã®é–‹å§‹æ™‚åˆ»
            start_time = (datetime.now() - timedelta(hours=self.period_hours)).isoformat()

            cursor.execute(
                """
                SELECT * FROM trades
                WHERE timestamp >= ?
                ORDER BY timestamp DESC
            """,
                (start_time,),
            )
            trades = [dict(row) for row in cursor.fetchall()]
            conn.close()

            self.result.trades_count = len(trades)

            # Phase 61.11: GCPãƒ­ã‚°ã‹ã‚‰TP/SLç™ºå‹•æ•°ã‚’å–å¾—ï¼ˆDBã«exitè¨˜éŒ²ãŒãªã„ãŸã‚ï¼‰
            # Phase 61.9ã®è‡ªå‹•åŸ·è¡Œæ¤œçŸ¥ãƒ­ã‚°ã‚’ä½¿ç”¨
            tp_from_logs = self._count_logs('textPayload:"TPè‡ªå‹•åŸ·è¡Œæ¤œçŸ¥"', 50)
            sl_from_logs = self._count_logs('textPayload:"SLè‡ªå‹•åŸ·è¡Œæ¤œçŸ¥"', 50)
            self.result.tp_triggered_count = tp_from_logs
            self.result.sl_triggered_count = sl_from_logs

            if trades:
                # Phase 61.11: pnlãŒã™ã¹ã¦NULLã‹ã©ã†ã‹ç¢ºèª
                pnls_with_value = [t.get("pnl") for t in trades if t.get("pnl") is not None]
                has_pnl_data = len(pnls_with_value) > 0

                if has_pnl_data:
                    # pnlãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å¾“æ¥ã®ãƒ­ã‚¸ãƒƒã‚¯
                    wins = [t for t in trades if (t.get("pnl") or 0) > 0]
                    self.result.win_rate = len(wins) / len(trades) * 100 if trades else 0.0

                    pnls = [t.get("pnl", 0) or 0 for t in trades]
                    self.result.total_pnl = sum(pnls)
                    self.result.avg_pnl = self.result.total_pnl / len(trades) if trades else 0.0

                    # æœ€å¤§åˆ©ç›Š/æå¤±
                    if pnls:
                        self.result.max_profit = max(pnls) if max(pnls) > 0 else 0
                        self.result.max_loss = min(pnls) if min(pnls) < 0 else 0

                    # æˆ¦ç•¥åˆ¥çµ±è¨ˆï¼ˆnotesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰æˆ¦ç•¥åã‚’æŠ½å‡ºï¼‰
                    for strategy in self.STRATEGIES:
                        strategy_trades = [t for t in trades if strategy in (t.get("notes") or "")]
                        if strategy_trades:
                            s_pnls = [t.get("pnl", 0) or 0 for t in strategy_trades]
                            s_wins = [p for p in s_pnls if p > 0]
                            self.result.strategy_stats[strategy] = {
                                "trades": len(strategy_trades),
                                "win_rate": len(s_wins) / len(strategy_trades) * 100,
                                "pnl": sum(s_pnls),
                            }
                else:
                    # Phase 61.11: pnlãŒã™ã¹ã¦NULLã®å ´åˆã¯GCPãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ã§æ¨å®š
                    # TPç™ºå‹•=å‹ã¡ã€SLç™ºå‹•=è² ã‘ã¨ã—ã¦æ¨å®š
                    total_exits = tp_from_logs + sl_from_logs
                    if total_exits > 0:
                        self.result.win_rate = (tp_from_logs / total_exits) * 100
                    else:
                        # æ±ºæ¸ˆè¨˜éŒ²ãŒãªã„å ´åˆã¯å‹ç‡ã‚’-1ï¼ˆN/Aè¡¨ç¤ºç”¨ï¼‰ã«è¨­å®š
                        self.result.win_rate = -1.0
                    self.result.total_pnl = 0.0
                    self.result.avg_pnl = 0.0
                    self.logger.info("pnlãƒ‡ãƒ¼ã‚¿ãªã— - GCPãƒ­ã‚°ã‹ã‚‰TP/SLç™ºå‹•æ•°ã§å‹ç‡æ¨å®š")

                # æœ€çµ‚å–å¼•æ™‚åˆ»
                self.result.last_trade_time = trades[0].get("timestamp")

                # Phase 62.16: ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸åˆ†æ
                self._analyze_slippage(trades)

            self.logger.info(
                f"å–å¼•å±¥æ­´åˆ†æå®Œäº† - {self.result.trades_count}ä»¶, "
                f"å‹ç‡: {self.result.win_rate:.1f}%, æç›Š: Â¥{self.result.total_pnl:,.0f}"
            )
        except Exception as e:
            self.logger.error(f"å–å¼•å±¥æ­´åˆ†æå¤±æ•—: {e}")

    def _analyze_slippage(self, trades: List[Dict[str, Any]]):
        """
        Phase 62.16: ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸åˆ†æ

        Args:
            trades: å–å¼•å±¥æ­´ãƒªã‚¹ãƒˆ
        """
        # ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å–å¼•ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        trades_with_slippage = [t for t in trades if t.get("slippage") is not None]

        if not trades_with_slippage:
            self.logger.info("â„¹ï¸ ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆPhase 62.16ä»¥å‰ã®å–å¼•ï¼‰")
            return

        self.result.slippage_count = len(trades_with_slippage)
        slippages = [t.get("slippage", 0) for t in trades_with_slippage]

        # å…¨ä½“çµ±è¨ˆ
        self.result.slippage_avg = sum(slippages) / len(slippages) if slippages else 0.0
        self.result.slippage_max = max(slippages) if slippages else 0.0
        self.result.slippage_min = min(slippages) if slippages else 0.0

        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼/æ±ºæ¸ˆåˆ¥çµ±è¨ˆ
        entry_slippages = [
            t.get("slippage", 0) for t in trades_with_slippage if t.get("trade_type") == "entry"
        ]
        exit_slippages = [
            t.get("slippage", 0)
            for t in trades_with_slippage
            if t.get("trade_type") in ["tp", "sl", "exit"]
        ]

        if entry_slippages:
            self.result.slippage_entry_avg = sum(entry_slippages) / len(entry_slippages)
        if exit_slippages:
            self.result.slippage_exit_avg = sum(exit_slippages) / len(exit_slippages)

        self.logger.info(
            f"ğŸ“Š Phase 62.16: ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸åˆ†æ - "
            f"ä»¶æ•°: {self.result.slippage_count}, "
            f"å¹³å‡: Â¥{self.result.slippage_avg:.0f}, "
            f"æœ€å¤§: Â¥{self.result.slippage_max:.0f}, "
            f"æœ€å°: Â¥{self.result.slippage_min:.0f}"
        )

    async def _check_system_health(self):
        """ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ç¢ºèªï¼ˆ6æŒ‡æ¨™ï¼‰"""
        # GCPãƒ­ã‚°ã‹ã‚‰ã‚¨ãƒ©ãƒ¼æ•°ãƒ»Containerå†èµ·å‹•ã‚’å–å¾—
        try:
            # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
            result = subprocess.run(
                [
                    "gcloud",
                    "run",
                    "services",
                    "describe",
                    "crypto-bot-service-prod",
                    "--region=asia-northeast1",
                    "--format=json",
                ],
                capture_output=True,
                text=True,
                timeout=30,
            )

            if result.returncode == 0:
                service_info = json.loads(result.stdout)
                conditions = service_info.get("status", {}).get("conditions", [])
                for cond in conditions:
                    if cond.get("type") == "Ready":
                        self.result.service_status = (
                            "Ready" if cond.get("status") == "True" else "NotReady"
                        )
                        break

                # æœ€æ–°ãƒªãƒ“ã‚¸ãƒ§ãƒ³æ™‚åˆ»
                latest_revision = service_info.get("status", {}).get("latestReadyRevisionName", "")
                if latest_revision:
                    self.result.last_deploy_time = service_info.get("metadata", {}).get(
                        "creationTimestamp", ""
                    )
            else:
                self.result.service_status = "unknown"
                self.logger.warning("GCPã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹å–å¾—å¤±æ•—ï¼ˆgcloudæœªè¨­å®š?ï¼‰")

        except subprocess.TimeoutExpired:
            self.logger.warning("GCPã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            self.result.service_status = "timeout"
        except FileNotFoundError:
            self.logger.warning("gcloud CLIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ?ï¼‰")
            self.result.service_status = "local"
        except Exception as e:
            self.logger.warning(f"GCPã‚µãƒ¼ãƒ“ã‚¹ç¢ºèªå¤±æ•—: {e}")
            self.result.service_status = "error"

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°æ•°å–å¾—
        try:
            since_time = (datetime.now() - timedelta(hours=self.period_hours)).strftime(
                "%Y-%m-%dT%H:%M:%SZ"
            )
            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    f'resource.type="cloud_run_revision" AND severity>=ERROR AND timestamp>="{since_time}"',
                    "--format=json",
                    "--limit=100",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )

            if result.returncode == 0:
                errors = json.loads(result.stdout) if result.stdout.strip() else []
                self.result.recent_error_count = len(errors)
            else:
                self.result.recent_error_count = -1  # å–å¾—å¤±æ•—

        except Exception as e:
            self.logger.warning(f"ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å–å¾—å¤±æ•—: {e}")
            self.result.recent_error_count = -1

        # Containerå†èµ·å‹•å›æ•°
        try:
            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    f'textPayload:"Container called exit" AND timestamp>="{since_time}"',
                    "--format=json",
                    "--limit=100",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )

            if result.returncode == 0:
                restarts = json.loads(result.stdout) if result.stdout.strip() else []
                self.result.container_restart_count = len(restarts)
        except Exception as e:
            self.logger.warning(f"Containerå†èµ·å‹•æ•°å–å¾—å¤±æ•—: {e}")

        self.logger.info(
            f"ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ç¢ºèªå®Œäº† - çŠ¶æ…‹: {self.result.service_status}, "
            f"ã‚¨ãƒ©ãƒ¼: {self.result.recent_error_count}ä»¶"
        )

    async def _check_tp_sl_placement(self):
        """TP/SLè¨­ç½®é©åˆ‡æ€§ç¢ºèªï¼ˆ4æŒ‡æ¨™ï¼‰- Phase 58.1æ”¹å–„ç‰ˆ"""
        try:
            if self.current_price <= 0:
                return

            # Phase 59.5: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸæ³¨æ–‡ã‚’ä½¿ç”¨ï¼ˆAPIå‘¼ã³å‡ºã—å‰Šæ¸›ï¼†ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ•´åˆæ€§ç¢ºä¿ï¼‰
            active_orders = self._cached_active_orders or []

            # Phase 61.8: take_profit/stop_lossã‚¿ã‚¤ãƒ—ã«å¯¾å¿œï¼ˆPhase 61.3ã§è¿½åŠ ã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ï¼‰
            tp_orders = [o for o in active_orders if o.get("type") in ["limit", "take_profit"]]
            sl_orders = [
                o for o in active_orders if o.get("type") in ["stop", "stop_limit", "stop_loss"]
            ]

            # TPè·é›¢è¨ˆç®—
            # Phase 61.8: take_profitæ³¨æ–‡ã¯trigger_priceã‚’ä½¿ç”¨
            if tp_orders and self.result.position_details:
                tp_order = tp_orders[0]
                tp_price = (
                    tp_order.get("price")
                    or tp_order.get("info", {}).get("trigger_price")
                    or tp_order.get("triggerPrice")
                    or 0
                )
                if tp_price:
                    tp_price = float(tp_price)
                    self.result.tp_distance_pct = (
                        abs(tp_price - self.current_price) / self.current_price * 100
                    )

            # SLè·é›¢è¨ˆç®—
            # Phase 61.8: stop_lossæ³¨æ–‡ã¯trigger_priceã‚’ä½¿ç”¨
            if sl_orders and self.result.position_details:
                sl_order = sl_orders[0]
                sl_price = (
                    sl_order.get("stopPrice")
                    or sl_order.get("info", {}).get("trigger_price")
                    or sl_order.get("triggerPrice")
                    or 0
                )
                if sl_price:
                    sl_price = float(sl_price)
                    self.result.sl_distance_pct = (
                        abs(sl_price - self.current_price) / self.current_price * 100
                    )

            # ãƒã‚¸ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã®ã«TP/SLãŒãªã„å ´åˆ
            if self.result.open_position_count > 0:
                if not tp_orders or not sl_orders:
                    self.result.tp_sl_placement_ok = False
                    self.logger.warning("ãƒã‚¸ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ãŒTP/SLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

            # Phase 58.1: ãƒã‚¸ã‚·ãƒ§ãƒ³é‡ã¨TP/SLæ³¨æ–‡é‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            # Phase 61.8: take_profit/stop_lossæ³¨æ–‡ã¯amountãŒNoneã®å ´åˆãŒã‚ã‚‹ãŸã‚ã€æ³¨æ–‡å­˜åœ¨ã®ã¿ãƒã‚§ãƒƒã‚¯
            if self.result.position_details and self.result.open_position_count > 0:
                # ãƒã‚¸ã‚·ãƒ§ãƒ³ç·é‡ã‚’è¨ˆç®—
                total_position_amount = sum(
                    abs(float(pos.get("amount", 0))) for pos in self.result.position_details
                )

                # TPæ³¨æ–‡ç·é‡ï¼ˆNoneã‚„NoneTypeã‚’0ã¨ã—ã¦å‡¦ç†ï¼‰
                total_tp_amount = sum(
                    abs(float(o.get("amount") or o.get("remaining") or 0))
                    for o in tp_orders
                    if o.get("amount") is not None or o.get("remaining") is not None
                )

                # SLæ³¨æ–‡ç·é‡ï¼ˆNoneã‚„NoneTypeã‚’0ã¨ã—ã¦å‡¦ç†ï¼‰
                total_sl_amount = sum(
                    abs(float(o.get("amount") or o.get("remaining") or 0))
                    for o in sl_orders
                    if o.get("amount") is not None or o.get("remaining") is not None
                )

                # Phase 61.8: take_profit/stop_lossæ³¨æ–‡ã¯amountãŒãªã„ãŸã‚ã€æ³¨æ–‡å­˜åœ¨ã§OKã¨ã™ã‚‹
                # æ³¨æ–‡é‡ãƒã‚§ãƒƒã‚¯ã¯amountãŒã‚ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ
                tolerance = 0.001

                # TPé‡ä¸è¶³ãƒã‚§ãƒƒã‚¯ï¼ˆamountãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                if total_position_amount > 0 and total_tp_amount > 0:
                    tp_coverage = total_tp_amount / total_position_amount
                    if tp_coverage < (1.0 - tolerance):
                        self.result.tp_sl_placement_ok = False
                        tp_pct = tp_coverage * 100
                        self.logger.warning(
                            f"âš ï¸ TPæ³¨æ–‡é‡ä¸è¶³: ãƒã‚¸ã‚·ãƒ§ãƒ³{total_position_amount:.4f}BTC vs "
                            f"TPæ³¨æ–‡{total_tp_amount:.4f}BTC (ã‚«ãƒãƒ¼ç‡: {tp_pct:.1f}%)"
                        )

                # SLé‡ä¸è¶³ãƒã‚§ãƒƒã‚¯ï¼ˆamountãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                if total_position_amount > 0 and total_sl_amount > 0:
                    sl_coverage = total_sl_amount / total_position_amount
                    if sl_coverage < (1.0 - tolerance):
                        self.result.tp_sl_placement_ok = False
                        sl_pct = sl_coverage * 100
                        self.logger.warning(
                            f"âš ï¸ SLæ³¨æ–‡é‡ä¸è¶³: ãƒã‚¸ã‚·ãƒ§ãƒ³{total_position_amount:.4f}BTC vs "
                            f"SLæ³¨æ–‡{total_sl_amount:.4f}BTC (ã‚«ãƒãƒ¼ç‡: {sl_pct:.1f}%)"
                        )

                # æ³¨æ–‡æ•°ã®è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                self.logger.info(
                    f"TP/SLè©³ç´° - ãƒã‚¸ã‚·ãƒ§ãƒ³: {total_position_amount:.4f}BTC, "
                    f"TP: {len(tp_orders)}ä»¶({total_tp_amount:.4f}BTC), "
                    f"SL: {len(sl_orders)}ä»¶({total_sl_amount:.4f}BTC)"
                )

            self.logger.info(
                f"TP/SLç¢ºèªå®Œäº† - TPè·é›¢: {self.result.tp_distance_pct or 'N/A'}%, "
                f"SLè·é›¢: {self.result.sl_distance_pct or 'N/A'}%"
            )
        except Exception as e:
            self.logger.error(f"TP/SLç¢ºèªå¤±æ•—: {e}")

    async def _calculate_uptime(self):
        """ç¨¼åƒç‡è¨ˆç®—ï¼ˆ5æŒ‡æ¨™ï¼‰"""
        try:
            # Phase 59.5 Fix: UTCæ™‚åˆ»ã‚’ä½¿ç”¨ï¼ˆGCPãƒ­ã‚°ã¯UTCä¿å­˜ï¼‰
            from datetime import timezone

            utc_now = datetime.now(timezone.utc)
            since_time = (utc_now - timedelta(hours=self.period_hours)).strftime(
                "%Y-%m-%dT%H:%M:%SZ"
            )

            # å–å¼•ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹ãƒ­ã‚°æ•°ã‹ã‚‰ç¨¼åƒç‡ã‚’æ¨å®š
            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    f'resource.type="cloud_run_revision" AND textPayload:"å–å¼•ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹" AND timestamp>="{since_time}"',
                    "--format=json",
                    "--limit=500",
                ],
                capture_output=True,
                text=True,
                timeout=60,
            )

            if result.returncode == 0:
                logs = json.loads(result.stdout) if result.stdout.strip() else []
                actual_runs = len(logs)

                # æœŸå¾…ã•ã‚Œã‚‹å®Ÿè¡Œå›æ•°ï¼ˆ7åˆ†é–“éš”: å‡¦ç†æ™‚é–“2åˆ†+å¾…æ©Ÿ5åˆ†ï¼‰
                # Phase 60.2: 5åˆ†â†’7åˆ†ã«ä¿®æ­£ï¼ˆå®Ÿæ¸¬å€¤ã«åŸºã¥ãï¼‰
                runs_per_hour = 60 / 7  # ç´„8.57å›/æ™‚é–“
                expected_runs = int(self.period_hours * runs_per_hour)

                # çµæœã‚’ä¿å­˜
                self.result.actual_cycle_count = actual_runs
                self.result.expected_cycle_count = expected_runs

                if expected_runs > 0:
                    self.result.uptime_rate = min(100.0, (actual_runs / expected_runs) * 100)
                    missed_runs = max(0, expected_runs - actual_runs)
                    self.result.total_downtime_minutes = missed_runs * 7  # 7åˆ†é–“éš”

                self.logger.info(
                    f"ç¨¼åƒç‡è¨ˆç®—å®Œäº† - {self.result.uptime_rate:.1f}% "
                    f"(å®Ÿè¡Œ{actual_runs}å›/æœŸå¾…{expected_runs}å›)"
                )

                # ã‚³ãƒ³ãƒ†ãƒŠå†èµ·å‹•å›æ•°ã‚’å–å¾—
                restart_result = subprocess.run(
                    [
                        "gcloud",
                        "logging",
                        "read",
                        f'resource.type="cloud_run_revision" AND textPayload:"TradingOrchestratorä¾å­˜æ€§çµ„ã¿ç«‹ã¦é–‹å§‹" AND timestamp>="{since_time}"',
                        "--format=json",
                        "--limit=50",
                    ],
                    capture_output=True,
                    text=True,
                    timeout=60,
                )
                if restart_result.returncode == 0:
                    restart_logs = (
                        json.loads(restart_result.stdout) if restart_result.stdout.strip() else []
                    )
                    self.result.container_restart_count = len(restart_logs)
                    self.logger.info(f"ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•å›æ•°: {self.result.container_restart_count}å›")
            else:
                # GCPãƒ­ã‚°å–å¾—å¤±æ•—æ™‚
                self.result.uptime_rate = -1
                self.logger.warning("ç¨¼åƒç‡è¨ˆç®—ä¸å¯ï¼ˆGCPãƒ­ã‚°å–å¾—å¤±æ•—ï¼‰")

        except FileNotFoundError:
            # ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ï¼ˆgcloudã‚³ãƒãƒ³ãƒ‰ãªã—ï¼‰
            self.result.uptime_rate = -1
            self.logger.info("ç¨¼åƒç‡è¨ˆç®—ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼‰")
        except Exception as e:
            self.logger.error(f"ç¨¼åƒç‡è¨ˆç®—å¤±æ•—: {e}")
            self.result.uptime_rate = -1

    async def _check_ml_model_status(self):
        """MLãƒ¢ãƒ‡ãƒ«ä½¿ç”¨çŠ¶æ³ç¢ºèªï¼ˆ4æŒ‡æ¨™ï¼‰- Phase 59.8è¿½åŠ """
        try:
            from src.core.config.threshold_manager import get_threshold
            from src.core.orchestration.ml_loader import MLModelLoader

            # stacking_enabledè¨­å®šç¢ºèª
            self.result.stacking_enabled = get_threshold("ensemble.stacking_enabled", False)

            # MLModelLoaderã§ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
            loader = MLModelLoader(self.logger)
            model = loader.load_model_with_priority()

            # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®š
            model_type = type(model).__name__
            self.result.ml_model_type = model_type

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
            if model_type == "StackingEnsemble":
                self.result.ml_model_level = 0
            elif model_type == "ProductionEnsemble":
                n_features = getattr(model, "n_features_", 0)
                self.result.ml_model_level = 1 if n_features >= 55 else 2
            elif model_type == "DummyModel":
                self.result.ml_model_level = 3
            else:
                self.result.ml_model_level = -1

            # ç‰¹å¾´é‡æ•°
            self.result.ml_feature_count = getattr(
                model, "n_features_", getattr(model, "n_features_in_", 0)
            )

            self.logger.info(
                f"MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèªå®Œäº† - {self.result.ml_model_type} "
                f"(Level {self.result.ml_model_level}, {self.result.ml_feature_count}ç‰¹å¾´é‡)"
            )
        except Exception as e:
            self.logger.error(f"MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèªå¤±æ•—: {e}")
            self.result.ml_model_type = "error"

    async def _analyze_sl_patterns(self):
        """Phase 62.18: SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆGCPãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ï¼‰"""
        import re
        from collections import defaultdict
        from datetime import timezone

        self.logger.info("SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æé–‹å§‹...")

        try:
            # GCPãƒ­ã‚°ã‹ã‚‰è‡ªå‹•åŸ·è¡Œæ¤œçŸ¥ãƒ­ã‚°ã‚’å–å¾—
            logs = self._fetch_gcp_logs_json(
                'textPayload:"Phase 61.9" AND textPayload:"è‡ªå‹•åŸ·è¡Œæ¤œçŸ¥"', limit=500
            )

            if not logs:
                self.logger.info("â„¹ï¸ SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ: è‡ªå‹•åŸ·è¡Œãƒ­ã‚°ãªã—")
                return

            # ãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹
            tp_executions = []
            sl_executions = []
            weekday_names = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]

            for log_entry in logs:
                text = log_entry.get("textPayload", "")
                ts = log_entry.get("timestamp", "")

                # TPè‡ªå‹•åŸ·è¡Œæ¤œçŸ¥
                tp_match = re.search(
                    r"Phase 61\.9: TPè‡ªå‹•åŸ·è¡Œæ¤œçŸ¥ - (\w+) ([\d.]+) BTC @ (\d+)å†† "
                    r"\((åˆ©ç›Š|æç›Š): ([+-]?\d+)å††\) æˆ¦ç•¥: (\w+)",
                    text,
                )
                if tp_match:
                    tp_executions.append(
                        {
                            "pnl": float(tp_match.group(5)),
                            "strategy": tp_match.group(6),
                            "timestamp": ts,
                        }
                    )
                    continue

                # SLè‡ªå‹•åŸ·è¡Œæ¤œçŸ¥
                sl_match = re.search(
                    r"Phase 61\.9: SLè‡ªå‹•åŸ·è¡Œæ¤œçŸ¥ - (\w+) ([\d.]+) BTC @ (\d+)å†† "
                    r"\((æå¤±|æç›Š): ([+-]?\d+)å††\) æˆ¦ç•¥: (\w+)",
                    text,
                )
                if sl_match:
                    sl_executions.append(
                        {
                            "pnl": float(sl_match.group(5)),
                            "strategy": sl_match.group(6),
                            "timestamp": ts,
                        }
                    )

            # çµæœã‚’æ ¼ç´
            self.result.sl_pattern_tp_count = len(tp_executions)
            self.result.sl_pattern_sl_count = len(sl_executions)
            self.result.sl_pattern_total_executions = len(tp_executions) + len(sl_executions)

            # SLæç›Šçµ±è¨ˆ
            if sl_executions:
                sl_pnls = [e["pnl"] for e in sl_executions]
                self.result.sl_pattern_sl_pnl_total = sum(sl_pnls)
                self.result.sl_pattern_sl_pnl_avg = sum(sl_pnls) / len(sl_pnls)

            # TPæç›Šçµ±è¨ˆ
            if tp_executions:
                tp_pnls = [e["pnl"] for e in tp_executions]
                self.result.sl_pattern_tp_pnl_total = sum(tp_pnls)
                self.result.sl_pattern_tp_pnl_avg = sum(tp_pnls) / len(tp_pnls)

            # æˆ¦ç•¥åˆ¥çµ±è¨ˆ
            strategy_data = defaultdict(
                lambda: {"sl_count": 0, "tp_count": 0, "sl_pnl": 0.0, "tp_pnl": 0.0}
            )
            for e in sl_executions:
                strategy_data[e["strategy"]]["sl_count"] += 1
                strategy_data[e["strategy"]]["sl_pnl"] += e["pnl"]
            for e in tp_executions:
                strategy_data[e["strategy"]]["tp_count"] += 1
                strategy_data[e["strategy"]]["tp_pnl"] += e["pnl"]

            for strategy, data in strategy_data.items():
                total = data["sl_count"] + data["tp_count"]
                self.result.sl_pattern_strategy_stats[strategy] = {
                    "sl_count": data["sl_count"],
                    "tp_count": data["tp_count"],
                    "total": total,
                    "sl_rate": (data["sl_count"] / total * 100) if total > 0 else 0,
                    "sl_pnl": data["sl_pnl"],
                    "tp_pnl": data["tp_pnl"],
                }

            # æ™‚é–“å¸¯ãƒ»æ›œæ—¥åˆ¥çµ±è¨ˆ
            hourly = defaultdict(int)
            weekday = defaultdict(int)
            for e in sl_executions:
                try:
                    ts_str = e["timestamp"].replace("Z", "+00:00")
                    ts = datetime.fromisoformat(ts_str)
                    ts_jst = ts + timedelta(hours=9)
                    hourly[ts_jst.hour] += 1
                    weekday[weekday_names[ts_jst.weekday()]] += 1
                except Exception:
                    pass

            self.result.sl_pattern_hourly_stats = dict(hourly)
            self.result.sl_pattern_weekday_stats = dict(weekday)

            self.logger.info(
                f"SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æå®Œäº† - TP:{len(tp_executions)}ä»¶, SL:{len(sl_executions)}ä»¶"
            )

        except Exception as e:
            self.logger.warning(f"SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æå¤±æ•—: {e}")

    def _fetch_gcp_logs_json(self, query: str, limit: int = 500) -> List[Dict[str, Any]]:
        """GCPãƒ­ã‚°ã‚’JSONå½¢å¼ã§å–å¾—"""
        try:
            from datetime import timezone

            utc_now = datetime.now(timezone.utc)
            since_time = (utc_now - timedelta(hours=self.period_hours)).strftime(
                "%Y-%m-%dT%H:%M:%SZ"
            )

            full_query = (
                f'resource.type="cloud_run_revision" AND '
                f'resource.labels.service_name="crypto-bot-service-prod" AND '
                f"({query}) AND "
                f'timestamp>="{since_time}"'
            )

            result = subprocess.run(
                [
                    "gcloud",
                    "logging",
                    "read",
                    full_query,
                    f"--limit={limit}",
                    "--format=json",
                ],
                capture_output=True,
                text=True,
                timeout=120,
            )

            if result.returncode == 0 and result.stdout.strip():
                return json.loads(result.stdout)
            return []

        except subprocess.TimeoutExpired:
            self.logger.warning("GCPãƒ­ã‚°å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            return []
        except json.JSONDecodeError:
            self.logger.warning("GCPãƒ­ã‚°JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼")
            return []
        except FileNotFoundError:
            self.logger.debug("GCPãƒ­ã‚°å–å¾—ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼‰")
            return []
        except Exception as e:
            self.logger.warning(f"GCPãƒ­ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []


class LiveReportGenerator:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

    def generate_json(self, result: LiveAnalysisResult) -> Dict[str, Any]:
        """JSONå½¢å¼ã§å‡ºåŠ›"""
        return asdict(result)

    def generate_markdown(self, result: LiveAnalysisResult) -> str:
        """Markdownå½¢å¼ã§å‡ºåŠ›"""
        lines = [
            "# ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰æ¨™æº–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            f"**åˆ†ææ—¥æ™‚**: {result.timestamp}",
            f"**å¯¾è±¡æœŸé–“**: ç›´è¿‘{result.analysis_period_hours}æ™‚é–“",
            "",
            "---",
            "",
            "## ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ…‹",
            "",
            "| æŒ‡æ¨™ | å€¤ | çŠ¶æ…‹ |",
            "|------|-----|------|",
        ]

        # è¨¼æ‹ é‡‘ç¶­æŒç‡ã®çŠ¶æ…‹åˆ¤å®šï¼ˆãƒãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³æ™‚ã¯æ˜ç¤ºçš„ã«è¡¨ç¤ºï¼‰
        if result.open_position_count == 0 and result.margin_ratio >= 500:
            margin_display = "N/A"
            margin_status = "ãƒã‚¸ã‚·ãƒ§ãƒ³ãªã—"
        else:
            margin_display = f"{result.margin_ratio:.1f}%"
            margin_status = (
                "æ­£å¸¸"
                if result.margin_ratio >= 100
                else "æ³¨æ„" if result.margin_ratio >= 80 else "å±é™º"
            )
        lines.append(f"| è¨¼æ‹ é‡‘ç¶­æŒç‡ | {margin_display} | {margin_status} |")
        lines.append(f"| åˆ©ç”¨å¯èƒ½æ®‹é«˜ | Â¥{result.available_balance:,.0f} | - |")
        lines.append(f"| ä½¿ç”¨ä¸­è¨¼æ‹ é‡‘ | Â¥{result.used_margin:,.0f} | - |")
        lines.append(f"| æœªå®Ÿç¾æç›Š | Â¥{result.unrealized_pnl:+,.0f} | - |")
        lines.append(f"| ãƒãƒ¼ã‚¸ãƒ³ã‚³ãƒ¼ãƒ« | {result.margin_call_status or 'ãªã—'} | - |")

        lines.extend(
            [
                "",
                "---",
                "",
                "## ãƒã‚¸ã‚·ãƒ§ãƒ³çŠ¶æ…‹",
                "",
                "| æŒ‡æ¨™ | å€¤ |",
                "|------|-----|",
                f"| ã‚ªãƒ¼ãƒ—ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ | {result.open_position_count}ä»¶ |",
                f"| æœªç´„å®šæ³¨æ–‡ | {result.pending_order_count}ä»¶ |",
            ]
        )

        if result.order_breakdown:
            breakdown_str = ", ".join(
                f"{k}:{v}" for k, v in result.order_breakdown.items() if v > 0
            )
            lines.append(f"| æ³¨æ–‡å†…è¨³ | {breakdown_str or 'ãªã—'} |")

        if result.losscut_price:
            lines.append(f"| ãƒ­ã‚¹ã‚«ãƒƒãƒˆä¾¡æ ¼ | Â¥{result.losscut_price:,.0f} |")

        # Phase 58.8: å­¤å…SL/TPè­¦å‘Š
        if result.orphan_sl_detected:
            lines.append(f"| âš ï¸ **å­¤å…SL/TPæ³¨æ–‡** | **{result.orphan_order_count}ä»¶æ¤œå‡º** |")

        # Phase 61.11: å‹ç‡ãŒN/Aï¼ˆ-1ï¼‰ã®å ´åˆã®è¡¨ç¤ºå¯¾å¿œ
        win_rate_str = "N/A (pnlãƒ‡ãƒ¼ã‚¿ãªã—)" if result.win_rate < 0 else f"{result.win_rate:.1f}%"
        # æ¨å®šå‹ç‡ã®å ´åˆã¯æ³¨è¨˜ã‚’è¿½åŠ 
        if (
            result.win_rate >= 0
            and result.total_pnl == 0
            and (result.tp_triggered_count > 0 or result.sl_triggered_count > 0)
        ):
            win_rate_str += " (TP/SLæ¨å®š)"

        lines.extend(
            [
                "",
                "---",
                "",
                "## å–å¼•å±¥æ­´åˆ†æ",
                "",
                "| æŒ‡æ¨™ | å€¤ |",
                "|------|-----|",
                f"| å–å¼•æ•° | {result.trades_count}ä»¶ |",
                f"| å‹ç‡ | {win_rate_str} |",
                f"| ç·æç›Š | Â¥{result.total_pnl:+,.0f} |",
                f"| å¹³å‡æç›Š | Â¥{result.avg_pnl:+,.0f} |",
                f"| æœ€å¤§åˆ©ç›Š | Â¥{result.max_profit:+,.0f} |",
                f"| æœ€å¤§æå¤± | Â¥{result.max_loss:+,.0f} |",
                f"| TPç™ºå‹• | {result.tp_triggered_count}å› |",
                f"| SLç™ºå‹• | {result.sl_triggered_count}å› |",
            ]
        )

        if result.strategy_stats:
            lines.extend(
                [
                    "",
                    "### æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                    "",
                    "| æˆ¦ç•¥ | å–å¼•æ•° | å‹ç‡ | æç›Š |",
                    "|------|--------|------|------|",
                ]
            )
            for strategy, stats in result.strategy_stats.items():
                lines.append(
                    f"| {strategy} | {stats['trades']}ä»¶ | {stats['win_rate']:.1f}% | Â¥{stats['pnl']:+,.0f} |"
                )

        lines.extend(
            [
                "",
                "---",
                "",
                "## ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§",
                "",
                "| æŒ‡æ¨™ | å€¤ | çŠ¶æ…‹ |",
                "|------|-----|------|",
                f"| APIå¿œç­”æ™‚é–“ | {result.api_response_time_ms:.0f}ms | {'æ­£å¸¸' if result.api_response_time_ms < 5000 else 'é…å»¶'} |",
                f"| ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ | {result.service_status} | {'æ­£å¸¸' if result.service_status == 'Ready' else 'ç¢ºèªè¦'} |",
            ]
        )

        if result.recent_error_count >= 0:
            error_status = "æ­£å¸¸" if result.recent_error_count < 10 else "æ³¨æ„"
            lines.append(f"| ç›´è¿‘ã‚¨ãƒ©ãƒ¼æ•° | {result.recent_error_count}ä»¶ | {error_status} |")

        lines.append(f"| Containerå†èµ·å‹• | {result.container_restart_count}å› | - |")

        if result.last_trade_time:
            lines.append(f"| æœ€çµ‚å–å¼• | {result.last_trade_time[:19]} | - |")

        if result.last_deploy_time:
            lines.append(f"| æœ€çµ‚ãƒ‡ãƒ—ãƒ­ã‚¤ | {result.last_deploy_time[:19]} | - |")

        lines.extend(
            [
                "",
                "---",
                "",
                "## TP/SLè¨­ç½®é©åˆ‡æ€§",
                "",
                "| æŒ‡æ¨™ | å€¤ | çŠ¶æ…‹ |",
                "|------|-----|------|",
            ]
        )

        if result.tp_distance_pct is not None:
            lines.append(f"| TPè·é›¢ | {result.tp_distance_pct:.2f}% | - |")
        if result.sl_distance_pct is not None:
            lines.append(f"| SLè·é›¢ | {result.sl_distance_pct:.2f}% | - |")

        tp_sl_status = "æ­£å¸¸" if result.tp_sl_placement_ok else "è¦ç¢ºèª"
        lines.append(f"| TP/SLè¨­ç½® | {tp_sl_status} | {tp_sl_status} |")

        lines.extend(
            [
                "",
                "---",
                "",
                "## ç¨¼åƒç‡",
                "",
                "| æŒ‡æ¨™ | å€¤ | çŠ¶æ…‹ |",
                "|------|-----|------|",
            ]
        )

        if result.uptime_rate >= 0:
            uptime_status = "é”æˆ" if result.uptime_rate >= 90 else "æœªé”"
            lines.append(f"| ç¨¼åƒæ™‚é–“ç‡ | {result.uptime_rate:.1f}% | {uptime_status} (ç›®æ¨™90%) |")
            lines.append(
                f"| å®Ÿè¡Œå›æ•° | {result.actual_cycle_count}å› / {result.expected_cycle_count}å› | - |"
            )
            lines.append(f"| ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ  | {result.total_downtime_minutes:.0f}åˆ† | - |")
            lines.append(f"| å†èµ·å‹•å›æ•° | {result.container_restart_count}å› | - |")
        else:
            lines.append("| ç¨¼åƒæ™‚é–“ç‡ | è¨ˆæ¸¬ä¸å¯ | - |")

        if result.last_incident_time:
            lines.append(f"| ç›´è¿‘éšœå®³ | {result.last_incident_time} | - |")

        # Phase 59.8: MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ 
        lines.extend(
            [
                "",
                "---",
                "",
                "## MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹",
                "",
                "| æŒ‡æ¨™ | å€¤ | çŠ¶æ…‹ |",
                "|------|-----|------|",
            ]
        )

        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
        model_status = (
            "æ­£å¸¸"
            if result.ml_model_type in ["StackingEnsemble", "ProductionEnsemble"]
            else "è¦ç¢ºèª"
        )
        lines.append(f"| ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— | {result.ml_model_type} | {model_status} |")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¬ãƒ™ãƒ«
        level_names = {0: "Stacking", 1: "Full(55)", 2: "Basic(49)", 3: "Dummy"}
        level_name = level_names.get(result.ml_model_level, "ä¸æ˜")
        level_status = "æ­£å¸¸" if result.ml_model_level <= 1 else "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­"
        lines.append(
            f"| ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¬ãƒ™ãƒ« | Level {result.ml_model_level} ({level_name}) | {level_status} |"
        )

        # ç‰¹å¾´é‡æ•°
        feature_status = "æ­£å¸¸" if result.ml_feature_count >= 55 else "ç¸®é€€"
        lines.append(f"| ç‰¹å¾´é‡æ•° | {result.ml_feature_count} | {feature_status} |")

        # Stackingè¨­å®š
        stacking_status = "æœ‰åŠ¹" if result.stacking_enabled else "ç„¡åŠ¹"
        lines.append(f"| Stackingè¨­å®š | {stacking_status} | - |")

        # Phase 62.16: ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ 
        if result.slippage_count > 0:
            lines.extend(
                [
                    "",
                    "---",
                    "",
                    "## ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸åˆ†æ (Phase 62.16)",
                    "",
                    "| æŒ‡æ¨™ | å€¤ | å‚™è€ƒ |",
                    "|------|-----|------|",
                    f"| è¨˜éŒ²ä»¶æ•° | {result.slippage_count}ä»¶ | - |",
                    f"| å¹³å‡ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ | Â¥{result.slippage_avg:+,.0f} | æ­£=ä¸åˆ©æ–¹å‘(buyæ™‚) |",
                    f"| æœ€å¤§ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ | Â¥{result.slippage_max:+,.0f} | - |",
                    f"| æœ€å°ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ | Â¥{result.slippage_min:+,.0f} | - |",
                ]
            )
            if result.slippage_entry_avg != 0:
                lines.append(f"| ã‚¨ãƒ³ãƒˆãƒªãƒ¼å¹³å‡ | Â¥{result.slippage_entry_avg:+,.0f} | - |")
            if result.slippage_exit_avg != 0:
                lines.append(f"| æ±ºæ¸ˆå¹³å‡ | Â¥{result.slippage_exit_avg:+,.0f} | - |")

        # Phase 62.18: SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ 
        if result.sl_pattern_total_executions > 0:
            total = result.sl_pattern_total_executions
            tp_rate = result.sl_pattern_tp_count / total * 100 if total > 0 else 0
            sl_rate = result.sl_pattern_sl_count / total * 100 if total > 0 else 0

            lines.extend(
                [
                    "",
                    "---",
                    "",
                    "## SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ (Phase 62.18)",
                    "",
                    "| æŒ‡æ¨™ | å€¤ | å‚™è€ƒ |",
                    "|------|-----|------|",
                    f"| ç·åŸ·è¡Œæ•° | {total}ä»¶ | TP+SL |",
                    f"| TPæ±ºæ¸ˆ | {result.sl_pattern_tp_count}ä»¶ ({tp_rate:.1f}%) | - |",
                    f"| SLæ±ºæ¸ˆ | {result.sl_pattern_sl_count}ä»¶ ({sl_rate:.1f}%) | - |",
                ]
            )
            if result.sl_pattern_sl_count > 0:
                lines.append(f"| SLåˆè¨ˆæç›Š | Â¥{result.sl_pattern_sl_pnl_total:+,.0f} | - |")
                lines.append(f"| SLå¹³å‡æç›Š | Â¥{result.sl_pattern_sl_pnl_avg:+,.0f} | - |")
            if result.sl_pattern_tp_count > 0:
                lines.append(f"| TPåˆè¨ˆåˆ©ç›Š | Â¥{result.sl_pattern_tp_pnl_total:+,.0f} | - |")

            # æˆ¦ç•¥åˆ¥çµ±è¨ˆ
            if result.sl_pattern_strategy_stats:
                lines.extend(
                    [
                        "",
                        "### æˆ¦ç•¥åˆ¥SLçµ±è¨ˆ",
                        "",
                        "| æˆ¦ç•¥ | SLæ•° | TPæ•° | SLç‡ | SLæç›Š |",
                        "|------|------|------|------|--------|",
                    ]
                )
                for strategy, stats in sorted(
                    result.sl_pattern_strategy_stats.items(),
                    key=lambda x: x[1]["sl_rate"],
                    reverse=True,
                ):
                    lines.append(
                        f"| {strategy} | {stats['sl_count']} | {stats['tp_count']} | "
                        f"{stats['sl_rate']:.1f}% | Â¥{stats['sl_pnl']:+,.0f} |"
                    )

        return "\n".join(lines)

    def append_to_csv(self, result: LiveAnalysisResult, csv_path: str):
        """CSVå±¥æ­´ã«è¿½è¨˜"""
        file_exists = Path(csv_path).exists()

        # ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿
        row = {
            "timestamp": result.timestamp,
            "period_hours": result.analysis_period_hours,
            "margin_ratio": result.margin_ratio,
            "available_balance": result.available_balance,
            "used_margin": result.used_margin,
            "unrealized_pnl": result.unrealized_pnl,
            "open_positions": result.open_position_count,
            "pending_orders": result.pending_order_count,
            "trades_count": result.trades_count,
            "win_rate": result.win_rate,
            "total_pnl": result.total_pnl,
            "tp_triggered": result.tp_triggered_count,
            "sl_triggered": result.sl_triggered_count,
            "api_response_ms": result.api_response_time_ms,
            "error_count": result.recent_error_count,
            "restart_count": result.container_restart_count,
            "uptime_rate": result.uptime_rate,
            "actual_cycles": result.actual_cycle_count,
            "expected_cycles": result.expected_cycle_count,
            "service_status": result.service_status,
            "tp_sl_ok": result.tp_sl_placement_ok,
            # Phase 59.8: MLãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹è¿½åŠ 
            "ml_model_type": result.ml_model_type,
            "ml_model_level": result.ml_model_level,
            "ml_feature_count": result.ml_feature_count,
            "stacking_enabled": result.stacking_enabled,
        }

        with open(csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=row.keys())
            if not file_exists:
                writer.writeheader()
            writer.writerow(row)


def determine_exit_code(
    infra_result: InfrastructureCheckResult,
    bot_result: BotFunctionCheckResult,
) -> int:
    """çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’æ±ºå®š

    Returns:
        0: æ­£å¸¸
        1: è‡´å‘½çš„å•é¡Œï¼ˆå³åº§å¯¾å¿œå¿…é ˆï¼‰
        2: è¦æ³¨æ„ï¼ˆè©³ç´°è¨ºæ–­æ¨å¥¨ï¼‰
        3: ç›£è¦–ç¶™ç¶šï¼ˆè»½å¾®ãªå•é¡Œï¼‰
    """
    total_critical = infra_result.critical_issues + bot_result.critical_issues
    total_warning = infra_result.warning_issues + bot_result.warning_issues

    # Silent Failureæ¤œå‡ºï¼ˆæœ€é‡è¦ï¼‰
    if bot_result.signal_count > 0 and bot_result.order_count == 0:
        return 1

    if total_critical >= 2:
        return 1
    elif total_critical >= 1:
        return 2
    elif total_warning >= 3:
        return 3
    else:
        return 0


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description="ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰çµ±åˆè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument("--hours", type=int, default=24, help="åˆ†æå¯¾è±¡æœŸé–“ï¼ˆæ™‚é–“ï¼‰")
    parser.add_argument(
        "--output", type=str, default="docs/æ¤œè¨¼è¨˜éŒ²/live", help="å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    parser.add_argument(
        "--exit-code",
        action="store_true",
        help="çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’è¿”å´ï¼ˆCI/CDé€£æºç”¨ï¼‰",
    )
    parser.add_argument(
        "--quick",
        action="store_true",
        help="ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆGCPãƒ­ã‚°ã®ã¿ã€APIå‘¼ã³å‡ºã—ãªã—ï¼‰",
    )
    args = parser.parse_args()

    logger = get_logger()

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰
    infra_checker = InfrastructureChecker(logger)
    infra_result = infra_checker.check()

    # Botæ©Ÿèƒ½è¨ºæ–­ï¼ˆå¸¸ã«å®Ÿè¡Œï¼‰
    bot_checker = BotFunctionChecker(logger, infra_checker)
    bot_result = bot_checker.check()

    # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã“ã“ã§çµ‚äº†
    if args.quick:
        print("\n" + "=" * 60)
        print("ç°¡æ˜“è¨ºæ–­çµæœ")
        print("=" * 60)
        print("\nğŸ”§ ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­:")
        print(f"   âœ… æ­£å¸¸é …ç›®: {infra_result.normal_checks}")
        print(f"   âš ï¸  è­¦å‘Šé …ç›®: {infra_result.warning_issues}")
        print(f"   âŒ è‡´å‘½çš„å•é¡Œ: {infra_result.critical_issues}")
        print(f"   ğŸ† ã‚¹ã‚³ã‚¢: {infra_result.total_score}ç‚¹")

        print("\nğŸ¤– Botæ©Ÿèƒ½è¨ºæ–­:")
        print(f"   âœ… æ­£å¸¸é …ç›®: {bot_result.normal_checks}")
        print(f"   âš ï¸  è­¦å‘Šé …ç›®: {bot_result.warning_issues}")
        print(f"   âŒ è‡´å‘½çš„å•é¡Œ: {bot_result.critical_issues}")
        print(f"   ğŸ† ã‚¹ã‚³ã‚¢: {bot_result.total_score}ç‚¹")

        # Phase 62.9-62.10: Makeræˆ¦ç•¥ã‚µãƒãƒªãƒ¼ï¼ˆç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ï¼‰
        entry_total = bot_result.entry_maker_success_count + bot_result.entry_maker_fallback_count
        tp_total = bot_result.tp_maker_success_count + bot_result.tp_maker_fallback_count
        if entry_total > 0 or tp_total > 0:
            print("\nğŸ’° Makeræˆ¦ç•¥:")
            if entry_total > 0:
                entry_rate = bot_result.entry_maker_success_count / entry_total * 100
                print(f"   ã‚¨ãƒ³ãƒˆãƒªãƒ¼: {entry_rate:.0f}%æˆåŠŸ")
            if tp_total > 0:
                tp_rate = bot_result.tp_maker_success_count / tp_total * 100
                print(f"   TPæ±ºæ¸ˆ: {tp_rate:.0f}%æˆåŠŸ")

        exit_code = determine_exit_code(infra_result, bot_result)
        status_map = {
            0: "ğŸŸ¢ æ­£å¸¸",
            1: "ğŸ’€ è‡´å‘½çš„å•é¡Œ",
            2: "ğŸŸ  è¦æ³¨æ„",
            3: "ğŸŸ¡ ç›£è¦–ç¶™ç¶š",
        }
        print(f"\nğŸ¯ æœ€çµ‚åˆ¤å®š: {status_map.get(exit_code, 'ä¸æ˜')}")
        print("=" * 60)

        if args.exit_code:
            sys.exit(exit_code)
        return

    # åˆ†æå®Ÿè¡Œï¼ˆAPIå‘¼ã³å‡ºã—ã‚ã‚Šï¼‰
    analyzer = LiveAnalyzer(period_hours=args.hours)
    result = await analyzer.analyze()

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generator = LiveReportGenerator()

    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # JSONå‡ºåŠ›ï¼ˆè¨ºæ–­çµæœã‚‚å«ã‚ã‚‹ï¼‰
    combined_result = {
        "live_analysis": generator.generate_json(result),
        "infrastructure_check": asdict(infra_result),
        "bot_function_check": asdict(bot_result),
    }
    json_path = output_dir / f"live_analysis_{timestamp}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(combined_result, f, ensure_ascii=False, indent=2)
    print(f"JSONå‡ºåŠ›: {json_path}")

    # Markdownå‡ºåŠ›ï¼ˆè¨ºæ–­çµæœã‚‚å«ã‚ã‚‹ï¼‰
    md_content = generator.generate_markdown(result)
    md_content += _generate_diagnostic_markdown(infra_result, bot_result)
    md_path = output_dir / f"live_analysis_{timestamp}.md"
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(md_content)
    print(f"Markdownå‡ºåŠ›: {md_path}")

    # CSVå±¥æ­´è¿½è¨˜
    csv_path = output_dir / "live_analysis_history.csv"
    generator.append_to_csv(result, str(csv_path))
    print(f"CSVå±¥æ­´è¿½è¨˜: {csv_path}")

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰çµ±åˆè¨ºæ–­ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"åˆ†ææœŸé–“: ç›´è¿‘{args.hours}æ™‚é–“")
    if result.open_position_count == 0 and result.margin_ratio >= 500:
        print("è¨¼æ‹ é‡‘ç¶­æŒç‡: N/A (ãƒã‚¸ã‚·ãƒ§ãƒ³ãªã—)")
    else:
        print(f"è¨¼æ‹ é‡‘ç¶­æŒç‡: {result.margin_ratio:.1f}%")
    print(f"å–å¼•æ•°: {result.trades_count}ä»¶")
    # Phase 61.11: å‹ç‡N/Aå¯¾å¿œ
    if result.win_rate < 0:
        print("å‹ç‡: N/A (pnlãƒ‡ãƒ¼ã‚¿ãªã—)")
    elif result.total_pnl == 0 and (result.tp_triggered_count > 0 or result.sl_triggered_count > 0):
        print(f"å‹ç‡: {result.win_rate:.1f}% (TP/SLæ¨å®š)")
    else:
        print(f"å‹ç‡: {result.win_rate:.1f}%")
    print(f"ç·æç›Š: Â¥{result.total_pnl:+,.0f}")
    if result.uptime_rate >= 0:
        print(f"ç¨¼åƒç‡: {result.uptime_rate:.1f}%")
    print(f"ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹: {result.service_status}")
    print(f"MLãƒ¢ãƒ‡ãƒ«: {result.ml_model_type} (Level {result.ml_model_level})")

    print("\nğŸ”§ ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­:")
    print(f"   âœ… æ­£å¸¸é …ç›®: {infra_result.normal_checks}")
    print(f"   âš ï¸  è­¦å‘Šé …ç›®: {infra_result.warning_issues}")
    print(f"   âŒ è‡´å‘½çš„å•é¡Œ: {infra_result.critical_issues}")
    print(f"   ğŸ† ã‚¹ã‚³ã‚¢: {infra_result.total_score}ç‚¹")

    print("\nğŸ¤– Botæ©Ÿèƒ½è¨ºæ–­:")
    print(f"   âœ… æ­£å¸¸é …ç›®: {bot_result.normal_checks}")
    print(f"   âš ï¸  è­¦å‘Šé …ç›®: {bot_result.warning_issues}")
    print(f"   âŒ è‡´å‘½çš„å•é¡Œ: {bot_result.critical_issues}")
    print(f"   ğŸ† ã‚¹ã‚³ã‚¢: {bot_result.total_score}ç‚¹")

    # Phase 62.9-62.10: Makeræˆ¦ç•¥ã‚µãƒãƒªãƒ¼
    entry_total = bot_result.entry_maker_success_count + bot_result.entry_maker_fallback_count
    tp_total = bot_result.tp_maker_success_count + bot_result.tp_maker_fallback_count
    if entry_total > 0 or tp_total > 0:
        print("\nğŸ’° Phase 62.9-62.10: Makeræˆ¦ç•¥:")
        if entry_total > 0:
            entry_rate = bot_result.entry_maker_success_count / entry_total * 100
            print(
                f"   ã‚¨ãƒ³ãƒˆãƒªãƒ¼: {bot_result.entry_maker_success_count}æˆåŠŸ/"
                f"{bot_result.entry_maker_fallback_count}FB ({entry_rate:.0f}%)"
            )
        if tp_total > 0:
            tp_rate = bot_result.tp_maker_success_count / tp_total * 100
            print(
                f"   TPæ±ºæ¸ˆ: {bot_result.tp_maker_success_count}æˆåŠŸ/"
                f"{bot_result.tp_maker_fallback_count}FB ({tp_rate:.0f}%)"
            )
        # æ¨å®šå‰Šæ¸›é¡
        maker_success = bot_result.entry_maker_success_count + bot_result.tp_maker_success_count
        if maker_success > 0:
            estimated = maker_success * 1000000 * 0.0014
            print(f"   æ¨å®šæ‰‹æ•°æ–™å‰Šæ¸›: Â¥{estimated:,.0f}")

    # Phase 62.18: SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚µãƒãƒªãƒ¼
    if result.sl_pattern_total_executions > 0:
        total = result.sl_pattern_total_executions
        tp_rate = result.sl_pattern_tp_count / total * 100 if total > 0 else 0
        sl_rate = result.sl_pattern_sl_count / total * 100 if total > 0 else 0

        print("\nğŸ“‰ Phase 62.18: SLãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:")
        print(f"   TPæ±ºæ¸ˆ: {result.sl_pattern_tp_count}ä»¶ ({tp_rate:.1f}%)")
        print(f"   SLæ±ºæ¸ˆ: {result.sl_pattern_sl_count}ä»¶ ({sl_rate:.1f}%)")
        if result.sl_pattern_sl_count > 0:
            print(f"   SLåˆè¨ˆæç›Š: Â¥{result.sl_pattern_sl_pnl_total:+,.0f}")
            print(f"   SLå¹³å‡æç›Š: Â¥{result.sl_pattern_sl_pnl_avg:+,.0f}")
        total_pnl = result.sl_pattern_tp_pnl_total + result.sl_pattern_sl_pnl_total
        print(f"   ç·æç›Š: Â¥{total_pnl:+,.0f}")

        # é«˜SLç‡æˆ¦ç•¥ã®è­¦å‘Š
        high_sl_strategies = [
            (s, d)
            for s, d in result.sl_pattern_strategy_stats.items()
            if d["sl_rate"] > 50 and d["total"] >= 3
        ]
        if high_sl_strategies:
            for strategy, data in high_sl_strategies:
                print(f"   âš ï¸ {strategy}: SLç‡{data['sl_rate']:.1f}%")

    exit_code = determine_exit_code(infra_result, bot_result)
    status_map = {
        0: "ğŸŸ¢ æ­£å¸¸",
        1: "ğŸ’€ è‡´å‘½çš„å•é¡Œ - å³åº§å¯¾å¿œå¿…é ˆ",
        2: "ğŸŸ  è¦æ³¨æ„ - è©³ç´°è¨ºæ–­æ¨å¥¨",
        3: "ğŸŸ¡ ç›£è¦–ç¶™ç¶š - è»½å¾®ãªå•é¡Œ",
    }
    print(f"\nğŸ¯ æœ€çµ‚åˆ¤å®š: {status_map.get(exit_code, 'ä¸æ˜')}")
    print("=" * 60)

    if args.exit_code:
        sys.exit(exit_code)


def _generate_diagnostic_markdown(
    infra_result: InfrastructureCheckResult,
    bot_result: BotFunctionCheckResult,
) -> str:
    """è¨ºæ–­çµæœã®Markdownç”Ÿæˆ"""
    lines = [
        "",
        "---",
        "",
        "## ã‚¤ãƒ³ãƒ•ãƒ©åŸºç›¤è¨ºæ–­",
        "",
        "| é …ç›® | çµæœ |",
        "|------|------|",
        f"| Cloud RunçŠ¶æ…‹ | {infra_result.cloud_run_status} |",
        f"| Secret Manageræ¨©é™ | {'âœ… å…¨æ­£å¸¸' if infra_result.bitbank_key_ok and infra_result.bitbank_secret_ok and infra_result.discord_ok else 'âŒ æ¬ å¦‚ã‚ã‚Š'} |",
        f"| Container exit(1) | {infra_result.container_exit_count}å› |",
        f"| RuntimeWarning | {infra_result.runtime_warning_count}å› |",
        f"| Discordã‚¨ãƒ©ãƒ¼ | {infra_result.discord_error_count}å› |",
        f"| APIæ®‹é«˜å–å¾— | {infra_result.api_balance_count}å› |",
        f"| ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ | {infra_result.fallback_count}å› |",
        f"| NoneTypeã‚¨ãƒ©ãƒ¼ | {infra_result.nonetype_error_count}å› |",
        f"| APIã‚¨ãƒ©ãƒ¼ | {infra_result.api_error_count}å› |",
        "",
        f"**ã‚¹ã‚³ã‚¢**: {infra_result.total_score}ç‚¹ (æ­£å¸¸:{infra_result.normal_checks} è­¦å‘Š:{infra_result.warning_issues} è‡´å‘½çš„:{infra_result.critical_issues})",
        "",
        "---",
        "",
        "## Botæ©Ÿèƒ½è¨ºæ–­",
        "",
        "| é …ç›® | çµæœ |",
        "|------|------|",
        f"| 55ç‰¹å¾´é‡æ¤œå‡º | {bot_result.feature_55_count}å› |",
        f"| 49ç‰¹å¾´é‡ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ | {bot_result.feature_49_count}å› |",
        f"| DummyModelä½¿ç”¨ | {bot_result.dummy_model_count}å› |",
        f"| ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ | {bot_result.signal_count}å› |",
        f"| æ³¨æ–‡å®Ÿè¡Œ | {bot_result.order_count}å› |",
        f"| æˆåŠŸç‡ | {bot_result.success_rate}% |",
        f"| ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æˆ¦ç•¥æ•° | {bot_result.active_strategy_count}/6 |",
        f"| MLäºˆæ¸¬å®Ÿè¡Œ | {bot_result.ml_prediction_count}å› |",
        f"| KellyåŸºæº–è¨ˆç®— | {bot_result.kelly_count}å› |",
        f"| Atomic EntryæˆåŠŸ | {bot_result.atomic_success_count}å› |",
        f"| ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ | {bot_result.atomic_rollback_count}å› |",
        "",
        "### æˆ¦ç•¥åˆ¥æ¤œå‡ºçŠ¶æ³",
        "",
        "| æˆ¦ç•¥ | æ¤œå‡ºæ•° |",
        "|------|--------|",
    ]

    for strategy, count in bot_result.strategy_counts.items():
        status = "âœ…" if count > 0 else "â„¹ï¸ æœªæ¤œå‡º"
        lines.append(f"| {strategy} | {count} {status} |")

    # Phase 62.9-62.10: Makeræˆ¦ç•¥ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    lines.extend(
        [
            "",
            "### Phase 62.9-62.10: Makeræˆ¦ç•¥",
            "",
            "| é …ç›® | æˆåŠŸ | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ | post_onlyã‚­ãƒ£ãƒ³ã‚»ãƒ« |",
            "|------|------|----------------|---------------------|",
        ]
    )

    # ã‚¨ãƒ³ãƒˆãƒªãƒ¼Maker
    entry_total = bot_result.entry_maker_success_count + bot_result.entry_maker_fallback_count
    entry_rate = (
        f"({bot_result.entry_maker_success_count / entry_total * 100:.0f}%)"
        if entry_total > 0
        else ""
    )
    lines.append(
        f"| ã‚¨ãƒ³ãƒˆãƒªãƒ¼Maker | {bot_result.entry_maker_success_count}å› {entry_rate} | "
        f"{bot_result.entry_maker_fallback_count}å› | "
        f"{bot_result.entry_post_only_cancelled_count}å› |"
    )

    # TP Maker
    tp_total = bot_result.tp_maker_success_count + bot_result.tp_maker_fallback_count
    tp_rate = f"({bot_result.tp_maker_success_count / tp_total * 100:.0f}%)" if tp_total > 0 else ""
    lines.append(
        f"| TP Maker | {bot_result.tp_maker_success_count}å› {tp_rate} | "
        f"{bot_result.tp_maker_fallback_count}å› | "
        f"{bot_result.tp_post_only_cancelled_count}å› |"
    )

    # æ‰‹æ•°æ–™å‰Šæ¸›åŠ¹æœã®æ¨å®š
    if entry_total > 0 or tp_total > 0:
        # MakeræˆåŠŸ1å›ã‚ãŸã‚Š0.14%å‰Šæ¸›ã€å–å¼•é‡‘é¡ã‚’100ä¸‡å††ã¨ä»®å®š
        estimated_savings = (
            (bot_result.entry_maker_success_count + bot_result.tp_maker_success_count)
            * 1000000
            * 0.0014
        )
        lines.extend(
            [
                "",
                f"**æ¨å®šæ‰‹æ•°æ–™å‰Šæ¸›åŠ¹æœ**: Â¥{estimated_savings:,.0f} "
                f"(MakeræˆåŠŸ{bot_result.entry_maker_success_count + bot_result.tp_maker_success_count}å› Ã— 0.14% Ã— 100ä¸‡å††)",
            ]
        )

    # Phase 62.13: ATRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµ±è¨ˆ
    atr_total = bot_result.atr_success_count + bot_result.atr_fallback_count
    if atr_total > 0:
        atr_success_rate = bot_result.atr_success_count / atr_total * 100
        atr_status = "âœ…" if atr_success_rate == 100 else ("âš ï¸" if atr_success_rate >= 80 else "âŒ")
        lines.extend(
            [
                "",
                "### Phase 62.13: ATRå–å¾—çŠ¶æ³",
                "",
                f"| é …ç›® | å›æ•° | çŠ¶æ…‹ |",
                f"|------|------|------|",
                f"| ATRå–å¾—æˆåŠŸ | {bot_result.atr_success_count}å› | {atr_status} ({atr_success_rate:.0f}%) |",
                f"| ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ | {bot_result.atr_fallback_count}å› | - |",
            ]
        )

    lines.extend(
        [
            "",
            f"**ã‚¹ã‚³ã‚¢**: {bot_result.total_score}ç‚¹ (æ­£å¸¸:{bot_result.normal_checks} è­¦å‘Š:{bot_result.warning_issues} è‡´å‘½çš„:{bot_result.critical_issues})",
            "",
        ]
    )

    return "\n".join(lines)


if __name__ == "__main__":
    asyncio.run(main())
