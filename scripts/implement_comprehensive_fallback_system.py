#!/usr/bin/env python3
"""
Phase 3.2: å®Ÿå–å¼•ç’°å¢ƒã§ã®åŒ…æ‹¬çš„ç‰¹å¾´é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…
å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ»APIéšœå®³ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œã«å¯¾å¿œã™ã‚‹å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
"""

import logging
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import numpy as np
import pandas as pd
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from crypto_bot.ml.feature_engines.technical_engine import TechnicalFeatureEngine
from crypto_bot.ml.preprocessor import FeatureEngineer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ComprehensiveFallbackSystem:
    """åŒ…æ‹¬çš„ç‰¹å¾´é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        self.fallback_values = self._initialize_fallback_values()
        self.feature_categories = self._categorize_features()
        self.calculation_methods = self._initialize_calculation_methods()

    def _initialize_fallback_values(self) -> Dict[str, float]:
        """ç‰¹å¾´é‡ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤å®šç¾©"""
        return {
            # åŸºæœ¬OHLCVï¼ˆçµ¶å¯¾ã«å­˜åœ¨ã™ã¹ãï¼‰
            "open": 10000000.0,
            "high": 10000000.0,
            "low": 10000000.0,
            "close": 10000000.0,
            "volume": 1000.0,
            # ãƒ©ã‚°ç‰¹å¾´é‡
            "close_lag_1": 10000000.0,
            "close_lag_2": 10000000.0,
            "close_lag_3": 10000000.0,
            "close_lag_4": 10000000.0,
            "close_lag_5": 10000000.0,
            "volume_lag_1": 1000.0,
            "volume_lag_2": 1000.0,
            "volume_lag_3": 1000.0,
            "volume_lag_4": 1000.0,
            "volume_lag_5": 1000.0,
            # ãƒªã‚¿ãƒ¼ãƒ³ç³»
            "returns_1": 0.0,
            "returns_2": 0.0,
            "returns_3": 0.0,
            "returns_5": 0.0,
            "returns_10": 0.0,
            "log_returns_1": 0.0,
            "log_returns_2": 0.0,
            "log_returns_3": 0.0,
            "log_returns_5": 0.0,
            "log_returns_10": 0.0,
            # ç§»å‹•å¹³å‡ç³»
            "sma_5": 10000000.0,
            "sma_10": 10000000.0,
            "sma_20": 10000000.0,
            "sma_50": 10000000.0,
            "sma_100": 10000000.0,
            "sma_200": 10000000.0,
            "ema_5": 10000000.0,
            "ema_10": 10000000.0,
            "ema_20": 10000000.0,
            "ema_50": 10000000.0,
            "ema_100": 10000000.0,
            "ema_200": 10000000.0,
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ç³»
            "price_position_20": 0.5,
            "price_position_50": 0.5,
            "price_vs_sma20": 1.0,
            "bb_position": 0.5,
            "intraday_position": 0.5,
            # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
            "bb_upper": 10200000.0,
            "bb_middle": 10000000.0,
            "bb_lower": 9800000.0,
            "bb_width": 0.02,
            "bb_squeeze": 0,
            # RSIç³»ï¼ˆæ—¢å­˜ã®ã‚‚ã®ã‚’çµ±åˆï¼‰
            "rsi_14": 50.0,
            "rsi_7": 50.0,
            "rsi_21": 50.0,
            "rsi_oversold": 0,
            "rsi_overbought": 0,
            # MACDç³»
            "macd": 0.0,
            "macd_signal": 0.0,
            "macd_hist": 0.0,
            "macd_cross_up": 0,
            "macd_cross_down": 0,
            # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
            "stoch_k": 50.0,
            "stoch_d": 50.0,
            "stoch_oversold": 0,
            "stoch_overbought": 0,
            # ATRãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
            "atr_14": 100000.0,  # ä¾¡æ ¼ã®1%ç¨‹åº¦
            "atr_7": 100000.0,
            "atr_21": 100000.0,
            "volatility_20": 0.02,
            "volatility_50": 0.02,
            "high_low_ratio": 1.01,
            "true_range": 100000.0,
            "volatility_ratio": 1.0,
            # å‡ºæ¥é«˜ç³»
            "volume_sma_20": 1000.0,
            "volume_ratio": 1.0,
            "volume_trend": 0.0,
            "vwap": 10000000.0,
            "vwap_distance": 0.0,
            "obv": 0.0,
            "obv_sma": 0.0,
            "cmf": 0.0,
            "mfi": 50.0,
            "ad_line": 0.0,
            # ãƒˆãƒ¬ãƒ³ãƒ‰ç³»
            "adx_14": 25.0,
            "plus_di": 25.0,
            "minus_di": 25.0,
            "trend_strength": 0.5,
            "trend_direction": 0,
            "cci_20": 0.0,
            "williams_r": -50.0,
            "ultimate_oscillator": 50.0,
            # ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹
            "support_distance": 0.05,
            "resistance_distance": 0.05,
            "support_strength": 0.5,
            "volume_breakout": 0,
            "price_breakout_up": 0,
            "price_breakout_down": 0,
            # ã‚­ãƒ£ãƒ³ãƒ‰ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
            "doji": 0,
            "hammer": 0,
            "engulfing": 0,
            "pinbar": 0,
            # çµ±è¨ˆç³»
            "skewness_20": 0.0,
            "kurtosis_20": 3.0,
            "zscore": 0.0,
            "mean_reversion_20": 0.0,
            "mean_reversion_50": 0.0,
            # æ™‚é–“ç³»
            "hour": 12,
            "day_of_week": 2,  # ç«æ›œæ—¥
            "is_weekend": 0,
            "is_asian_session": 0,
            "is_european_session": 0,
            "is_us_session": 0,
            # ãã®ä»–æŒ‡æ¨™
            "roc_10": 0.0,
            "roc_20": 0.0,
            "trix": 0.0,
            "mass_index": 1.0,
            "keltner_upper": 10200000.0,
            "keltner_lower": 9800000.0,
            "donchian_upper": 10200000.0,
            "donchian_lower": 9800000.0,
            "ichimoku_conv": 10000000.0,
            "ichimoku_base": 10000000.0,
            "price_efficiency": 0.5,
            "trend_consistency": 0.5,
            "volume_price_correlation": 0.0,
            "volatility_regime": 0.5,
            "momentum_quality": 0.5,
            "market_phase": 0.5,
            "momentum_14": 0.0,
        }

    def _categorize_features(self) -> Dict[str, List[str]]:
        """ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        return {
            "basic_ohlcv": ["open", "high", "low", "close", "volume"],
            "lag_features": [f"close_lag_{i}" for i in range(1, 6)]
            + [f"volume_lag_{i}" for i in range(1, 6)],
            "returns": [f"returns_{i}" for i in [1, 2, 3, 5, 10]]
            + [f"log_returns_{i}" for i in [1, 2, 3, 5, 10]],
            "moving_averages": [f"sma_{i}" for i in [5, 10, 20, 50, 100, 200]]
            + [f"ema_{i}" for i in [5, 10, 20, 50, 100, 200]],
            "technical_indicators": [
                "rsi_14",
                "rsi_7",
                "rsi_21",
                "macd",
                "macd_signal",
                "macd_hist",
                "atr_14",
                "atr_7",
                "atr_21",
            ],
            "volume_indicators": ["volume_sma_20", "volume_ratio", "obv", "cmf", "mfi"],
            "volatility_indicators": [
                "volatility_20",
                "volatility_50",
                "bb_width",
                "true_range",
            ],
            "time_features": [
                "hour",
                "day_of_week",
                "is_weekend",
                "is_asian_session",
                "is_european_session",
                "is_us_session",
            ],
        }

    def _initialize_calculation_methods(self) -> Dict[str, callable]:
        """ç‰¹å¾´é‡è¨ˆç®—ãƒ¡ã‚½ãƒƒãƒ‰åˆæœŸåŒ–"""
        return {
            "lag_features": self._calculate_lag_features,
            "returns": self._calculate_returns,
            "moving_averages": self._calculate_moving_averages,
            "rsi": self._calculate_rsi_safe,
            "volatility": self._calculate_volatility_safe,
            "volume_indicators": self._calculate_volume_indicators,
            "time_features": self._calculate_time_features,
        }

    def _calculate_lag_features(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """ãƒ©ã‚°ç‰¹å¾´é‡ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            # Close lag features
            for i in range(1, 6):
                if len(df) > i:
                    features[f"close_lag_{i}"] = df["close"].shift(i)
                else:
                    features[f"close_lag_{i}"] = pd.Series(
                        [self.fallback_values[f"close_lag_{i}"]] * len(df),
                        index=df.index,
                    )

            # Volume lag features
            for i in range(1, 6):
                if len(df) > i:
                    features[f"volume_lag_{i}"] = df["volume"].shift(i)
                else:
                    features[f"volume_lag_{i}"] = pd.Series(
                        [self.fallback_values[f"volume_lag_{i}"]] * len(df),
                        index=df.index,
                    )

        except Exception as e:
            logger.warning(f"Lagç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            for i in range(1, 6):
                features[f"close_lag_{i}"] = pd.Series(
                    [self.fallback_values[f"close_lag_{i}"]] * len(df), index=df.index
                )
                features[f"volume_lag_{i}"] = pd.Series(
                    [self.fallback_values[f"volume_lag_{i}"]] * len(df), index=df.index
                )

        return features

    def _calculate_returns(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """ãƒªã‚¿ãƒ¼ãƒ³ç‰¹å¾´é‡ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            close = df["close"]

            # Simple returns
            for period in [1, 2, 3, 5, 10]:
                if len(close) > period:
                    features[f"returns_{period}"] = close.pct_change(period)
                    features[f"log_returns_{period}"] = np.log(
                        close / close.shift(period)
                    )
                else:
                    features[f"returns_{period}"] = pd.Series(
                        [0.0] * len(df), index=df.index
                    )
                    features[f"log_returns_{period}"] = pd.Series(
                        [0.0] * len(df), index=df.index
                    )

        except Exception as e:
            logger.warning(f"Returnsç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            for period in [1, 2, 3, 5, 10]:
                features[f"returns_{period}"] = pd.Series(
                    [0.0] * len(df), index=df.index
                )
                features[f"log_returns_{period}"] = pd.Series(
                    [0.0] * len(df), index=df.index
                )

        return features

    def _calculate_moving_averages(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """ç§»å‹•å¹³å‡ç‰¹å¾´é‡ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            close = df["close"]

            # SMA
            for period in [5, 10, 20, 50, 100, 200]:
                if len(close) >= period:
                    features[f"sma_{period}"] = close.rolling(
                        window=period, min_periods=1
                    ).mean()
                else:
                    features[f"sma_{period}"] = pd.Series(
                        [close.mean()] * len(df), index=df.index
                    )

            # EMA
            for period in [5, 10, 20, 50, 100, 200]:
                if len(close) >= period:
                    features[f"ema_{period}"] = close.ewm(
                        span=period, min_periods=1
                    ).mean()
                else:
                    features[f"ema_{period}"] = pd.Series(
                        [close.mean()] * len(df), index=df.index
                    )

        except Exception as e:
            logger.warning(f"ç§»å‹•å¹³å‡ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            for period in [5, 10, 20, 50, 100, 200]:
                avg_price = df["close"].mean() if len(df["close"]) > 0 else 10000000.0
                features[f"sma_{period}"] = pd.Series(
                    [avg_price] * len(df), index=df.index
                )
                features[f"ema_{period}"] = pd.Series(
                    [avg_price] * len(df), index=df.index
                )

        return features

    def _calculate_rsi_safe(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """RSIç‰¹å¾´é‡ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            close = df["close"]

            for period in [7, 14, 21]:
                if len(close) >= period + 1:
                    # æ¨™æº–RSIè¨ˆç®—
                    delta = close.diff()
                    gain = (
                        (delta.where(delta > 0, 0))
                        .rolling(window=period, min_periods=1)
                        .mean()
                    )
                    loss = (
                        (-delta.where(delta < 0, 0))
                        .rolling(window=period, min_periods=1)
                        .mean()
                    )
                    rs = gain / (loss + 1e-10)
                    rsi = 100 - (100 / (1 + rs))
                    features[f"rsi_{period}"] = rsi
                elif len(close) >= 2:
                    # æœ€å°ãƒ‡ãƒ¼ã‚¿ã§ã®ç°¡æ˜“RSI
                    price_change = (close.iloc[-1] / close.iloc[0] - 1) * 100
                    if price_change > 2:
                        rsi_val = 65.0
                    elif price_change < -2:
                        rsi_val = 35.0
                    else:
                        rsi_val = 50.0
                    features[f"rsi_{period}"] = pd.Series(
                        [rsi_val] * len(df), index=df.index
                    )
                else:
                    features[f"rsi_{period}"] = pd.Series(
                        [50.0] * len(df), index=df.index
                    )

            # RSIæ¡ä»¶ç‰¹å¾´é‡
            if "rsi_14" in features:
                features["rsi_oversold"] = (features["rsi_14"] < 30).astype(int)
                features["rsi_overbought"] = (features["rsi_14"] > 70).astype(int)
            else:
                features["rsi_oversold"] = pd.Series([0] * len(df), index=df.index)
                features["rsi_overbought"] = pd.Series([0] * len(df), index=df.index)

        except Exception as e:
            logger.warning(f"RSIç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            for period in [7, 14, 21]:
                features[f"rsi_{period}"] = pd.Series([50.0] * len(df), index=df.index)
            features["rsi_oversold"] = pd.Series([0] * len(df), index=df.index)
            features["rsi_overbought"] = pd.Series([0] * len(df), index=df.index)

        return features

    def _calculate_volatility_safe(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            close = df["close"]
            high = df["high"]
            low = df["low"]

            # ATRè¨ˆç®—
            for period in [7, 14, 21]:
                if len(df) >= period:
                    tr1 = high - low
                    tr2 = np.abs(high - close.shift(1))
                    tr3 = np.abs(low - close.shift(1))
                    true_range = np.maximum(tr1, np.maximum(tr2, tr3))
                    features[f"atr_{period}"] = true_range.rolling(
                        window=period, min_periods=1
                    ).mean()
                else:
                    avg_price = close.mean() if len(close) > 0 else 10000000.0
                    features[f"atr_{period}"] = pd.Series(
                        [avg_price * 0.01] * len(df), index=df.index
                    )  # 1%

            # Volatility
            for period in [20, 50]:
                if len(close) >= period:
                    returns = close.pct_change()
                    features[f"volatility_{period}"] = returns.rolling(
                        window=period, min_periods=1
                    ).std()
                else:
                    features[f"volatility_{period}"] = pd.Series(
                        [0.02] * len(df), index=df.index
                    )  # 2%

        except Exception as e:
            logger.warning(f"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            for period in [7, 14, 21]:
                features[f"atr_{period}"] = pd.Series(
                    [100000.0] * len(df), index=df.index
                )
            for period in [20, 50]:
                features[f"volatility_{period}"] = pd.Series(
                    [0.02] * len(df), index=df.index
                )

        return features

    def _calculate_volume_indicators(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """å‡ºæ¥é«˜æŒ‡æ¨™ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            volume = df["volume"]
            close = df["close"]

            # Volume SMA
            if len(volume) >= 20:
                features["volume_sma_20"] = volume.rolling(
                    window=20, min_periods=1
                ).mean()
                features["volume_ratio"] = volume / features["volume_sma_20"]
            else:
                avg_volume = volume.mean() if len(volume) > 0 else 1000.0
                features["volume_sma_20"] = pd.Series(
                    [avg_volume] * len(df), index=df.index
                )
                features["volume_ratio"] = pd.Series([1.0] * len(df), index=df.index)

            # OBV (On Balance Volume)
            if len(df) > 1:
                price_change = close.diff()
                obv_values = []
                obv = 0
                for i, change in enumerate(price_change):
                    if pd.isna(change):
                        obv_values.append(obv)
                    elif change > 0:
                        obv += volume.iloc[i]
                        obv_values.append(obv)
                    elif change < 0:
                        obv -= volume.iloc[i]
                        obv_values.append(obv)
                    else:
                        obv_values.append(obv)
                features["obv"] = pd.Series(obv_values, index=df.index)
            else:
                features["obv"] = pd.Series([0.0] * len(df), index=df.index)

        except Exception as e:
            logger.warning(f"å‡ºæ¥é«˜æŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            features["volume_sma_20"] = pd.Series([1000.0] * len(df), index=df.index)
            features["volume_ratio"] = pd.Series([1.0] * len(df), index=df.index)
            features["obv"] = pd.Series([0.0] * len(df), index=df.index)

        return features

    def _calculate_time_features(self, df: pd.DataFrame) -> Dict[str, pd.Series]:
        """æ™‚é–“ç‰¹å¾´é‡ã®å®‰å…¨è¨ˆç®—"""
        features = {}

        try:
            # æ™‚é–“ç‰¹å¾´é‡
            features["hour"] = pd.Series([dt.hour for dt in df.index], index=df.index)
            features["day_of_week"] = pd.Series(
                [dt.dayofweek for dt in df.index], index=df.index
            )
            features["is_weekend"] = (features["day_of_week"] >= 5).astype(int)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¤å®šï¼ˆUTCåŸºæº–ï¼‰
            features["is_asian_session"] = (
                (features["hour"] >= 0) & (features["hour"] < 9)
            ).astype(int)
            features["is_european_session"] = (
                (features["hour"] >= 8) & (features["hour"] < 17)
            ).astype(int)
            features["is_us_session"] = (
                (features["hour"] >= 13) & (features["hour"] < 22)
            ).astype(int)

        except Exception as e:
            logger.warning(f"æ™‚é–“ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            features["hour"] = pd.Series([12] * len(df), index=df.index)
            features["day_of_week"] = pd.Series([2] * len(df), index=df.index)
            features["is_weekend"] = pd.Series([0] * len(df), index=df.index)
            features["is_asian_session"] = pd.Series([0] * len(df), index=df.index)
            features["is_european_session"] = pd.Series([0] * len(df), index=df.index)
            features["is_us_session"] = pd.Series([0] * len(df), index=df.index)

        return features

    def ensure_all_features(
        self, features_df: pd.DataFrame, original_df: pd.DataFrame
    ) -> pd.DataFrame:
        """å…¨ç‰¹å¾´é‡ã®å®Œå…¨æ€§ä¿è¨¼"""
        logger.info("ğŸ” åŒ…æ‹¬çš„ç‰¹å¾´é‡å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹")

        # å¿…è¦ãªç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆ125ç‰¹å¾´é‡ï¼‰
        required_features = list(self.fallback_values.keys())

        # ä¸è¶³ç‰¹å¾´é‡ç‰¹å®š
        missing_features = []
        for feature in required_features:
            if feature not in features_df.columns:
                missing_features.append(feature)

        if not missing_features:
            logger.info("âœ… ã™ã¹ã¦ã®ç‰¹å¾´é‡ãŒå­˜åœ¨")
            return features_df

        logger.warning(
            f"âš ï¸ ä¸è¶³ç‰¹å¾´é‡: {len(missing_features)}å€‹ - {missing_features[:10]}..."
        )

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ä¸è¶³ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
        generated_features = {}

        # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆé‡è¤‡é™¤å»ã®ãŸã‚æ—¢å­˜ãƒã‚§ãƒƒã‚¯ï¼‰
        basic_missing = [
            f for f in missing_features if f in self.feature_categories["basic_ohlcv"]
        ]
        if basic_missing:
            logger.warning(f"âš ï¸ åŸºæœ¬OHLCVç‰¹å¾´é‡ä¸è¶³: {basic_missing}")
            for feature in basic_missing:
                generated_features[feature] = pd.Series(
                    [self.fallback_values[feature]] * len(original_df),
                    index=original_df.index,
                )

        # ãƒ©ã‚°ç‰¹å¾´é‡
        lag_missing = [
            f for f in missing_features if f in self.feature_categories["lag_features"]
        ]
        if lag_missing:
            lag_features = self._calculate_lag_features(original_df)
            for feature in lag_missing:
                if feature in lag_features:
                    generated_features[feature] = lag_features[feature]

        # ãƒªã‚¿ãƒ¼ãƒ³ç‰¹å¾´é‡
        returns_missing = [
            f for f in missing_features if f in self.feature_categories["returns"]
        ]
        if returns_missing:
            returns_features = self._calculate_returns(original_df)
            for feature in returns_missing:
                if feature in returns_features:
                    generated_features[feature] = returns_features[feature]

        # ç§»å‹•å¹³å‡ç‰¹å¾´é‡
        ma_missing = [
            f
            for f in missing_features
            if f in self.feature_categories["moving_averages"]
        ]
        if ma_missing:
            ma_features = self._calculate_moving_averages(original_df)
            for feature in ma_missing:
                if feature in ma_features:
                    generated_features[feature] = ma_features[feature]

        # RSIç‰¹å¾´é‡
        rsi_missing = [f for f in missing_features if "rsi" in f]
        if rsi_missing:
            rsi_features = self._calculate_rsi_safe(original_df)
            for feature in rsi_missing:
                if feature in rsi_features:
                    generated_features[feature] = rsi_features[feature]

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡
        vol_missing = [
            f
            for f in missing_features
            if f in self.feature_categories["volatility_indicators"] or "atr" in f
        ]
        if vol_missing:
            vol_features = self._calculate_volatility_safe(original_df)
            for feature in vol_missing:
                if feature in vol_features:
                    generated_features[feature] = vol_features[feature]

        # å‡ºæ¥é«˜ç‰¹å¾´é‡
        volume_missing = [
            f
            for f in missing_features
            if f in self.feature_categories["volume_indicators"]
        ]
        if volume_missing:
            volume_features = self._calculate_volume_indicators(original_df)
            for feature in volume_missing:
                if feature in volume_features:
                    generated_features[feature] = volume_features[feature]

        # æ™‚é–“ç‰¹å¾´é‡
        time_missing = [
            f for f in missing_features if f in self.feature_categories["time_features"]
        ]
        if time_missing:
            time_features = self._calculate_time_features(original_df)
            for feature in time_missing:
                if feature in time_features:
                    generated_features[feature] = time_features[feature]

        # ã¾ã ä¸è¶³ã—ã¦ã„ã‚‹ç‰¹å¾´é‡ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤é©ç”¨
        still_missing = [f for f in missing_features if f not in generated_features]
        for feature in still_missing:
            default_value = self.fallback_values.get(feature, 0.0)
            generated_features[feature] = pd.Series(
                [default_value] * len(original_df), index=original_df.index
            )
            logger.warning(f"âš ï¸ {feature}: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä½¿ç”¨ = {default_value}")

        # ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ã‚’è¿½åŠ 
        for feature, values in generated_features.items():
            features_df[feature] = values

        logger.info(f"âœ… åŒ…æ‹¬çš„ç‰¹å¾´é‡å®Œå…¨æ€§ä¿è¨¼å®Œäº†: {len(generated_features)}å€‹ç”Ÿæˆ")
        return features_df


def patch_feature_engineer_with_comprehensive_fallback():
    """FeatureEngineerã«åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’ãƒ‘ãƒƒãƒ"""

    def enhanced_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ‹¡å¼µç‰¹å¾´é‡å¤‰æ›ï¼ˆåŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãï¼‰"""
        logger.info("ğŸš€ åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãç‰¹å¾´é‡å¤‰æ›é–‹å§‹")

        try:
            # å…ƒã®å¤‰æ›å‡¦ç†å®Ÿè¡Œ
            original_transform = FeatureEngineer.transform
            features_df = original_transform(self, df)

            # åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ é©ç”¨
            fallback_system = ComprehensiveFallbackSystem()
            features_df = fallback_system.ensure_all_features(features_df, df)

            # æœ€çµ‚æ¤œè¨¼
            expected_count = 125
            actual_count = len(features_df.columns)

            if actual_count >= expected_count:
                logger.info(f"âœ… åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ: {actual_count}ç‰¹å¾´é‡ç”Ÿæˆ")
                return features_df
            else:
                logger.warning(f"âš ï¸ ç‰¹å¾´é‡æ•°ä¸è¶³: {actual_count}/{expected_count}")
                return features_df

        except Exception as e:
            logger.error(f"âŒ åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            # å®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæœ€å°é™ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§125ç‰¹å¾´é‡ç”Ÿæˆ
            return self._create_emergency_fallback_features(df)

    def _create_emergency_fallback_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç·Šæ€¥æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæœ€å°é™ã®125ç‰¹å¾´é‡ç”Ÿæˆ"""
        logger.warning("ğŸš¨ ç·Šæ€¥æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: 125ç‰¹å¾´é‡ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”Ÿæˆ")

        fallback_system = ComprehensiveFallbackSystem()
        features_data = {}

        for feature, default_value in fallback_system.fallback_values.items():
            features_data[feature] = [default_value] * len(df)

        features_df = pd.DataFrame(features_data, index=df.index)
        logger.warning(f"âš ï¸ ç·Šæ€¥æ™‚125ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: ã™ã¹ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤")

        return features_df

    # ãƒ‘ãƒƒãƒé©ç”¨
    FeatureEngineer.transform = enhanced_transform
    FeatureEngineer._create_emergency_fallback_features = (
        _create_emergency_fallback_features
    )
    logger.info("âœ… FeatureEngineeråŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ‘ãƒƒãƒé©ç”¨å®Œäº†")


def test_comprehensive_fallback_system():
    """åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    logger.info("ğŸ§ª åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")

    # ãƒ‘ãƒƒãƒé©ç”¨
    patch_feature_engineer_with_comprehensive_fallback()

    # è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {"name": "æœ€å°ãƒ‡ãƒ¼ã‚¿ï¼ˆ2ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰", "size": 2, "expected_features": 125},
        {"name": "å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ5ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰", "size": 5, "expected_features": 125},
        {"name": "ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ20ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰", "size": 20, "expected_features": 125},
        {"name": "é€šå¸¸ãƒ‡ãƒ¼ã‚¿ï¼ˆ50ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰", "size": 50, "expected_features": 125},
    ]

    success_count = 0

    for test_case in test_cases:
        logger.info(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {test_case['name']}")

        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            size = test_case["size"]
            base_price = 10000000.0
            price_changes = np.random.normal(0, 0.01, size)

            prices = [base_price]
            for change in price_changes:
                new_price = prices[-1] * (1 + change)
                prices.append(max(new_price, base_price * 0.9))

            test_data = {
                "open": prices[:-1],
                "high": [p * 1.01 for p in prices[:-1]],
                "low": [p * 0.99 for p in prices[:-1]],
                "close": prices[1:],
                "volume": [1000 + np.random.randint(-200, 200) for _ in range(size)],
            }

            df = pd.DataFrame(test_data)
            df.index = pd.date_range("2025-01-01", periods=size, freq="H")

            # è¨­å®šèª­ã¿è¾¼ã¿
            config_path = str(project_root / "config/production/production.yml")
            with open(config_path, "r") as f:
                config = yaml.safe_load(f)

            # ç‰¹å¾´é‡ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            feature_engineer = FeatureEngineer(config)
            features_df = feature_engineer.transform(df)

            # çµæœæ¤œè¨¼
            actual_features = len(features_df.columns)
            expected_features = test_case["expected_features"]

            logger.info(f"   ç‰¹å¾´é‡æ•°: {actual_features}/{expected_features}")

            if actual_features >= expected_features:
                logger.info(f"   âœ… {test_case['name']} æˆåŠŸï¼")
                success_count += 1
            else:
                logger.warning(f"   âš ï¸ {test_case['name']} ç‰¹å¾´é‡ä¸è¶³")

            # NaNå€¤ãƒã‚§ãƒƒã‚¯
            nan_features = features_df.columns[features_df.isnull().any()].tolist()
            if nan_features:
                logger.warning(f"   âš ï¸ NaNå€¤ã‚’å«ã‚€ç‰¹å¾´é‡: {len(nan_features)}å€‹")
            else:
                logger.info(f"   âœ… ã™ã¹ã¦ã®ç‰¹å¾´é‡ã§NaNå€¤ãªã—")

        except Exception as e:
            logger.error(f"   âŒ {test_case['name']} ã‚¨ãƒ©ãƒ¼: {e}")

    # ç·åˆçµæœ
    total_tests = len(test_cases)
    success_rate = (success_count / total_tests) * 100

    logger.info(f"\nğŸ“Š åŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ:")
    logger.info(f"   æˆåŠŸ: {success_count}/{total_tests} ({success_rate:.1f}%)")

    return success_count == total_tests


if __name__ == "__main__":
    try:
        success = test_comprehensive_fallback_system()
        if success:
            print("\n" + "=" * 60)
            print("âœ… Phase 3.2å®Œäº†ï¼šåŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…æˆåŠŸï¼")
            print("=" * 60)
            print("ğŸš€ å®Ÿå–å¼•ç’°å¢ƒã§ã®å®Œå…¨ãªç‰¹å¾´é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Ÿè£…å®Œäº†")
            print("ğŸ“Š 2-50ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§125ç‰¹å¾´é‡ä¿è¨¼ç¢ºèª")
            print("ğŸ”§ FeatureEngineeråŒ…æ‹¬çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ‘ãƒƒãƒé©ç”¨æ¸ˆã¿")
            print("âœ… APIéšœå®³ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œã«å¯¾å¿œã™ã‚‹å®Œå…¨è‡ªå‹•å›å¾©ã‚·ã‚¹ãƒ†ãƒ ")
            print("ğŸ¯ å®Ÿå–å¼•ç’°å¢ƒã§ã®å …ç‰¢æ€§å¤§å¹…å‘ä¸Š")
            print("=" * 60)
        else:
            print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—")
            sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
