#!/usr/bin/env python3
"""
å®Ÿãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡ç”Ÿæˆæ™‚ã®enhanced_defaultæ±šæŸ“è©³ç´°è¨ºæ–­

ç›®çš„:
- å®Ÿéš›ã®BTC/JPYãƒ‡ãƒ¼ã‚¿ã§ç‰¹å¾´é‡ç”Ÿæˆæ™‚ã®æ±šæŸ“çŠ¶æ³ç¢ºèª
- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ã¨åŒã˜æ¡ä»¶ã§ã®å•é¡Œå†ç¾
- æ ¹æœ¬åŸå› ã®ç‰¹å®š
"""

import logging
import os
import sys

import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append("/Users/nao/Desktop/bot")

import yaml

from crypto_bot.data.fetcher import MarketDataFetcher
from crypto_bot.ml.feature_engines.batch_calculator import BatchFeatureCalculator
from crypto_bot.ml.feature_engines.technical_engine import TechnicalFeatureEngine

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def load_real_data():
    """å®Ÿéš›ã®BTC/JPYãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    csv_path = "data/btc_usd_2024_hourly.csv"

    if os.path.exists(csv_path):
        logger.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {csv_path}")
        df = pd.read_csv(csv_path, index_col=0, parse_dates=True)

        # æœ€æ–°100ä»¶ã«åˆ¶é™ï¼ˆè¨ºæ–­ç”¨ï¼‰
        df = df.tail(100)
        logger.info(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
        return df
    else:
        logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {csv_path}")
        return None


def diagnose_feature_generation():
    """å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®ç‰¹å¾´é‡ç”Ÿæˆè¨ºæ–­"""
    logger.info("ğŸ” å®Ÿãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡ç”Ÿæˆè¨ºæ–­é–‹å§‹")

    # è¨­å®šèª­ã¿è¾¼ã¿
    config_path = "/Users/nao/Desktop/bot/config/production/production.yml"
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    raw_data = load_real_data()
    if raw_data is None:
        return False

    try:
        # ãƒãƒƒãƒè¨ˆç®—æ©Ÿãƒ»ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        batch_calc = BatchFeatureCalculator(config)
        tech_engine = TechnicalFeatureEngine(config, batch_calc)

        logger.info("ğŸ”§ ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰")

        # å…¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ç‰¹å¾´é‡ãƒãƒƒãƒè¨ˆç®—
        feature_batches = tech_engine.calculate_all_technical_batches(raw_data)

        # ç‰¹å¾´é‡çµ±åˆ
        feature_df = raw_data.copy()
        total_features = 0
        enhanced_default_count = 0
        missing_features = []

        for batch in feature_batches:
            if len(batch) > 0:
                batch_features = batch.to_dataframe()

                # enhanced_defaultæ±šæŸ“ãƒã‚§ãƒƒã‚¯
                for col in batch_features.columns:
                    if "enhanced_default" in str(col):
                        enhanced_default_count += 1
                        logger.error(f"âŒ enhanced_defaultæ±šæŸ“æ¤œå‡º: {col}")

                    # ç‰¹å¾´é‡ã®å®Ÿéš›ã®å€¤ã‚’ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
                    sample_values = batch_features[col].dropna().head(3)
                    if any("enhanced_default" in str(val) for val in sample_values):
                        logger.error(
                            f"âŒ å€¤ãƒ¬ãƒ™ãƒ«ã§enhanced_defaultæ±šæŸ“: {col} = {sample_values.tolist()}"
                        )

                # é‡è¤‡åˆ—ã‚’é™¤å»
                overlapping_cols = batch_features.columns.intersection(
                    feature_df.columns
                )
                if len(overlapping_cols) > 0:
                    batch_features = batch_features.drop(columns=overlapping_cols)

                # ç‰¹å¾´é‡çµ±åˆ
                if not batch_features.empty:
                    feature_df = feature_df.join(batch_features, how="left")
                    total_features += len(batch_features.columns)
                    logger.info(
                        f"   âœ… {batch.name}: {len(batch_features.columns)}ç‰¹å¾´é‡è¿½åŠ "
                    )

        # æœŸå¾…ã•ã‚Œã‚‹é‡è¦ç‰¹å¾´é‡ã®å­˜åœ¨ç¢ºèª
        expected_features = [
            "hour",
            "day_of_week",
            "rsi_14",
            "rsi_21",
            "macd",
            "sma_20",
        ]
        for feature in expected_features:
            if feature not in feature_df.columns:
                missing_features.append(feature)
                logger.error(f"âŒ é‡è¦ç‰¹å¾´é‡æ¬ æ: {feature}")
            else:
                sample_vals = feature_df[feature].dropna().head(3)
                logger.info(f"âœ… {feature}: {sample_vals.tolist()}")

        # æœ€çµ‚çµæœ
        logger.info("ğŸ“Š è¨ºæ–­çµæœ:")
        logger.info(f"   ç·ç‰¹å¾´é‡æ•°: {total_features}")
        logger.info(f"   enhanced_defaultæ±šæŸ“: {enhanced_default_count}å€‹")
        logger.info(f"   é‡è¦ç‰¹å¾´é‡æ¬ æ: {len(missing_features)}å€‹")

        if enhanced_default_count > 0:
            logger.error("âŒ enhanced_defaultæ±šæŸ“ãŒæ®‹å­˜ï¼")

            # æ±šæŸ“åˆ—ã®è©³ç´°ç¢ºèª
            contaminated_cols = [
                col for col in feature_df.columns if "enhanced_default" in str(col)
            ]
            logger.error(f"æ±šæŸ“åˆ—: {contaminated_cols}")

        if missing_features:
            logger.error(f"âŒ é‡è¦ç‰¹å¾´é‡æ¬ æ: {missing_features}")

        # 125ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§ç¢ºèª
        ml_extra_features = config.get("ml", {}).get("extra_features", [])
        expected_count = len(ml_extra_features) + 5  # OHLCV
        actual_count = len(feature_df.columns)

        logger.info(f"ğŸ“Š 125ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§:")
        logger.info(f"   æœŸå¾…: {expected_count}ç‰¹å¾´é‡")
        logger.info(f"   å®Ÿéš›: {actual_count}ç‰¹å¾´é‡")

        if actual_count != expected_count:
            logger.warning(f"âš ï¸ ç‰¹å¾´é‡æ•°ä¸ä¸€è‡´: {actual_count} != {expected_count}")

        # ç‰¹å¾´é‡ä¸€è¦§ä¿å­˜
        feature_list_path = "/Users/nao/Desktop/bot/results/real_data_features_list.txt"
        with open(feature_list_path, "w") as f:
            f.write("å®Ÿãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡ç”Ÿæˆçµæœ:\n")
            f.write(f"ç·æ•°: {len(feature_df.columns)}\n\n")
            for i, col in enumerate(feature_df.columns):
                sample_val = (
                    feature_df[col].dropna().iloc[0]
                    if not feature_df[col].dropna().empty
                    else "NaN"
                )
                f.write(f"{i+1:3d}. {col}: {sample_val}\n")

        logger.info(f"âœ… ç‰¹å¾´é‡ä¸€è¦§ä¿å­˜: {feature_list_path}")

        return enhanced_default_count == 0 and len(missing_features) == 0

    except Exception as e:
        logger.error(f"âŒ è¨ºæ–­å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("=" * 60)
    logger.info("å®Ÿãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡ç”Ÿæˆãƒ»enhanced_defaultæ±šæŸ“è¨ºæ–­")
    logger.info("=" * 60)

    success = diagnose_feature_generation()

    if success:
        print("\nâœ… è¨ºæ–­å®Œäº†: enhanced_defaultæ±šæŸ“ãªã—ãƒ»é‡è¦ç‰¹å¾´é‡å®Œå…¨")
        print("ğŸš€ ç‰¹å¾´é‡ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸ãƒ»ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’æº–å‚™å®Œäº†")
    else:
        print("\nâŒ è¨ºæ–­å¤±æ•—: enhanced_defaultæ±šæŸ“ã¾ãŸã¯é‡è¦ç‰¹å¾´é‡æ¬ æ")
        print("ğŸ”§ technical_engine.pyè¿½åŠ ä¿®æ­£ãŒå¿…è¦")

    return 0 if success else 1


if __name__ == "__main__":
    exit(main())
