#!/usr/bin/env python3
"""
ç‰¹å¾´é‡æ•°çµ±ä¸€åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´é‡æ•°ã‚’æ­£ç¢ºã«æŠŠæ¡ã—ã€çµ±ä¸€åŒ–æ–¹é‡ã‚’æ±ºå®š
"""

import logging
import sys
from pathlib import Path
from typing import Any, Dict, List

import joblib
import pandas as pd
import yaml

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from crypto_bot.data.fetcher import MarketDataFetcher
from crypto_bot.ml.ensemble import TradingEnsembleClassifier
from crypto_bot.ml.preprocessor import FeatureEngineer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def analyze_current_system_features():
    """ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´é‡æ•°ã‚’æ­£ç¢ºã«åˆ†æ"""

    print("ğŸ” ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ç‰¹å¾´é‡æ•°åˆ†æé–‹å§‹")
    print("=" * 60)

    # 1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœŸå¾…ç‰¹å¾´é‡æ•°ç¢ºèª
    config_path = str(project_root / "config/production/production.yml")
    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    # extra_featuresæ•°ç¢ºèª
    extra_features = config.get("ml", {}).get("extra_features", [])
    base_features_count = 5  # OHLCV
    expected_total = base_features_count + len(extra_features)

    print(f"ğŸ“Š è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ:")
    print(f"   - base_features: {base_features_count}")
    print(f"   - extra_features: {len(extra_features)}")
    print(f"   - æœŸå¾…åˆè¨ˆ: {expected_total}")

    # 2. å®Ÿéš›ã®FeatureEngineerã§ãƒ†ã‚¹ãƒˆç”Ÿæˆ
    print(f"\nğŸ”§ å®Ÿéš›ã®ç‰¹å¾´é‡ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆååˆ†ãªã‚µã‚¤ã‚ºï¼‰
    test_data_rows = 100
    test_data = {
        "open": [10000.0 + i * 10 for i in range(test_data_rows)],
        "high": [10100.0 + i * 10 for i in range(test_data_rows)],
        "low": [9900.0 + i * 10 for i in range(test_data_rows)],
        "close": [10050.0 + i * 10 for i in range(test_data_rows)],
        "volume": [1000.0 + i * 5 for i in range(test_data_rows)],
    }

    df = pd.DataFrame(test_data)
    df.index = pd.date_range("2025-01-01", periods=test_data_rows, freq="H")

    # ç‰¹å¾´é‡ç”Ÿæˆ
    feature_engineer = FeatureEngineer(config)
    features_df = feature_engineer.transform(df)

    actual_features = len(features_df.columns)
    feature_names = list(features_df.columns)

    print(f"   - å®Ÿéš›ç”Ÿæˆæ•°: {actual_features}")
    print(f"   - ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ: {feature_names[:10]}... (æœ€åˆã®10å€‹)")

    # 3. ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    print(f"\nğŸ“‹ ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†æ:")

    metadata_path = project_root / "models/production/model_metadata.yaml"
    if metadata_path.exists():
        with open(metadata_path, "r") as f:
            metadata = yaml.safe_load(f)

        model_features = metadata.get("features_count", "Unknown")
        model_phase = metadata.get("phase", "Unknown")
        model_feature_names = metadata.get("feature_names", [])

        print(f"   - ãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡æ•°: {model_features}")
        print(f"   - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚§ãƒ¼ã‚º: {model_phase}")
        print(f"   - ãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡æ•°: {len(model_feature_names)}")
    else:
        print("   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹")

    # 4. feature_order.jsonç¢ºèª
    print(f"\nğŸ“ feature_order.jsonåˆ†æ:")

    feature_order_path = project_root / "config/core/feature_order.json"
    if feature_order_path.exists():
        import json

        with open(feature_order_path, "r") as f:
            feature_order = json.load(f)

        ordered_features = len(feature_order.get("feature_order", []))
        print(f"   - feature_orderæ•°: {ordered_features}")
    else:
        print("   - feature_order.jsonæœªç™ºè¦‹")

    # 5. å®Ÿéš›ã«ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ¤– å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ:")

    model_path = project_root / "models/production/model.pkl"
    if model_path.exists():
        try:
            model = joblib.load(model_path)

            # ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
            X_test = features_df.iloc[:50]  # 50è¡Œã§ãƒ†ã‚¹ãƒˆ
            predictions = model.predict_proba(X_test)

            print(f"   - ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: æˆåŠŸ")
            print(f"   - ãƒ†ã‚¹ãƒˆäºˆæ¸¬: æˆåŠŸ ({len(predictions)}è¡Œäºˆæ¸¬)")
            print(f"   - å…¥åŠ›ç‰¹å¾´é‡æ•°: {X_test.shape[1]}")

        except Exception as e:
            print(f"   - ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("   - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹")

    # 6. çµ±ä¸€åŒ–æ–¹é‡ã®ææ¡ˆ
    print(f"\n" + "=" * 60)
    print("ğŸ“Š ç‰¹å¾´é‡æ•°çµ±ä¸€åˆ†æçµæœ")
    print("=" * 60)

    if metadata_path.exists():
        print(f"ğŸ¯ ç¾åœ¨ã®çŠ¶æ³:")
        print(f"   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æœŸå¾…å€¤: {expected_total}")
        print(f"   - å®Ÿéš›ç”Ÿæˆæ•°: {actual_features}")
        print(f"   - ä¿å­˜ãƒ¢ãƒ‡ãƒ«æœŸå¾…æ•°: {model_features}")

        if actual_features == model_features:
            print(f"âœ… æ¨å¥¨çµ±ä¸€ç‰¹å¾´é‡æ•°: {actual_features}")
            print(f"   ç†ç”±: ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ¢ãƒ‡ãƒ«ãŒä¸€è‡´")
            return actual_features
        else:
            print(f"âš ï¸ ä¸ä¸€è‡´æ¤œå‡º:")
            print(f"   - ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆ: {actual_features}")
            print(f"   - ãƒ¢ãƒ‡ãƒ«æœŸå¾…: {model_features}")

            # ã‚ˆã‚Šå¤§ãã„æ–¹ã‚’æ¨å¥¨ï¼ˆå®‰å…¨å´ï¼‰
            recommended = max(actual_features, model_features)
            print(f"âœ… æ¨å¥¨çµ±ä¸€ç‰¹å¾´é‡æ•°: {recommended}")
            print(f"   ç†ç”±: ä¸ä¸€è‡´è§£æ¶ˆã®ãŸã‚å¤§ãã„æ–¹ã‚’æ¡ç”¨")
            return recommended
    else:
        print(f"âœ… æ¨å¥¨çµ±ä¸€ç‰¹å¾´é‡æ•°: {actual_features}")
        print(f"   ç†ç”±: ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆæ•°ã‚’åŸºæº–")
        return actual_features


def create_feature_unification_plan(target_feature_count: int):
    """ç‰¹å¾´é‡çµ±ä¸€åŒ–è¨ˆç”»ä½œæˆ"""

    print(f"\n" + "=" * 60)
    print(f"ğŸ¯ ç‰¹å¾´é‡çµ±ä¸€åŒ–è¨ˆç”»: {target_feature_count}ç‰¹å¾´é‡")
    print("=" * 60)

    plan = {
        "target_feature_count": target_feature_count,
        "files_to_update": [
            "models/production/model_metadata.yaml",
            "config/core/feature_order.json",
            "models/production/model.pkl",
            "tests/unit/test_*.py (æœŸå¾…å€¤æ›´æ–°)",
            "crypto_bot/ml/feature_order_manager.py",
            "scripts/diagnose_prediction_bias.py",
        ],
        "actions": [
            f"1. {target_feature_count}ç‰¹å¾´é‡ã§ã®ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’",
            f"2. feature_order.json {target_feature_count}ç‰¹å¾´é‡ã«æ›´æ–°",
            f"3. model_metadata.yamlç‰¹å¾´é‡æ•°çµ±ä¸€",
            f"4. å…¨ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æœŸå¾…å€¤çµ±ä¸€",
            f"5. è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æœŸå¾…å€¤çµ±ä¸€",
        ],
    }

    for i, action in enumerate(plan["actions"], 1):
        print(f"   {action}")

    print(f"\nğŸ“ æ›´æ–°å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«:")
    for file in plan["files_to_update"]:
        print(f"   - {file}")

    return plan


if __name__ == "__main__":
    try:
        # ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ åˆ†æ
        recommended_features = analyze_current_system_features()

        # çµ±ä¸€åŒ–è¨ˆç”»ä½œæˆ
        plan = create_feature_unification_plan(recommended_features)

        print(f"\n" + "=" * 60)
        print("âœ… ç‰¹å¾´é‡æ•°çµ±ä¸€åˆ†æå®Œäº†")
        print("=" * 60)
        print(f"ğŸ¯ çµ±ä¸€ç›®æ¨™: {recommended_features}ç‰¹å¾´é‡")
        print("ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: çµ±ä¸€åŒ–å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ")
        print("=" * 60)

    except Exception as e:
        logger.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
