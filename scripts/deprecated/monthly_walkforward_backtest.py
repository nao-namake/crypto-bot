#!/usr/bin/env python3
"""
1ãƒ¶æœˆé–“ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
127ç‰¹å¾´é‡ vs 97ç‰¹å¾´é‡ vs 26ç‰¹å¾´é‡ã®æ€§èƒ½æ¯”è¼ƒ
"""

import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

import joblib
import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.model_selection import TimeSeriesSplit

sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

from crypto_bot.ml.preprocessor import FeatureEngineer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def load_feature_sets():
    """æœ€é©åŒ–ç‰¹å¾´é‡ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿"""
    sets_path = Path("results/feature_analysis/optimized_feature_sets.json")

    if not sets_path.exists():
        logger.error(f"ç‰¹å¾´é‡ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sets_path}")
        logger.info("å…ˆã« analyze_127_features_detailed.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return None

    with open(sets_path, "r") as f:
        feature_sets = json.load(f)

    logger.info("ç‰¹å¾´é‡ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†:")
    logger.info(f"  ã‚ªãƒªã‚¸ãƒŠãƒ«: {len(feature_sets['original_features'])}ç‰¹å¾´é‡")
    logger.info(f"  é‡è¤‡å‰Šé™¤ç‰ˆ: {len(feature_sets['reduced_features'])}ç‰¹å¾´é‡")
    logger.info(f"  å³é¸ç‰ˆ: {len(feature_sets['essential_features'])}ç‰¹å¾´é‡")

    return feature_sets


def load_backtest_data():
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    data_path = Path("data/btc_usd_2024_hourly.csv")

    if not data_path.exists():
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
        logger.info("å…ˆã« create_backtest_data.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return None

    df = pd.read_csv(data_path)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df = df.sort_values("timestamp").reset_index(drop=True)

    logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
    logger.info(f"æœŸé–“: {df['timestamp'].min()} - {df['timestamp'].max()}")

    return df


def create_monthly_splits(df, n_months=6):
    """æœˆæ¬¡ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²ä½œæˆ"""
    df = df.copy()
    df["year_month"] = df["timestamp"].dt.to_period("M")

    unique_months = df["year_month"].unique()
    unique_months = sorted(unique_months)

    logger.info(f"åˆ©ç”¨å¯èƒ½æœˆ: {len(unique_months)}ãƒ¶æœˆ")

    splits = []

    # æœ€åˆã®3ãƒ¶æœˆã‚’å­¦ç¿’ã€æ¬¡ã®1ãƒ¶æœˆã‚’ãƒ†ã‚¹ãƒˆã¨ã—ã¦ã€1ãƒ¶æœˆãšã¤ãšã‚‰ã™
    train_months = 3
    test_months = 1

    for i in range(len(unique_months) - train_months):
        if i + train_months + test_months > len(unique_months):
            break

        # å­¦ç¿’æœŸé–“
        train_start = unique_months[i]
        train_end = unique_months[i + train_months - 1]

        # ãƒ†ã‚¹ãƒˆæœŸé–“
        test_start = unique_months[i + train_months]
        test_end = unique_months[
            min(i + train_months + test_months - 1, len(unique_months) - 1)
        ]

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
        train_mask = (df["year_month"] >= train_start) & (df["year_month"] <= train_end)
        test_mask = (df["year_month"] >= test_start) & (df["year_month"] <= test_end)

        train_indices = df[train_mask].index.tolist()
        test_indices = df[test_mask].index.tolist()

        if len(train_indices) > 100 and len(test_indices) > 20:  # æœ€å°ãƒ‡ãƒ¼ã‚¿æ•°ç¢ºèª
            splits.append(
                {
                    "train_indices": train_indices,
                    "test_indices": test_indices,
                    "train_period": f"{train_start} - {train_end}",
                    "test_period": f"{test_start} - {test_end}",
                    "train_size": len(train_indices),
                    "test_size": len(test_indices),
                }
            )

    logger.info(f"ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²ä½œæˆ: {len(splits)}åˆ†å‰²")

    return splits


def generate_features_for_set(df, feature_set, set_name):
    """æŒ‡å®šç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§ç‰¹å¾´é‡ç”Ÿæˆ"""
    logger.info(f"{set_name}ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹: {len(feature_set)}ç‰¹å¾´é‡")

    # è¨­å®šä½œæˆ
    config = {
        "ml": {
            "feat_period": 14,
            "lags": [1, 2, 3, 4, 5],
            "rolling_window": 20,
            "target_type": "classification",
            "extra_features": feature_set,
        }
    }

    try:
        engineer = FeatureEngineer(config)
        features = engineer.fit_transform(df)

        # ç‰¹å¾´é‡æ•°èª¿æ•´
        target_count = len(feature_set)
        if features.shape[1] != target_count:
            logger.warning(
                f"{set_name}: ç‰¹å¾´é‡æ•°èª¿æ•´ {features.shape[1]} â†’ {target_count}"
            )

            # ä¸è¶³åˆ†è£œå®Œ
            while features.shape[1] < target_count:
                dummy_name = f"dummy_{features.shape[1]}"
                features[dummy_name] = np.random.normal(0, 0.01, len(features))

            # éå‰°åˆ†å‰Šé™¤
            if features.shape[1] > target_count:
                features = features.iloc[:, :target_count]

        logger.info(f"{set_name}ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {features.shape}")
        return features

    except Exception as e:
        logger.error(f"{set_name}ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


def create_targets(df):
    """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ"""
    returns = df["close"].pct_change().fillna(0)

    # å‹•çš„é–¾å€¤ï¼ˆæœˆæ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ï¼‰
    rolling_vol = returns.rolling(30 * 24).std().fillna(returns.std())  # 30æ—¥é–“
    buy_threshold = 0.8 * rolling_vol
    sell_threshold = -0.8 * rolling_vol

    targets = np.where(
        returns > buy_threshold, 1, np.where(returns < sell_threshold, 0, -1)
    )

    # æœ‰åŠ¹ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ã¿
    valid_mask = targets != -1

    return targets, valid_mask


def train_and_evaluate_model(X_train, X_test, y_train, y_test, model_name):
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡"""
    try:
        # LightGBMãƒ¢ãƒ‡ãƒ«
        model = lgb.LGBMClassifier(
            objective="binary",
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            verbose=-1,
        )

        model.fit(X_train, y_train)

        # äºˆæ¸¬
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]

        # è©•ä¾¡æŒ‡æ¨™
        accuracy = accuracy_score(y_test, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_test, y_pred, average="binary"
        )

        # äºˆæ¸¬å¤šæ§˜æ€§
        pred_std = np.std(y_pred_proba)
        pred_range = np.max(y_pred_proba) - np.min(y_pred_proba)

        return {
            "model": model,
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
            "pred_std": pred_std,
            "pred_range": pred_range,
            "predictions": y_pred,
            "probabilities": y_pred_proba,
        }

    except Exception as e:
        logger.error(f"{model_name}ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def simulate_trading_performance(y_true, y_pred, y_proba, initial_balance=10000):
    """å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    balance = initial_balance
    positions = []
    trades = 0
    wins = 0

    for i in range(len(y_true)):
        if y_proba[i] > 0.7:  # å¼·ã„BUYã‚·ã‚°ãƒŠãƒ«
            # ãƒ­ãƒ³ã‚°å–å¼•
            if y_true[i] == 1:  # å®Ÿéš›ã«ä¸Šæ˜‡
                profit = balance * 0.02  # 2%åˆ©ç›Š
                balance += profit
                wins += 1
            else:
                loss = balance * 0.01  # 1%æå¤±
                balance -= loss
            trades += 1

        elif y_proba[i] < 0.3:  # å¼·ã„SELLã‚·ã‚°ãƒŠãƒ«
            # ã‚·ãƒ§ãƒ¼ãƒˆå–å¼•
            if y_true[i] == 0:  # å®Ÿéš›ã«ä¸‹è½
                profit = balance * 0.02  # 2%åˆ©ç›Š
                balance += profit
                wins += 1
            else:
                loss = balance * 0.01  # 1%æå¤±
                balance -= loss
            trades += 1

    win_rate = wins / trades if trades > 0 else 0
    total_return = (balance - initial_balance) / initial_balance

    return {
        "final_balance": balance,
        "total_return": total_return,
        "trades": trades,
        "wins": wins,
        "win_rate": win_rate,
    }


def run_walkforward_backtest():
    """ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger.info("=" * 80)
    logger.info("1ãƒ¶æœˆé–“ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹")
    logger.info("=" * 80)

    # ãƒ‡ãƒ¼ã‚¿ãƒ»ç‰¹å¾´é‡ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    feature_sets = load_feature_sets()
    if feature_sets is None:
        return None

    df = load_backtest_data()
    if df is None:
        return None

    # æœˆæ¬¡åˆ†å‰²ä½œæˆ
    splits = create_monthly_splits(df)
    if len(splits) == 0:
        logger.error("æœ‰åŠ¹ãªåˆ†å‰²ãŒä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ
    targets, valid_mask = create_targets(df)

    # çµæœæ ¼ç´
    results = {"original_127": [], "reduced_97": [], "essential_26": []}

    # ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå
    set_configs = {
        "original_127": feature_sets["original_features"],
        "reduced_97": feature_sets["reduced_features"],
        "essential_26": feature_sets["essential_features"],
    }

    # å„åˆ†å‰²ã§ãƒ†ã‚¹ãƒˆ
    for split_idx, split in enumerate(splits):
        logger.info(f"\nåˆ†å‰² {split_idx + 1}/{len(splits)}")
        logger.info(f"å­¦ç¿’æœŸé–“: {split['train_period']} ({split['train_size']}ä»¶)")
        logger.info(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {split['test_period']} ({split['test_size']}ä»¶)")

        # å„ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆ
        for set_name, feature_list in set_configs.items():
            logger.info(f"\n{set_name}ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå‡¦ç†ä¸­...")

            # ç‰¹å¾´é‡ç”Ÿæˆ
            features = generate_features_for_set(df, feature_list, set_name)
            if features is None:
                continue

            # æœ‰åŠ¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            train_indices = [
                i
                for i in split["train_indices"]
                if i < len(valid_mask) and valid_mask[i]
            ]
            test_indices = [
                i
                for i in split["test_indices"]
                if i < len(valid_mask) and valid_mask[i]
            ]

            if len(train_indices) < 50 or len(test_indices) < 10:
                logger.warning(f"{set_name}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                continue

            # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
            X_train = features.iloc[train_indices].fillna(0)
            X_test = features.iloc[test_indices].fillna(0)
            y_train = targets[train_indices]
            y_test = targets[test_indices]

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡
            eval_result = train_and_evaluate_model(
                X_train, X_test, y_train, y_test, set_name
            )
            if eval_result is None:
                continue

            # å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            trading_result = simulate_trading_performance(
                y_test, eval_result["predictions"], eval_result["probabilities"]
            )

            # çµæœè¨˜éŒ²
            split_result = {
                "split_idx": split_idx,
                "train_period": split["train_period"],
                "test_period": split["test_period"],
                "train_size": len(X_train),
                "test_size": len(X_test),
                "accuracy": eval_result["accuracy"],
                "f1_score": eval_result["f1_score"],
                "pred_std": eval_result["pred_std"],
                "final_balance": trading_result["final_balance"],
                "total_return": trading_result["total_return"],
                "trades": trading_result["trades"],
                "win_rate": trading_result["win_rate"],
            }

            results[set_name].append(split_result)

            logger.info(f"  ç²¾åº¦: {eval_result['accuracy']:.3f}")
            logger.info(f"  F1: {eval_result['f1_score']:.3f}")
            logger.info(f"  å–å¼•åç›Š: {trading_result['total_return']:.1%}")
            logger.info(f"  å‹ç‡: {trading_result['win_rate']:.1%}")

    return results


def analyze_results(results):
    """çµæœåˆ†æãƒ»æ¯”è¼ƒ"""
    logger.info("\n" + "=" * 80)
    logger.info("ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœåˆ†æ")
    logger.info("=" * 80)

    summary = {}

    for set_name, set_results in results.items():
        if not set_results:
            continue

        df_results = pd.DataFrame(set_results)

        summary[set_name] = {
            "n_tests": len(set_results),
            "avg_accuracy": df_results["accuracy"].mean(),
            "std_accuracy": df_results["accuracy"].std(),
            "avg_f1": df_results["f1_score"].mean(),
            "std_f1": df_results["f1_score"].std(),
            "avg_return": df_results["total_return"].mean(),
            "std_return": df_results["total_return"].std(),
            "avg_win_rate": df_results["win_rate"].mean(),
            "avg_trades": df_results["trades"].mean(),
            "best_return": df_results["total_return"].max(),
            "worst_return": df_results["total_return"].min(),
            "consistent_profitable": (df_results["total_return"] > 0).sum()
            / len(df_results),
        }

    # çµæœè¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ“Š ç‰¹å¾´é‡ã‚»ãƒƒãƒˆåˆ¥æ€§èƒ½æ¯”è¼ƒ")
    print("=" * 80)

    for set_name, stats in summary.items():
        print(f"\nğŸ” {set_name.upper()}:")
        print(f"  ãƒ†ã‚¹ãƒˆå›æ•°: {stats['n_tests']}å›")
        print(f"  å¹³å‡ç²¾åº¦: {stats['avg_accuracy']:.1%} (Â±{stats['std_accuracy']:.1%})")
        print(f"  å¹³å‡F1ã‚¹ã‚³ã‚¢: {stats['avg_f1']:.1%} (Â±{stats['std_f1']:.1%})")
        print(f"  å¹³å‡åç›Šç‡: {stats['avg_return']:.1%} (Â±{stats['std_return']:.1%})")
        print(f"  å¹³å‡å‹ç‡: {stats['avg_win_rate']:.1%}")
        print(f"  å¹³å‡å–å¼•æ•°: {stats['avg_trades']:.0f}å›")
        print(f"  æœ€é«˜åç›Š: {stats['best_return']:.1%}")
        print(f"  æœ€ä½åç›Š: {stats['worst_return']:.1%}")
        print(f"  åˆ©ç›Šä¸€è²«æ€§: {stats['consistent_profitable']:.1%}")

    # æ¨å¥¨æ±ºå®š
    if summary:
        best_set = max(summary.keys(), key=lambda x: summary[x]["avg_return"])
        print(f"\nğŸ† æ¨å¥¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ: {best_set.upper()}")
        print(f"   ç†ç”±: æœ€é«˜å¹³å‡åç›Šç‡ {summary[best_set]['avg_return']:.1%}")

    return summary


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = run_walkforward_backtest()
    if results is None:
        return

    # çµæœåˆ†æ
    summary = analyze_results(results)

    # çµæœä¿å­˜
    results_dir = Path("results/walkforward_backtest")
    results_dir.mkdir(parents=True, exist_ok=True)

    # è©³ç´°çµæœä¿å­˜
    detailed_path = results_dir / "monthly_walkforward_results.json"
    with open(detailed_path, "w") as f:
        json.dump(results, f, indent=2, default=str)

    # ã‚µãƒãƒªãƒ¼ä¿å­˜
    summary_path = results_dir / "performance_summary.json"
    with open(summary_path, "w") as f:
        json.dump(summary, f, indent=2)

    logger.info(f"\nçµæœä¿å­˜å®Œäº†:")
    logger.info(f"  è©³ç´°: {detailed_path}")
    logger.info(f"  ã‚µãƒãƒªãƒ¼: {summary_path}")

    print("\n" + "=" * 80)
    print("ğŸ¯ çµè«–ã¨æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    print("=" * 80)
    print("1. æœ€ã‚‚åç›Šæ€§ã®é«˜ã„ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’æœ¬ç•ªæ¡ç”¨")
    print("2. å®‰å®šæ€§ï¼ˆæ¨™æº–åå·®ï¼‰ã‚‚è€ƒæ…®ã—ãŸæœ€çµ‚æ±ºå®š")
    print("3. é¸æŠã—ãŸã‚»ãƒƒãƒˆã§final_model.pklã‚’ä½œæˆ")
    print("4. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆâ†’bitbankå®Ÿå–å¼•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")


if __name__ == "__main__":
    main()
