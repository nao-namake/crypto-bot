"""
Live trading command for Bitbank
"""

import logging
import os
import sys
import time
from typing import Optional

import click
import pandas as pd

from crypto_bot.api.health import update_init_status, update_status
from crypto_bot.data.fetcher import MarketDataFetcher
from crypto_bot.execution.engine import EntryExit, Position
from crypto_bot.execution.factory import create_exchange_client
from crypto_bot.risk.manager import RiskManager
from crypto_bot.strategy.factory import StrategyFactory
from crypto_bot.utils.config import load_config
from crypto_bot.utils.pre_computed_cache import PreComputedCache
from crypto_bot.utils.trading_integration_service import TradingIntegrationService

logger = logging.getLogger(__name__)


def resolve_env_var(value):
    """ç’°å¢ƒå¤‰æ•°ç½®æ›ãƒ‘ã‚¿ãƒ¼ãƒ³ ${ENV_VAR} ã‚’è§£æ±º"""
    if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
        env_var_name = value[2:-1]  # ${} ã‚’é™¤å»
        return os.getenv(env_var_name)
    return value


def initialize_bitbank_credentials(dd: dict) -> tuple[str, str]:
    """Bitbank APIèªè¨¼æƒ…å ±ã‚’åˆæœŸåŒ–"""
    api_key = resolve_env_var(dd.get("api_key")) or os.getenv("BITBANK_API_KEY")
    api_secret = resolve_env_var(dd.get("api_secret")) or os.getenv(
        "BITBANK_API_SECRET"
    )

    if not api_key or not api_secret:
        logger.error(
            "Bitbank API credentials not found. Please set BITBANK_API_KEY "
            "and BITBANK_API_SECRET environment variables"
        )
        logger.error(f"Config api_key: {dd.get('api_key', 'Not set')}")
        api_key_status = "Set" if os.getenv("BITBANK_API_KEY") else "Not set"
        logger.error(f"Env BITBANK_API_KEY: {api_key_status}")
        secret_status = "Set" if os.getenv("BITBANK_API_SECRET") else "Not set"
        logger.error(f"Env BITBANK_API_SECRET: {secret_status}")
        sys.exit(1)

    logger.info(
        f"âœ… Bitbank API credentials resolved successfully - " f"Key: {api_key[:8]}..."
    )
    if dd.get("api_key", "").startswith("${"):
        logger.info(
            "ğŸ“ Environment variable substitution performed for API credentials"
        )

    return api_key, api_secret


def initialize_strategy(cfg: dict, config_path: str, fetcher) -> object:
    """æˆ¦ç•¥ã‚’åˆæœŸåŒ–"""
    strategy_config = cfg.get("strategy", {})
    strategy_type = strategy_config.get("type", "single")
    strategy_name = strategy_config.get("name", "ml")

    logger.info(f"ğŸ“Š [INIT-3] Strategy Type: {strategy_type}")
    logger.info(f"ğŸ“Š [INIT-3] Strategy Name: {strategy_name}")
    logger.info(f"â° [INIT-3] Timestamp: {pd.Timestamp.now()}")
    logger.info("ğŸ¤– [INIT-3] Initializing Strategy (this may take time)...")

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹æ¤œè¨¼
    sp = strategy_config.get("params", {})
    model_path = sp.get("model_path", "model.pkl")

    if not os.path.isabs(model_path):
        # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¾ãŸã¯modelãƒ•ã‚©ãƒ«ãƒ€ã‚’åŸºæº–ã«è§£æ±º
        possible_paths = [
            os.path.join(os.getcwd(), model_path),
            os.path.join(os.getcwd(), "model", model_path),
            os.path.join(os.path.dirname(config_path), "..", "model", model_path),
        ]
        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                strategy_config["params"]["model_path"] = model_path
                break
        else:
            logger.error(f"Model file not found: {model_path}")
            sys.exit(1)

    logger.info(f"ğŸ“Š [INIT-3] Using model: {model_path}")

    # StrategyFactoryã§æˆ¦ç•¥ä½œæˆ
    if strategy_type == "multi_timeframe_ensemble":
        logger.info("ğŸ”„ [INIT-3] Initializing Multi-Timeframe Ensemble Strategy...")
        strategy = StrategyFactory.create_strategy(strategy_config, cfg)

        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æˆ¦ç•¥ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã‚’è¨­å®š
        if hasattr(strategy, "set_data_fetcher"):
            logger.info(
                "ğŸ”— [INIT-3] Setting data fetcher for multi-timeframe strategy..."
            )
            strategy.set_data_fetcher(fetcher)
            logger.info(
                "âœ… [INIT-3] Data fetcher configured for multi-timeframe strategy"
            )

        logger.info(
            "âœ… [INIT-3] Multi-Timeframe Ensemble Strategy initialized successfully"
        )
    else:
        # å¾“æ¥ã®MLæˆ¦ç•¥ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
        logger.info("ğŸ¤– [INIT-3] Initializing traditional ML Strategy...")
        strategy = StrategyFactory.create_strategy(strategy_config, cfg)
        logger.info("âœ… [INIT-3] Traditional Strategy initialized successfully")

    # ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚’è¨˜éŒ²
    try:
        update_init_status("features", "feature_system")
    except Exception:
        pass

    return strategy


def get_account_balance(fetcher, cfg: dict) -> float:
    """å£åº§æ®‹é«˜ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰"""
    try:
        # å®Ÿéš›ã®å£åº§æ®‹é«˜ã‚’å–å¾—
        balance_data = fetcher.fetch_balance()
        jpy_balance = balance_data.get("JPY", {}).get("free", 0.0)
        if jpy_balance > 0:
            balance = jpy_balance
            logger.info(f"ğŸ’° [INIT-4] Real account balance: {balance:.2f} JPY")
            return balance
        else:
            raise ValueError("JPY balance is 0 or not found")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to get real balance: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: liveè¨­å®šã¾ãŸã¯backtestè¨­å®šã‹ã‚‰å–å¾—
        live_config = cfg.get("live", {})
        if "starting_balance" in live_config:
            balance = live_config["starting_balance"]
            logger.info(f"ğŸ’° [INIT-4] Using live.starting_balance: {balance:.2f} JPY")
        else:
            balance = cfg["backtest"]["starting_balance"]
            logger.info(
                f"ğŸ’° [INIT-4] Using backtest.starting_balance as fallback: "
                f"{balance:.2f} JPY"
            )
        return balance


def fetch_latest_data(fetcher, dd: dict, symbol: str) -> Optional[pd.DataFrame]:
    """æœ€æ–°ã®ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        logger.info("ğŸ“Š [DATA-FETCH] Fetching price data from Bitbank API...")
        logger.info(f"â° [DATA-FETCH] Timestamp: {pd.Timestamp.now()}")

        # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«å–å¾—ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®sinceè¨­å®šã‚’ä½¿ç”¨ï¼‰
        current_time = pd.Timestamp.now(tz="UTC")

        if dd.get("since"):
            since_time = pd.Timestamp(dd["since"])
            if since_time.tz is None:
                since_time = since_time.tz_localize("UTC")
            logger.info(f"ğŸ” [DEBUG] Using config since: {since_time}")
        else:
            # å‹•çš„since_hoursè¨ˆç®—ï¼ˆåœŸæ—¥ã‚®ãƒ£ãƒƒãƒ—ãƒ»ç¥æ—¥å¯¾å¿œï¼‰
            base_hours = dd.get("since_hours", 48)

            # æ›œæ—¥åˆ¤å®šï¼ˆæœˆæ›œæ—¥=0, æ—¥æ›œæ—¥=6ï¼‰
            current_day = current_time.dayofweek
            current_hour = current_time.hour

            # åœŸæ—¥ã‚®ãƒ£ãƒƒãƒ—å¯¾å¿œ
            if current_day == 0:  # æœˆæ›œæ—¥
                # æœˆæ›œæ—¥ã¯åœŸæ—¥ã‚®ãƒ£ãƒƒãƒ—ã‚’è€ƒæ…®ã—ã¦å»¶é•·
                extended_hours = base_hours + 48  # 2æ—¥é–“è¿½åŠ 
                logger.info(
                    f"ğŸ—“ï¸ Monday detected: extending lookback from {base_hours}h to {extended_hours}h"
                )
                hours_back = extended_hours
            elif current_day <= 1 and current_hour < 12:  # æœˆæ›œãƒ»ç«æ›œåˆå‰
                # æœˆæ›œåˆå¾Œãƒ»ç«æ›œåˆå‰ã‚‚å°‘ã—å»¶é•·
                extended_hours = base_hours + 24  # 1æ—¥é–“è¿½åŠ 
                logger.info(
                    f"ğŸŒ… Early week detected: extending lookback from {base_hours}h to {extended_hours}h"
                )
                hours_back = extended_hours
            else:
                # å¹³æ—¥ã¯é€šå¸¸ã®è¨­å®š
                hours_back = base_hours

            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å¦¥å½“æ€§æ¤œè¨¼ãƒ»ä¿®æ­£
            since_time = current_time - pd.Timedelta(hours=hours_back)
            current_timestamp = int(current_time.timestamp() * 1000)
            since_timestamp = int(since_time.timestamp() * 1000)

            # æœªæ¥ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¤œå‡ºãƒ»ä¿®æ­£
            if since_timestamp > current_timestamp:
                logger.error(
                    f"ğŸš¨ [PHASE-H22.2] CRITICAL: Future timestamp detected! since={since_timestamp}, current={current_timestamp}"
                )
                # å®‰å…¨ãªéå»æ™‚åˆ»ã«ä¿®æ­£ï¼ˆ96æ™‚é–“å‰ï¼‰
                since_time = current_time - pd.Timedelta(hours=96)
                since_timestamp = int(since_time.timestamp() * 1000)
                logger.warning(
                    f"ğŸ”§ [PHASE-H22.2] Auto-corrected to safe past time: {since_time} (timestamp={since_timestamp})"
                )

            # æ¥µç«¯ã«å¤ã„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¤œå‡ºãƒ»ä¿®æ­£
            max_hours_back = 720  # 30æ—¥é–“ã®ä¸Šé™
            if hours_back > max_hours_back:
                logger.warning(
                    f"âš ï¸ [PHASE-H22.2] Excessive hours_back detected: {hours_back}h > {max_hours_back}h, capping"
                )
                hours_back = max_hours_back
                since_time = current_time - pd.Timedelta(hours=hours_back)

        logger.info(
            f"ğŸ”„ Fetching latest data since: {since_time} " f"(current: {current_time})"
        )

        # ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ±ºå®š
        base_timeframe = "1h"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if (
            "multi_timeframe_data" in dd
            and "base_timeframe" in dd["multi_timeframe_data"]
        ):
            base_timeframe = dd["multi_timeframe_data"]["base_timeframe"]
            logger.info(
                f"ğŸ”§ [DATA-FETCH] Using base_timeframe from multi_timeframe_data: {base_timeframe}"
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®timeframeè¨­å®šã‚’ä½¿ç”¨ï¼ˆãŸã ã—4hã¯å¼·åˆ¶çš„ã«1hã«å¤‰æ›´ï¼‰
            timeframe_raw = dd.get("timeframe", "1h")
            if timeframe_raw == "4h":
                base_timeframe = "1h"  # 4hè¦æ±‚ã‚’å¼·åˆ¶çš„ã«1hã«å¤‰æ›
                logger.warning(
                    "ğŸš¨ [DATA-FETCH] Phase H.3.2: 4h timeframe detected in main loop, forcing to 1h (Bitbank API compatibility)"
                )
            else:
                base_timeframe = timeframe_raw
                logger.info(
                    f"ğŸ”§ [DATA-FETCH] Using timeframe from data config: {base_timeframe}"
                )

        price_df = fetcher.get_price_df(
            timeframe=base_timeframe,
            since=since_time,
            limit=dd.get("limit", 500),
            paginate=dd.get("paginate", True),
            per_page=dd.get("per_page", 100),
            max_consecutive_empty=dd.get("max_consecutive_empty", None),
            max_consecutive_no_new=dd.get("max_consecutive_no_new", None),
            max_attempts=dd.get("max_attempts", None),
        )
        logger.info(
            f"âœ… [DATA-FETCH] Price data fetched successfully: "
            f"{len(price_df)} records"
        )
        logger.info(f"â° [DATA-FETCH] Fetch completed at: {pd.Timestamp.now()}")
        return price_df
    except Exception as e:
        logger.error(f"âŒ [DATA-FETCH] Failed to fetch price data: {e}")
        logger.info("â° [DATA-FETCH] Waiting 30 seconds before retry...")
        return None


def execute_bitbank_trade(
    order,
    position,
    symbol: str,
    exchange_id: str,
    api_key: str,
    api_secret: str,
    cfg: dict,
    dd: dict,
    integration_service=None,
    is_exit: bool = False,
) -> bool:
    """Bitbankå®Ÿå–å¼•ã‚’å®Ÿè¡Œ"""
    try:
        if exchange_id == "bitbank":
            # Bitbankå®Ÿå–å¼•
            # ä¿¡ç”¨å–å¼•ãƒ¢ãƒ¼ãƒ‰è¨­å®šã®å–å¾—
            live_config = cfg.get("live", {})
            margin_config = live_config.get("margin_trading", {})
            margin_enabled = margin_config.get("enabled", False)
            force_margin = margin_config.get("force_margin_mode", False)
            verify_margin = margin_config.get("verify_margin_status", False)

            # force_margin_modeè¨­å®šå‡¦ç†
            if force_margin:
                margin_enabled = True
                logger.info(
                    "ğŸ”’ Force margin mode enabled - overriding margin_enabled setting"
                )

            logger.info(
                f"Margin trading mode: {margin_enabled} (force: {force_margin}, verify: {verify_margin})"
            )

            client = create_exchange_client(
                exchange_id=exchange_id,
                api_key=api_key,
                api_secret=api_secret,
                ccxt_options=dd.get("ccxt_options", {}),
                margin_mode=margin_enabled,  # ä¿¡ç”¨å–å¼•ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–
            )

            # ãƒãƒ¼ã‚¸ãƒ³çŠ¶æ…‹æ¤œè¨¼ï¼ˆverify_margin_status=trueã®å ´åˆï¼‰
            if verify_margin:
                try:
                    if hasattr(client, "is_margin_enabled"):
                        actual_margin_status = client.is_margin_enabled()
                        logger.info(
                            f"ğŸ” Margin status verification: expected={margin_enabled}, actual={actual_margin_status}"
                        )
                        if margin_enabled and not actual_margin_status:
                            logger.warning(
                                "âš ï¸ Margin mode mismatch - expected enabled but actual disabled"
                            )
                    elif hasattr(client, "exchange") and hasattr(
                        client.exchange, "privateGetAccount"
                    ):
                        # Bitbank APIã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ç¢ºèª
                        account_info = client.exchange.privateGetAccount()
                        logger.info(
                            f"ğŸ” Account info retrieved for margin verification: {account_info}"
                        )
                except Exception as e:
                    logger.warning(f"ğŸ” Margin status verification failed: {e}")

            # Phase 8çµ±è¨ˆã‚·ã‚¹ãƒ†ãƒ ã¨ExecutionClientçµ±åˆï¼ˆNoneãƒã‚§ãƒƒã‚¯è¿½åŠ ï¼‰
            if integration_service is not None:
                integration_service.integrate_with_execution_client(client)
                logger.debug("ğŸ“Š Statistics system integrated with execution client")
            else:
                logger.debug("ğŸ“Š Statistics system not available (fallback mode)")

            # æœ€å°æ³¨æ–‡é‡ãƒã‚§ãƒƒã‚¯ï¼ˆBitbank BTC/JPYã¯0.0001ä»¥ä¸Šï¼‰
            min_amount = 0.0001
            if order.lot < min_amount:
                logger.warning(
                    f"âš ï¸ Order amount {order.lot} "
                    f"too small, adjusting to minimum "
                    f"{min_amount}"
                )
                adjusted_amount = min_amount
            else:
                adjusted_amount = order.lot

            # å®Ÿéš›ã®æ³¨æ–‡é€ä¿¡
            order_result = client.create_order(
                symbol=symbol,
                type="market",
                side=order.side.lower(),
                amount=adjusted_amount,
            )

            order_type = "EXIT" if is_exit else "ENTRY"
            logger.info(f"âœ… REAL BITBANK {order_type} ORDER EXECUTED: {order_result}")
            return True
        else:
            # å®Ÿå–å¼•å¼·åˆ¶åŒ–: éå¯¾å¿œå–å¼•æ‰€ã§ã®å®Ÿè¡Œã‚’æ‹’å¦
            logger.error(f"ğŸš¨ UNSUPPORTED EXCHANGE: {exchange_id}")
            logger.error("Real trading is only supported for Bitbank")
            logger.error("Configure exchange_id='bitbank' for real trading")
            raise RuntimeError(f"Unsupported exchange for real trading: {exchange_id}")

    except Exception as e:
        logger.error(f"âŒ BITBANK ORDER FAILED: {e}")
        logger.error(f"Error details: {type(e).__name__}: {str(e)}")

        if exchange_id == "bitbank":
            # Bitbank APIã‚¨ãƒ©ãƒ¼ã®è©³ç´°ãƒ­ã‚°
            api_key_status = "Yes" if api_key else "No"
            api_secret_status = "Yes" if api_secret else "No"
            logger.error(f"API Key present: {api_key_status}")
            logger.error(f"API Secret present: {api_secret_status}")
            logger.error(f"Margin mode: {margin_enabled}")
            logger.error(
                f"Order details: {order.side} " f"{order.lot} at {order.price}"
            )

            # ã‚¨ãƒ©ãƒ¼40024ã®å ´åˆã¯ä¿¡ç”¨å–å¼•è¨­å®šã®å•é¡Œã¨ã—ã¦ç¶™ç¶šå®Ÿè¡Œ
            if "40024" in str(e):
                logger.warning(
                    "âš ï¸ Error 40024 detected - likely " "margin trading permission issue"
                )
                logger.warning(
                    "ğŸ”„ Continuing trading loop - " "will retry on next iteration"
                )
            elif "timeout" in str(e).lower() or "connection" in str(e).lower():
                logger.warning("âš ï¸ Network/timeout error detected")
                logger.warning(
                    "ğŸ”„ Continuing trading loop - " "will retry on next iteration"
                )
            else:
                logger.warning("âš ï¸ Trading error occurred - continuing loop")

        return False


@click.command()
@click.option(
    "--config", "-c", "config_path", required=True, type=click.Path(exists=True)
)
@click.option(
    "--max-trades",
    type=int,
    default=0,
    help="0=ç„¡é™ã€‚æˆç«‹ã—ãŸç´„å®šæ•°ãŒã“ã®å€¤ã«é”ã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—çµ‚äº†",
)
@click.option(
    "--simple",
    is_flag=True,
    default=False,
    help="ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ï¼ˆçµ±è¨ˆã‚·ã‚¹ãƒ†ãƒ ãªã—ã€æœ€å°é™ã®åˆæœŸåŒ–ï¼‰",
)
def live_bitbank_command(config_path: str, max_trades: int, simple: bool):
    """
    Bitbankæœ¬ç•ªã§ã®ãƒ©ã‚¤ãƒ–ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã€‚
    97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ã§BTC/JPYãƒšã‚¢ã®å®Ÿå–å¼•ã‚’è¡Œã†ã€‚

    --simple ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€çµ±è¨ˆã‚·ã‚¹ãƒ†ãƒ ãªã—ã®è»½é‡ç‰ˆã§å®Ÿè¡Œã€‚
    é€šå¸¸ç‰ˆã§ã¯APIã‚µãƒ¼ãƒãƒ¼æ©Ÿèƒ½ã‚‚çµ±åˆã—ã€ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‰çŠ¶æ³ç¢ºèªãŒå¯èƒ½ã€‚
    """
    cfg = load_config(config_path)

    # è¨­å®šç¢ºèª
    exchange_id = cfg["data"].get("exchange", "bitbank")
    symbol = cfg["data"].get("symbol", "BTC/JPY")

    init_prefix = "[SIMPLE-INIT]" if simple else "[INIT-1]"
    logger.info(
        f"ğŸš€ {init_prefix} Starting Bitbank live trading{' (Simple Mode)' if simple else ''} - "
        f"Exchange: {exchange_id}, Symbol: {symbol}"
    )
    if not simple:
        logger.info(f"â° {init_prefix} Timestamp: {pd.Timestamp.now()}")

    # åˆæœŸåŒ–çŠ¶æ³ã‚’æ›´æ–°ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    if not simple:
        try:
            update_init_status("basic", "basic_system")
        except Exception:
            pass

    # Phase 3: å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿å®Œå…¨ç„¡åŠ¹åŒ– - å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ä½¿ç”¨ã—ãªã„
    dd = cfg.get("data", {})
    # Phase 3ã§å¤–éƒ¨APIå®Œå…¨é™¤å»

    # Bitbankç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼åˆæœŸåŒ–
    logger.info("ğŸ”Œ [INIT-2] Initializing Bitbank data fetcher...")
    logger.info(f"â° [INIT-2] Timestamp: {pd.Timestamp.now()}")
    fetcher = MarketDataFetcher(
        exchange_id=exchange_id,
        symbol=symbol,
        ccxt_options=dd.get("ccxt_options", {}),
    )
    logger.info("âœ… [INIT-2] Bitbank data fetcher initialized successfully")

    # APIèªè¨¼æƒ…å ±ã®åˆæœŸåŒ–
    api_key, api_secret = initialize_bitbank_credentials(dd)

    # æˆ¦ç•¥ã®åˆæœŸåŒ–
    strategy = initialize_strategy(cfg, config_path, fetcher)

    # RiskManageråˆæœŸåŒ–
    logger.info("âš–ï¸ [INIT-4] Initializing Risk Manager...")
    logger.info(f"â° [INIT-4] Timestamp: {pd.Timestamp.now()}")
    risk_config = cfg.get("risk", {})
    kelly_config = risk_config.get("kelly_criterion", {})
    risk_manager = RiskManager(
        risk_per_trade=risk_config.get("risk_per_trade", 0.01),
        stop_atr_mult=risk_config.get("stop_atr_mult", 1.5),
        kelly_enabled=kelly_config.get("enabled", False),
        kelly_lookback_window=kelly_config.get("lookback_window", 50),
        kelly_max_fraction=kelly_config.get("max_fraction", 0.25),
    )
    logger.info("âœ… [INIT-4] Risk Manager initialized successfully")

    position = Position()

    # å£åº§æ®‹é«˜ã®å–å¾—
    balance = get_account_balance(fetcher, cfg)

    # æ”¹å–„ç‰ˆ: åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã°æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    logger.info("ğŸš€ [INIT-5] Starting improved initialization with cache support...")

    # åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒã‚§ãƒƒã‚¯
    initial_data = None
    cache_loaded = False

    # äº‹å‰å–å¾—ã—ãŸåˆæœŸãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
    try:
        import pickle
        from pathlib import Path

        # Dockerå†…ã¨ãƒ­ãƒ¼ã‚«ãƒ«ã®ä¸¡æ–¹ã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«ãƒ‘ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        cache_paths = [
            Path("/app/cache/initial_data.pkl"),  # Dockerå†…
            Path("cache/initial_data.pkl"),  # ãƒ­ãƒ¼ã‚«ãƒ«
        ]

        for cache_path in cache_paths:
            if cache_path.exists():
                logger.info(f"ğŸ“¦ [INIT-CACHE] Loading initial data from {cache_path}")
                with open(cache_path, "rb") as f:
                    cache_content = pickle.load(f)
                    initial_data = cache_content.get("data")
                    # metadata = cache_content.get("metadata", {})  # ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ

                if initial_data is not None and not initial_data.empty:
                    logger.info(
                        f"âœ… [INIT-CACHE] Loaded {len(initial_data)} records from cache"
                    )
                    logger.info(
                        f"ğŸ“ˆ [INIT-CACHE] Data range: {initial_data.index.min()} to {initial_data.index.max()}"
                    )
                    cache_loaded = True

                    # æˆ¦ç•¥ã«åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
                    if hasattr(strategy, "set_initial_data"):
                        strategy.set_initial_data(initial_data)
                    break

    except Exception as e:
        logger.warning(f"âš ï¸ [INIT-CACHE] Failed to load cache: {e}")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã¯æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    if not cache_loaded:
        logger.info("ğŸ“Š [INIT-5] No cache found, fetching minimal initial data...")
        try:
            # æœ€å°é™ã®200ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼‰
            initial_data = fetch_latest_data(fetcher, dd, symbol)
            if initial_data is not None and len(initial_data) >= 100:
                logger.info(
                    f"âœ… [INIT-5] Fetched {len(initial_data)} records successfully"
                )
            else:
                logger.warning(
                    "âš ï¸ [INIT-5] Insufficient initial data, will fetch in main loop"
                )
        except Exception as e:
            logger.error(f"âŒ [INIT-5] Failed to fetch initial data: {e}")
            logger.info("ğŸ”„ [INIT-5] Will retry in main loop")

    # Phase 12.3: PreComputedCacheã‚‚ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    cache = PreComputedCache()
    if not cache_loaded and cache.has_valid_cache():
        logger.info("ğŸ“¦ [INIT-CACHE] Loading from PreComputedCache as fallback...")
        cache_data = cache.load_all()
        if cache_data:
            logger.info(
                f"âœ… [INIT-CACHE] Loaded: {len(cache_data.get('market_data', []))} records"
            )
            if hasattr(strategy, "set_cached_data"):
                strategy.set_cached_data(cache_data)

    # æœ€å°é™ã®åˆæœŸåŒ–ã®ã¿å®Ÿè¡Œ
    entry_exit = EntryExit(cfg, fetcher, risk_manager)
    position = Position()

    # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã®æœ€çµ‚ç¢ºèª
    logger.info(
        "ğŸ” [INIT-VERIFY] Verifying ensemble model states after initialization..."
    )
    if hasattr(strategy, "timeframe_processors"):
        model_ready = False
        for tf, processor in strategy.timeframe_processors.items():
            if processor:
                fitted = processor.is_fitted
                enabled = processor.ensemble_enabled
                logger.info(f"  âœ… {tf} processor: fitted={fitted}, enabled={enabled}")
                if fitted and enabled:
                    model_ready = True
            else:
                logger.warning(f"  âŒ {tf} processor: NOT INITIALIZED")

        if model_ready:
            logger.info(
                "ğŸ¯ [INIT-VERIFY] At least one ensemble model is ready for trading"
            )
        else:
            logger.warning(
                "âš ï¸ [INIT-VERIFY] No ensemble models are ready - will use fallback strategies"
            )
            logger.info(
                "ğŸ”„ [INIT-VERIFY] Models will be trained automatically when sufficient data is collected"
            )
    else:
        logger.info("â„¹ï¸ [INIT-VERIFY] Strategy does not use ensemble models")

    # Phase 8çµ±è¨ˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    integration_service = None
    if not simple:
        logger.info("ğŸ“Š [INIT-10] Initializing Phase 8 Statistics System...")
        logger.info(f"â° [INIT-10] Timestamp: {pd.Timestamp.now()}")

        try:
            # TradingIntegrationServiceåˆæœŸåŒ–ï¼ˆCloud Runç’°å¢ƒçµ±ä¸€ï¼‰
            integration_service = TradingIntegrationService(
                base_dir="/app",
                initial_balance=balance,  # Phase G.2.4.1: Cloud Runç’°å¢ƒãƒ‘ã‚¹çµ±ä¸€
            )

            # MLStrategyã¨ã®çµ±åˆ
            integration_service.integrate_with_ml_strategy(strategy)
            logger.info(
                "âœ… [INIT-9] Phase 8 Statistics System initialized successfully"
            )

        except Exception as e:
            logger.warning(f"âš ï¸ [INIT-9] Statistics System initialization failed: {e}")
            logger.info(
                "ğŸ”„ [INIT-9] Continuing with basic status.json fallback system..."
            )

            # Phase G.2.4.2: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - åŸºæœ¬çš„ãªstatus.jsonä½œæˆ
            try:
                import json

                basic_status = {
                    "last_updated": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "system_status": "running",
                    "total_profit": 0.0,
                    "trade_count": 0,
                    "position": "No active position",
                    "status": "Statistics system fallback active",
                }
                with open("/app/status.json", "w", encoding="utf-8") as f:
                    json.dump(basic_status, f, indent=2, ensure_ascii=False)
                logger.info(
                    "âœ… [INIT-9] Basic status.json created successfully (fallback mode)"
                )
            except Exception as fallback_error:
                logger.error(
                    f"âŒ [INIT-9] Fallback status.json creation failed: {fallback_error}"
                )
                logger.info("ğŸ”„ [INIT-9] Continuing without status file (minimal mode)")

            integration_service = None  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯None
    else:
        logger.info("ğŸ“Š [SIMPLE-INIT] Skipping statistics system (simple mode)")

    # åˆæœŸåŒ–çŠ¶æ³ã‚’æ›´æ–°ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    if not simple:
        try:
            update_init_status("statistics", "statistics_system")
        except Exception:
            pass

    trade_done = 0
    complete_prefix = "[SIMPLE-COMPLETE]" if simple else "[INIT-COMPLETE]"
    logger.info(
        f"ğŸŠ {complete_prefix} === Bitbank Live Trading Started{' (Simple)' if simple else ''} ===  Ctrl+C ã§åœæ­¢"
    )
    logger.info(
        f"ğŸš€ {complete_prefix} 97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­ - Symbol: {symbol}, Balance: {balance}"
    )
    if not simple:
        logger.info(f"â° {complete_prefix} Timestamp: {pd.Timestamp.now()}")

    loop_prefix = "[SIMPLE-LOOP]" if simple else "[LOOP-START]"
    logger.info(f"ğŸ”„ {loop_prefix} Starting main trading loop...")
    if not simple:
        logger.info(f"â° {loop_prefix} Timestamp: {pd.Timestamp.now()}")

    # åˆæœŸåŒ–å®Œäº†ã‚’è¨˜éŒ²ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    if not simple:
        try:
            update_init_status("complete", "trading_loop")
        except Exception:
            pass

    try:
        while True:
            iter_prefix = "[SIMPLE-LOOP]" if simple else "[LOOP-ITER]"
            logger.info(f"ğŸ”„ {iter_prefix} Starting new trading iteration...")
            if not simple:
                logger.info(f"â° {iter_prefix} Timestamp: {pd.Timestamp.now()}")

            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            price_df = fetch_latest_data(fetcher, dd, symbol)
            if price_df is None:
                time.sleep(30)
                continue

            if price_df.empty:
                logger.warning("No price data received, waiting...")
                time.sleep(30)
                continue

            latest_time = price_df.index[-1]
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ä¸€è‡´: latest_timeã«UTCã‚’ä»˜åŠ ã—ã¦tz-aware timestampåŒå£«ã§è¨ˆç®—
            if latest_time.tz is None:
                latest_time = latest_time.tz_localize("UTC")
            time_diff = pd.Timestamp.now(tz="UTC") - latest_time
            hours_old = time_diff.total_seconds() / 3600

            logger.info(
                f"Received {len(price_df)} price records, "
                f"latest: {latest_time} ({hours_old:.1f}h ago)"
            )

            # ãƒ‡ãƒ¼ã‚¿é®®åº¦ç›£è¦–ï¼ˆ1æ™‚é–“ä»¥ä¸Šå¤ã„å ´åˆã¯è­¦å‘Šã€3æ™‚é–“ä»¥ä¸Šã¯å¼·åˆ¶å†å–å¾—ï¼‰
            if hours_old > 3:
                logger.error(
                    f"ğŸš¨ Data is {hours_old:.1f} hours old - FORCING FRESH DATA FETCH"
                )
                logger.info("â° Waiting 30 seconds before fresh data fetch...")
                time.sleep(30)
                continue
            elif hours_old > 1:
                logger.warning(
                    f"âš ï¸ Data is {hours_old:.1f} hours old - monitoring for freshness"
                )

            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ¤å®š
            logger.info("ğŸ“Š [ENTRY-JUDGE] Starting entry order generation...")
            logger.info(f"â° [ENTRY-JUDGE] Timestamp: {pd.Timestamp.now()}")
            logger.info(f"ğŸ” [DEBUG] Price data shape: {tuple(price_df.shape)}")
            logger.info(f"ğŸ” [DEBUG] Price data latest: {price_df.tail(1).to_dict()}")

            try:
                entry_order = entry_exit.generate_entry_order(price_df, position)
                logger.info(
                    f"âœ… [ENTRY-JUDGE] Entry judgment completed - "
                    f"Order exists: {entry_order.exist}"
                )

                # ã‚·ã‚°ãƒŠãƒ«è©³ç´°æƒ…å ±ãƒ­ã‚°
                if hasattr(entry_order, "side") and hasattr(entry_order, "price"):
                    logger.info(
                        f"ğŸ” [DEBUG] Entry order details: side={getattr(entry_order, 'side', 'N/A')}, price={getattr(entry_order, 'price', 'N/A')}, lot={getattr(entry_order, 'lot', 'N/A')}"
                    )

            except Exception as entry_error:
                logger.error(
                    f"âŒ [ENTRY-JUDGE] Entry order generation failed: {entry_error}"
                )
                logger.info("ğŸ”„ [ENTRY-JUDGE] Continuing to next iteration...")
                time.sleep(30)
                continue

            prev_trades = trade_done
            if entry_order.exist:
                logger.info(
                    f"Entry order generated: {entry_order.side} "
                    f"{entry_order.lot} at {entry_order.price}"
                )

                # å®Ÿéš›ã®Bitbankå–å¼•å®Ÿè¡Œ
                if execute_bitbank_trade(
                    entry_order,
                    position,
                    symbol,
                    exchange_id,
                    api_key,
                    api_secret,
                    cfg,
                    dd,
                    integration_service,
                ):
                    # ãƒã‚¸ã‚·ãƒ§ãƒ³æ›´æ–°
                    position.exist = True
                    position.side = entry_order.side
                    position.entry_price = entry_order.price
                    position.lot = entry_order.lot
                    position.stop_price = entry_order.stop_price

                    trade_done += 1
                    logger.info(
                        f"Trade #{trade_done} executed on Bitbank - "
                        f"Position: {position.side} {position.lot}"
                    )
                else:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯60ç§’å¾…æ©Ÿ
                    logger.info("â° Waiting 60 seconds before next trading attempt...")
                    time.sleep(60)

            # ã‚¨ã‚°ã‚¸ãƒƒãƒˆåˆ¤å®š
            logger.info("ğŸ“Š [EXIT-JUDGE] Starting exit order generation...")
            logger.info(f"â° [EXIT-JUDGE] Timestamp: {pd.Timestamp.now()}")
            logger.info(
                f"ğŸ” [DEBUG] Current position state: exist={position.exist}, side={getattr(position, 'side', 'N/A')}"
            )

            try:
                exit_order = entry_exit.generate_exit_order(price_df, position)
                logger.info(
                    f"âœ… [EXIT-JUDGE] Exit judgment completed - "
                    f"Order exists: {exit_order.exist}"
                )

                # ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«è©³ç´°æƒ…å ±ãƒ­ã‚°
                if hasattr(exit_order, "side") and hasattr(exit_order, "price"):
                    logger.info(
                        f"ğŸ” [DEBUG] Exit order details: side={getattr(exit_order, 'side', 'N/A')}, price={getattr(exit_order, 'price', 'N/A')}, lot={getattr(exit_order, 'lot', 'N/A')}"
                    )

            except Exception as exit_error:
                logger.error(
                    f"âŒ [EXIT-JUDGE] Exit order generation failed: {exit_error}"
                )
                logger.info("ğŸ”„ [EXIT-JUDGE] Continuing to next iteration...")
                time.sleep(30)
                continue

            if exit_order.exist:
                logger.info(
                    f"Exit order generated: {exit_order.side} "
                    f"{exit_order.lot} at {exit_order.price}"
                )

                # å®Ÿéš›ã®Bitbankå–å¼•å®Ÿè¡Œ
                if execute_bitbank_trade(
                    exit_order,
                    position,
                    symbol,
                    exchange_id,
                    api_key,
                    api_secret,
                    cfg,
                    dd,
                    integration_service,
                    is_exit=True,
                ):
                    # ãƒã‚¸ã‚·ãƒ§ãƒ³è§£æ¶ˆ
                    position.exist = False
                    position.side = None

                    trade_done += 1
                    logger.info(
                        f"Trade #{trade_done} exit executed on Bitbank - "
                        f"Position closed"
                    )

            # æ®‹é«˜ã‚’ EntryExit ã¸åæ˜ 
            entry_exit.current_balance = balance

            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
            profit = balance - cfg["backtest"]["starting_balance"]
            if not simple:
                update_status(
                    total_profit=profit,
                    trade_count=trade_done,
                    position=position.side if position.exist else None,
                )

            # å®šæœŸçš„ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å‡ºåŠ›
            if trade_done != prev_trades:
                pos_str = position.side if position.exist else "None"
                logger.info(
                    f"Status - Trades: {trade_done}, "
                    f"Profit: {profit:.2f}, Position: {pos_str}"
                )

            if max_trades and trade_done >= max_trades:
                logger.info("Reached max-trades. Exit.")
                break

            # å–å¼•é–“éš”ã®è¨­å®š
            interval = cfg.get("live", {}).get("trade_interval", 60)
            logger.info(
                f"â° [SLEEP] Waiting {interval} seconds until next iteration..."
            )
            logger.info(f"â° [SLEEP] Sleep start: {pd.Timestamp.now()}")
            time.sleep(interval)
            logger.info(f"â° [SLEEP] Sleep end: {pd.Timestamp.now()}")

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ [SHUTDOWN] Interrupted. Bye.")
    except Exception as e:
        logger.error(f"âŒ [ERROR] Live trading error: {e}")
        logger.error(f"â° [ERROR] Error occurred at: {pd.Timestamp.now()}")
        import traceback

        logger.error(f"ğŸ” [ERROR] Traceback: {traceback.format_exc()}")
        raise
