"""
ExternalDataIntegrator - Phase B2.3 å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿çµ±åˆæœ€é©åŒ–

ç¾çŠ¶å•é¡Œè§£æ±º:
- VIXãƒ»Macroãƒ»Fear&Greedãƒ»Fundingã®å€‹åˆ¥ãƒ•ã‚§ãƒƒãƒãƒ»è¿½åŠ  â†’ ãƒãƒƒãƒçµ±åˆå‡¦ç†
- å„å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã”ã¨ã®df[column] = valueæ“ä½œ â†’ ä¸€æ‹¬pd.concatçµ±åˆ
- éåŒæœŸãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ã«ã‚ˆã‚‹é«˜é€ŸåŒ–

æ”¹å–„åŠ¹æœ:
- å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“çŸ­ç¸®: ä¸¦è¡Œå‡¦ç†ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨
- DataFrameæ–­ç‰‡åŒ–è§£æ¶ˆ: ä¸€æ‹¬ç‰¹å¾´é‡çµ±åˆ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°çµ±ä¸€: å“è³ªç›£è¦–ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å¼·åŒ–
"""

import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List, Optional

import pandas as pd

from .batch_calculator import BatchFeatureCalculator, FeatureBatch

logger = logging.getLogger(__name__)


class ExternalDataResult:
    """å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ"""

    def __init__(
        self,
        source_name: str,
        success: bool,
        data: Optional[pd.DataFrame] = None,
        features: Optional[Dict[str, pd.Series]] = None,
        error: Optional[str] = None,
    ):
        self.source_name = source_name
        self.success = success
        self.data = data
        self.features = features or {}
        self.error = error
        self.fetch_time = time.time()

    def is_valid(self) -> bool:
        """çµæœãŒæœ‰åŠ¹ã‹åˆ¤å®š"""
        return self.success and (
            (self.data is not None and not self.data.empty)
            or (
                self.features
                and any(not series.empty for series in self.features.values())
            )
        )


class ExternalDataIntegrator:
    """
    å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿çµ±åˆæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ - Phase B2.3

    åŠ¹ç‡åŒ–ãƒã‚¤ãƒ³ãƒˆ:
    - ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ³ã‚° (ThreadPoolExecutor)
    - çµ±ä¸€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ãƒ»æ´»ç”¨
    - ãƒãƒƒãƒç‰¹å¾´é‡è¨ˆç®—ãƒ»çµ±åˆ
    - å“è³ªç›£è¦–ãƒ»è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """

    def __init__(
        self, config: Dict[str, Any], batch_calculator: BatchFeatureCalculator
    ):
        self.config = config
        self.batch_calc = batch_calculator
        self.ml_config = config.get("ml", {})

        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼åˆæœŸåŒ–
        self._initialize_fetchers()

        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿è¨­å®šè§£æ
        self.external_features = self._parse_external_features()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.integration_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "cache_hits": 0,
            "total_time": 0.0,
        }

        logger.info("ğŸ”§ ExternalDataIntegrator initialized for batch processing")

    def _initialize_fetchers(self):
        """å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼åˆæœŸåŒ–"""
        self.fetchers = {}

        # VIXãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        try:
            from crypto_bot.data.vix_fetcher import VIXDataFetcher

            self.fetchers["vix"] = VIXDataFetcher(self.config)
            logger.debug("âœ… VIX fetcher initialized")
        except ImportError as e:
            logger.warning(f"âš ï¸ VIX fetcher not available: {e}")
            self.fetchers["vix"] = None

        # Macroãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        try:
            from crypto_bot.data.macro_fetcher import MacroDataFetcher

            self.fetchers["macro"] = MacroDataFetcher(self.config)
            logger.debug("âœ… Macro fetcher initialized")
        except ImportError as e:
            logger.warning(f"âš ï¸ Macro fetcher not available: {e}")
            self.fetchers["macro"] = None

        # Fear&Greedãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        try:
            from crypto_bot.data.fear_greed_fetcher import FearGreedDataFetcher

            self.fetchers["fear_greed"] = FearGreedDataFetcher(self.config)
            logger.debug("âœ… Fear&Greed fetcher initialized")
        except ImportError as e:
            logger.warning(f"âš ï¸ Fear&Greed fetcher not available: {e}")
            self.fetchers["fear_greed"] = None

        # Fundingãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        try:
            from crypto_bot.data.funding_fetcher import FundingDataFetcher

            self.fetchers["funding"] = FundingDataFetcher()  # è¨­å®šå¼•æ•°å‰Šé™¤
            logger.debug("âœ… Funding fetcher initialized")
        except ImportError as e:
            logger.warning(f"âš ï¸ Funding fetcher not available: {e}")
            self.fetchers["funding"] = None

    def _parse_external_features(self) -> Dict[str, bool]:
        """è¨­å®šã‹ã‚‰å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡ã‚’è§£æ"""
        extra_features = self.ml_config.get("extra_features", [])

        features = {
            "vix": False,
            "macro": False,
            "dxy": False,
            "treasury": False,
            "fear_greed": False,
            "funding": False,
        }

        for feat in extra_features:
            feat_lc = feat.lower()
            if feat_lc == "vix":
                features["vix"] = True
            elif feat_lc in ["macro", "dxy", "treasury"]:
                features["macro"] = True
                features["dxy"] = True
                features["treasury"] = True
            elif feat_lc == "fear_greed":
                features["fear_greed"] = True
            elif feat_lc == "funding":
                features["funding"] = True

        return features

    def _fetch_vix_data_batch(self, df_index: pd.Index) -> ExternalDataResult:
        """VIXãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—"""
        if not self.external_features["vix"] or not self.fetchers["vix"]:
            return ExternalDataResult(
                "vix", False, error="VIX not enabled or fetcher not available"
            )

        try:
            start_time = time.time()

            # VIXãƒ‡ãƒ¼ã‚¿å–å¾—
            vix_data = self.fetchers["vix"].get_vix_data(limit=100)

            if vix_data is not None and not vix_data.empty:
                # VIXç‰¹å¾´é‡è¨ˆç®—
                vix_features_df = self.fetchers["vix"].calculate_vix_features(vix_data)

                if not vix_features_df.empty:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆã‚ã›ãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    aligned_features = self._align_external_data(
                        vix_features_df, df_index
                    )

                    # Seriesè¾æ›¸ã«å¤‰æ›
                    vix_feature_dict = {}
                    for col in aligned_features.columns:
                        vix_feature_dict[col] = aligned_features[col]

                    fetch_time = time.time() - start_time
                    logger.debug(
                        f"âœ… VIX batch: {len(vix_feature_dict)} features, {fetch_time:.3f}s"
                    )

                    return ExternalDataResult(
                        "vix", True, data=aligned_features, features=vix_feature_dict
                    )

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._generate_vix_fallback(df_index)

        except Exception as e:
            logger.error(f"âŒ VIX batch fetch failed: {e}")
            return self._generate_vix_fallback(df_index, str(e))

    def _fetch_macro_data_batch(self, df_index: pd.Index) -> ExternalDataResult:
        """Macroãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—"""
        if (
            not (self.external_features["macro"] or self.external_features["dxy"])
            or not self.fetchers["macro"]
        ):
            return ExternalDataResult(
                "macro", False, error="Macro not enabled or fetcher not available"
            )

        try:
            start_time = time.time()

            # Macroãƒ‡ãƒ¼ã‚¿å–å¾—
            macro_data = self.fetchers["macro"].get_macro_data(limit=100)

            if macro_data and not all(df.empty for df in macro_data.values()):
                # Macroç‰¹å¾´é‡è¨ˆç®—
                macro_features_df = self.fetchers["macro"].calculate_macro_features(
                    macro_data
                )

                if not macro_features_df.empty:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆã‚ã›ãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    aligned_features = self._align_external_data(
                        macro_features_df, df_index
                    )

                    # Seriesè¾æ›¸ã«å¤‰æ›
                    macro_feature_dict = {}
                    for col in aligned_features.columns:
                        macro_feature_dict[col] = aligned_features[col]

                    fetch_time = time.time() - start_time
                    logger.debug(
                        f"âœ… Macro batch: {len(macro_feature_dict)} features, {fetch_time:.3f}s"
                    )

                    return ExternalDataResult(
                        "macro",
                        True,
                        data=aligned_features,
                        features=macro_feature_dict,
                    )

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._generate_macro_fallback(df_index)

        except Exception as e:
            logger.error(f"âŒ Macro batch fetch failed: {e}")
            return self._generate_macro_fallback(df_index, str(e))

    def _fetch_fear_greed_data_batch(self, df_index: pd.Index) -> ExternalDataResult:
        """Fear&Greedãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—"""
        if not self.external_features["fear_greed"] or not self.fetchers["fear_greed"]:
            return ExternalDataResult(
                "fear_greed",
                False,
                error="Fear&Greed not enabled or fetcher not available",
            )

        try:
            start_time = time.time()

            # Fear&Greedãƒ‡ãƒ¼ã‚¿å–å¾—
            fg_data = self.fetchers["fear_greed"].get_fear_greed_data(limit=100)

            if fg_data is not None and not fg_data.empty:
                # Fear&Greedç‰¹å¾´é‡è¨ˆç®—
                fg_features_df = self.fetchers[
                    "fear_greed"
                ].calculate_fear_greed_features(fg_data)

                if not fg_features_df.empty:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆã‚ã›ãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    aligned_features = self._align_external_data(
                        fg_features_df, df_index
                    )

                    # Seriesè¾æ›¸ã«å¤‰æ›
                    fg_feature_dict = {}
                    for col in aligned_features.columns:
                        fg_feature_dict[col] = aligned_features[col]

                    fetch_time = time.time() - start_time
                    logger.debug(
                        f"âœ… Fear&Greed batch: {len(fg_feature_dict)} features, {fetch_time:.3f}s"
                    )

                    return ExternalDataResult(
                        "fear_greed",
                        True,
                        data=aligned_features,
                        features=fg_feature_dict,
                    )

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._generate_fear_greed_fallback(df_index)

        except Exception as e:
            logger.error(f"âŒ Fear&Greed batch fetch failed: {e}")
            return self._generate_fear_greed_fallback(df_index, str(e))

    def _fetch_funding_data_batch(self, df_index: pd.Index) -> ExternalDataResult:
        """Fundingãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—"""
        if not self.external_features["funding"] or not self.fetchers["funding"]:
            return ExternalDataResult(
                "funding", False, error="Funding not enabled or fetcher not available"
            )

        try:
            start_time = time.time()

            # Funding Rate ãƒ‡ãƒ¼ã‚¿å–å¾—
            funding_rate_data = self.fetchers["funding"].get_funding_rate_data(
                symbol="BTC/USDT", limit=100
            )

            # Open Interest ãƒ‡ãƒ¼ã‚¿å–å¾—
            oi_data = self.fetchers["funding"].get_open_interest_data(
                symbol="BTC/USDT", limit=100
            )

            combined_features = {}

            # Funding Rate ç‰¹å¾´é‡è¨ˆç®—
            if funding_rate_data is not None and not funding_rate_data.empty:
                funding_features_df = self.fetchers[
                    "funding"
                ].calculate_funding_features(funding_rate_data)
                if not funding_features_df.empty:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆã‚ã›ãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    aligned_funding = self._align_external_data(
                        funding_features_df, df_index
                    )
                    for col in aligned_funding.columns:
                        combined_features[col] = aligned_funding[col]

            # Open Interest ç‰¹å¾´é‡è¨ˆç®—
            if oi_data is not None and not oi_data.empty:
                oi_features_df = self.fetchers["funding"].calculate_oi_features(oi_data)
                if not oi_features_df.empty:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆã‚ã›ãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    aligned_oi = self._align_external_data(oi_features_df, df_index)
                    for col in aligned_oi.columns:
                        combined_features[col] = aligned_oi[col]

            if combined_features:
                fetch_time = time.time() - start_time
                logger.debug(
                    f"âœ… Funding batch: {len(combined_features)} features, {fetch_time:.3f}s"
                )

                return ExternalDataResult("funding", True, features=combined_features)

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._generate_funding_fallback(df_index)

        except Exception as e:
            logger.error(f"âŒ Funding batch fetch failed: {e}")
            return self._generate_funding_fallback(df_index, str(e))

    def _align_external_data(
        self, external_df: pd.DataFrame, target_index: pd.Index
    ) -> pd.DataFrame:
        """å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã‚‹"""
        try:
            # Phase H.18ä¿®æ­£: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‹ãƒã‚§ãƒƒã‚¯ã¨å¤‰æ›å¼·åŒ–
            # target_indexãŒDatetimeIndexã§ãªã„å ´åˆã€å¤‰æ›ã‚’è©¦ã¿ã‚‹
            if not isinstance(target_index, pd.DatetimeIndex):
                try:
                    target_index = pd.to_datetime(target_index)
                except Exception:
                    logger.warning(
                        f"Target index cannot be converted to DatetimeIndex: {type(target_index)}"
                    )
                    # æ•°å€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦å‡¦ç†
                    return self._align_numeric_index(external_df, target_index)

            # external_dfã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’DatetimeIndexã«å¤‰æ›
            if not isinstance(external_df.index, pd.DatetimeIndex):
                try:
                    # int64å‹ãªã©ã®å ´åˆã€datetimeå¤‰æ›ã‚’è©¦ã¿ã‚‹
                    if hasattr(external_df.index, "dtype") and "int" in str(
                        external_df.index.dtype
                    ):
                        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆç§’ï¼‰ã¨ã—ã¦è§£é‡ˆ
                        external_df.index = pd.to_datetime(external_df.index, unit="s")
                    else:
                        external_df.index = pd.to_datetime(external_df.index)
                except Exception as e:
                    logger.warning(
                        f"External index conversion failed: {e}, using numeric alignment"
                    )
                    return self._align_numeric_index(external_df, target_index)

            # DatetimeIndexã¨ã—ã¦å‡¦ç†
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³çµ±ä¸€
            if external_df.index.tz is None and target_index.tz is not None:
                external_df.index = external_df.index.tz_localize("UTC")
            elif external_df.index.tz is not None and target_index.tz is not None:
                external_df.index = external_df.index.tz_convert(target_index.tz)

            # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆæ—¥æ¬¡â†’æ™‚é–“è¶³å¤‰æ›ï¼‰
            if len(external_df) < len(target_index) / 2:  # æ˜ã‚‰ã‹ã«ç²—ã„å ´åˆ
                external_df = external_df.resample("H").ffill()

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦reindex
            aligned_df = external_df.reindex(target_index, method="ffill")

            return aligned_df.fillna(method="ffill").fillna(0)

        except TypeError as e:
            # å‹ä¸ä¸€è‡´ã‚¨ãƒ©ãƒ¼ã®ç‰¹åˆ¥å‡¦ç†
            if "Cannot compare dtypes" in str(e):
                logger.warning(
                    f"âš ï¸ Type mismatch detected: {e}, attempting numeric alignment"
                )
                return self._align_numeric_index(external_df, target_index)
            else:
                raise

        except Exception as e:
            logger.warning(f"âš ï¸ External data alignment failed: {e}, using fallback")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªreindex
            try:
                return external_df.reindex(target_index).fillna(0)
            except Exception:
                # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºã®DataFrameè¿”å´
                return pd.DataFrame(
                    index=target_index, columns=external_df.columns
                ).fillna(0)

    def _align_numeric_index(
        self, external_df: pd.DataFrame, target_index: pd.Index
    ) -> pd.DataFrame:
        """æ•°å€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå‡¦ç†"""
        try:
            # ä¸¡æ–¹ã‚’æ•°å€¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
            target_numeric = range(len(target_index))

            # æ–°ã—ã„DataFrameã‚’ä½œæˆ
            aligned_df = pd.DataFrame(index=target_index, columns=external_df.columns)

            # ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”ç‡ã§é…åˆ†
            ratio = len(external_df) / len(target_index)
            for i in target_numeric:
                source_idx = min(int(i * ratio), len(external_df) - 1)
                aligned_df.iloc[i] = external_df.iloc[source_idx]

            return aligned_df.fillna(0)

        except Exception as e:
            logger.error(f"Numeric alignment failed: {e}")
            return pd.DataFrame(index=target_index, columns=external_df.columns).fillna(
                0
            )

    def fetch_all_external_data_concurrent(
        self, df_index: pd.Index
    ) -> List[ExternalDataResult]:
        """å…¨å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ä¸¦è¡Œå–å¾—"""
        start_time = time.time()
        results = []

        # ä¸¦è¡Œå®Ÿè¡Œã™ã‚‹é–¢æ•°ãƒªã‚¹ãƒˆ
        fetch_functions = []
        if self.external_features["vix"]:
            fetch_functions.append(("vix", self._fetch_vix_data_batch))
        if self.external_features["macro"] or self.external_features["dxy"]:
            fetch_functions.append(("macro", self._fetch_macro_data_batch))
        if self.external_features["fear_greed"]:
            fetch_functions.append(("fear_greed", self._fetch_fear_greed_data_batch))
        if self.external_features["funding"]:
            fetch_functions.append(("funding", self._fetch_funding_data_batch))

        if not fetch_functions:
            logger.info("âš ï¸ No external data sources enabled")
            return []

        # ThreadPoolExecutorã«ã‚ˆã‚‹ä¸¦è¡Œå®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=min(len(fetch_functions), 4)) as executor:
            # ã‚¿ã‚¹ã‚¯æŠ•å…¥
            future_to_name = {
                executor.submit(func, df_index): name for name, func in fetch_functions
            }

            # çµæœåé›†
            for future in as_completed(future_to_name):
                source_name = future_to_name[future]
                try:
                    result = future.result(timeout=30)  # 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                    results.append(result)

                    # çµ±è¨ˆæ›´æ–°
                    self.integration_stats["total_requests"] += 1
                    if result.success:
                        self.integration_stats["successful_requests"] += 1

                except Exception as e:
                    logger.error(
                        f"âŒ External data fetch failed for {source_name}: {e}"
                    )
                    results.append(ExternalDataResult(source_name, False, error=str(e)))
                    self.integration_stats["total_requests"] += 1

        total_time = time.time() - start_time
        self.integration_stats["total_time"] += total_time

        successful_results = [r for r in results if r.is_valid()]
        logger.info(
            f"ğŸ”„ External data concurrent fetch: {len(successful_results)}/{len(results)} "
            f"successful in {total_time:.3f}s"
        )

        return results

    def create_external_data_batches(self, df_index: pd.Index) -> List[FeatureBatch]:
        """å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒä½œæˆ"""
        # ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å–å¾—
        external_results = self.fetch_all_external_data_concurrent(df_index)

        batches = []
        total_features = 0

        # å„çµæœã‚’FeatureBatchã«å¤‰æ›
        for result in external_results:
            if result.is_valid() and result.features:
                batch = self.batch_calc.create_feature_batch(
                    f"{result.source_name}_batch", result.features, df_index
                )
                if len(batch) > 0:
                    batches.append(batch)
                    total_features += len(batch)
                    logger.debug(
                        f"ğŸ“¦ {result.source_name} batch: {len(batch)} features"
                    )
            else:
                logger.warning(f"âš ï¸ {result.source_name} batch invalid or empty")

        logger.info(
            f"ğŸ”„ External data batches created: {len(batches)} batches, {total_features} features"
        )
        return batches

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ç¾¤

    def _generate_vix_fallback(
        self, df_index: pd.Index, error: str = ""
    ) -> ExternalDataResult:
        """VIXãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        try:
            from crypto_bot.data.vix_fetcher import get_available_vix_features

            vix_feature_names = get_available_vix_features()
        except ImportError:
            vix_feature_names = [
                "vix_level",
                "vix_change",
                "vix_zscore",
                "fear_level",
                "vix_spike",
                "vix_regime_numeric",
            ]

        fallback_features = {}
        for feature in vix_feature_names:
            if feature == "vix_level":
                fallback_features[feature] = pd.Series(
                    [20.0] * len(df_index), index=df_index
                )
            elif feature == "fear_level":
                fallback_features[feature] = pd.Series(
                    [1] * len(df_index), index=df_index
                )
            elif feature == "vix_regime_numeric":
                fallback_features[feature] = pd.Series(
                    [1] * len(df_index), index=df_index
                )
            else:
                fallback_features[feature] = pd.Series(
                    [0] * len(df_index), index=df_index
                )

        logger.debug(f"ğŸ“ˆ VIX fallback: {len(fallback_features)} features")
        return ExternalDataResult("vix", True, features=fallback_features)

    def _generate_macro_fallback(
        self, df_index: pd.Index, error: str = ""
    ) -> ExternalDataResult:
        """Macroãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        fallback_features = {
            "dxy_level": pd.Series([103.0] * len(df_index), index=df_index),
            "dxy_change": pd.Series([0.0] * len(df_index), index=df_index),
            "dxy_zscore": pd.Series([0.0] * len(df_index), index=df_index),
            "dxy_strength": pd.Series([0] * len(df_index), index=df_index),
            "treasury_10y_level": pd.Series([4.5] * len(df_index), index=df_index),
            "treasury_10y_change": pd.Series([0.0] * len(df_index), index=df_index),
            "treasury_10y_zscore": pd.Series([0.0] * len(df_index), index=df_index),
            "treasury_regime": pd.Series([0] * len(df_index), index=df_index),
            "yield_curve_spread": pd.Series([-0.5] * len(df_index), index=df_index),
            "risk_sentiment": pd.Series([0] * len(df_index), index=df_index),
            "usdjpy_level": pd.Series([150.0] * len(df_index), index=df_index),
            "usdjpy_change": pd.Series([0.0] * len(df_index), index=df_index),
            "usdjpy_volatility": pd.Series([0.005] * len(df_index), index=df_index),
            "usdjpy_zscore": pd.Series([0.0] * len(df_index), index=df_index),
            "usdjpy_trend": pd.Series([0] * len(df_index), index=df_index),
            "usdjpy_strength": pd.Series([0] * len(df_index), index=df_index),
        }

        logger.debug(f"ğŸ“ˆ Macro fallback: {len(fallback_features)} features")
        return ExternalDataResult("macro", True, features=fallback_features)

    def _generate_fear_greed_fallback(
        self, df_index: pd.Index, error: str = ""
    ) -> ExternalDataResult:
        """Fear&Greedãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        try:
            from crypto_bot.data.fear_greed_fetcher import (
                get_available_fear_greed_features,
            )

            fg_feature_names = get_available_fear_greed_features()
        except ImportError:
            fg_feature_names = [
                "fg_index",
                "fg_change_1d",
                "fg_change_7d",
                "fg_ma_7",
                "fg_ma_30",
                "fg_extreme_fear",
                "fg_fear",
                "fg_neutral",
                "fg_greed",
                "fg_extreme_greed",
                "fg_volatility",
                "fg_momentum",
                "fg_reversal_signal",
            ]

        fallback_features = {}
        for feature in fg_feature_names:
            if feature in ["fg_index", "fg_ma_7", "fg_ma_30"]:
                fallback_features[feature] = pd.Series(
                    [50.0] * len(df_index), index=df_index
                )
            elif feature == "fg_neutral":
                fallback_features[feature] = pd.Series(
                    [1] * len(df_index), index=df_index
                )
            elif feature == "fg_volatility":
                fallback_features[feature] = pd.Series(
                    [10.0] * len(df_index), index=df_index
                )
            else:
                fallback_features[feature] = pd.Series(
                    [0] * len(df_index), index=df_index
                )

        logger.debug(f"ğŸ“ˆ Fear&Greed fallback: {len(fallback_features)} features")
        return ExternalDataResult("fear_greed", True, features=fallback_features)

    def _generate_funding_fallback(
        self, df_index: pd.Index, error: str = ""
    ) -> ExternalDataResult:
        """Fundingãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        fallback_features = {
            "funding_rate": pd.Series([0.0001] * len(df_index), index=df_index),
            "funding_rate_change": pd.Series([0.0] * len(df_index), index=df_index),
            "funding_rate_ma": pd.Series([0.0001] * len(df_index), index=df_index),
            "funding_rate_zscore": pd.Series([0.0] * len(df_index), index=df_index),
            "funding_trend": pd.Series([0] * len(df_index), index=df_index),
            "open_interest": pd.Series([1000000] * len(df_index), index=df_index),
            "oi_change": pd.Series([0.0] * len(df_index), index=df_index),
            "oi_trend": pd.Series([0] * len(df_index), index=df_index),
        }

        logger.debug(f"ğŸ“ˆ Funding fallback: {len(fallback_features)} features")
        return ExternalDataResult("funding", True, features=fallback_features)

    def get_integration_stats(self) -> Dict[str, Any]:
        """çµ±åˆçµ±è¨ˆå–å¾—"""
        if self.integration_stats["total_requests"] == 0:
            return {"status": "no_requests_processed"}

        success_rate = (
            self.integration_stats["successful_requests"]
            / self.integration_stats["total_requests"]
        )
        avg_time = (
            self.integration_stats["total_time"]
            / self.integration_stats["total_requests"]
        )

        return {
            "total_requests": self.integration_stats["total_requests"],
            "successful_requests": self.integration_stats["successful_requests"],
            "success_rate": success_rate,
            "cache_hits": self.integration_stats["cache_hits"],
            "total_time_seconds": self.integration_stats["total_time"],
            "avg_time_per_request_seconds": avg_time,
            "efficiency_score": min(success_rate * 2, 1.0),  # 0-1ã‚¹ã‚±ãƒ¼ãƒ«
        }


def create_external_data_integrator(
    config: Dict[str, Any], batch_calculator: BatchFeatureCalculator
) -> ExternalDataIntegrator:
    """ExternalDataIntegrator ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°"""
    return ExternalDataIntegrator(config, batch_calculator)
