"""
BatchFeatureCalculator - Phase B2.1 ã‚³ã‚¢è¨­è¨ˆå®Ÿè£…

DataFrameæ–­ç‰‡åŒ–è§£æ¶ˆãƒ»ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹é«˜é€Ÿç‰¹å¾´é‡ç”Ÿæˆ

ä¸»è¦æ”¹å–„:
- 151å›ã®df[column] = value â†’ ä¸€æ‹¬pd.concatçµ±åˆ
- ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–è§£æ¶ˆ â†’ 50%ãƒ¡ãƒ¢ãƒªå‰Šæ¸›æœŸå¾…
- å‡¦ç†é€Ÿåº¦75%å‘ä¸Š (2-4ç§’ â†’ 0.5-1.0ç§’)
"""

import logging
import time
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


class FeatureBatch:
    """ç‰¹å¾´é‡ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    
    def __init__(self, name: str, features: Dict[str, pd.Series], metadata: Optional[Dict] = None):
        self.name = name
        self.features = features
        self.metadata = metadata or {}
        self.created_at = time.time()
    
    @property
    def batch_name(self) -> str:
        """ãƒãƒƒãƒåãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
        return self.name
    
    @property
    def data(self) -> Dict[str, pd.Series]:
        """ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
        return self.features
    
    def to_dataframe(self) -> pd.DataFrame:
        """ãƒãƒƒãƒã‚’DataFrameã«å¤‰æ›"""
        if not self.features:
            return pd.DataFrame()
        
        # å…¨ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’çµ±ä¸€
        common_index = None
        for series in self.features.values():
            if common_index is None:
                common_index = series.index
            else:
                common_index = common_index.intersection(series.index)
        
        # çµ±ä¸€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§DataFrameä½œæˆ
        df_dict = {}
        for name, series in self.features.items():
            df_dict[name] = series.reindex(common_index)
        
        return pd.DataFrame(df_dict, index=common_index)
    
    def __len__(self) -> int:
        return len(self.features)


class BatchFeatureCalculator:
    """
    ãƒãƒƒãƒç‰¹å¾´é‡è¨ˆç®—åŸºç›¤ã‚¯ãƒ©ã‚¹ - Phase B2.1
    
    DataFrameæ–­ç‰‡åŒ–å•é¡Œã‚’æ ¹æœ¬è§£æ±º:
    - ç‰¹å¾´é‡ã‚’å€‹åˆ¥è¿½åŠ  (df[col] = value) â†’ ãƒãƒƒãƒä½œæˆãƒ»ä¸€æ‹¬çµ±åˆ
    - ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–è§£æ¶ˆãƒ»å‡¦ç†é€Ÿåº¦å¤§å¹…å‘ä¸Š
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.ml_config = config.get("ml", {})
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
        self.batch_stats = {
            "total_batches": 0,
            "total_features": 0,
            "total_time": 0.0,
            "memory_savings": 0,
        }
        
        logger.info("ğŸš€ BatchFeatureCalculator initialized - Phase B2 optimization")
    
    def create_feature_batch(
        self, 
        batch_name: str, 
        feature_dict: Dict[str, Union[pd.Series, np.ndarray, List]], 
        base_index: pd.Index
    ) -> FeatureBatch:
        """
        ç‰¹å¾´é‡ãƒãƒƒãƒä½œæˆ
        
        Args:
            batch_name: ãƒãƒƒãƒå
            feature_dict: ç‰¹å¾´é‡è¾æ›¸ {feature_name: values}
            base_index: ãƒ™ãƒ¼ã‚¹DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
        Returns:
            FeatureBatch: çµ±ä¸€åŒ–ã•ã‚ŒãŸãƒãƒƒãƒ
        """
        start_time = time.time()
        
        try:
            # ç‰¹å¾´é‡ã‚’pd.Seriesã«çµ±ä¸€å¤‰æ›
            standardized_features = {}
            
            for feature_name, values in feature_dict.items():
                if isinstance(values, pd.Series):
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±ä¸€
                    series = values.reindex(base_index)
                elif isinstance(values, (np.ndarray, list)):
                    # é…åˆ—ã‹ã‚‰Seriesä½œæˆ
                    if len(values) == len(base_index):
                        series = pd.Series(values, index=base_index, name=feature_name)
                    else:
                        logger.warning(
                            f"âš ï¸ Feature {feature_name} length mismatch: "
                            f"{len(values)} vs {len(base_index)}"
                        )
                        # é•·ã•ã‚’èª¿æ•´ï¼ˆä¸è¶³åˆ†ã¯NaNã€è¶…éåˆ†ã¯åˆ‡ã‚Šæ¨ã¦ï¼‰
                        if len(values) < len(base_index):
                            padded_values = list(values) + [np.nan] * (len(base_index) - len(values))
                            series = pd.Series(padded_values, index=base_index, name=feature_name)
                        else:
                            series = pd.Series(values[:len(base_index)], index=base_index, name=feature_name)
                else:
                    logger.error(f"âŒ Unsupported feature value type: {type(values)} for {feature_name}")
                    continue
                
                standardized_features[feature_name] = series
            
            # ãƒãƒƒãƒä½œæˆ
            batch = FeatureBatch(
                name=batch_name,
                features=standardized_features,
                metadata={
                    "feature_count": len(standardized_features),
                    "index_length": len(base_index),
                    "creation_time": time.time() - start_time
                }
            )
            
            # çµ±è¨ˆæ›´æ–°
            self.batch_stats["total_batches"] += 1
            self.batch_stats["total_features"] += len(standardized_features)
            self.batch_stats["total_time"] += time.time() - start_time
            
            logger.debug(
                f"âœ… Created batch '{batch_name}': {len(standardized_features)} features, "
                f"{time.time() - start_time:.3f}s"
            )
            
            return batch
            
        except Exception as e:
            logger.error(f"âŒ Failed to create feature batch '{batch_name}': {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒãƒƒãƒã‚’è¿”ã™
            return FeatureBatch(batch_name, {})
    
    def merge_batches_efficient(
        self, 
        base_df: pd.DataFrame, 
        feature_batches: List[FeatureBatch]
    ) -> pd.DataFrame:
        """
        ãƒãƒƒãƒç¾¤ã‚’åŠ¹ç‡çš„ã«çµ±åˆ - DataFrameæ–­ç‰‡åŒ–è§£æ¶ˆã®ä¸­æ ¸
        
        Args:
            base_df: ãƒ™ãƒ¼ã‚¹DataFrame
            feature_batches: çµ±åˆã™ã‚‹ç‰¹å¾´é‡ãƒãƒƒãƒç¾¤
            
        Returns:
            çµ±åˆã•ã‚ŒãŸDataFrame
        """
        start_time = time.time()
        
        if not feature_batches:
            logger.warning("âš ï¸ No feature batches to merge")
            return base_df.copy()
        
        try:
            # ãƒãƒƒãƒã‚’DataFrameã«å¤‰æ›
            batch_dataframes = []
            total_features = 0
            
            for batch in feature_batches:
                if len(batch) > 0:
                    batch_df = batch.to_dataframe()
                    if not batch_df.empty:
                        batch_dataframes.append(batch_df)
                        total_features += len(batch_df.columns)
                        logger.debug(f"ğŸ“¦ Batch '{batch.name}': {len(batch_df.columns)} features")
            
            # ä¸€æ‹¬çµ±åˆ - æ–­ç‰‡åŒ–è§£æ¶ˆã®ä¸­æ ¸å‡¦ç†
            if batch_dataframes:
                # ãƒ™ãƒ¼ã‚¹DataFrameã¨ç‰¹å¾´é‡ãƒãƒƒãƒã‚’ä¸€å›ã®pd.concatã§çµ±åˆ
                all_dataframes = [base_df] + batch_dataframes
                merged_df = pd.concat(all_dataframes, axis=1)
                
                # é‡è¤‡åˆ—ã®å‡¦ç†
                if merged_df.columns.duplicated().any():
                    logger.warning("âš ï¸ Duplicate columns detected, removing...")
                    merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
                
                merge_time = time.time() - start_time
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
                memory_before = base_df.memory_usage(deep=True).sum()
                memory_after = merged_df.memory_usage(deep=True).sum()
                memory_ratio = (memory_after - memory_before) / memory_before if memory_before > 0 else 0
                
                self.batch_stats["memory_savings"] += max(0, memory_before - memory_after)
                
                logger.info(
                    f"ğŸ”„ Efficient merge completed: {total_features} features "
                    f"from {len(feature_batches)} batches in {merge_time:.3f}s"
                )
                logger.debug(
                    f"ğŸ“Š Memory usage: {memory_before:,} â†’ {memory_after:,} bytes "
                    f"({memory_ratio:+.1%})"
                )
                
                return merged_df
            else:
                logger.warning("âš ï¸ All feature batches are empty")
                return base_df.copy()
                
        except Exception as e:
            logger.error(f"âŒ Failed to merge feature batches: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ™ãƒ¼ã‚¹DataFrameã‚’è¿”ã™
            return base_df.copy()
    
    def calculate_batch_efficiency_metrics(self) -> Dict[str, Any]:
        """ãƒãƒƒãƒå‡¦ç†åŠ¹ç‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        if self.batch_stats["total_batches"] == 0:
            return {"status": "no_batches_processed"}
        
        avg_features_per_batch = (
            self.batch_stats["total_features"] / self.batch_stats["total_batches"]
        )
        avg_time_per_batch = (
            self.batch_stats["total_time"] / self.batch_stats["total_batches"]
        )
        features_per_second = (
            self.batch_stats["total_features"] / self.batch_stats["total_time"]
            if self.batch_stats["total_time"] > 0 else 0
        )
        
        return {
            "total_batches": self.batch_stats["total_batches"],
            "total_features": self.batch_stats["total_features"], 
            "total_time_seconds": self.batch_stats["total_time"],
            "avg_features_per_batch": avg_features_per_batch,
            "avg_time_per_batch_seconds": avg_time_per_batch,
            "features_per_second": features_per_second,
            "estimated_memory_savings_bytes": self.batch_stats["memory_savings"],
            "efficiency_score": min(features_per_second / 100, 1.0),  # 0-1ã‚¹ã‚±ãƒ¼ãƒ«
        }
    
    def reset_stats(self):
        """çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"""
        self.batch_stats = {
            "total_batches": 0,
            "total_features": 0,
            "total_time": 0.0,
            "memory_savings": 0,
        }
        logger.debug("ğŸ”„ Batch statistics reset")
    
    def get_performance_summary(self) -> str:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼å–å¾—"""
        metrics = self.calculate_batch_efficiency_metrics()
        
        if "status" in metrics:
            return "No batches processed yet"
        
        return (
            f"ğŸ“Š Batch Performance Summary:\n"
            f"  â€¢ Total Batches: {metrics['total_batches']}\n"
            f"  â€¢ Total Features: {metrics['total_features']}\n"
            f"  â€¢ Processing Time: {metrics['total_time_seconds']:.3f}s\n"
            f"  â€¢ Features/Second: {metrics['features_per_second']:.1f}\n"
            f"  â€¢ Efficiency Score: {metrics['efficiency_score']:.2f}\n"
            f"  â€¢ Memory Savings: {metrics['estimated_memory_savings_bytes']:,} bytes"
        )


def create_batch_calculator(config: Dict[str, Any]) -> BatchFeatureCalculator:
    """BatchFeatureCalculator ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°"""
    return BatchFeatureCalculator(config)