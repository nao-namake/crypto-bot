"""
ML Dataset Processor - Phase 16.3-A Split

çµ±åˆå‰: crypto_bot/ml/preprocessor.pyï¼ˆ3,314è¡Œï¼‰
åˆ†å‰²å¾Œ: crypto_bot/ml/preprocessing/dataset_processor.py

æ©Ÿèƒ½:
- prepare_ml_dataset: æ©Ÿæ¢°å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
- prepare_ml_dataset_enhanced: ç‰¹å¾´é‡å®Œå…¨æ€§ä¿è¨¼ä»˜ãMLç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ

Phase 16.3-Aå®Ÿè£…æ—¥: 2025å¹´8æœˆ8æ—¥
"""

from __future__ import annotations

import logging
from typing import Any, Dict, Tuple

import numpy as np
import pandas as pd

# åˆ†å‰²å¾Œimportèª¿æ•´
from .pipeline_builder import build_ml_pipeline

# Phase 3: å¤–éƒ¨APIä¾å­˜å®Œå…¨é™¤å»
ENHANCED_FEATURES_AVAILABLE = False

# å¿…è¦ãªä¾å­˜é–¢ä¿‚
from crypto_bot.ml.target import make_classification_target, make_regression_target

logger = logging.getLogger(__name__)


def prepare_ml_dataset(
    df: pd.DataFrame, config: Dict[str, Any]
) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:
    """
    æ©Ÿæ¢°å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã€‚
    æˆ»ã‚Šå€¤: Xï¼ˆç‰¹å¾´é‡ï¼‰, y_regï¼ˆå›å¸°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰, y_clfï¼ˆåˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰

    - å¿…è¦ãªã¶ã‚“ã ã‘æœ€åˆã®è¡Œã‚’ãƒ‰ãƒ­ãƒƒãƒ—ï¼ˆrolling/lagsï¼‰
    - horizon, thresholdã¯config["ml"]ã‹ã‚‰å–å¾—
    """
    logger.info(f"prepare_ml_dataset input df shape: {tuple(df.shape)}")
    pipeline = build_ml_pipeline(config)
    X_arr = pipeline.fit_transform(df)

    logger.info(f"Pipeline output type: {type(X_arr)}")
    if hasattr(X_arr, "shape"):
        shape_info = X_arr.shape
    elif hasattr(X_arr, "__len__"):
        shape_info = len(X_arr)
    else:
        shape_info = "unknown"
    logger.info(f"Pipeline output shape: {shape_info}")

    # Targetã®DataFrameã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒX_arrã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨æƒã†ã‚ˆã†ã«èª¿æ•´
    ml_config = config.get("ml", {})
    rolling_window = ml_config.get("rolling_window", 10)
    lags = ml_config.get("lags", [1, 2])
    extra_features = ml_config.get("extra_features", [])

    # Phase 2: 97ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–
    # extra_featuresãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€å¿…è¦ãªãƒ‰ãƒ­ãƒƒãƒ—æ•°ã‚’èª¿æ•´
    if extra_features and any(
        f in extra_features for f in ["ema_200", "sma_200", "bb_200", "rsi_14"]
    ):
        # ã‚ˆã‚Šé•·ã„æœŸé–“ãŒå¿…è¦ãªå ´åˆã¯ãƒ‰ãƒ­ãƒƒãƒ—æ•°ã‚’å¢—ã‚„ã™
        win = max(rolling_window, 200, 14)  # ATR, SMA200, RSI14ã‚’è€ƒæ…®
    else:
        win = rolling_window

    drop_n = win + max(lags) if lags else win

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ¬ æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€å®‰å…¨ã«å‡¦ç†
    if len(df) <= drop_n:
        logger.warning(f"Not enough data: len(df)={len(df)}, drop_n={drop_n}")
        # å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å‡¦ç†ã§ãã‚‹ã‚ˆã†èª¿æ•´
        drop_n = max(0, len(df) - 5)  # æœ€ä½5è¡Œã¯æ®‹ã™

    y_reg = make_regression_target(df, config.get("ml", {}).get("horizon", 1))
    y_clf = make_classification_target(df, config.get("ml", {}).get("horizon", 1))

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¯„å›²ã‚’èª¿æ•´
    if isinstance(X_arr, np.ndarray):
        valid_length = min(len(X_arr), len(df) - drop_n)
        idx = df.index[drop_n : drop_n + valid_length]
        X = pd.DataFrame(X_arr[: len(idx)], index=idx)
    else:
        # X_arrãŒDataFrameãªã©ã®å ´åˆ
        idx = df.index[drop_n:]
        X = pd.DataFrame(X_arr, index=idx)

    # å…±é€šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ãã‚ãˆã‚‹
    common_idx = X.index.intersection(y_reg.index).intersection(y_clf.index)
    if len(common_idx) == 0:
        logger.error("No common index found between X, y_reg, y_clf")
        logger.info(f"X.index: {X.index[:5]}...")
        logger.info(f"y_reg.index: {y_reg.index[:5]}...")
        logger.info(f"y_clf.index: {y_clf.index[:5]}...")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æœ€å°ã®å…±é€šç¯„å›²ã‚’ä½¿ç”¨
        min_len = min(len(X), len(y_reg), len(y_clf))
        if min_len > 0:
            X = X.iloc[:min_len]
            common_idx = X.index
        else:
            raise ValueError("Cannot align X, y_reg, y_clf indices")
    else:
        X = X.loc[common_idx]

    return X, y_reg.loc[common_idx], y_clf.loc[common_idx]


# Phase H.11: ç‰¹å¾´é‡å®Œå…¨æ€§ä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
def prepare_ml_dataset_enhanced(
    df: pd.DataFrame, config: Dict[str, Any]
) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:
    """
    ç‰¹å¾´é‡å®Œå…¨æ€§ä¿è¨¼ä»˜ãMLç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ

    Args:
        df: OHLCVãƒ‡ãƒ¼ã‚¿
        config: è¨­å®šè¾æ›¸

    Returns:
        (ç‰¹å¾´é‡DataFrame, å›å¸°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ, åˆ†é¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ)
    """
    logger.info("ğŸš€ [ENHANCED-ML] Starting enhanced ML dataset preparation...")
    logger.info(f"ğŸ“Š [ENHANCED-ML] Input shape: {tuple(df.shape)}")

    # Phase H.11: ç‰¹å¾´é‡å®Œå…¨æ€§ä¿è¨¼å®Ÿè¡Œ
    if ENHANCED_FEATURES_AVAILABLE:
        logger.info("âœ… [ENHANCED-ML] Using enhanced feature engineering system")
        # Phase 3: enhance_feature_engineeringæ©Ÿèƒ½å®Œå…¨ç„¡åŠ¹åŒ–
        enhanced_df, feature_report = df, {"status": "disabled"}

        # ç‰¹å¾´é‡ãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›
        logger.info(f"ğŸ“‹ [ENHANCED-ML] Feature report: {feature_report.get('status')}")

        # æ‹¡å¼µã•ã‚ŒãŸDataFrameã§MLç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        pipeline = build_ml_pipeline(config)
        X_arr = pipeline.fit_transform(enhanced_df)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆï¼ˆå…ƒã®DataFrameã‚’ä½¿ç”¨ï¼‰
        y_reg = make_regression_target(df, config)
        y_clf = make_classification_target(df, config)

        logger.info(
            f"âœ… [ENHANCED-ML] Enhanced pipeline output shape: {X_arr.shape if hasattr(X_arr, 'shape') else 'unknown'}"
        )

    else:
        logger.info(
            "âš ï¸ [ENHANCED-ML] Enhanced features unavailable, using standard ML pipeline"
        )
        # æ¨™æº–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½¿ç”¨
        return prepare_ml_dataset(df, config)

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ï¼ˆæ¨™æº–prepare_ml_datasetã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    ml_config = config.get("ml", {})
    rolling_window = ml_config.get("rolling_window", 10)
    lags = ml_config.get("lags", [1, 2])

    win = rolling_window
    drop_n = win + max(lags) if lags else win

    idx = enhanced_df.index[drop_n:]
    if isinstance(X_arr, np.ndarray):
        result_df = enhanced_df  # å…ƒã®DataFrameã¾ãŸã¯æ‹¡å¼µDataFrame
    else:
        result_df = enhanced_df

    # å®‰å…¨ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´
    if len(result_df) <= drop_n:
        logger.warning(
            f"âš ï¸ [ENHANCED-ML] Insufficient data length: {len(result_df)} <= {drop_n}"
        )
        drop_n = max(0, len(result_df) - 5)

    drop_n = win + max(lags) if lags else win

    idx = result_df.index[drop_n:]
    X = pd.DataFrame(X_arr[drop_n:], index=idx)

    logger.info(
        f"âœ… [ENHANCED-ML] Enhanced ML dataset ready: X{tuple(X.shape)}, y_reg{tuple(y_reg.loc[idx].shape)}, y_clf{tuple(y_clf.loc[idx].shape)}"
    )

    return X, y_reg.loc[idx], y_clf.loc[idx]
