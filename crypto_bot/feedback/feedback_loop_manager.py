# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«å: crypto_bot/feedback/feedback_loop_manager.py
# èª¬æ˜:
# Phase C2: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
# äºˆæ¸¬çµæœåé›†ãƒ»åˆ†æãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æ›´æ–°ãƒ»ç¶™ç¶šçš„å­¦ç¿’ãƒ»é©å¿œæœ€é©åŒ–
# Phase C2å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆãƒ»è‡ªå‹•æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«å®Ÿç¾
# =============================================================================

import logging
import os
import pickle
import threading
from collections import defaultdict, deque
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

import numpy as np
from scipy import stats

logger = logging.getLogger(__name__)


class FeedbackType(Enum):
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç¨®åˆ¥"""

    PREDICTION_OUTCOME = "prediction_outcome"
    TRADE_RESULT = "trade_result"
    MARKET_ENVIRONMENT = "market_environment"
    WEIGHT_ADJUSTMENT = "weight_adjustment"
    PERFORMANCE_METRIC = "performance_metric"


@dataclass
class FeedbackEvent:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ"""

    timestamp: datetime
    event_id: str
    feedback_type: FeedbackType
    timeframe: str

    # äºˆæ¸¬é–¢é€£
    prediction: Optional[Any] = None
    actual_outcome: Optional[Any] = None
    confidence: Optional[float] = None
    prediction_correct: Optional[bool] = None

    # å–å¼•é–¢é€£
    trade_id: Optional[str] = None
    entry_price: Optional[float] = None
    exit_price: Optional[float] = None
    pnl: Optional[float] = None
    trade_successful: Optional[bool] = None

    # å¸‚å ´é–¢é€£
    market_context: Optional[Dict[str, Any]] = None
    market_regime: Optional[str] = None
    volatility_level: Optional[float] = None

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–¢é€£
    parameters_before: Optional[Dict[str, Any]] = None
    parameters_after: Optional[Dict[str, Any]] = None
    adjustment_reason: Optional[str] = None

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class LearningInsight:
    """å­¦ç¿’ã‚¤ãƒ³ã‚µã‚¤ãƒˆ"""

    insight_id: str
    timestamp: datetime
    insight_type: str
    confidence_level: float
    description: str
    data_evidence: Dict[str, Any]
    recommended_actions: List[str]
    impact_assessment: str


class FeedbackLoopManager:
    """
    Phase C2: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

    æ©Ÿèƒ½:
    - åŒ…æ‹¬çš„äºˆæ¸¬çµæœãƒ»å–å¼•çµæœãƒ»å¸‚å ´ç’°å¢ƒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†
    - çµ±è¨ˆçš„åˆ†æãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»å­¦ç¿’ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
    - è‡ªå‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãƒ»ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒ»æˆ¦ç•¥æœ€é©åŒ–
    - ç¶™ç¶šçš„å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«ãƒ»é©å¿œçš„æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ 
    - Phase C2ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆãƒ»æœ€é©åŒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    - A/Bãƒ†ã‚¹ãƒˆãƒ»å®Ÿé¨“è¨ˆç”»ãƒ»åŠ¹æœæ¸¬å®šæ”¯æ´
    """

    def __init__(self, config: Dict[str, Any]):
        """
        ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–

        Parameters:
        -----------
        config : Dict[str, Any]
            ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨­å®šè¾æ›¸
        """
        self.config = config

        # åŸºæœ¬è¨­å®š
        feedback_config = config.get("feedback_loop", {})
        self.timeframes = feedback_config.get("timeframes", ["15m", "1h", "4h"])
        self.learning_enabled = feedback_config.get("learning_enabled", True)
        self.auto_parameter_adjustment = feedback_config.get("auto_adjustment", True)
        self.feedback_window = feedback_config.get("feedback_window", 200)
        self.analysis_interval = feedback_config.get("analysis_interval", 300)  # ç§’

        # å­¦ç¿’è¨­å®š
        learning_config = feedback_config.get("learning", {})
        self.min_samples_for_learning = learning_config.get("min_samples", 50)
        self.learning_threshold = learning_config.get("threshold", 0.6)
        self.insight_confidence_threshold = learning_config.get(
            "insight_confidence", 0.7
        )
        self.max_parameter_change = learning_config.get("max_parameter_change", 0.2)

        # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜è¨­å®š
        pattern_config = feedback_config.get("pattern_recognition", {})
        self.pattern_detection_enabled = pattern_config.get("enabled", True)
        self.pattern_min_occurrences = pattern_config.get("min_occurrences", 10)
        self.pattern_significance_level = pattern_config.get("significance_level", 0.05)

        # ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
        self.feedback_events: deque = deque(maxlen=self.feedback_window * 5)
        self.learning_insights: deque = deque(maxlen=100)
        self.parameter_history: deque = deque(maxlen=200)

        # åˆ†æãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        self.prediction_analysis = {
            timeframe: {
                "correct_predictions": deque(maxlen=self.feedback_window),
                "incorrect_predictions": deque(maxlen=self.feedback_window),
                "confidence_scores": deque(maxlen=self.feedback_window),
                "market_contexts": deque(maxlen=self.feedback_window),
            }
            for timeframe in self.timeframes
        }

        self.trade_analysis = {
            timeframe: {
                "successful_trades": deque(maxlen=self.feedback_window),
                "failed_trades": deque(maxlen=self.feedback_window),
                "trade_durations": deque(maxlen=self.feedback_window),
                "pnl_history": deque(maxlen=self.feedback_window),
            }
            for timeframe in self.timeframes
        }

        # ãƒ‘ã‚¿ãƒ¼ãƒ³è¿½è·¡
        self.discovered_patterns = {}
        self.pattern_performance = defaultdict(list)

        # çµ±è¨ˆè¿½è·¡
        self.feedback_stats = {
            "total_events": 0,
            "prediction_events": 0,
            "trade_events": 0,
            "parameter_adjustments": 0,
            "insights_generated": 0,
            "patterns_discovered": 0,
            "learning_cycles": 0,
            "automatic_improvements": 0,
        }

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå‚ç…§ï¼ˆå¤–éƒ¨ã‹ã‚‰è¨­å®šï¼‰
        self.dynamic_weight_adjuster = None
        self.performance_monitor = None
        self.market_analyzer = None

        # å­¦ç¿’ã‚¹ãƒ¬ãƒƒãƒ‰ç®¡ç†
        self.learning_thread: Optional[threading.Thread] = None
        self.stop_learning = threading.Event()
        self.learning_active = False

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.parameter_update_callbacks: List[Callable] = []

        # ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–
        self.enable_persistence = feedback_config.get("persistence", {}).get(
            "enabled", False
        )
        self.persistence_path = feedback_config.get("persistence", {}).get(
            "path", "data/feedback_history"
        )

        logger.info("ğŸ”„ FeedbackLoopManager initialized")
        logger.info(f"   Learning enabled: {self.learning_enabled}")
        logger.info(f"   Auto parameter adjustment: {self.auto_parameter_adjustment}")
        logger.info(f"   Feedback window: {self.feedback_window}")

    def set_components(
        self,
        dynamic_weight_adjuster=None,
        performance_monitor=None,
        market_analyzer=None,
    ):
        """Phase C2ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­å®š"""
        self.dynamic_weight_adjuster = dynamic_weight_adjuster
        self.performance_monitor = performance_monitor
        self.market_analyzer = market_analyzer

        logger.info("ğŸ”— Feedback loop components connected")

    def start_learning_cycle(self):
        """ç¶™ç¶šçš„å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹"""
        try:
            if self.learning_active:
                logger.warning("Learning cycle already active")
                return

            self.learning_active = True
            self.stop_learning.clear()

            self.learning_thread = threading.Thread(
                target=self._learning_loop, daemon=True, name="FeedbackLearning"
            )
            self.learning_thread.start()

            logger.info("ğŸš€ Feedback learning cycle started")

        except Exception as e:
            logger.error(f"âŒ Failed to start learning cycle: {e}")

    def stop_learning_cycle(self):
        """ç¶™ç¶šçš„å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«åœæ­¢"""
        try:
            if not self.learning_active:
                return

            self.stop_learning.set()
            self.learning_active = False

            if self.learning_thread and self.learning_thread.is_alive():
                self.learning_thread.join(timeout=10.0)

            logger.info("ğŸ›‘ Feedback learning cycle stopped")

        except Exception as e:
            logger.error(f"âŒ Failed to stop learning cycle: {e}")

    def _learning_loop(self):
        """å­¦ç¿’ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        try:
            logger.info("ğŸ§  Feedback learning loop started")

            while not self.stop_learning.wait(self.analysis_interval):
                try:
                    if self.learning_enabled:
                        self._perform_learning_cycle()
                        self.feedback_stats["learning_cycles"] += 1

                except Exception as e:
                    logger.error(f"Learning cycle error: {e}")

            logger.info("ğŸ§  Feedback learning loop ended")

        except Exception as e:
            logger.error(f"âŒ Learning loop failed: {e}")

    def _perform_learning_cycle(self):
        """å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ"""
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
            insights = self._analyze_feedback_data()

            # 2. ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ãƒ»èªè­˜
            if self.pattern_detection_enabled:
                patterns = self._discover_patterns()
                insights.extend(patterns)

            # 3. å­¦ç¿’ã‚¤ãƒ³ã‚µã‚¤ãƒˆè©•ä¾¡ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            validated_insights = self._validate_insights(insights)

            # 4. è‡ªå‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
            if self.auto_parameter_adjustment:
                adjustments = self._generate_parameter_adjustments(validated_insights)
                self._apply_parameter_adjustments(adjustments)

            # 5. ã‚¤ãƒ³ã‚µã‚¤ãƒˆè¨˜éŒ²
            for insight in validated_insights:
                self.learning_insights.append(insight)
                self.feedback_stats["insights_generated"] += 1

            if validated_insights:
                logger.info(f"ğŸ§  Generated {len(validated_insights)} learning insights")

        except Exception as e:
            logger.error(f"Learning cycle execution failed: {e}")

    def record_prediction_feedback(
        self,
        timeframe: str,
        prediction: Any,
        actual_outcome: Any,
        confidence: float,
        market_context: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ):
        """äºˆæ¸¬ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²"""
        try:
            prediction_correct = prediction == actual_outcome

            event = FeedbackEvent(
                timestamp=datetime.now(),
                event_id=f"pred_{timeframe}_{datetime.now().timestamp()}",
                feedback_type=FeedbackType.PREDICTION_OUTCOME,
                timeframe=timeframe,
                prediction=prediction,
                actual_outcome=actual_outcome,
                confidence=confidence,
                prediction_correct=prediction_correct,
                market_context=market_context,
                metadata=metadata,
            )

            self._record_feedback_event(event)

            # åˆ†æãƒ‡ãƒ¼ã‚¿æ›´æ–°
            if prediction_correct:
                self.prediction_analysis[timeframe]["correct_predictions"].append(event)
            else:
                self.prediction_analysis[timeframe]["incorrect_predictions"].append(
                    event
                )

            self.prediction_analysis[timeframe]["confidence_scores"].append(confidence)
            if market_context:
                self.prediction_analysis[timeframe]["market_contexts"].append(
                    market_context
                )

            self.feedback_stats["prediction_events"] += 1

        except Exception as e:
            logger.error(f"Prediction feedback recording failed: {e}")

    def record_trade_feedback(
        self,
        timeframe: str,
        trade_id: str,
        entry_price: float,
        exit_price: float,
        pnl: float,
        market_context: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ):
        """å–å¼•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²"""
        try:
            trade_successful = pnl > 0

            event = FeedbackEvent(
                timestamp=datetime.now(),
                event_id=f"trade_{timeframe}_{trade_id}",
                feedback_type=FeedbackType.TRADE_RESULT,
                timeframe=timeframe,
                trade_id=trade_id,
                entry_price=entry_price,
                exit_price=exit_price,
                pnl=pnl,
                trade_successful=trade_successful,
                market_context=market_context,
                metadata=metadata,
            )

            self._record_feedback_event(event)

            # åˆ†æãƒ‡ãƒ¼ã‚¿æ›´æ–°
            if trade_successful:
                self.trade_analysis[timeframe]["successful_trades"].append(event)
            else:
                self.trade_analysis[timeframe]["failed_trades"].append(event)

            self.trade_analysis[timeframe]["pnl_history"].append(pnl)

            self.feedback_stats["trade_events"] += 1

        except Exception as e:
            logger.error(f"Trade feedback recording failed: {e}")

    def record_parameter_adjustment(
        self,
        component_name: str,
        parameters_before: Dict[str, Any],
        parameters_after: Dict[str, Any],
        adjustment_reason: str,
        metadata: Optional[Dict[str, Any]] = None,
    ):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²"""
        try:
            event = FeedbackEvent(
                timestamp=datetime.now(),
                event_id=f"param_{component_name}_{datetime.now().timestamp()}",
                feedback_type=FeedbackType.WEIGHT_ADJUSTMENT,
                timeframe="all",
                parameters_before=parameters_before,
                parameters_after=parameters_after,
                adjustment_reason=adjustment_reason,
                metadata=metadata,
            )

            self._record_feedback_event(event)
            self.parameter_history.append(event)

            self.feedback_stats["parameter_adjustments"] += 1

        except Exception as e:
            logger.error(f"Parameter adjustment recording failed: {e}")

    def _record_feedback_event(self, event: FeedbackEvent):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²"""
        try:
            self.feedback_events.append(event)
            self.feedback_stats["total_events"] += 1

            # æ°¸ç¶šåŒ–
            if self.enable_persistence:
                self._persist_feedback_event(event)

        except Exception as e:
            logger.error(f"Feedback event recording failed: {e}")

    def _analyze_feedback_data(self) -> List[LearningInsight]:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿åˆ†æ"""
        insights = []

        try:
            for timeframe in self.timeframes:
                # äºˆæ¸¬ç²¾åº¦åˆ†æ
                prediction_insights = self._analyze_prediction_performance(timeframe)
                insights.extend(prediction_insights)

                # å–å¼•æˆæœåˆ†æ
                trade_insights = self._analyze_trade_performance(timeframe)
                insights.extend(trade_insights)

                # å¸‚å ´ç’°å¢ƒé–¢é€£åˆ†æ
                market_insights = self._analyze_market_context_patterns(timeframe)
                insights.extend(market_insights)

        except Exception as e:
            logger.error(f"Feedback data analysis failed: {e}")

        return insights

    def _analyze_prediction_performance(self, timeframe: str) -> List[LearningInsight]:
        """äºˆæ¸¬æ€§èƒ½åˆ†æ"""
        insights = []

        try:
            correct_preds = list(
                self.prediction_analysis[timeframe]["correct_predictions"]
            )
            incorrect_preds = list(
                self.prediction_analysis[timeframe]["incorrect_predictions"]
            )

            if (
                len(correct_preds) + len(incorrect_preds)
                < self.min_samples_for_learning
            ):
                return insights

            # 1. ä¿¡é ¼åº¦vsæ­£ç¢ºæ€§åˆ†æ
            correct_confidences = [
                pred.confidence for pred in correct_preds if pred.confidence is not None
            ]
            incorrect_confidences = [
                pred.confidence
                for pred in incorrect_preds
                if pred.confidence is not None
            ]

            if len(correct_confidences) >= 10 and len(incorrect_confidences) >= 10:
                # t-æ¤œå®šã«ã‚ˆã‚‹æœ‰æ„å·®åˆ†æ
                t_stat, p_value = stats.ttest_ind(
                    correct_confidences, incorrect_confidences
                )

                if p_value < 0.05:
                    avg_correct_conf = np.mean(correct_confidences)
                    avg_incorrect_conf = np.mean(incorrect_confidences)

                    if avg_correct_conf > avg_incorrect_conf:
                        insight = LearningInsight(
                            insight_id=f"confidence_calibration_{timeframe}",
                            timestamp=datetime.now(),
                            insight_type="confidence_analysis",
                            confidence_level=1 - p_value,
                            description=f"{timeframe}: High confidence predictions are more accurate",
                            data_evidence={
                                "correct_confidence_avg": avg_correct_conf,
                                "incorrect_confidence_avg": avg_incorrect_conf,
                                "p_value": p_value,
                                "t_statistic": t_stat,
                            },
                            recommended_actions=[
                                "Increase confidence threshold for trading signals",
                                "Apply higher weights to high-confidence predictions",
                            ],
                            impact_assessment="high",
                        )
                        insights.append(insight)

            # 2. æœ€è¿‘ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            recent_correct = len(
                [
                    pred
                    for pred in correct_preds
                    if pred.timestamp > datetime.now() - timedelta(hours=24)
                ]
            )
            recent_total = len(
                [
                    pred
                    for pred in correct_preds + incorrect_preds
                    if pred.timestamp > datetime.now() - timedelta(hours=24)
                ]
            )

            if recent_total >= 20:
                recent_accuracy = recent_correct / recent_total

                # å…¨ä½“å¹³å‡ã¨æ¯”è¼ƒ
                total_correct = len(correct_preds)
                total_all = len(correct_preds) + len(incorrect_preds)
                overall_accuracy = total_correct / total_all if total_all > 0 else 0

                if abs(recent_accuracy - overall_accuracy) > 0.1:  # 10%ä»¥ä¸Šã®å·®
                    trend_direction = (
                        "improving"
                        if recent_accuracy > overall_accuracy
                        else "declining"
                    )

                    insight = LearningInsight(
                        insight_id=f"accuracy_trend_{timeframe}",
                        timestamp=datetime.now(),
                        insight_type="performance_trend",
                        confidence_level=0.8,
                        description=(
                            f"{timeframe}: Prediction accuracy {trend_direction}"
                        ),
                        data_evidence={
                            "recent_accuracy": recent_accuracy,
                            "overall_accuracy": overall_accuracy,
                            "trend_direction": trend_direction,
                            "recent_samples": recent_total,
                        },
                        recommended_actions=[
                            ("Maintain" if trend_direction == "improving" else "Review")
                            + " current prediction strategy",
                            "Monitor prediction accuracy more closely",
                        ],
                        impact_assessment="medium",
                    )
                    insights.append(insight)

        except Exception as e:
            logger.error(f"Prediction performance analysis failed for {timeframe}: {e}")

        return insights

    def _analyze_trade_performance(self, timeframe: str) -> List[LearningInsight]:
        """å–å¼•æˆæœåˆ†æ"""
        insights = []

        try:
            successful_trades = list(
                self.trade_analysis[timeframe]["successful_trades"]
            )
            failed_trades = list(self.trade_analysis[timeframe]["failed_trades"])
            pnl_history = list(self.trade_analysis[timeframe]["pnl_history"])

            if len(successful_trades) + len(failed_trades) < 20:
                return insights

            # 1. PnLåˆ†å¸ƒåˆ†æ
            if len(pnl_history) >= 30:
                win_rate = len(successful_trades) / (
                    len(successful_trades) + len(failed_trades)
                )
                avg_win = np.mean([trade.pnl for trade in successful_trades])
                avg_loss = np.mean([trade.pnl for trade in failed_trades])

                # ãƒªã‚¹ã‚¯ãƒ»ãƒªãƒ¯ãƒ¼ãƒ‰æ¯”
                if avg_loss < 0:
                    risk_reward_ratio = abs(avg_win / avg_loss)

                    if win_rate < 0.5 and risk_reward_ratio < 1.5:
                        insight = LearningInsight(
                            insight_id=f"risk_reward_{timeframe}",
                            timestamp=datetime.now(),
                            insight_type="risk_analysis",
                            confidence_level=0.9,
                            description=f"{timeframe}: Poor risk-reward profile detected",
                            data_evidence={
                                "win_rate": win_rate,
                                "risk_reward_ratio": risk_reward_ratio,
                                "avg_win": avg_win,
                                "avg_loss": avg_loss,
                            },
                            recommended_actions=[
                                "Tighten stop-loss levels",
                                "Extend take-profit targets",
                                "Improve entry signal quality",
                            ],
                            impact_assessment="high",
                        )
                        insights.append(insight)

                # 2. é€£ç¶šæå¤±ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                consecutive_losses = 0
                max_consecutive_losses = 0

                for trade in list(reversed(failed_trades + successful_trades))[-50:]:
                    if not trade.trade_successful:
                        consecutive_losses += 1
                        max_consecutive_losses = max(
                            max_consecutive_losses, consecutive_losses
                        )
                    else:
                        consecutive_losses = 0

                if max_consecutive_losses >= 5:
                    insight = LearningInsight(
                        insight_id=f"consecutive_losses_{timeframe}",
                        timestamp=datetime.now(),
                        insight_type="risk_management",
                        confidence_level=0.85,
                        description=f"{timeframe}: High consecutive loss streaks detected",
                        data_evidence={
                            "max_consecutive_losses": max_consecutive_losses,
                            "current_streak": consecutive_losses,
                        },
                        recommended_actions=[
                            "Implement position sizing reduction after consecutive losses",
                            "Review entry signal criteria",
                            "Add market regime filters",
                        ],
                        impact_assessment="medium",
                    )
                    insights.append(insight)

        except Exception as e:
            logger.error(f"Trade performance analysis failed for {timeframe}: {e}")

        return insights

    def _analyze_market_context_patterns(self, timeframe: str) -> List[LearningInsight]:
        """å¸‚å ´ç’°å¢ƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        insights = []

        try:
            market_contexts = list(
                self.prediction_analysis[timeframe]["market_contexts"]
            )
            correct_preds = list(
                self.prediction_analysis[timeframe]["correct_predictions"]
            )

            if len(market_contexts) < 30:
                return insights

            # VIX ãƒ¬ãƒ™ãƒ«åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            vix_performance = {"low": [], "medium": [], "high": []}

            for i, context in enumerate(market_contexts):
                if "vix_level" in context and i < len(correct_preds):
                    vix = context["vix_level"]
                    correct = correct_preds[i].prediction_correct

                    if vix < 20:
                        vix_performance["low"].append(correct)
                    elif vix < 30:
                        vix_performance["medium"].append(correct)
                    else:
                        vix_performance["high"].append(correct)

            # å„VIXãƒ¬ãƒ™ãƒ«ã§ã®ç²¾åº¦æ¯”è¼ƒ
            vix_accuracies = {}
            for level, results in vix_performance.items():
                if len(results) >= 10:
                    vix_accuracies[level] = np.mean(results)

            if len(vix_accuracies) >= 2:
                best_vix_level = max(vix_accuracies, key=vix_accuracies.get)
                worst_vix_level = min(vix_accuracies, key=vix_accuracies.get)

                if (
                    vix_accuracies[best_vix_level] - vix_accuracies[worst_vix_level]
                    > 0.15
                ):  # 15%ä»¥ä¸Šã®å·®
                    insight = LearningInsight(
                        insight_id=f"vix_performance_{timeframe}",
                        timestamp=datetime.now(),
                        insight_type="market_environment",
                        confidence_level=0.8,
                        description=f"{timeframe}: Performance varies significantly with VIX levels",
                        data_evidence={
                            "vix_accuracies": vix_accuracies,
                            "best_vix_level": best_vix_level,
                            "worst_vix_level": worst_vix_level,
                        },
                        recommended_actions=[
                            f"Increase confidence threshold during {worst_vix_level} VIX periods",
                            f"Optimize strategy parameters for {best_vix_level} VIX conditions",
                        ],
                        impact_assessment="medium",
                    )
                    insights.append(insight)

        except Exception as e:
            logger.error(f"Market context analysis failed for {timeframe}: {e}")

        return insights

    def _discover_patterns(self) -> List[LearningInsight]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹"""
        insights = []

        try:
            # æ™‚é–“å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
            hourly_performance = self._analyze_hourly_patterns()
            if hourly_performance:
                insights.extend(hourly_performance)

            # æ›œæ—¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
            daily_performance = self._analyze_daily_patterns()
            if daily_performance:
                insights.extend(daily_performance)

            self.feedback_stats["patterns_discovered"] += len(insights)

        except Exception as e:
            logger.error(f"Pattern discovery failed: {e}")

        return insights

    def _analyze_hourly_patterns(self) -> List[LearningInsight]:
        """æ™‚é–“å¸¯ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        insights = []

        try:
            # éå»ã®ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰æ™‚é–“å¸¯åˆ¥æˆåŠŸç‡ã‚’è¨ˆç®—
            hourly_success = defaultdict(list)

            recent_events = [
                e
                for e in self.feedback_events
                if e.timestamp > datetime.now() - timedelta(days=7)
            ]

            for event in recent_events:
                if (
                    event.feedback_type == FeedbackType.PREDICTION_OUTCOME
                    and event.prediction_correct is not None
                ):
                    hour = event.timestamp.hour
                    hourly_success[hour].append(event.prediction_correct)

            # å„æ™‚é–“å¸¯ã®æˆåŠŸç‡è¨ˆç®—
            hourly_rates = {}
            for hour, successes in hourly_success.items():
                if len(successes) >= self.pattern_min_occurrences:
                    hourly_rates[hour] = np.mean(successes)

            if len(hourly_rates) >= 6:  # æœ€ä½6æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
                best_hours = sorted(
                    hourly_rates.items(), key=lambda x: x[1], reverse=True
                )[:3]
                worst_hours = sorted(hourly_rates.items(), key=lambda x: x[1])[:3]

                best_rate = np.mean([rate for _, rate in best_hours])
                worst_rate = np.mean([rate for _, rate in worst_hours])

                if best_rate - worst_rate > 0.2:  # 20%ä»¥ä¸Šã®å·®
                    insight = LearningInsight(
                        insight_id="hourly_performance_pattern",
                        timestamp=datetime.now(),
                        insight_type="temporal_pattern",
                        confidence_level=0.75,
                        description="Significant hourly performance variation detected",
                        data_evidence={
                            "best_hours": dict(best_hours),
                            "worst_hours": dict(worst_hours),
                            "performance_gap": best_rate - worst_rate,
                        },
                        recommended_actions=[
                            f"Increase trading activity during hours: {[h for h, _ in best_hours]}",
                            f"Reduce or avoid trading during hours: {[h for h, _ in worst_hours]}",
                        ],
                        impact_assessment="medium",
                    )
                    insights.append(insight)

        except Exception as e:
            logger.error(f"Hourly pattern analysis failed: {e}")

        return insights

    def _analyze_daily_patterns(self) -> List[LearningInsight]:
        """æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        insights = []

        try:
            # æ›œæ—¥åˆ¥æˆåŠŸç‡åˆ†æ
            daily_success = defaultdict(list)

            recent_events = [
                e
                for e in self.feedback_events
                if e.timestamp > datetime.now() - timedelta(days=30)
            ]

            for event in recent_events:
                if (
                    event.feedback_type == FeedbackType.TRADE_RESULT
                    and event.trade_successful is not None
                ):
                    weekday = event.timestamp.weekday()  # 0=æœˆæ›œæ—¥
                    daily_success[weekday].append(event.trade_successful)

            # å„æ›œæ—¥ã®æˆåŠŸç‡è¨ˆç®—
            daily_rates = {}
            weekday_names = [
                "Monday",
                "Tuesday",
                "Wednesday",
                "Thursday",
                "Friday",
                "Saturday",
                "Sunday",
            ]

            for day, successes in daily_success.items():
                if len(successes) >= self.pattern_min_occurrences:
                    daily_rates[weekday_names[day]] = np.mean(successes)

            if len(daily_rates) >= 5:  # å¹³æ—¥ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
                best_day = max(daily_rates, key=daily_rates.get)
                worst_day = min(daily_rates, key=daily_rates.get)

                if daily_rates[best_day] - daily_rates[worst_day] > 0.15:  # 15%ä»¥ä¸Šã®å·®
                    insight = LearningInsight(
                        insight_id="daily_performance_pattern",
                        timestamp=datetime.now(),
                        insight_type="temporal_pattern",
                        confidence_level=0.7,
                        description="Significant daily performance variation detected",
                        data_evidence={
                            "daily_rates": daily_rates,
                            "best_day": best_day,
                            "worst_day": worst_day,
                        },
                        recommended_actions=[
                            f"Optimize strategy for {best_day} trading",
                            f"Review strategy performance on {worst_day}",
                        ],
                        impact_assessment="low",
                    )
                    insights.append(insight)

        except Exception as e:
            logger.error(f"Daily pattern analysis failed: {e}")

        return insights

    def _validate_insights(
        self, insights: List[LearningInsight]
    ) -> List[LearningInsight]:
        """ã‚¤ãƒ³ã‚µã‚¤ãƒˆæ¤œè¨¼ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        validated = []

        try:
            for insight in insights:
                # ä¿¡é ¼åº¦é–¾å€¤ãƒã‚§ãƒƒã‚¯
                if insight.confidence_level >= self.insight_confidence_threshold:

                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    existing_ids = [
                        existing.insight_id for existing in self.learning_insights
                    ]
                    if insight.insight_id not in existing_ids:
                        validated.append(insight)

        except Exception as e:
            logger.error(f"Insight validation failed: {e}")

        return validated

    def _generate_parameter_adjustments(
        self, insights: List[LearningInsight]
    ) -> List[Dict[str, Any]]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ç”Ÿæˆ"""
        adjustments = []

        try:
            for insight in insights:
                if insight.impact_assessment in ["high", "medium"]:

                    # ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ¥èª¿æ•´æˆ¦ç•¥
                    if insight.insight_type == "confidence_analysis":
                        # ä¿¡é ¼åº¦é–¾å€¤èª¿æ•´
                        adjustment = {
                            "component": "ensemble_confidence",
                            "parameter": "confidence_threshold",
                            "current_value": 0.65,
                            "adjustment_factor": 1.1,
                            "reason": f"Confidence calibration insight: {insight.insight_id}",
                        }
                        adjustments.append(adjustment)

                    elif insight.insight_type == "risk_analysis":
                        # ãƒªã‚¹ã‚¯ç®¡ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
                        adjustment = {
                            "component": "risk_management",
                            "parameter": "position_sizing",
                            "current_value": 1.0,
                            "adjustment_factor": 0.9,
                            "reason": f"Risk analysis insight: {insight.insight_id}",
                        }
                        adjustments.append(adjustment)

                    elif insight.insight_type == "market_environment":
                        # å¸‚å ´ç’°å¢ƒé‡ã¿èª¿æ•´
                        adjustment = {
                            "component": "market_weights",
                            "parameter": "vix_sensitivity",
                            "current_value": 1.0,
                            "adjustment_factor": 1.2,
                            "reason": f"Market environment insight: {insight.insight_id}",
                        }
                        adjustments.append(adjustment)

        except Exception as e:
            logger.error(f"Parameter adjustment generation failed: {e}")

        return adjustments

    def _apply_parameter_adjustments(self, adjustments: List[Dict[str, Any]]):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´é©ç”¨"""
        try:
            for adjustment in adjustments:
                # èª¿æ•´å¹…åˆ¶é™
                factor = adjustment["adjustment_factor"]
                limited_factor = max(
                    1 - self.max_parameter_change,
                    min(1 + self.max_parameter_change, factor),
                )

                # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆ¥èª¿æ•´é©ç”¨
                component = adjustment["component"]
                success = False

                if (
                    component == "dynamic_weight_adjuster"
                    and self.dynamic_weight_adjuster
                ):
                    # å‹•çš„é‡ã¿èª¿æ•´å™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
                    success = self._update_weight_adjuster_parameters(
                        adjustment, limited_factor
                    )

                elif component == "performance_monitor" and self.performance_monitor:
                    # æ€§èƒ½ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
                    success = self._update_monitor_parameters(
                        adjustment, limited_factor
                    )

                if success:
                    self.feedback_stats["automatic_improvements"] += 1
                    logger.info(
                        f"âœ… Applied parameter adjustment: {adjustment['reason']}"
                    )

        except Exception as e:
            logger.error(f"Parameter adjustment application failed: {e}")

    def _update_weight_adjuster_parameters(
        self, adjustment: Dict[str, Any], factor: float
    ) -> bool:
        """é‡ã¿èª¿æ•´å™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°"""
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿè£…ã¯å…·ä½“çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ä¾å­˜ï¼‰
            # ã“ã“ã§ã¯ä¾‹ã¨ã—ã¦å­¦ç¿’ç‡ã‚’èª¿æ•´
            if hasattr(self.dynamic_weight_adjuster, "learning_rate"):
                old_value = self.dynamic_weight_adjuster.learning_rate
                new_value = old_value * factor
                self.dynamic_weight_adjuster.learning_rate = new_value

                logger.info(
                    f"ğŸ”§ Updated learning_rate: {old_value:.4f} â†’ {new_value:.4f}"
                )
                return True

        except Exception as e:
            logger.error(f"Weight adjuster parameter update failed: {e}")

        return False

    def _update_monitor_parameters(
        self, adjustment: Dict[str, Any], factor: float
    ) -> bool:
        """ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°"""
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿè£…ã¯å…·ä½“çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ä¾å­˜ï¼‰
            # ã“ã“ã§ã¯ä¾‹ã¨ã—ã¦é–¾å€¤ã‚’èª¿æ•´
            if hasattr(self.performance_monitor, "accuracy_threshold"):
                old_value = self.performance_monitor.accuracy_threshold
                new_value = old_value * factor
                self.performance_monitor.accuracy_threshold = new_value

                logger.info(
                    f"ğŸ”§ Updated accuracy_threshold: {old_value:.4f} â†’ {new_value:.4f}"
                )
                return True

        except Exception as e:
            logger.error(f"Monitor parameter update failed: {e}")

        return False

    def _persist_feedback_event(self, event: FeedbackEvent):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆæ°¸ç¶šåŒ–"""
        try:
            if not os.path.exists(self.persistence_path):
                os.makedirs(self.persistence_path)

            # æ—¥ä»˜åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            date_str = event.timestamp.strftime("%Y%m%d")
            file_path = os.path.join(self.persistence_path, f"feedback_{date_str}.pkl")

            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            daily_events = []
            if os.path.exists(file_path):
                try:
                    with open(file_path, "rb") as f:
                        daily_events = pickle.load(f)
                except Exception:
                    daily_events = []

            # æ–°ã‚¤ãƒ™ãƒ³ãƒˆè¿½åŠ ãƒ»ä¿å­˜
            daily_events.append(asdict(event))
            with open(file_path, "wb") as f:
                pickle.dump(daily_events, f)

        except Exception as e:
            logger.error(f"Feedback event persistence failed: {e}")

    def get_learning_summary(self) -> Dict[str, Any]:
        """å­¦ç¿’ã‚µãƒãƒªãƒ¼å–å¾—"""
        try:
            summary = {
                "timestamp": datetime.now(),
                "learning_active": self.learning_active,
                "feedback_stats": self.feedback_stats.copy(),
            }

            # æœ€è¿‘ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
            recent_insights = list(self.learning_insights)[-10:]
            summary["recent_insights"] = [
                {
                    "insight_id": insight.insight_id,
                    "timestamp": insight.timestamp.isoformat(),
                    "insight_type": insight.insight_type,
                    "confidence_level": insight.confidence_level,
                    "description": insight.description,
                    "impact_assessment": insight.impact_assessment,
                }
                for insight in recent_insights
            ]

            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥çµ±è¨ˆ
            timeframe_stats = {}
            for timeframe in self.timeframes:
                correct_count = len(
                    self.prediction_analysis[timeframe]["correct_predictions"]
                )
                incorrect_count = len(
                    self.prediction_analysis[timeframe]["incorrect_predictions"]
                )
                total_predictions = correct_count + incorrect_count

                successful_trades = len(
                    self.trade_analysis[timeframe]["successful_trades"]
                )
                failed_trades = len(self.trade_analysis[timeframe]["failed_trades"])
                total_trades = successful_trades + failed_trades

                timeframe_stats[timeframe] = {
                    "prediction_accuracy": (
                        correct_count / total_predictions
                        if total_predictions > 0
                        else 0
                    ),
                    "total_predictions": total_predictions,
                    "trade_win_rate": (
                        successful_trades / total_trades if total_trades > 0 else 0
                    ),
                    "total_trades": total_trades,
                }

            summary["timeframe_statistics"] = timeframe_stats

            return summary

        except Exception as e:
            logger.error(f"Learning summary generation failed: {e}")
            return {"error": str(e)}

    def add_parameter_update_callback(self, callback: Callable):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ """
        self.parameter_update_callbacks.append(callback)

    def reset_statistics(self):
        """çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"""
        try:
            # çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ
            for key in self.feedback_stats:
                self.feedback_stats[key] = 0

            # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
            self.feedback_events.clear()
            self.learning_insights.clear()
            self.parameter_history.clear()

            for timeframe in self.timeframes:
                for category in self.prediction_analysis[timeframe]:
                    self.prediction_analysis[timeframe][category].clear()
                for category in self.trade_analysis[timeframe]:
                    self.trade_analysis[timeframe][category].clear()

            logger.info("ğŸ“Š Feedback loop manager statistics reset")

        except Exception as e:
            logger.error(f"Statistics reset failed: {e}")


# ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°


def create_feedback_loop_manager(config: Dict[str, Any]) -> FeedbackLoopManager:
    """
    ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ

    Parameters:
    -----------
    config : Dict[str, Any]
        è¨­å®šè¾æ›¸

    Returns:
    --------
    FeedbackLoopManager
        åˆæœŸåŒ–æ¸ˆã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    """
    return FeedbackLoopManager(config)
