"""
INITæ®µéšã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ç‰ˆ
Phase 2.2: INITæ®µéšã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ãƒ»ATRè¨ˆç®—æ”¹å–„

main.pyã®INIT-5ï½INIT-8æ®µéšã‚’å¼·åŒ–ã—ãŸç‰ˆ
"""

import logging
import time
from typing import Any, Optional

import pandas as pd

logger = logging.getLogger(__name__)


def enhanced_init_5_fetch_price_data(
    fetcher, dd: dict, max_retries: int = 5, timeout: int = 120
) -> Optional[pd.DataFrame]:
    """
    INIT-5æ®µéš: åˆæœŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå¼·åŒ–ç‰ˆï¼‰

    Args:
        fetcher: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        dd: ãƒ‡ãƒ¼ã‚¿è¨­å®šè¾æ›¸
        max_retries: æœ€å¤§å†è©¦è¡Œå›æ•°
        timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°ï¼ˆPhase H.7: 60â†’120ç§’å»¶é•·ï¼‰

    Returns:
        DataFrame: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    logger.info("ğŸ“ˆ [INIT-5] Fetching initial price data for ATR calculation...")
    logger.info(f"â° [INIT-5] Timestamp: {pd.Timestamp.now()}")
    logger.info(
        f"ğŸ”§ [INIT-5] Configuration: max_retries={max_retries}, timeout={timeout}s (Phase H.7å»¶é•·)"
    )

    # Phase H.6.1: å‹•çš„sinceè¨ˆç®—ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    current_time = pd.Timestamp.now(tz="UTC")

    if dd.get("since"):
        since_time = pd.Timestamp(dd["since"])
        if since_time.tz is None:
            since_time = since_time.tz_localize("UTC")
        logger.info(f"ğŸ”§ [INIT-5] Using config since: {since_time}")
    else:
        # å‹•çš„since_hoursè¨ˆç®—ï¼ˆåœŸæ—¥ã‚®ãƒ£ãƒƒãƒ—ãƒ»ç¥æ—¥å¯¾å¿œï¼‰
        base_hours = dd.get("since_hours", 120)  # Phase H.5.3: 120æ™‚é–“ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        # æ›œæ—¥åˆ¤å®šï¼ˆæœˆæ›œæ—¥=0, æ—¥æ›œæ—¥=6ï¼‰
        current_day = current_time.dayofweek
        current_hour = current_time.hour

        # åœŸæ—¥ã‚®ãƒ£ãƒƒãƒ—å¯¾å¿œ
        if current_day == 0:  # æœˆæ›œæ—¥
            # æœˆæ›œæ—¥ã¯åœŸæ—¥ã‚®ãƒ£ãƒƒãƒ—ã‚’è€ƒæ…®ã—ã¦å»¶é•·
            extended_hours = dd.get("weekend_extension_hours", 72)  # 3æ—¥é–“è¿½åŠ 
            lookback_hours = base_hours + extended_hours
            logger.info(
                f"ğŸ”§ [INIT-5] Monday detected: extending lookback by {extended_hours}h to {lookback_hours}h"
            )
        elif current_day == 1 and current_hour < 12:  # ç«æ›œæ—¥åˆå‰
            # ç«æ›œæ—¥åˆå‰ã‚‚å°‘ã—å»¶é•·
            extended_hours = dd.get("early_week_extension_hours", 36)  # 1.5æ—¥è¿½åŠ 
            lookback_hours = base_hours + extended_hours
            logger.info(
                f"ğŸ”§ [INIT-5] Tuesday morning: extending by {extended_hours}h to {lookback_hours}h"
            )
        else:
            lookback_hours = base_hours

        since_time = current_time - pd.Timedelta(hours=lookback_hours)
        logger.info(
            f"ğŸ” [INIT-5] Dynamic since calculation - Day: {current_day}, Hour: {current_hour}, "
            f"Lookback: {lookback_hours}h, Since: {since_time}"
        )
        logger.info(
            f"   â° Time span: {lookback_hours} hours ({lookback_hours/24:.1f} days)"
        )
        logger.info(f"   ğŸ“Š Expected 1h records: ~{lookback_hours}")

    # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã®åˆæœŸåŒ–ç¢ºèª
    try:
        logger.info("ğŸ” [INIT-5] Verifying external data fetchers...")

        # yfinanceä¾å­˜é–¢ä¿‚ç¢ºèª
        import yfinance  # noqa: F401

        logger.info("âœ… [INIT-5] yfinance module verified")

        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        try:
            from crypto_bot.data.vix_fetcher import VIXDataFetcher

            vix_fetcher = VIXDataFetcher()  # noqa: F841
            logger.info("âœ… [INIT-5] VIX fetcher initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ [INIT-5] VIX fetcher initialization failed: {e}")

        try:
            from crypto_bot.data.macro_fetcher import MacroDataFetcher

            macro_fetcher = MacroDataFetcher()  # noqa: F841
            logger.info("âœ… [INIT-5] Macro fetcher initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ [INIT-5] Macro fetcher initialization failed: {e}")

        try:
            from crypto_bot.data.fear_greed_fetcher import FearGreedDataFetcher

            fear_greed_fetcher = FearGreedDataFetcher()  # noqa: F841
            logger.info("âœ… [INIT-5] Fear&Greed fetcher initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ [INIT-5] Fear&Greed fetcher initialization failed: {e}")

    except ImportError as e:
        logger.error(f"âŒ [INIT-5] External data fetcher dependency error: {e}")
        logger.error("âŒ [INIT-5] This will cause external data fetchers to fail")

    # ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†
    initial_df = None

    # Phase H.3.2: ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æˆ¦ç•¥å¯¾å¿œãƒ»INIT-5ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å¼·åˆ¶
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ˜ç¤ºçš„ã«å–å¾—ï¼ˆ4hç›´æ¥è¦æ±‚é˜²æ­¢ï¼‰
    base_timeframe = "1h"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # multi_timeframe_dataè¨­å®šã‹ã‚‰ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
    if "multi_timeframe_data" in dd and "base_timeframe" in dd["multi_timeframe_data"]:
        base_timeframe = dd["multi_timeframe_data"]["base_timeframe"]
        logger.info(
            f"ğŸ”§ [INIT-5] Using base_timeframe from multi_timeframe_data: {base_timeframe}"
        )
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®timeframeè¨­å®šã‚’ä½¿ç”¨ï¼ˆãŸã ã—4hã¯å¼·åˆ¶çš„ã«1hã«å¤‰æ›´ï¼‰
        timeframe_raw = dd.get("timeframe", "1h")
        if timeframe_raw == "4h":
            base_timeframe = "1h"  # 4hè¦æ±‚ã‚’å¼·åˆ¶çš„ã«1hã«å¤‰æ›
            logger.warning(
                "ğŸš¨ [INIT-5] Phase H.3.2: 4h timeframe detected, forcing to 1h (Bitbank API compatibility)"
            )
        else:
            base_timeframe = timeframe_raw
            logger.info(
                f"ğŸ”§ [INIT-5] Using timeframe from data config: {base_timeframe}"
            )

    timeframe = base_timeframe
    # Phase H.7.1: INIT-5å°‚ç”¨ã®è»½é‡è¨­å®šï¼ˆATRè¨ˆç®—ã«å¿…è¦ãªæœ€å°é™ï¼‰
    init_limit = 30  # ATRè¨ˆç®—ã«ååˆ†ãªé‡ï¼ˆperiod=14 + ãƒãƒƒãƒ•ã‚¡ï¼‰
    init_paginate = False  # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç„¡åŠ¹åŒ–ã§é«˜é€ŸåŒ–

    logger.info(
        f"ğŸ”§ [INIT-5] Phase H.7 Optimized: timeframe={timeframe}, limit={init_limit}, paginate={init_paginate}"
    )
    logger.info(
        "ğŸ”§ [INIT-5] Using lightweight settings for faster initialization (30 records, no pagination)"
    )

    for attempt in range(max_retries):
        try:
            start_time = time.time()
            logger.info(
                f"ğŸ”„ [INIT-5] Attempt {attempt + 1}/{max_retries} - "
                f"Fetching initial price data..."
            )

            # Cloud Runå¯¾å¿œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ãƒ‡ãƒ¼ã‚¿å–å¾—
            from concurrent.futures import ThreadPoolExecutor
            from concurrent.futures import TimeoutError as FutureTimeoutError

            def fetch_data():
                # Phase H.7.1: INIT-5å°‚ç”¨ã®è»½é‡è¨­å®šã‚’ä½¿ç”¨
                return fetcher.get_price_df(
                    timeframe=timeframe,
                    since=since_time,  # Phase H.6.1: sinceæ™‚åˆ»ã‚’è¿½åŠ 
                    limit=init_limit,  # Phase H.7.1: 30ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿
                    paginate=init_paginate,  # Phase H.7.1: Falseï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç„¡åŠ¹ï¼‰
                    per_page=30,  # Phase H.7.1: å˜ä¸€å‘¼ã³å‡ºã—ã§å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—
                    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç„¡åŠ¹ãªã®ã§ä»¥ä¸‹ã¯ä¸è¦ã ãŒå¿µã®ãŸã‚è¨­å®š
                    max_consecutive_empty=1,
                    max_consecutive_no_new=1,
                    max_attempts=1,
                )

            try:
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(fetch_data)
                    initial_df = future.result(timeout=timeout)

                fetch_time = time.time() - start_time
                logger.info(
                    f"âœ… [INIT-5] Initial price data fetched successfully: "
                    f"{len(initial_df)} records in {fetch_time:.2f}s"
                )
                logger.info(
                    "âœ… [INIT-5] Phase H.7 optimization successful - lightweight fetch completed"
                )

                # ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèª
                if initial_df is not None and not initial_df.empty:
                    required_columns = ["open", "high", "low", "close", "volume"]
                    missing_columns = [
                        col for col in required_columns if col not in initial_df.columns
                    ]

                    if missing_columns:
                        logger.warning(
                            f"âš ï¸ [INIT-5] Missing required columns: {missing_columns}"
                        )
                    else:
                        logger.info("âœ… [INIT-5] All required columns present")

                    # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ç¢ºèª
                    logger.info(
                        f"ğŸ“Š [INIT-5] Data range: "
                        f"{initial_df.index.min()} to {initial_df.index.max()}"
                    )
                    logger.info(
                        f"ğŸ“Š [INIT-5] Price range: "
                        f"{initial_df['close'].min():.2f} to "
                        f"{initial_df['close'].max():.2f}"
                    )

                break

            except (FutureTimeoutError, TimeoutError) as e:
                logger.error(f"â° [INIT-5] Timeout error: {e}")
                raise

        except Exception as e:
            fetch_time = time.time() - start_time
            error_str = str(e)

            # Phase F.4: APIåˆ¶é™ã‚¨ãƒ©ãƒ¼ç‰¹åˆ¥å‡¦ç†
            if "10000" in error_str or "rate limit" in error_str.lower():
                logger.error(
                    f"ğŸš¨ [INIT-5] API rate limit error detected (attempt {attempt + 1}): {e}"
                )
                # APIåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚ˆã‚Šé•·ã„å¾…æ©Ÿæ™‚é–“
                wait_time = min((attempt + 1) * 20, 120)  # æœ€å¤§2åˆ†å¾…æ©Ÿ
                logger.warning(
                    f"â³ [INIT-5] API limit backoff: waiting {wait_time}s for recovery..."
                )
            else:
                logger.error(
                    f"âŒ [INIT-5] Attempt {attempt + 1} failed after {fetch_time:.2f}s: {e}"
                )
                # é€šå¸¸ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ¨™æº–çš„ãªå¾…æ©Ÿæ™‚é–“
                wait_time = min((attempt + 1) * 10, 60)
                logger.info(
                    f"â³ [INIT-5] Standard backoff: waiting {wait_time}s before retry..."
                )

            if attempt < max_retries - 1:
                time.sleep(wait_time)
            else:
                logger.error(
                    f"âŒ [INIT-5] All {max_retries} attempts failed - "
                    "data fetch completely failed. Consider increasing timeout or reducing API load."
                )
                initial_df = None

    return initial_df


def enhanced_init_6_calculate_atr(
    initial_df: Optional[pd.DataFrame], period: int = 14
) -> Optional[pd.Series]:
    """
    INIT-6æ®µéš: ATRè¨ˆç®—ï¼ˆå¼·åŒ–ç‰ˆï¼‰

    Args:
        initial_df: åˆæœŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        period: ATRè¨ˆç®—æœŸé–“

    Returns:
        Series: ATRå€¤ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    logger.info("ğŸ”¢ [INIT-6] Calculating ATR...")
    logger.info(f"â° [INIT-6] Timestamp: {pd.Timestamp.now()}")
    logger.info(f"ğŸ”§ [INIT-6] ATR period: {period}")

    atr_series = None

    if initial_df is not None and not initial_df.empty:
        try:
            # ãƒ‡ãƒ¼ã‚¿å“è³ªã®å†ç¢ºèª
            required_columns = ["high", "low", "close"]
            missing_columns = [
                col for col in required_columns if col not in initial_df.columns
            ]

            if missing_columns:
                logger.error(
                    f"âŒ [INIT-6] Missing required columns for ATR: {missing_columns}"
                )
                return None

            # ATRè¨ˆç®—ã«å¿…è¦ãªæœ€å°ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ç¢ºèª
            min_records = period + 1
            if len(initial_df) < min_records:
                logger.error(
                    f"âŒ [INIT-6] Insufficient data for ATR calculation: "
                    f"{len(initial_df)} < {min_records}"
                )
                return None

            logger.info(
                f"ğŸ“Š [INIT-6] Data validation passed: "
                f"{len(initial_df)} records available"
            )

            # ATRè¨ˆç®—å®Ÿè¡Œ
            from crypto_bot.indicator.calculator import IndicatorCalculator

            calculator = IndicatorCalculator()

            start_time = time.time()
            atr_series = calculator.calculate_atr(initial_df, period=period)
            calc_time = time.time() - start_time

            logger.info(
                f"âœ… [INIT-6] ATR calculated successfully: "
                f"{len(atr_series)} values in {calc_time:.2f}s"
            )

            # ATRå€¤ã®å“è³ªç¢ºèª
            if atr_series is not None and not atr_series.empty:
                latest_atr = atr_series.iloc[-1]
                mean_atr = atr_series.mean()
                logger.info(
                    f"ğŸ“Š [INIT-6] ATR statistics: "
                    f"latest={latest_atr:.6f}, mean={mean_atr:.6f}"
                )

                # ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯
                if latest_atr <= 0 or latest_atr > 1.0:
                    logger.warning(
                        f"âš ï¸ [INIT-6] ATR value may be unusual: {latest_atr}"
                    )  # noqa: E501

            else:
                logger.error("âŒ [INIT-6] ATR calculation returned empty series")
                atr_series = None

        except Exception as e:
            logger.error(f"âŒ [INIT-6] ATR calculation failed: {e}")
            logger.error(f"âŒ [INIT-6] Error type: {type(e).__name__}")
            atr_series = None

    else:
        logger.warning("âš ï¸ [INIT-6] No initial data available for ATR calculation")

    return atr_series


def enhanced_init_6_fallback_atr(period: int = 14) -> pd.Series:
    """
    INIT-6æ®µéš: ATRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ç”Ÿæˆï¼ˆå¼·åŒ–ç‰ˆï¼‰

    Args:
        period: ATRæœŸé–“

    Returns:
        Series: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ATRå€¤
    """
    logger.info("ğŸ”§ [INIT-6] Using enhanced fallback ATR calculation...")

    # ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’ç”Ÿæˆ
    # æš—å·è³‡ç”£ã®å…¸å‹çš„ãªATRå€¤: 0.005-0.02 (0.5%-2%)
    base_atr = 0.01  # 1%

    # æ™‚ç³»åˆ—çš„ã«å¤‰åŒ–ã™ã‚‹ATRå€¤ã‚’ç”Ÿæˆï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ï¼‰
    import numpy as np

    np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
    atr_values = []

    for _ in range(period):
        # åŸºæœ¬å€¤ã«å°ã•ãªå¤‰å‹•ã‚’åŠ ãˆã‚‹
        variation = np.random.normal(0, 0.001)  # 0.1%ã®æ¨™æº–åå·®
        atr_value = max(0.005, base_atr + variation)  # æœ€å°0.5%
        atr_values.append(atr_value)

    atr_series = pd.Series(atr_values)
    latest_atr = atr_series.iloc[-1]

    logger.info(
        f"âœ… [INIT-6] Enhanced fallback ATR generated: " f"{len(atr_series)} values"
    )
    logger.info(
        f"ğŸ“Š [INIT-6] Fallback ATR statistics: "
        f"latest={latest_atr:.6f}, mean={atr_series.mean():.6f}"
    )

    return atr_series


def enhanced_init_7_initialize_entry_exit(
    strategy, risk_manager, atr_series: pd.Series
) -> Any:
    """
    INIT-7æ®µéš: Entry/Exitã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆå¼·åŒ–ç‰ˆï¼‰

    Args:
        strategy: å–å¼•æˆ¦ç•¥
        risk_manager: ãƒªã‚¹ã‚¯ç®¡ç†
        atr_series: ATRå€¤

    Returns:
        EntryExit: Entry/Exitã‚·ã‚¹ãƒ†ãƒ 
    """
    logger.info("ğŸ¯ [INIT-7] Initializing Entry/Exit system...")
    logger.info(f"â° [INIT-7] Timestamp: {pd.Timestamp.now()}")

    try:
        # ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
        from crypto_bot.execution.engine import EntryExit

        # ATRå€¤ã®æœ€çµ‚ç¢ºèª
        if atr_series is None or atr_series.empty:
            logger.error("âŒ [INIT-7] ATR series is None or empty")
            raise ValueError("ATR series is required for Entry/Exit initialization")

        latest_atr = atr_series.iloc[-1]
        logger.info(f"ğŸ“Š [INIT-7] Using ATR value: {latest_atr:.6f}")

        # Entry/Exitã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        entry_exit = EntryExit(
            strategy=strategy, risk_manager=risk_manager, atr_series=atr_series
        )

        logger.info("âœ… [INIT-7] Entry/Exit system initialized successfully")
        return entry_exit

    except Exception as e:
        logger.error(f"âŒ [INIT-7] Entry/Exit system initialization failed: {e}")
        raise


def enhanced_init_8_clear_cache() -> None:
    """
    INIT-8æ®µéš: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    """
    logger.info("ğŸ§¹ [INIT-8] Clearing old cache for fresh data...")
    logger.info(f"â° [INIT-8] Timestamp: {pd.Timestamp.now()}")

    try:
        from crypto_bot.ml.external_data_cache import (
            clear_global_cache,
            get_global_cache,
        )

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã®ç¢ºèª
        cache = get_global_cache()
        cache_info = cache.get_cache_info()
        logger.info(f"ğŸ“Š [INIT-8] Cache info before clear: {cache_info}")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Ÿè¡Œ
        clear_global_cache()

        # ã‚¯ãƒªã‚¢å¾Œã®ç¢ºèª
        cache_info_after = cache.get_cache_info()
        logger.info(f"ğŸ“Š [INIT-8] Cache info after clear: {cache_info_after}")

        logger.info("âœ… [INIT-8] Cache cleared successfully")

    except Exception as e:
        logger.error(f"âŒ [INIT-8] Cache clear failed: {e}")
        logger.warning("âš ï¸ [INIT-8] Continuing without cache clear...")


# ä½¿ç”¨ä¾‹ï¼ˆmain.pyã§ã®ç½®ãæ›ãˆç”¨ï¼‰
def enhanced_init_sequence(fetcher, dd: dict, strategy, risk_manager, balance: float):
    """
    INIT-5ï½INIT-8ã®å¼·åŒ–ç‰ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹

    Args:
        fetcher: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        dd: ãƒ‡ãƒ¼ã‚¿è¨­å®š
        strategy: å–å¼•æˆ¦ç•¥
        risk_manager: ãƒªã‚¹ã‚¯ç®¡ç†
        balance: åˆæœŸæ®‹é«˜

    Returns:
        tuple: (entry_exit, position)
    """
    logger.info("ğŸš€ [INIT-ENHANCED] Starting enhanced initialization sequence...")

    # INIT-5: åˆæœŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    initial_df = enhanced_init_5_fetch_price_data(fetcher, dd)

    # INIT-6: ATRè¨ˆç®—ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    atr_series = enhanced_init_6_calculate_atr(initial_df)

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    if atr_series is None or atr_series.empty:
        logger.info("ğŸ”§ [INIT-6] Using enhanced fallback ATR calculation")
        atr_series = enhanced_init_6_fallback_atr()

    # INIT-7: Entry/ExitåˆæœŸåŒ–ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    entry_exit = enhanced_init_7_initialize_entry_exit(
        strategy, risk_manager, atr_series
    )
    entry_exit.current_balance = balance

    # INIT-8: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    enhanced_init_8_clear_cache()

    # PositionåˆæœŸåŒ–
    from crypto_bot.execution.engine import Position

    position = Position()

    logger.info(
        "âœ… [INIT-ENHANCED] Enhanced initialization sequence completed successfully"
    )

    return entry_exit, position
