# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«å: crypto_bot/strategy/multi_timeframe_ensemble.py
# èª¬æ˜:
# ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  Ã— ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’çµ±åˆæˆ¦ç•¥
# 15åˆ†è¶³ãƒ»1æ™‚é–“è¶³ãƒ»4æ™‚é–“è¶³ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã§å‹ç‡å‘ä¸Šã‚’å®Ÿç¾
# =============================================================================

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

from crypto_bot.data.multi_timeframe_fetcher import MultiTimeframeDataFetcher
from crypto_bot.execution.engine import Position, Signal
from crypto_bot.strategy.base import StrategyBase
from crypto_bot.strategy.ensemble_ml_strategy import EnsembleMLStrategy

logger = logging.getLogger(__name__)


class MultiTimeframeEnsembleStrategy(StrategyBase):
    """
    ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  Ã— ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’çµ±åˆæˆ¦ç•¥

    å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚’é©ç”¨ã—ã€
    ã•ã‚‰ã«ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§ã‚‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã‚’è¡Œã†2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
    """

    def __init__(self, config: dict):
        super().__init__()
        self.config = config

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¨­å®š
        multi_config = config.get("multi_timeframe", {})
        self.timeframes = multi_config.get("timeframes", ["15m", "1h", "4h"])
        self.weights = multi_config.get("weights", [0.3, 0.5, 0.2])

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆè¨­å®š
        ensemble_config = config.get("ml", {}).get("ensemble", {})
        self.ensemble_enabled = ensemble_config.get("enabled", True)
        self.ensemble_method = ensemble_config.get("method", "trading_stacking")
        self.confidence_threshold = ensemble_config.get("confidence_threshold", 0.65)

        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼åˆæœŸåŒ–
        self.multi_timeframe_fetcher = None
        self._base_fetcher = None  # å¾Œã§è¨­å®š

        # ãƒ‡ãƒ¼ã‚¿å“è³ªè¨­å®š
        data_config = multi_config.get("multi_timeframe_data", {})
        self.base_timeframe = data_config.get("base_timeframe", "1h")
        self.data_quality_threshold = multi_config.get("data_quality_threshold", 0.9)

        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥
        self.ensemble_strategies = {}
        self._initialize_ensemble_strategies()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
        self.data_cache = {}
        self.cache_timeout = timedelta(minutes=3)
        self.last_cache_time = {}
        self.prediction_history = []
        self.timeframe_performance = {}

        logger.info(
            f"Initialized Multi-Timeframe Ensemble Strategy: {self.timeframes} "
            f"with weights {self.weights}"
        )
        logger.info(f"  - Base timeframe: {self.base_timeframe}")
        logger.info(f"  - Data quality threshold: {self.data_quality_threshold}")

    def set_data_fetcher(self, base_fetcher):
        """
        ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã‚’è¨­å®šã—ã€ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆPhase H.2.2å¼·åŒ–ï¼‰

        Args:
            base_fetcher: MarketDataFetcher ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        try:
            self._base_fetcher = base_fetcher
            self.multi_timeframe_fetcher = MultiTimeframeDataFetcher(
                base_fetcher=base_fetcher,
                config=self.config,  # Phase H.2.2: å®Œå…¨ãªè¨­å®šã‚’æ¸¡ã™
                timeframes=self.timeframes,
                base_timeframe=self.base_timeframe,
                cache_enabled=True,
                data_quality_threshold=self.data_quality_threshold,
                synchronization_enabled=True,
            )
            logger.info(
                "âœ… Multi-timeframe data fetcher initialized with config support"
            )
            logger.info(f"  - Timeframes: {self.timeframes}")
            logger.info(f"  - Base timeframe: {self.base_timeframe}")
            logger.info(f"  - Quality threshold: {self.data_quality_threshold}")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize multi-timeframe fetcher: {e}")
            self.multi_timeframe_fetcher = None

    def _initialize_ensemble_strategies(self):
        """å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥åˆæœŸåŒ–"""
        for timeframe in self.timeframes:
            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥è¨­å®šä½œæˆ
            tf_config = self._create_timeframe_config(timeframe)

            try:
                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«MLæˆ¦ç•¥ä½œæˆ
                strategy = EnsembleMLStrategy(
                    model_path=None,  # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§ã¯ä¸è¦
                    threshold=None,
                    config=tf_config,
                )

                self.ensemble_strategies[timeframe] = strategy
                logger.info(f"Created ensemble strategy for {timeframe}")

            except Exception as e:
                logger.error(f"Failed to create ensemble strategy for {timeframe}: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬è¨­å®š
                self.ensemble_strategies[timeframe] = None

    def _create_timeframe_config(self, timeframe: str) -> Dict:
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥è¨­å®šä½œæˆ"""
        tf_config = self.config.copy()

        # ãƒ‡ãƒ¼ã‚¿è¨­å®šæ›´æ–°
        if "data" not in tf_config:
            tf_config["data"] = {
                "exchange": "csv",
                "csv_path": ("/Users/nao/Desktop/bot/data/btc_usd_2024_hourly.csv"),
                "symbol": "BTC/USDT",
            }

        tf_config["data"]["timeframe"] = timeframe

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ç‰¹å¾´é‡èª¿æ•´
        if "ml" not in tf_config:
            tf_config["ml"] = {}

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šï¼ˆå…¨ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã§æœ‰åŠ¹ï¼‰
        if "ensemble" not in tf_config["ml"]:
            tf_config["ml"]["ensemble"] = {
                "enabled": True,
                "method": "trading_stacking",
                "confidence_threshold": 0.65,
                "risk_adjustment": True,
            }

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ç‰¹å¾´é‡æœ€é©åŒ–
        if timeframe == "15m":
            # 15åˆ†è¶³: é«˜é »åº¦ãƒ»è»½é‡ç‰¹å¾´é‡
            tf_config["ml"]["extra_features"] = [
                "rsi_14",
                "rsi_7",
                "macd",
                "bb_percent",
                "volume_zscore",
                "vix",
                "momentum_14",
                "day_of_week",
                "hour_of_day",
                "price_change_1h",
                "volatility_1h",
                "breakout_signal",
            ]
            tf_config["ml"]["feat_period"] = 7
            # 15åˆ†è¶³ç”¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
            tf_config["ml"]["ensemble"]["confidence_threshold"] = 0.6  # ã‚ˆã‚Šç©æ¥µçš„

        elif timeframe == "4h":
            # 4æ™‚é–“è¶³: ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèªãƒ»é•·æœŸç‰¹å¾´é‡
            tf_config["ml"]["extra_features"] = [
                "sma_200",
                "sma_50",
                "ema_50",
                "adx",
                "dxy",
                "fear_greed",
                "trend_strength",
                "bb_width",
                "cmf",
                "support_resistance",
                "fibonacci_level",
                "central_bank_policy",
                "macro_regime",
            ]
            tf_config["ml"]["feat_period"] = 21
            # 4æ™‚é–“è¶³ç”¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
            tf_config["ml"]["ensemble"]["confidence_threshold"] = 0.7  # ã‚ˆã‚Šä¿å®ˆçš„

        else:  # 1h (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
            # 1æ™‚é–“è¶³: 101ç‰¹å¾´é‡ãƒ•ãƒ«ã‚»ãƒƒãƒˆ
            tf_config["ml"]["extra_features"] = self._get_full_feature_set()
            tf_config["ml"]["feat_period"] = 14
            # 1æ™‚é–“è¶³ç”¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
            tf_config["ml"]["ensemble"]["confidence_threshold"] = 0.65

        return tf_config

    def _get_full_feature_set(self) -> List[str]:
        """101ç‰¹å¾´é‡ãƒ•ãƒ«ã‚»ãƒƒãƒˆå–å¾—"""
        return [
            # VIXææ€–æŒ‡æ•°ï¼ˆ6ç‰¹å¾´é‡ï¼‰
            "vix",
            "vix_change",
            "vix_zscore",
            "vix_spike",
            "fear_level",
            "volatility_regime",
            # DXYãƒ»é‡‘åˆ©ï¼ˆ10ç‰¹å¾´é‡ï¼‰
            "dxy",
            "dxy_change",
            "us_10y",
            "yield_curve",
            "real_rates",
            "dollar_strength",
            "fed_funds_rate",
            "treasury_volatility",
            "currency_momentum",
            "rate_expectations",
            # Fear&Greedï¼ˆ13ç‰¹å¾´é‡ï¼‰
            "fear_greed",
            "fear_greed_ma",
            "fear_greed_change",
            "extreme_fear",
            "extreme_greed",
            "sentiment_regime",
            "sentiment_divergence",
            "social_sentiment",
            "options_sentiment",
            "momentum_sentiment",
            "volume_sentiment",
            "breadth_sentiment",
            "volatility_sentiment",
            # Funding Rateãƒ»OIï¼ˆ17ç‰¹å¾´é‡ï¼‰
            "funding",
            "funding_ma",
            "funding_change",
            "funding_extreme",
            "oi_change",
            "oi_volume_ratio",
            "leverage_ratio",
            "long_short_ratio",
            "liquidation_risk",
            "perpetual_basis",
            "futures_basis",
            "options_flow",
            "institutional_flow",
            "retail_sentiment",
            "whale_activity",
            "exchange_flows",
            "stablecoin_flows",
            # åŸºæœ¬ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ï¼ˆ20ç‰¹å¾´é‡ï¼‰
            "rsi_14",
            "rsi_7",
            "rsi_21",
            "macd",
            "macd_signal",
            "macd_histogram",
            "bb_percent",
            "bb_width",
            "sma_20",
            "sma_50",
            "sma_200",
            "ema_12",
            "ema_26",
            "ema_50",
            "adx",
            "cci",
            "williams_r",
            "stoch_k",
            "stoch_d",
            "momentum_14",
            # ãã®ä»–é‡è¦ç‰¹å¾´é‡ï¼ˆ35ç‰¹å¾´é‡ï¼‰
            "day_of_week",
            "hour_of_day",
            "mochipoyo_long_signal",
            "mochipoyo_short_signal",
            "price_change_1h",
            "price_change_4h",
            "price_change_24h",
            "volume_change_1h",
            "volume_change_24h",
            "volume_zscore",
            "volatility_1h",
            "volatility_24h",
            "support_resistance",
            "trend_strength",
            "breakout_signal",
            "reversal_signal",
            "fibonacci_level",
            "pivot_points",
            "bollinger_squeeze",
            "volume_profile",
            "order_flow",
            "market_microstructure",
            "cross_asset_correlation",
            "sector_rotation",
            "macro_regime",
            "central_bank_policy",
            "economic_surprises",
            "earnings_season",
            "options_expiry",
            "futures_rollover",
            "seasonal_patterns",
            "anomaly_detection",
            "regime_change",
            "tail_risk",
            "skewness",
        ]

    def logic_signal(self, price_df: pd.DataFrame, position: Position) -> Signal:
        """
        ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  Ã— ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ

        2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:
        1. å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
        2. ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
        """
        try:
            logger.debug("Multi-Timeframe Ensemble: Generating integrated signal")

            # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å–å¾—
            timeframe_predictions = self._get_timeframe_ensemble_predictions(price_df)

            if not timeframe_predictions:
                logger.warning("No timeframe predictions available")
                return Signal()

            # çµ±åˆã‚·ã‚°ãƒŠãƒ«è¨ˆç®—
            integrated_signal, signal_info = self._integrate_ensemble_signals(
                timeframe_predictions, position
            )

            # ã‚·ã‚°ãƒŠãƒ«åˆ¤å®š
            final_signal = self._make_final_signal_decision(
                integrated_signal, signal_info, price_df, position
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
            self._track_prediction_performance(
                timeframe_predictions, integrated_signal, signal_info
            )

            return final_signal

        except Exception as e:
            logger.error(f"Multi-timeframe ensemble signal generation failed: {e}")
            return Signal()

    def _get_timeframe_ensemble_predictions(
        self, price_df: pd.DataFrame
    ) -> Dict[str, Dict]:
        """å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å–å¾—"""
        predictions = {}

        for timeframe in self.timeframes:
            try:
                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—
                tf_data = self._get_timeframe_data(price_df, timeframe)

                if tf_data.empty:
                    logger.warning(f"No data available for {timeframe}")
                    continue

                strategy = self.ensemble_strategies.get(timeframe)
                if strategy is None:
                    logger.warning(f"No strategy available for {timeframe}")
                    continue

                # ãƒ€ãƒŸãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å–å¾—
                dummy_position = Position()
                dummy_position.exist = False

                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã§ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
                signal = strategy.logic_signal(tf_data, dummy_position)

                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©³ç´°æƒ…å ±å–å¾—
                ensemble_info = strategy.get_ensemble_performance_info()

                predictions[timeframe] = {
                    "signal": signal,
                    "ensemble_info": ensemble_info,
                    "data_quality": self._assess_data_quality(tf_data),
                }

                logger.debug(f"Got ensemble prediction for {timeframe}: {signal.side}")

            except Exception as e:
                logger.error(f"Failed to get ensemble prediction for {timeframe}: {e}")
                continue

        return predictions

    def _get_timeframe_data(
        self, price_df: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ–°ã—ã„MultiTimeframeDataFetcherä½¿ç”¨ï¼‰"""
        try:
            # MultiTimeframeDataFetcherãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ä½¿ç”¨
            if self.multi_timeframe_fetcher is not None:
                # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                multi_data = self.multi_timeframe_fetcher.get_multi_timeframe_data()
                if timeframe in multi_data:
                    logger.debug(
                        f"âœ… Got {timeframe} data from multi-timeframe fetcher: {len(multi_data[timeframe])} records"
                    )
                    return multi_data[timeframe]
                else:
                    logger.warning(
                        f"âš ï¸ {timeframe} not available from multi-timeframe fetcher"
                    )

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹å¼ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰
            cache_key = f"{timeframe}_data"
            current_time = datetime.now()

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if (
                cache_key in self.data_cache
                and cache_key in self.last_cache_time
                and current_time - self.last_cache_time[cache_key] < self.cache_timeout
            ):
                logger.debug(f"ğŸ“‹ Using cached {timeframe} data")
                return self.data_cache[cache_key]

            # å¾“æ¥ã®ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
            logger.debug(f"ğŸ”„ Fallback timeframe conversion for {timeframe}")

            if timeframe == "15m":
                # 1æ™‚é–“è¶³ã‹ã‚‰15åˆ†è¶³ã«è£œé–“
                tf_data = price_df.resample("15T").interpolate(method="linear")
            elif timeframe == "4h":
                # 1æ™‚é–“è¶³ã‹ã‚‰4æ™‚é–“è¶³ã«é›†ç´„
                tf_data = price_df.resample("4h").agg(
                    {
                        "open": "first",
                        "high": "max",
                        "low": "min",
                        "close": "last",
                        "volume": "sum",
                    }
                )
            else:  # 1h
                tf_data = price_df.copy()

            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆPhase H.9.3: å³åº§å–å¼•é–‹å§‹å¯¾å¿œãƒ»18è¡Œå®Ÿç¨¼åƒè¨±å¯ï¼‰
            if len(tf_data) < 18:  # æœ€å°ãƒ‡ãƒ¼ã‚¿è¦ä»¶ï¼ˆ50â†’18ã«ç·©å’Œãƒ»å®Ÿãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãç¾å®Ÿçš„è¨­å®šï¼‰
                logger.warning(
                    f"Insufficient data for {timeframe}: {len(tf_data)} rows (minimum: 18)"
                )
                return pd.DataFrame()
            elif len(tf_data) < 30:  # è»½åº¦è­¦å‘Šãƒ¬ãƒ™ãƒ«
                logger.info(
                    f"âš ï¸ Limited data for {timeframe}: {len(tf_data)} rows (recommended: 30+)"
                )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            self.data_cache[cache_key] = tf_data
            self.last_cache_time[cache_key] = current_time

            logger.debug(f"âœ… Generated {timeframe} data: {len(tf_data)} records")
            return tf_data

        except Exception as e:
            logger.error(f"âŒ Failed to generate {timeframe} data: {e}")
            return pd.DataFrame()

    def _assess_data_quality(self, data: pd.DataFrame) -> Dict[str, float]:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡"""
        if data.empty:
            return {"quality_score": 0.0}

        try:
            # åŸºæœ¬å“è³ªæŒ‡æ¨™
            total_cells = len(data) * len(data.columns)
            null_cells = data.isnull().sum().sum()
            completeness = 1.0 - (null_cells / total_cells)
            data_length_score = min(len(data) / 100.0, 1.0)  # 100è¡Œä»¥ä¸Šã§æº€ç‚¹

            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§
            price_validity = 1.0
            if "close" in data.columns:
                price_changes = data["close"].pct_change().abs()
                extreme_changes = (price_changes > 0.1).sum()  # 10%ä»¥ä¸Šã®å¤‰åŒ–
                if len(data) > 0:
                    price_validity = 1.0 - (extreme_changes / len(data))

            quality_score = (
                completeness * 0.4 + data_length_score * 0.3 + price_validity * 0.3
            )

            return {
                "quality_score": quality_score,
                "completeness": completeness,
                "data_length_score": data_length_score,
                "price_validity": price_validity,
            }

        except Exception as e:
            logger.error(f"Data quality assessment failed: {e}")
            return {"quality_score": 0.5}

    def _integrate_ensemble_signals(
        self, timeframe_predictions: Dict, position: Position
    ) -> Tuple[float, Dict]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚°ãƒŠãƒ«çµ±åˆ"""
        signal_values = []
        weights = []
        integration_info = {
            "timeframe_signals": {},
            "quality_weights": {},
            "ensemble_confidence": {},
            "method": "quality_weighted_ensemble",
        }

        for i, timeframe in enumerate(self.timeframes):
            if timeframe not in timeframe_predictions:
                continue

            prediction = timeframe_predictions[timeframe]
            signal = prediction["signal"]
            data_quality = prediction["data_quality"]
            ensemble_info = prediction["ensemble_info"]

            # ã‚·ã‚°ãƒŠãƒ«å€¤å¤‰æ›
            if signal.side == "BUY":
                signal_value = 0.75
            elif signal.side == "SELL":
                signal_value = 0.25
            else:
                signal_value = 0.5

            # å“è³ªèª¿æ•´é‡ã¿è¨ˆç®—
            base_weight = self.weights[i] if i < len(self.weights) else 0.1
            quality_score = data_quality.get("quality_score", 0.5)
            ensemble_confidence = ensemble_info.get("average_confidence", 0.5)

            # çµ±åˆé‡ã¿ï¼ˆåŸºæœ¬é‡ã¿ Ã— ãƒ‡ãƒ¼ã‚¿å“è³ª Ã— ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¿¡é ¼åº¦ï¼‰
            adjusted_weight = base_weight * quality_score * ensemble_confidence

            signal_values.append(signal_value)
            weights.append(adjusted_weight)

            # è©³ç´°æƒ…å ±è¨˜éŒ²
            integration_info["timeframe_signals"][timeframe] = signal_value
            integration_info["quality_weights"][timeframe] = adjusted_weight
            integration_info["ensemble_confidence"][timeframe] = ensemble_confidence

        # é‡ã¿ä»˜ãçµ±åˆè¨ˆç®—
        if signal_values and sum(weights) > 0:
            weighted_sum = sum(s * w for s, w in zip(signal_values, weights))
            integrated_signal = weighted_sum / sum(weights)
        else:
            integrated_signal = 0.5  # ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«

        integration_info["integrated_signal"] = integrated_signal
        integration_info["total_weight"] = sum(weights)
        integration_info["signal_consensus"] = self._calculate_consensus(signal_values)

        return integrated_signal, integration_info

    def _calculate_consensus(self, signal_values: List[float]) -> float:
        """ã‚·ã‚°ãƒŠãƒ«åˆæ„åº¦è¨ˆç®—"""
        if len(signal_values) < 2:
            return 1.0

        # æ¨™æº–åå·®ãƒ™ãƒ¼ã‚¹ã®åˆæ„åº¦ï¼ˆä½åˆ†æ•£ = é«˜åˆæ„åº¦ï¼‰
        std_dev = np.std(signal_values)
        max_std = 0.25  # æœ€å¤§æƒ³å®šæ¨™æº–åå·®
        consensus = 1.0 - min(std_dev / max_std, 1.0)

        return consensus

    def _make_final_signal_decision(
        self,
        integrated_signal: float,
        signal_info: Dict,
        price_df: pd.DataFrame,
        position: Position,
    ) -> Signal:
        """æœ€çµ‚ã‚·ã‚°ãƒŠãƒ«åˆ¤å®š"""
        if not price_df.empty:
            current_price = float(price_df["close"].iloc[-1])
        else:
            current_price = None

        if current_price is None:
            return Signal()

        # å‹•çš„é–¾å€¤è¨ˆç®—
        dynamic_threshold = self._calculate_multi_timeframe_threshold(signal_info)

        # åˆæ„åº¦ãƒã‚§ãƒƒã‚¯
        consensus = signal_info.get("signal_consensus", 0.0)
        min_consensus = 0.6  # æœ€ä½åˆæ„åº¦è¦ä»¶

        position_exists = position is not None and position.exist

        if position_exists:
            # ã‚¨ã‚°ã‚¸ãƒƒãƒˆåˆ¤å®š
            exit_threshold = (
                0.4 + (1.0 - consensus) * 0.1
            )  # ä½åˆæ„åº¦ã§ã¯æ—©ã‚ã«ã‚¨ã‚°ã‚¸ãƒƒãƒˆ

            if integrated_signal < exit_threshold:
                logger.info(
                    f"Multi-timeframe ensemble EXIT: "
                    f"signal={integrated_signal:.3f} < {exit_threshold:.3f}"
                )
                return Signal(side="SELL", price=current_price)

            return Signal()  # ãƒ›ãƒ¼ãƒ«ãƒ‰

        else:
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ¤å®š
            if (
                integrated_signal > (0.5 + dynamic_threshold)
                and consensus >= min_consensus
            ):
                logger.info(
                    f"Multi-timeframe ensemble LONG: signal={integrated_signal:.3f}, "
                    f"consensus={consensus:.3f}"
                )
                return Signal(side="BUY", price=current_price)

            elif (
                integrated_signal < (0.5 - dynamic_threshold)
                and consensus >= min_consensus
            ):
                logger.info(
                    f"Multi-timeframe ensemble SHORT: signal={integrated_signal:.3f}, "
                    f"consensus={consensus:.3f}"
                )
                return Signal(side="SELL", price=current_price)

            return Signal()  # ãƒ›ãƒ¼ãƒ«ãƒ‰

    def _calculate_multi_timeframe_threshold(self, signal_info: Dict) -> float:
        """ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å‹•çš„é–¾å€¤è¨ˆç®—"""
        base_threshold = self.confidence_threshold - 0.5  # åŸºæœ¬é–¾å€¤èª¿æ•´

        # ç·åˆå“è³ªã‚¹ã‚³ã‚¢
        total_weight = signal_info.get("total_weight", 1.0)
        quality_adjustment = min(total_weight, 1.0) * 0.05  # é«˜å“è³ªã»ã©ç©æ¥µçš„

        # åˆæ„åº¦èª¿æ•´
        consensus = signal_info.get("signal_consensus", 0.5)
        consensus_adjustment = (consensus - 0.5) * 0.1  # é«˜åˆæ„åº¦ã»ã©ç©æ¥µçš„

        dynamic_threshold = base_threshold - quality_adjustment - consensus_adjustment

        return max(0.05, min(0.2, dynamic_threshold))  # ç¯„å›²åˆ¶é™

    def _track_prediction_performance(
        self, timeframe_predictions: Dict, integrated_signal: float, signal_info: Dict
    ):
        """äºˆæ¸¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡"""
        prediction_record = {
            "timestamp": datetime.now(),
            "timeframe_predictions": timeframe_predictions,
            "integrated_signal": integrated_signal,
            "signal_info": signal_info,
        }

        self.prediction_history.append(prediction_record)

        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.prediction_history) > 100:
            self.prediction_history.pop(0)

    def get_multi_ensemble_info(self) -> Dict:
        """ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ Ã—ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆæƒ…å ±å–å¾—"""
        try:
            info = {
                "strategy_type": "multi_timeframe_ensemble",
                "timeframes": self.timeframes,
                "weights": self.weights,
                "ensemble_enabled": self.ensemble_enabled,
                "confidence_threshold": self.confidence_threshold,
                "prediction_history_size": len(self.prediction_history),
                "timeframe_strategies": {},
            }

            # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æƒ…å ±
            for timeframe, strategy in self.ensemble_strategies.items():
                if strategy:
                    try:
                        tf_info = strategy.get_ensemble_performance_info()
                        info["timeframe_strategies"][timeframe] = tf_info
                    except Exception as e:
                        info["timeframe_strategies"][timeframe] = {"error": str(e)}
                else:
                    info["timeframe_strategies"][timeframe] = {
                        "status": "not_available"
                    }

            # æœ€è¿‘ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
            if self.prediction_history:
                recent_predictions = self.prediction_history[-10:]
                info["recent_performance"] = self._analyze_recent_performance(
                    recent_predictions
                )

            return info

        except Exception as e:
            logger.error(f"Failed to get multi-ensemble info: {e}")
            return {"error": str(e)}

    def _analyze_recent_performance(self, recent_predictions: List[Dict]) -> Dict:
        """æœ€è¿‘ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        try:
            integrated_signals = [p["integrated_signal"] for p in recent_predictions]
            consensus_scores = [
                p["signal_info"].get("signal_consensus", 0.5)
                for p in recent_predictions
            ]

            return {
                "avg_integrated_signal": np.mean(integrated_signals),
                "signal_volatility": np.std(integrated_signals),
                "avg_consensus": np.mean(consensus_scores),
                "consensus_stability": np.std(consensus_scores),
                "prediction_count": len(recent_predictions),
            }

        except Exception as e:
            logger.error(f"Performance analysis failed: {e}")
            return {}
