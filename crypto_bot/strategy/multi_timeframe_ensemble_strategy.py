# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«å: crypto_bot/strategy/multi_timeframe_ensemble_strategy.py
# èª¬æ˜:
# Phase C1: 2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆæˆ¦ç•¥ï¼ˆå®Œå…¨ç‰ˆï¼‰
# æ—¢å­˜multi_timeframe_ensemble.pyæ”¹è‰¯ãƒ»Phase BåŸºç›¤çµ±åˆãƒ»Phase C1ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆ
# ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…Ã—ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’å®Œå…¨å®Ÿè£…
# =============================================================================

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

from crypto_bot.data.multi_timeframe_fetcher import MultiTimeframeDataFetcher
from crypto_bot.execution.engine import Position, Signal
from crypto_bot.ml.cross_timeframe_ensemble import create_cross_timeframe_integrator
from crypto_bot.ml.preprocessor import FeatureEngineer
from crypto_bot.ml.timeframe_ensemble import (
    TimeframeEnsembleProcessor,
    create_timeframe_ensemble_processor,
)
from crypto_bot.strategy.base import StrategyBase
from crypto_bot.utils.ensemble_confidence import EnsembleConfidenceCalculator

# Phase BåŸºç›¤çµ±åˆ
try:
    from crypto_bot.feature_engineering.batch_feature_calculator import (
        BatchFeatureCalculator,
    )
    from crypto_bot.feature_engineering.external_data_integrator import (
        ExternalDataIntegrator,
    )
    from crypto_bot.feature_engineering.technical_feature_engine import (
        TechnicalFeatureEngine,
    )

    PHASE_B_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ Phase BåŸºç›¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆæˆåŠŸ")
except ImportError as e:
    logger = logging.getLogger(__name__)
    logger.warning(f"âš ï¸ Phase BåŸºç›¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœªåˆ©ç”¨: {e}")
    PHASE_B_AVAILABLE = False

logger = logging.getLogger(__name__)


class MultiTimeframeEnsembleStrategy(StrategyBase):
    """
    Phase C1: 2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆæˆ¦ç•¥

    çµ±åˆæ©Ÿèƒ½:
    - Stage 1: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆ15m/1h/4hå„ã€…ã§è¤‡æ•°ãƒ¢ãƒ‡ãƒ«çµ±åˆï¼‰
    - Stage 2: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆ3ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ äºˆæ¸¬ã®é‡ã¿ä»˜ãçµ±åˆï¼‰
    - Phase BåŸºç›¤çµ±åˆ: BatchFeatureCalculatorãƒ»TechnicalFeatureEngineãƒ»ExternalDataIntegrator
    - Phase C1çµ±åˆ: çµ±ä¸€ä¿¡é ¼åº¦è¨ˆç®—ãƒ»å‹•çš„é‡ã¿èª¿æ•´ãƒ»å¸‚å ´ç’°å¢ƒé©å¿œ
    - 151ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨å¯¾å¿œãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    """

    def __init__(self, config: dict):
        """
        2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥åˆæœŸåŒ–

        Parameters:
        -----------
        config : dict
            æˆ¦ç•¥è¨­å®šè¾æ›¸ï¼ˆãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ»ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ»Phase Bè¨­å®šå«ã‚€ï¼‰
        """
        super().__init__()
        self.config = config

        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¨­å®š
        multi_config = config.get("multi_timeframe", {})
        self.timeframes = multi_config.get("timeframes", ["15m", "1h", "4h"])
        self.base_weights = multi_config.get("weights", [0.3, 0.5, 0.2])
        self.base_timeframe = multi_config.get("base_timeframe", "1h")
        self.data_quality_threshold = multi_config.get("data_quality_threshold", 0.9)

        logger.info(
            f"ğŸ”§ Strategy data quality threshold set to: {self.data_quality_threshold}"
        )

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
        ensemble_config = config.get("ml", {}).get("ensemble", {})
        self.ensemble_enabled = ensemble_config.get("enabled", True)
        self.ensemble_method = ensemble_config.get("method", "trading_stacking")
        self.confidence_threshold = ensemble_config.get("confidence_threshold", 0.65)

        # Phase C1çµ±åˆ: æ–°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
        self.confidence_calculator = EnsembleConfidenceCalculator(config)
        self.cross_timeframe_integrator = create_cross_timeframe_integrator(config)

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼è¾æ›¸
        self.timeframe_processors: Dict[str, TimeframeEnsembleProcessor] = {}

        # Phase BåŸºç›¤çµ±åˆåˆæœŸåŒ–
        if PHASE_B_AVAILABLE:
            self._initialize_phase_b_components()
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥æ–¹å¼
            self.feature_engineer = FeatureEngineer(config)
            self.batch_processor = None

        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼
        self.multi_timeframe_fetcher: Optional[MultiTimeframeDataFetcher] = None
        self._base_fetcher = None

        # çµ±åˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†
        self.data_cache = {}
        self.prediction_cache = {}
        self.cache_timeout = timedelta(minutes=3)
        self.last_cache_time = {}

        # çµ±è¨ˆãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
        self.strategy_stats = {
            "total_predictions": 0,
            "stage1_ensemble_predictions": 0,
            "stage2_integration_predictions": 0,
            "phase_b_batch_processing": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "high_confidence_signals": 0,
            "low_confidence_rejections": 0,
        }

        # å±¥æ­´ç®¡ç†
        self.prediction_history: List[Dict] = []
        self.performance_history: List[Dict] = []
        self.max_history_size = 100

        logger.info("ğŸš€ MultiTimeframeEnsembleStrategy (Phase C1) initialized")
        logger.info(f"   Timeframes: {self.timeframes}")
        logger.info(f"   Base weights: {self.base_weights}")
        logger.info(f"   Ensemble method: {self.ensemble_method}")
        logger.info(f"   Phase B integration: {PHASE_B_AVAILABLE}")

    def _initialize_phase_b_components(self):
        """Phase BåŸºç›¤ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        try:
            # BatchFeatureCalculatoråˆæœŸåŒ–
            self.batch_calculator = BatchFeatureCalculator(self.config)

            # TechnicalFeatureEngineåˆæœŸåŒ–
            self.technical_engine = TechnicalFeatureEngine(self.config)

            # ExternalDataIntegratoråˆæœŸåŒ–
            self.external_integrator = ExternalDataIntegrator(self.config)

            # çµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆPhase Bçµ±åˆç‰ˆï¼‰
            self.feature_engineer = FeatureEngineer(self.config)

            logger.info("âœ… Phase BåŸºç›¤çµ±åˆå®Œäº†")
            self.phase_b_integrated = True

        except Exception as e:
            logger.error(f"âŒ Phase BåŸºç›¤çµ±åˆå¤±æ•—: {e}")
            logger.info("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥æ–¹å¼ä½¿ç”¨")
            self.feature_engineer = FeatureEngineer(self.config)
            self.phase_b_integrated = False

    def _initialize_timeframe_processors(self):
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–"""
        for timeframe in self.timeframes:
            try:
                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹åŒ–è¨­å®šä½œæˆ
                tf_config = self._create_timeframe_specific_config(timeframe)

                # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ä½œæˆï¼ˆPhase C1ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
                processor = create_timeframe_ensemble_processor(
                    timeframe=timeframe,
                    config=tf_config,
                    feature_engineer=self.feature_engineer,  # Phase Bçµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
                )

                self.timeframe_processors[timeframe] = processor
                logger.info(f"âœ… {timeframe} ensemble processor created")

            except Exception as e:
                logger.error(f"âŒ Failed to create {timeframe} processor: {e}")
                self.timeframe_processors[timeframe] = None

    def _create_timeframe_specific_config(self, timeframe: str) -> Dict:
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹åŒ–è¨­å®šä½œæˆ"""
        tf_config = self.config.copy()

        # ãƒ‡ãƒ¼ã‚¿è¨­å®šæ›´æ–°
        if "data" not in tf_config:
            tf_config["data"] = {}
        tf_config["data"]["timeframe"] = timeframe

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ç‰¹å¾´é‡æœ€é©åŒ–
        if timeframe == "15m":
            # 15åˆ†è¶³: é«˜é »åº¦ãƒ»è»½é‡ç‰¹å¾´é‡
            tf_config["ml"]["extra_features"] = self._get_short_term_features()
            tf_config["ml"]["feat_period"] = 7
            tf_config["ml"]["ensemble"]["confidence_threshold"] = 0.6  # ã‚ˆã‚Šç©æ¥µçš„

        elif timeframe == "4h":
            # 4æ™‚é–“è¶³: ãƒˆãƒ¬ãƒ³ãƒ‰ç¢ºèªãƒ»é•·æœŸç‰¹å¾´é‡
            tf_config["ml"]["extra_features"] = self._get_long_term_features()
            tf_config["ml"]["feat_period"] = 21
            tf_config["ml"]["ensemble"]["confidence_threshold"] = 0.7  # ã‚ˆã‚Šä¿å®ˆçš„

        else:  # 1h (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
            # 1æ™‚é–“è¶³: 151ç‰¹å¾´é‡ãƒ•ãƒ«ã‚»ãƒƒãƒˆ
            tf_config["ml"]["extra_features"] = self._get_full_feature_set()
            tf_config["ml"]["feat_period"] = 14
            tf_config["ml"]["ensemble"]["confidence_threshold"] = 0.65  # ãƒãƒ©ãƒ³ã‚¹å‹

        return tf_config

    def _get_short_term_features(self) -> List[str]:
        """çŸ­æœŸå–å¼•ç”¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆï¼ˆ15åˆ†è¶³ç‰¹åŒ–ï¼‰"""
        return [
            "rsi_14",
            "rsi_7",
            "macd",
            "bb_percent",
            "volume_zscore",
            "vix",
            "momentum_14",
            "day_of_week",
            "hour_of_day",
            "price_change_1h",
            "volatility_1h",
            "breakout_signal",
            "stoch",
            "willr",
            "adx",
            "cmf",
            "atr_7",
        ]

    def _get_long_term_features(self) -> List[str]:
        """é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ç”¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆï¼ˆ4æ™‚é–“è¶³ç‰¹åŒ–ï¼‰"""
        return [
            "sma_200",
            "sma_50",
            "ema_50",
            "adx",
            "dxy",
            "fear_greed",
            "trend_strength",
            "bb_width",
            "cmf",
            "support_resistance",
            "fibonacci_level",
            "central_bank_policy",
            "macro_regime",
            "vix",
            "funding",
            "cross_correlation",
            "regime_detection",
        ]

    def _get_full_feature_set(self) -> List[str]:
        """151ç‰¹å¾´é‡ãƒ•ãƒ«ã‚»ãƒƒãƒˆï¼ˆ1æ™‚é–“è¶³ãƒ»ãƒ¡ã‚¤ãƒ³ï¼‰"""
        # æ—¢å­˜multi_timeframe_ensemble.pyã‹ã‚‰æŠ½å‡ºãƒ»Phase C1å¯¾å¿œæ”¹è‰¯
        return [
            # VIXææ€–æŒ‡æ•°ï¼ˆ6ç‰¹å¾´é‡ï¼‰
            "vix",
            "vix_change",
            "vix_zscore",
            "vix_spike",
            "fear_level",
            "volatility_regime",
            # DXYãƒ»é‡‘åˆ©ï¼ˆ10ç‰¹å¾´é‡ï¼‰
            "dxy",
            "dxy_change",
            "us_10y",
            "yield_curve",
            "real_rates",
            "dollar_strength",
            "fed_funds_rate",
            "treasury_volatility",
            "currency_momentum",
            "rate_expectations",
            # Fear&Greedï¼ˆ13ç‰¹å¾´é‡ï¼‰
            "fear_greed",
            "fear_greed_ma",
            "fear_greed_change",
            "extreme_fear",
            "extreme_greed",
            "sentiment_regime",
            "sentiment_divergence",
            "social_sentiment",
            "options_sentiment",
            "momentum_sentiment",
            "volume_sentiment",
            "breadth_sentiment",
            "volatility_sentiment",
            # Funding Rateãƒ»OIï¼ˆ17ç‰¹å¾´é‡ï¼‰
            "funding",
            "funding_ma",
            "funding_change",
            "funding_extreme",
            "oi_change",
            "oi_volume_ratio",
            "leverage_ratio",
            "long_short_ratio",
            "liquidation_risk",
            "perpetual_basis",
            "futures_basis",
            "options_flow",
            "institutional_flow",
            "retail_sentiment",
            "whale_activity",
            "exchange_flows",
            "stablecoin_flows",
            # åŸºæœ¬ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ï¼ˆ20ç‰¹å¾´é‡ï¼‰
            "rsi_14",
            "rsi_7",
            "rsi_21",
            "macd",
            "macd_signal",
            "macd_histogram",
            "bb_percent",
            "bb_width",
            "sma_20",
            "sma_50",
            "sma_200",
            "ema_12",
            "ema_26",
            "ema_50",
            "adx",
            "cci",
            "williams_r",
            "stoch_k",
            "stoch_d",
            "momentum_14",
            # Phase 3.2A-Dé«˜åº¦ç‰¹å¾´é‡ï¼ˆ65ç‰¹å¾´é‡ï¼‰
            "price_position",
            "candle_patterns",
            "support_resistance",
            "breakout_signals",
            "autocorrelation",
            "seasonal_patterns",
            "regime_detection",
            "cycle_analysis",
            "cross_correlation",
            "relative_strength",
            "spread_analysis",
            "volatility_regime",
            "momentum_signals",
            "liquidity_indicators",
            # æ™‚é–“ãƒ»ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ï¼ˆ20ç‰¹å¾´é‡ï¼‰
            "day_of_week",
            "hour_of_day",
            "mochipoyo_long_signal",
            "mochipoyo_short_signal",
            "price_change_1h",
            "price_change_4h",
            "price_change_24h",
            "volume_change_1h",
            "volume_change_24h",
            "volume_zscore",
            "volatility_1h",
            "volatility_24h",
            "trend_strength",
            "breakout_signal",
            "reversal_signal",
            "fibonacci_level",
            "pivot_points",
            "bollinger_squeeze",
            "volume_profile",
            "order_flow",
        ]

    def set_data_fetcher(self, base_fetcher):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼è¨­å®šãƒ»åˆæœŸåŒ–"""
        try:
            self._base_fetcher = base_fetcher

            # MultiTimeframeDataFetcheråˆæœŸåŒ–
            self.multi_timeframe_fetcher = MultiTimeframeDataFetcher(
                base_fetcher=base_fetcher,
                config=self.config,
                timeframes=self.timeframes,
                base_timeframe=self.base_timeframe,
                cache_enabled=True,
                data_quality_threshold=self.data_quality_threshold,
            )

            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
            self._initialize_timeframe_processors()

            logger.info("âœ… Multi-timeframe data fetcher & processors initialized")

        except Exception as e:
            logger.error(f"âŒ Failed to initialize data fetcher: {e}")
            self.multi_timeframe_fetcher = None

    def fit_ensemble_models(self, price_df: pd.DataFrame, y: pd.Series):
        """å…¨ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        if not self.timeframe_processors:
            logger.error("Timeframe processors not initialized")
            return

        logger.info("ğŸ¯ Training multi-timeframe ensemble models")
        logger.info(
            f"ğŸ“Š Original data shape: {tuple(price_df.shape)}, label shape: {tuple(y.shape)}"
        )

        for timeframe, processor in self.timeframe_processors.items():
            if processor is None:
                continue

            try:
                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿æº–å‚™
                tf_data = self._get_timeframe_data(price_df, timeframe)
                if tf_data.empty:
                    logger.warning(f"No data for {timeframe} training")
                    continue

                logger.info(f"ğŸ“Š {timeframe} data shape: {tuple(tf_data.shape)}")

                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ
                tf_labels = self._generate_timeframe_labels(
                    tf_data, price_df, y, timeframe
                )

                if tf_labels is None or len(tf_labels) == 0:
                    logger.warning(f"âš ï¸ Failed to generate labels for {timeframe}")
                    continue

                logger.info(f"ğŸ“Š {timeframe} labels shape: {tuple(tf_labels.shape)}")

                # ãƒ‡ãƒ¼ã‚¿ã¨ãƒ©ãƒ™ãƒ«ã®é•·ã•ã‚’ç¢ºèª
                if len(tf_data) != len(tf_labels):
                    logger.error(
                        f"âŒ {timeframe} data/label mismatch: data={len(tf_data)}, labels={len(tf_labels)}"
                    )
                    continue

                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                processor.fit(tf_data, tf_labels)
                logger.info(f"âœ… {timeframe} ensemble model trained successfully")
                logger.info(f"   - Processor fitted: {processor.is_fitted}")

            except Exception as e:
                logger.error(f"âŒ {timeframe} ensemble training failed: {e}")
                logger.error(f"   - Error type: {type(e).__name__}")
                logger.error(f"   - Error details: {str(e)}")

    def logic_signal(self, price_df: pd.DataFrame, position: Position) -> Signal:
        """
        Phase C1: 2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ

        Stage 1: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆå„15m/1h/4hã§è¤‡æ•°ãƒ¢ãƒ‡ãƒ«çµ±åˆï¼‰
        Stage 2: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆ3ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ äºˆæ¸¬é‡ã¿ä»˜ãçµ±åˆï¼‰
        """
        self.strategy_stats["total_predictions"] += 1
        start_time = datetime.now()

        try:
            logger.info(
                "ğŸš€ [LOGIC-SIGNAL] Phase C1: 2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆé–‹å§‹"
            )
            logger.info(
                f"ğŸ“Š [LOGIC-SIGNAL] Input price_df shape: {tuple(price_df.shape)}"
            )
            logger.info(f"ğŸ“Š [LOGIC-SIGNAL] Position exists: {position.exist}")

            # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã®ç¢ºèªãƒ­ã‚°
            logger.info("ğŸ” [LOGIC-SIGNAL] Checking ensemble model states...")
            if hasattr(self, "timeframe_processors"):
                for tf, processor in self.timeframe_processors.items():
                    if processor:
                        logger.info(
                            f"  - {tf} processor: fitted={processor.is_fitted}, enabled={processor.ensemble_enabled}"
                        )
                    else:
                        logger.warning(f"  - {tf} processor: NOT INITIALIZED")
            else:
                logger.error("âŒ [LOGIC-SIGNAL] No timeframe processors found!")

            # å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            logger.info("ğŸ”„ [LOGIC-SIGNAL] Step 1: å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆé–‹å§‹")
            context_start = datetime.now()
            market_context = self._generate_market_context(price_df)
            context_elapsed = (datetime.now() - context_start).total_seconds()
            logger.info(
                f"âœ… [LOGIC-SIGNAL] Step 1å®Œäº†: å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ ({context_elapsed:.2f}ç§’)"
            )
            logger.debug(f"ğŸ“Š [LOGIC-SIGNAL] Market context: {market_context}")

            # Stage 1: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œ
            logger.info(
                "ğŸ”„ [LOGIC-SIGNAL] Step 2: Stage 1 ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬é–‹å§‹"
            )
            stage1_start = datetime.now()
            timeframe_predictions = self._execute_stage1_ensemble_predictions(
                price_df, market_context
            )
            stage1_elapsed = (datetime.now() - stage1_start).total_seconds()
            logger.info(
                f"âœ… [LOGIC-SIGNAL] Step 2å®Œäº†: Stage 1äºˆæ¸¬ ({stage1_elapsed:.2f}ç§’)"
            )
            logger.info(
                f"ğŸ“Š [LOGIC-SIGNAL] Timeframe predictions count: {len(timeframe_predictions)}"
            )

            if not timeframe_predictions:
                logger.warning(
                    "âš ï¸ [LOGIC-SIGNAL] No Stage 1 predictions available - returning empty signal"
                )
                total_elapsed = (datetime.now() - start_time).total_seconds()
                logger.info(
                    f"ğŸ [LOGIC-SIGNAL] å‡¦ç†çµ‚äº†ï¼ˆç©ºã‚·ã‚°ãƒŠãƒ«ï¼‰ - ç·å‡¦ç†æ™‚é–“: {total_elapsed:.2f}ç§’"
                )
                return Signal()

            # Stage 2: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
            logger.info(
                "ğŸ”„ [LOGIC-SIGNAL] Step 3: Stage 2 ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆé–‹å§‹"
            )
            stage2_start = datetime.now()
            integrated_signal, integration_info = self._execute_stage2_integration(
                timeframe_predictions, market_context
            )
            stage2_elapsed = (datetime.now() - stage2_start).total_seconds()
            logger.info(
                f"âœ… [LOGIC-SIGNAL] Step 3å®Œäº†: Stage 2çµ±åˆ ({stage2_elapsed:.2f}ç§’)"
            )
            # Phase H.20.1.1: numpyé…åˆ—å®‰å…¨å‡¦ç†
            safe_signal = (
                float(integrated_signal)
                if hasattr(integrated_signal, "__len__")
                else float(integrated_signal)
            )
            logger.info(f"ğŸ“Š [LOGIC-SIGNAL] Integrated signal: {safe_signal:.3f}")

            # æœ€çµ‚ã‚·ã‚°ãƒŠãƒ«åˆ¤å®š
            logger.info("ğŸ”„ [LOGIC-SIGNAL] Step 4: æœ€çµ‚ã‚·ã‚°ãƒŠãƒ«åˆ¤å®šé–‹å§‹")
            decision_start = datetime.now()
            final_signal = self._make_final_ensemble_decision(
                integrated_signal, integration_info, price_df, position
            )
            decision_elapsed = (datetime.now() - decision_start).total_seconds()
            logger.info(
                f"âœ… [LOGIC-SIGNAL] Step 4å®Œäº†: æœ€çµ‚åˆ¤å®š ({decision_elapsed:.2f}ç§’)"
            )
            logger.info(
                f"ğŸ“Š [LOGIC-SIGNAL] Final signal: side={final_signal.side}, price={final_signal.price}"
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
            logger.info("ğŸ”„ [LOGIC-SIGNAL] Step 5: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡é–‹å§‹")
            track_start = datetime.now()
            self._track_ensemble_performance(
                timeframe_predictions, integrated_signal, integration_info, final_signal
            )
            track_elapsed = (datetime.now() - track_start).total_seconds()
            logger.info(
                f"âœ… [LOGIC-SIGNAL] Step 5å®Œäº†: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ ({track_elapsed:.2f}ç§’)"
            )

            total_elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(
                f"ğŸ [LOGIC-SIGNAL] å‡¦ç†å®Œäº† - ç·å‡¦ç†æ™‚é–“: {total_elapsed:.2f}ç§’"
            )
            return final_signal

        except Exception as e:
            total_elapsed = (datetime.now() - start_time).total_seconds()
            logger.error(f"âŒ [LOGIC-SIGNAL] Phase C1 2æ®µéšã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¤±æ•—: {e}")
            logger.error(
                f"ğŸ [LOGIC-SIGNAL] ã‚¨ãƒ©ãƒ¼çµ‚äº† - å‡¦ç†æ™‚é–“: {total_elapsed:.2f}ç§’"
            )
            import traceback

            logger.error(f"ğŸ“‹ [LOGIC-SIGNAL] Stack trace: {traceback.format_exc()}")
            return Signal()

    def _execute_stage1_ensemble_predictions(
        self, price_df: pd.DataFrame, market_context: Dict
    ) -> Dict[str, Dict]:
        """Stage 1: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œ"""
        predictions = {}
        self.strategy_stats["stage1_ensemble_predictions"] += 1

        for timeframe in self.timeframes:
            try:
                processor = self.timeframe_processors.get(timeframe)
                if processor is None:
                    logger.warning(f"No processor for {timeframe}")
                    continue

                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿å–å¾—
                tf_data = self._get_timeframe_data(price_df, timeframe)
                if tf_data.empty:
                    logger.warning(f"No data for {timeframe}")
                    continue

                # Phase BåŸºç›¤çµ±åˆ: ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
                if PHASE_B_AVAILABLE and hasattr(self, "batch_calculator"):
                    tf_data = self._apply_phase_b_processing(tf_data, timeframe)
                    self.strategy_stats["phase_b_batch_processing"] += 1

                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆPhase C1ã‚³ã‚¢æ©Ÿèƒ½ï¼‰
                pred_result, prob_result, conf_result, pred_info = (
                    processor.predict_with_confidence(tf_data, market_context)
                )

                predictions[timeframe] = {
                    "prediction": pred_result,
                    "probability": prob_result,
                    "confidence": conf_result,
                    "info": pred_info,
                }

                # Phase H.21.1: numpyé…åˆ—format stringä¿®æ­£ï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«å¾©æ´»ï¼‰
                safe_conf = (
                    float(conf_result[0])
                    if hasattr(conf_result[0], "__len__")
                    else float(conf_result[0])
                )
                logger.debug(f"âœ… Stage 1 {timeframe}: conf={safe_conf:.3f}")

            except Exception as e:
                logger.error(f"âŒ Stage 1 {timeframe} failed: {e}")
                continue

        return predictions

    def _apply_phase_b_processing(
        self, data: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """Phase BåŸºç›¤ãƒãƒƒãƒå‡¦ç†é©ç”¨"""
        try:
            # TechnicalFeatureEngineé©ç”¨
            technical_features = self.technical_engine.calculate_features(data)

            # ExternalDataIntegratoré©ç”¨
            external_features = self.external_integrator.integrate_external_data(data)

            # BatchFeatureCalculatoré©ç”¨
            batch_result = self.batch_calculator.calculate_batch_features(
                {
                    "price_data": data,
                    "technical_features": technical_features,
                    "external_features": external_features,
                    "timeframe": timeframe,
                }
            )

            return batch_result.get("processed_data", data)

        except Exception as e:
            logger.error(f"Phase B processing failed for {timeframe}: {e}")
            return data

    def _execute_stage2_integration(
        self, timeframe_predictions: Dict, market_context: Dict
    ) -> Tuple[float, Dict]:
        """Stage 2: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ"""
        self.strategy_stats["stage2_integration_predictions"] += 1

        # Phase C1çµ±åˆ: CrossTimeframeIntegratorä½¿ç”¨
        integrated_signal, integration_info = (
            self.cross_timeframe_integrator.integrate_timeframe_predictions(
                timeframe_predictions, market_context
            )
        )

        # Phase H.26: numpyé…åˆ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼å®Œå…¨ä¿®æ­£
        safe_signal = (
            float(integrated_signal.flat[0])
            if isinstance(integrated_signal, np.ndarray)
            else float(integrated_signal)
        )

        # consensus_scoreã‚‚å®‰å…¨ã«å‡¦ç†
        consensus_raw = integration_info.get("consensus_score", 0)
        safe_consensus = (
            float(consensus_raw.flat[0])
            if isinstance(consensus_raw, np.ndarray)
            else float(consensus_raw)
        )

        logger.debug(
            f"âœ… Stage 2 integration: signal={safe_signal:.3f}, "
            f"consensus={safe_consensus:.3f}"
        )

        return integrated_signal, integration_info

    def _generate_market_context(self, price_df: pd.DataFrame) -> Dict:
        """å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆPhase C1çµ±åˆç‰ˆï¼‰"""
        context = {}

        try:
            # åŸºæœ¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            if len(price_df) >= 20:
                returns = price_df["close"].pct_change().dropna()
                context["volatility"] = (
                    returns.rolling(20).std().iloc[-1] if len(returns) >= 20 else 0.02
                )
            else:
                context["volatility"] = 0.02

            # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
            if len(price_df) >= 50:
                sma_50 = price_df["close"].rolling(50).mean().iloc[-1]
                current_price = price_df["close"].iloc[-1]
                context["trend_strength"] = min(
                    abs(current_price - sma_50) / sma_50, 1.0
                )
            else:
                context["trend_strength"] = 0.5

            # VIXæƒ…å ±ï¼ˆå¤–éƒ¨ãƒ‡ãƒ¼ã‚¿çµ±åˆå¯¾å¿œï¼‰
            if PHASE_B_AVAILABLE and hasattr(self, "external_integrator"):
                external_data = self.external_integrator.get_latest_external_data()
                context["vix_level"] = external_data.get("vix", 20.0)
                context["dxy_level"] = external_data.get("dxy", 103.0)
                context["fear_greed"] = external_data.get("fear_greed", 50)
            else:
                context["vix_level"] = 20.0
                context["dxy_level"] = 103.0
                context["fear_greed"] = 50

            # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆPhase C1çµ±åˆï¼‰
            context["market_regime"] = self.confidence_calculator.assess_market_regime(
                context
            )

        except Exception as e:
            logger.error(f"Market context generation failed: {e}")

        return context

    def _get_timeframe_data(
        self, price_df: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
        cache_key = f"{timeframe}_data"
        current_time = datetime.now()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if (
            cache_key in self.data_cache
            and cache_key in self.last_cache_time
            and current_time - self.last_cache_time[cache_key] < self.cache_timeout
        ):
            self.strategy_stats["cache_hits"] += 1
            return self.data_cache[cache_key]

        self.strategy_stats["cache_misses"] += 1

        try:
            # MultiTimeframeDataFetcherä½¿ç”¨ï¼ˆå„ªå…ˆï¼‰
            if self.multi_timeframe_fetcher is not None:
                multi_data = self.multi_timeframe_fetcher.get_multi_timeframe_data()
                if timeframe in multi_data:
                    tf_data = multi_data[timeframe]
                    logger.debug(
                        f"âœ… {timeframe} data from fetcher: {len(tf_data)} records"
                    )
                else:
                    tf_data = pd.DataFrame()
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥æ–¹å¼
                tf_data = self._convert_timeframe_data(price_df, timeframe)

            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆPhase H.9.3: å³åº§å–å¼•é–‹å§‹å¯¾å¿œãƒ»18è¡Œå®Ÿç¨¼åƒè¨±å¯ï¼‰
            if (
                len(tf_data) < 18
            ):  # æœ€å°ãƒ‡ãƒ¼ã‚¿è¦ä»¶ï¼ˆ50â†’18ã«ç·©å’Œãƒ»å®Ÿãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãç¾å®Ÿçš„è¨­å®šï¼‰
                logger.warning(
                    f"Insufficient {timeframe} data: {len(tf_data)} rows (minimum: 18)"
                )
            elif len(tf_data) < 20:  # è»½åº¦è­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼ˆrolling_window=10å¯¾å¿œï¼‰
                logger.info(
                    f"âš ï¸ Limited {timeframe} data: {len(tf_data)} rows (recommended: 20+)"
                )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            self.data_cache[cache_key] = tf_data
            self.last_cache_time[cache_key] = current_time

            return tf_data

        except Exception as e:
            logger.error(f"âŒ Failed to get {timeframe} data: {e}")
            return pd.DataFrame()

    def _convert_timeframe_data(
        self, price_df: pd.DataFrame, timeframe: str
    ) -> pd.DataFrame:
        """å¾“æ¥æ–¹å¼ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›"""
        try:
            if timeframe == "15m":
                return price_df.resample("15T").interpolate(method="linear")
            elif timeframe == "4h":
                return price_df.resample("4h").agg(
                    {
                        "open": "first",
                        "high": "max",
                        "low": "min",
                        "close": "last",
                        "volume": "sum",
                    }
                )
            else:  # 1h
                return price_df.copy()
        except Exception as e:
            logger.error(f"Timeframe conversion failed for {timeframe}: {e}")
            return pd.DataFrame()

    def _generate_timeframe_labels(
        self,
        tf_data: pd.DataFrame,
        original_df: pd.DataFrame,
        original_y: pd.Series,
        timeframe: str,
    ) -> pd.Series:
        """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ

        Args:
            tf_data: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿
            original_df: å…ƒã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆ1æ™‚é–“è¶³ï¼‰
            original_y: å…ƒã®ãƒ©ãƒ™ãƒ«
            timeframe: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ 

        Returns:
            pd.Series: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾å¿œã™ã‚‹ãƒ©ãƒ™ãƒ«
        """
        try:
            if tf_data.empty:
                logger.warning(f"Empty data for {timeframe} label generation")
                return pd.Series()

            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ä¾¡æ ¼å¤‰åŒ–ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ
            if timeframe == "15m":
                # 15åˆ†è¶³: æ¬¡ã®15åˆ†ã®ä¾¡æ ¼å¤‰åŒ–ã‚’äºˆæ¸¬
                price_change = tf_data["close"].pct_change().shift(-1)
                tf_labels = (price_change > 0).astype(int)

            elif timeframe == "4h":
                # 4æ™‚é–“è¶³: æ¬¡ã®4æ™‚é–“ã®ä¾¡æ ¼å¤‰åŒ–ã‚’äºˆæ¸¬
                price_change = tf_data["close"].pct_change().shift(-1)
                tf_labels = (price_change > 0).astype(int)

            else:  # 1h
                # 1æ™‚é–“è¶³: å…ƒã®ãƒ©ãƒ™ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§æ•´åˆæ€§ç¢ºä¿ï¼‰
                # tf_dataã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º
                common_index = tf_data.index.intersection(original_y.index)
                if len(common_index) == 0:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä¸€è‡´ã—ãªã„å ´åˆã¯ã€å…ƒã®ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨
                    tf_labels = original_y.iloc[: len(tf_data)]
                else:
                    tf_labels = original_y.loc[common_index]

            # NaNã‚’é™¤å»ï¼ˆæœ€å¾Œã®è¡Œã«ã¯ãƒ©ãƒ™ãƒ«ãŒãªã„ï¼‰
            tf_labels = tf_labels.dropna()

            # ãƒ‡ãƒ¼ã‚¿ã¨ãƒ©ãƒ™ãƒ«ã®é•·ã•ã‚’èª¿æ•´ï¼ˆæœ€å¾Œã®è¡Œã‚’é™¤å¤–ï¼‰
            if len(tf_data) > len(tf_labels):
                # tf_dataã®é•·ã•ã«åˆã‚ã›ã‚‹ãŸã‚ã€æœ€å¾Œã«NaNã‚’è¿½åŠ 
                nan_count = len(tf_data) - len(tf_labels)
                nan_series = pd.Series(
                    [np.nan] * nan_count, index=tf_data.index[-nan_count:]
                )
                tf_labels = pd.concat([tf_labels, nan_series])
                logger.debug(
                    f"ğŸ“Š {timeframe} labels padded with {nan_count} NaN values"
                )

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æƒãˆã‚‹
            tf_labels.index = tf_data.index

            logger.info(
                f"âœ… {timeframe} labels generated: {len(tf_labels)} labels, "
                f"non-NaN labels: {tf_labels.notna().sum()}, "
                f"positive rate: {tf_labels.dropna().mean():.2%}"
            )

            return tf_labels

        except Exception as e:
            logger.error(f"âŒ Failed to generate {timeframe} labels: {e}")
            logger.error(f"   - tf_data shape: {tuple(tf_data.shape)}")
            logger.error(f"   - original_y shape: {tuple(original_y.shape)}")
            return pd.Series()

    def _make_final_ensemble_decision(
        self,
        integrated_signal: float,
        integration_info: Dict,
        price_df: pd.DataFrame,
        position: Position,
    ) -> Signal:
        """æœ€çµ‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ¤å®šï¼ˆPhase C1çµ±åˆç‰ˆï¼‰"""
        if price_df.empty:
            return Signal()

        current_price = float(price_df["close"].iloc[-1])
        consensus_score = integration_info.get("consensus_score", 0.0)
        integration_quality = integration_info.get("integration_quality", "poor")

        # Phase H.26: consensus_scoreã®å®‰å…¨å‡¦ç†
        safe_consensus_score = (
            float(consensus_score.flat[0])
            if isinstance(consensus_score, np.ndarray)
            else float(consensus_score)
        )

        # ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if safe_consensus_score < self.cross_timeframe_integrator.consensus_threshold:
            logger.debug(f"ğŸš« Low consensus rejection: {safe_consensus_score:.3f}")
            self.strategy_stats["low_confidence_rejections"] += 1
            return Signal()

        # Phase C1çµ±åˆ: CrossTimeframeIntegratoræœ€çµ‚ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
        final_signal = self.cross_timeframe_integrator.create_final_signal(
            integrated_signal, integration_info, current_price, position.exist
        )

        if final_signal.side != "":  # æœ‰åŠ¹ã‚·ã‚°ãƒŠãƒ«
            self.strategy_stats["high_confidence_signals"] += 1
            logger.info(
                f"ğŸ¯ Phase C1 Final Signal: {final_signal.side}, "
                f"consensus={consensus_score:.3f}, quality={integration_quality}"
            )

        return final_signal

    def _track_ensemble_performance(
        self,
        timeframe_predictions: Dict,
        integrated_signal: float,
        integration_info: Dict,
        final_signal: Signal,
    ):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡"""
        record = {
            "timestamp": datetime.now(),
            "timeframe_count": len(timeframe_predictions),
            "integrated_signal": integrated_signal,
            "consensus_score": integration_info.get("consensus_score", 0.0),
            "integration_quality": integration_info.get(
                "integration_quality", "unknown"
            ),
            "final_signal": final_signal.side,
            "timeframe_confidences": {},
        }

        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ä¿¡é ¼åº¦è¨˜éŒ²
        for tf, pred_data in timeframe_predictions.items():
            confidence = pred_data.get("confidence", [0.5])
            record["timeframe_confidences"][tf] = (
                confidence[0] if hasattr(confidence, "__len__") else confidence
            )

        self.prediction_history.append(record)

        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.prediction_history) > self.max_history_size:
            self.prediction_history.pop(0)

    def get_ensemble_strategy_info(self) -> Dict:
        """Phase C1çµ±åˆæˆ¦ç•¥æƒ…å ±å–å¾—"""
        info = {
            "strategy_type": "multi_timeframe_ensemble_phase_c1",
            "phase_b_integrated": PHASE_B_AVAILABLE
            and hasattr(self, "phase_b_integrated"),
            "timeframes": self.timeframes,
            "base_weights": self.base_weights,
            "ensemble_method": self.ensemble_method,
            "confidence_threshold": self.confidence_threshold,
            "strategy_stats": self.strategy_stats.copy(),
            "prediction_history_size": len(self.prediction_history),
        }

        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼æƒ…å ±
        info["timeframe_processors"] = {}
        for tf, processor in self.timeframe_processors.items():
            if processor:
                try:
                    info["timeframe_processors"][tf] = processor.get_processor_info()
                except Exception as e:
                    info["timeframe_processors"][tf] = {"error": str(e)}

        # CrossTimeframeIntegratoræƒ…å ±
        try:
            info["cross_timeframe_integrator"] = (
                self.cross_timeframe_integrator.get_integrator_info()
            )
        except Exception as e:
            info["cross_timeframe_integrator"] = {"error": str(e)}

        # æœ€è¿‘ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        if self.prediction_history:
            recent_predictions = self.prediction_history[-10:]
            info["recent_performance"] = self._analyze_recent_ensemble_performance(
                recent_predictions
            )

        return info

    def _analyze_recent_ensemble_performance(
        self, recent_predictions: List[Dict]
    ) -> Dict:
        """æœ€è¿‘ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        try:
            consensus_scores = [p["consensus_score"] for p in recent_predictions]
            integrated_signals = [p["integrated_signal"] for p in recent_predictions]

            quality_counts = {}
            signal_counts = {}
            for p in recent_predictions:
                quality = p["integration_quality"]
                signal = p["final_signal"]
                quality_counts[quality] = quality_counts.get(quality, 0) + 1
                signal_counts[signal] = signal_counts.get(signal, 0) + 1

            return {
                "avg_consensus": np.mean(consensus_scores) if consensus_scores else 0.0,
                "consensus_stability": (
                    np.std(consensus_scores) if consensus_scores else 0.0
                ),
                "avg_integrated_signal": (
                    np.mean(integrated_signals) if integrated_signals else 0.5
                ),
                "signal_diversity": (
                    np.std(integrated_signals) if integrated_signals else 0.0
                ),
                "prediction_count": len(recent_predictions),
                "quality_distribution": quality_counts,
                "signal_distribution": signal_counts,
            }

        except Exception as e:
            logger.error(f"Ensemble performance analysis failed: {e}")
            return {}

    def reset_statistics(self):
        """çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"""
        for key in self.strategy_stats:
            self.strategy_stats[key] = 0
        self.prediction_history.clear()
        self.performance_history.clear()
        self.data_cache.clear()
        self.prediction_cache.clear()

        # ã‚µãƒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±è¨ˆãƒªã‚»ãƒƒãƒˆ
        for processor in self.timeframe_processors.values():
            if processor:
                processor.reset_statistics()
        self.cross_timeframe_integrator.reset_statistics()
        self.confidence_calculator.reset_statistics()

        logger.info("ğŸ“Š Multi-timeframe ensemble strategy statistics reset")
