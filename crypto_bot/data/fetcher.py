# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«å: crypto_bot/data/fetcher.py
# èª¬æ˜:
# ãƒ»MarketDataFetcherï¼šå–å¼•æ‰€ï¼ˆBybitç­‰ï¼‰ã‹ã‚‰OHLCVãƒ‡ãƒ¼ã‚¿ã‚’DataFrameå½¢å¼ã§å–å¾—ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ãƒ»DataPreprocessorï¼šå–å¾—ã—ãŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆOHLCVï¼‰ã®é‡è¤‡é™¤å»ã€æ¬ æè£œå®Œã€å¤–ã‚Œå€¤é™¤å»ãªã©ã®å‰å‡¦ç†ã‚’ä¸€æ‹¬ã§è¡Œã†
# ãƒ».envãƒ•ã‚¡ã‚¤ãƒ«ã‚„APIã‚­ãƒ¼è‡ªå‹•èª­è¾¼ã€Bybitå°‚ç”¨ã®ç´°ã‹ã„å·¥å¤«ã‚‚ã‚ã‚Š
# ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ•´å½¢ã®ä¸­å¿ƒçš„ãªå½¹å‰²
# =============================================================================

import logging
import numbers
import os
from datetime import datetime
from typing import List, Optional, Union

import numpy as np
import pandas as pd
from dotenv import load_dotenv
from pandas.tseries.frequencies import to_offset

from crypto_bot.execution.factory import create_exchange_client

load_dotenv()

logger = logging.getLogger(__name__)


class MarketDataFetcher:
    def __init__(
        self,
        exchange_id: str = "bitbank",
        api_key: Optional[str] = None,
        api_secret: Optional[str] = None,
        symbol: str = "BTC/JPY",
        testnet: bool = False,
        ccxt_options: Optional[dict] = None,
        csv_path: Optional[str] = None,
    ):
        self.exchange_id = exchange_id
        self.symbol = symbol
        self.csv_path = csv_path
        self.testnet = testnet

        # CSV ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯APIæ¥ç¶šã‚’ã‚¹ã‚­ãƒƒãƒ—
        if csv_path:
            self.client = None
            self.exchange = None
        else:
            api_key = api_key or os.getenv(f"{exchange_id.upper()}_API_KEY")
            api_secret = api_secret or os.getenv(f"{exchange_id.upper()}_API_SECRET")
            env_test_key = os.getenv(f"{exchange_id.upper()}_TESTNET_API_KEY")
            testnet = testnet or bool(env_test_key)
            self.client = create_exchange_client(
                exchange_id=exchange_id,
                api_key=api_key,
                api_secret=api_secret,
                testnet=testnet,
                ccxt_options=ccxt_options or {},
            )
            # Bitbankå›ºæœ‰ã®è¨­å®šãŒã‚ã‚Œã°è¿½åŠ 
            if exchange_id == "bitbank":
                # Bitbankç‰¹æœ‰ã®è¨­å®šã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã§å®Ÿè£…
                pass
            self.exchange = getattr(self.client, "_exchange", self.client)

    def get_price_df(
        self,
        timeframe: str = "1m",
        since: Optional[Union[int, float, str, datetime]] = None,
        limit: Optional[int] = None,
        paginate: bool = False,
        sleep: bool = True,
        per_page: int = 500,
    ) -> pd.DataFrame:
        # CSV ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ CSV ã‹ã‚‰èª­ã¿è¾¼ã¿
        if self.csv_path:
            return self._get_price_from_csv(since, limit)

        import time

        since_ms: Optional[int] = None
        if since is not None:
            if isinstance(since, str):
                dt = datetime.fromisoformat(since.replace("Z", "+00:00"))
                since_ms = int(dt.timestamp() * 1000)
            elif isinstance(since, datetime):
                since_ms = int(since.timestamp() * 1000)
            elif isinstance(since, numbers.Real):
                ts = int(since)
                since_ms = ts if ts > 1e12 else int(ts * 1000)
            else:
                raise TypeError(f"Unsupported type for since: {type(since)}")

        max_records = limit if limit is not None else float("inf")

        if paginate and limit:
            logger.info(f"ğŸ”„ Paginated fetch: limit={limit}, per_page={per_page}")
            records: List = []
            seen_ts = set()
            last_since = since_ms
            retries = 0
            MAX_RETRIES = 20  # 5â†’20ã«å¢—åŠ 

            while len(records) < max_records and retries < MAX_RETRIES:
                logger.info(
                    f"ğŸ”„ Batch {retries+1}: fetching from {last_since}, "
                    f"target={len(records)}/{max_records}"
                )

                batch = self.client.fetch_ohlcv(
                    self.symbol, timeframe, last_since, per_page
                )

                if isinstance(batch, pd.DataFrame):
                    logger.info(f"âœ… Received DataFrame directly: {len(batch)} records")
                    return batch

                if not batch:
                    logger.warning(f"âš ï¸ Empty batch received at retry {retries}")
                    retries += 1
                    continue

                logger.info(f"ğŸ“Š Batch received: {len(batch)} records")
                added = False
                for row in batch:
                    ts = row[0]
                    if ts not in seen_ts:
                        seen_ts.add(ts)
                        records.append(row)
                        last_since = ts + 1
                        added = True

                if not added:
                    logger.warning(f"âš ï¸ No new records added in batch {retries}")
                    retries += 1
                else:
                    logger.info(f"âœ… Added records: total={len(records)}")

                if (
                    sleep
                    and hasattr(self.exchange, "rateLimit")
                    and self.exchange.rateLimit
                ):
                    time.sleep(self.exchange.rateLimit / 1000.0)

            logger.info(
                f"âœ… Pagination complete: {len(records)} total records collected"
            )
            data = records if limit is None else records[:limit]

        else:
            raw = self.client.fetch_ohlcv(self.symbol, timeframe, since_ms, limit)
            if (
                sleep
                and hasattr(self.exchange, "rateLimit")
                and self.exchange.rateLimit
            ):
                time.sleep(self.exchange.rateLimit / 1000.0)
            if isinstance(raw, pd.DataFrame):
                return raw
            data = raw or []

            # Bitbankå›ºæœ‰ã®å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè£…ï¼‰
            if not data and self.exchange_id == "bitbank":
                # Bitbankç‰¹æœ‰ã®å‡¦ç†ãŒå¿…è¦ãªå ´åˆã¯ã“ã“ã§å®Ÿè£…
                pass

        if not data:
            return pd.DataFrame()

        df = pd.DataFrame(
            data, columns=["timestamp", "open", "high", "low", "close", "volume"]
        )
        df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
        df = df.set_index("datetime")

        if isinstance(since, datetime) or (isinstance(since, str) and since):
            df = df.iloc[1:]

        if limit is not None:
            df = df.head(limit)

        return df[["open", "high", "low", "close", "volume"]]

    def _get_price_from_csv(
        self,
        since: Optional[Union[int, float, str, datetime]] = None,
        limit: Optional[int] = None,
    ) -> pd.DataFrame:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿

        Parameters
        ----------
        since : Optional[Union[int, float, str, datetime]]
            é–‹å§‹æ™‚åˆ»
        limit : Optional[int]
            å–å¾—ä»¶æ•°åˆ¶é™

        Returns
        -------
        pd.DataFrame
            ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        """
        if not os.path.exists(self.csv_path):
            raise FileNotFoundError(f"CSV file not found: {self.csv_path}")

        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        df = pd.read_csv(self.csv_path, parse_dates=True, index_col=0)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒdatetimeã§ãªã„å ´åˆã¯å¤‰æ›
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’ UTC ã«è¨­å®š
        if df.index.tz is None:
            df.index = df.index.tz_localize("UTC")

        # since ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if since is not None:
            if isinstance(since, str):
                since_dt = pd.to_datetime(since, utc=True)
            elif isinstance(since, datetime):
                since_dt = since
                if since_dt.tzinfo is None:
                    since_dt = since_dt.replace(tzinfo=pd.Timestamp.now().tz)
            else:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å ´åˆ
                since_dt = pd.to_datetime(since, unit="ms", utc=True)

            df = df[df.index >= since_dt]

        # limit ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ä»¶æ•°åˆ¶é™
        if limit is not None:
            df = df.head(limit)

        # å¿…è¦ãªåˆ—ã®ã¿è¿”ã™
        required_columns = ["open", "high", "low", "close", "volume"]
        available_columns = [col for col in required_columns if col in df.columns]

        if not available_columns:
            raise ValueError(
                f"Required columns {required_columns} not found in CSV file"
            )

        return df[available_columns]


class DataPreprocessor:
    @staticmethod
    def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:
        return df[~df.index.duplicated(keep="first")]

    @staticmethod
    def fill_missing_bars(df: pd.DataFrame, timeframe: str = "1h") -> pd.DataFrame:
        freq_offset = to_offset(timeframe)
        idx = pd.date_range(
            start=df.index[0],
            end=df.index[-1],
            freq=freq_offset,
            tz=df.index.tz,
        )
        df2 = df.reindex(idx)
        for col in ["open", "high", "low", "close", "volume"]:
            df2[col] = df2[col].ffill()
        return df2

    @staticmethod
    def remove_outliers(
        df: pd.DataFrame, thresh: float = 3.5, window: int = 20
    ) -> pd.DataFrame:
        df = df.copy()
        price_cols = ["open", "high", "low", "close"]
        for col in [c for c in price_cols if c in df.columns]:
            median = (
                df[col]
                .rolling(
                    window=window,
                    center=True,
                    min_periods=1,
                )
                .median()
            )
            deviation = (df[col] - median).abs()
            mad = deviation.rolling(
                window=window,
                center=True,
                min_periods=1,
            ).median()
            mad = mad + 1e-8
            modified_zscore = 0.6745 * deviation / mad
            is_outlier = modified_zscore > thresh
            temp = df[col].copy()
            temp[is_outlier] = np.nan
            filled = temp.rolling(
                window=window,
                center=True,
                min_periods=1,
            ).mean()
            filled = filled.fillna(method="ffill").fillna(method="bfill")
            df[col] = np.where(is_outlier, filled, df[col])
        return df

    @staticmethod
    def clean(
        df: pd.DataFrame,
        timeframe: str = "1h",
        thresh: float = 3.5,
        window: int = 20,
    ) -> pd.DataFrame:
        df = DataPreprocessor.remove_duplicates(df)
        df = DataPreprocessor.fill_missing_bars(df, timeframe)
        df = DataPreprocessor.remove_outliers(df, thresh, window)
        for col in ["open", "high", "low", "close", "volume"]:
            df[col] = df[col].ffill().bfill()
        return df


class OIDataFetcher:
    """OIï¼ˆæœªæ±ºæ¸ˆå»ºç‰ï¼‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹"""

    def __init__(self, market_fetcher: MarketDataFetcher):
        self.market_fetcher = market_fetcher
        self.exchange = market_fetcher.exchange
        self.symbol = market_fetcher.symbol

    def get_oi_data(
        self,
        timeframe: str = "1h",
        since: Optional[Union[str, datetime]] = None,
        limit: Optional[int] = None,
    ) -> pd.DataFrame:
        """
        OIï¼ˆæœªæ±ºæ¸ˆå»ºç‰ï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Returns
        -------
        pd.DataFrame
            OIãƒ‡ãƒ¼ã‚¿ï¼ˆindex: datetime, columns: oi_amount, oi_valueï¼‰
        """
        try:
            # Bitbankã®å ´åˆã®OIå–å¾—ï¼ˆç¾ç‰©ãƒ»ä¿¡ç”¨å–å¼•å¯¾å¿œï¼‰
            if self.market_fetcher.exchange_id == "bitbank":
                # Bitbankç¾ç‰©å–å¼•ã«ã¯OIãŒãªã„ãŸã‚ã€ä»£æ›¿æŒ‡æ¨™ã‚’ä½¿ç”¨
                # å–å¼•é‡Ã—ä¾¡æ ¼ã§ãƒã‚¸ã‚·ãƒ§ãƒ³è¦æ¨¡ã‚’æ¨å®š
                logger.info("Generating OI approximation for Bitbank")

                # æœ€æ–°ã®ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                price_data = self.market_fetcher.get_price_df(
                    timeframe="1h", limit=168  # 1é€±é–“åˆ†
                )

                if not price_data.empty:
                    # ãƒã‚¸ã‚·ãƒ§ãƒ³è¦æ¨¡ã®æ¨å®šï¼ˆå‡ºæ¥é«˜Ã—ä¾¡æ ¼ï¼‰
                    position_size = price_data["volume"] * price_data["close"]

                    result = pd.DataFrame(
                        {
                            "oi_amount": position_size,
                            "oi_value": position_size * price_data["close"],
                        }
                    )

                    return result

                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç©ºã®DataFrame
                return pd.DataFrame(columns=["oi_amount", "oi_value"])

        except Exception as e:
            logger.warning(f"Could not fetch OI approximation: {e}")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç©ºã®DataFrameã‚’è¿”ã™
        return pd.DataFrame(columns=["oi_amount", "oi_value"])

    def calculate_oi_features(self, df: pd.DataFrame, window: int = 24) -> pd.DataFrame:
        """
        OIé–¢é€£ã®ç‰¹å¾´é‡ã‚’è¨ˆç®—

        Parameters
        ----------
        df : pd.DataFrame
            OIãƒ‡ãƒ¼ã‚¿
        window : int
            ç§»å‹•å¹³å‡ã®æœŸé–“

        Returns
        -------
        pd.DataFrame
            OIç‰¹å¾´é‡ä»˜ãDataFrame
        """
        if df.empty or "oi_amount" not in df.columns:
            return df

        # OIå¤‰åŒ–ç‡
        df["oi_pct_change"] = df["oi_amount"].pct_change()

        # OIç§»å‹•å¹³å‡
        df[f"oi_ma_{window}"] = df["oi_amount"].rolling(window=window).mean()

        # OIæ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰
        df["oi_zscore"] = (
            df["oi_amount"] - df["oi_amount"].rolling(window=window).mean()
        ) / df["oi_amount"].rolling(window=window).std()

        # OIå‹¢ã„ï¼ˆmomentumï¼‰
        df["oi_momentum"] = df["oi_amount"] / df["oi_amount"].shift(window) - 1

        # OIæ€¥æ¿€ãªå¤‰åŒ–æ¤œçŸ¥
        df["oi_spike"] = (
            df["oi_pct_change"].abs()
            > df["oi_pct_change"].rolling(window=window).std() * 2
        ).astype(int)

        return df
