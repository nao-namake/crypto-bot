"""
ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ - Phase 28å®Œäº†ãƒ»Phase 29æœ€é©åŒ–ç‰ˆ

Phase 28å®Œäº†ãƒ»Phase 29æœ€é©åŒ–ï¼š
- ãƒšãƒ¼ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ¼ãƒ‰ã¨åŒã˜ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§CSVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- æœ¬ç•ªã¨åŒä¸€ã®trading_cycle_managerã‚’ä½¿ç”¨
- CSVãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—ã§é †æ¬¡å‡¦ç†ã—ã€å„æ™‚ç‚¹ã§å–å¼•åˆ¤å®šã‚’å®Ÿè¡Œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€ãƒ«ãƒƒã‚¯ã‚¢ãƒ˜ãƒƒãƒ‰ã‚’é˜²æ­¢

è¨­è¨ˆåŸå‰‡:
- æœ¬ç•ªã¨ãƒšãƒ¼ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ¼ãƒ‰ã®åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ä½¿ç”¨
- CSVãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹é«˜é€Ÿãƒ»å®‰å®šã—ãŸãƒ‡ãƒ¼ã‚¿ä¾›çµ¦
- æ™‚åˆ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹æ­£ç¢ºãªæ™‚ç³»åˆ—å‡¦ç†
- BacktestReporterã«ã‚ˆã‚‹è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd

from ..config import get_threshold
from .base_runner import BaseRunner


class BacktestRunner(BaseRunner):
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã‚¯ãƒ©ã‚¹ï¼ˆPhase 28å®Œäº†ãƒ»Phase 29æœ€é©åŒ–ç‰ˆï¼‰"""

    def __init__(self, orchestrator_ref, logger):
        """
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼åˆæœŸåŒ–

        Args:
            orchestrator_ref: TradingOrchestratorã¸ã®å‚ç…§
            logger: ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 
        """
        super().__init__(orchestrator_ref, logger)

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçŠ¶æ…‹ç®¡ç†
        self.backtest_start = None
        self.backtest_end = None
        self.current_timestamp = None
        self.csv_data = {}  # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥CSVãƒ‡ãƒ¼ã‚¿
        self.data_index = 0  # ç¾åœ¨ã®å‡¦ç†ä½ç½®
        self.total_data_points = 0

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆPhase 28å®Œäº†ãƒ»Phase 29æœ€é©åŒ–ï¼‰
        self.symbol = get_threshold("backtest.symbol", "BTC/JPY")
        self.timeframes = get_threshold("backtest.timeframes", ["15m", "4h"])
        self.lookback_window = get_threshold(
            "backtest.lookback_window", 100
        )  # å„æ™‚ç‚¹ã§éå»Nä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¾›çµ¦

        # çµ±è¨ˆæƒ…å ±
        self.cycle_count = 0
        self.processed_timestamps = []
        self.session_stats = {}

    async def run(self) -> bool:
        """
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ

        Returns:
            å®Ÿè¡ŒæˆåŠŸãƒ»å¤±æ•—
        """
        try:
            self.logger.info("ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é–‹å§‹ï¼ˆPhase 22ãƒ»ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰æ’é™¤ç‰ˆï¼‰")

            # 1. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“è¨­å®š
            await self._setup_backtest_period()

            # 2. CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            await self._load_csv_data()

            # 3. ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if not await self._validate_data():
                self.logger.error("âŒ CSVãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã™")
                return False

            # 4. æ™‚ç³»åˆ—ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            await self._run_time_series_backtest()

            # 5. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            await self._generate_final_backtest_report()

            self.logger.info("âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†", discord_notify=True)
            return True

        except Exception as e:
            self.logger.error(f"âŒ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", discord_notify=True)
            await self._save_error_report(str(e))
            raise

    async def _setup_backtest_period(self):
        """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“è¨­å®š"""
        # å¤–éƒ¨è¨­å®šã‹ã‚‰æœŸé–“ã‚’å–å¾—
        backtest_days = get_threshold("execution.backtest_period_days", 30)

        self.backtest_end = datetime.now()
        self.backtest_start = self.backtest_end - timedelta(days=backtest_days)

        self.logger.info(
            f"ğŸ“… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“: {self.backtest_start.strftime('%Y-%m-%d')} "
            f"~ {self.backtest_end.strftime('%Y-%m-%d')} ({backtest_days}æ—¥é–“)"
        )

    async def _load_csv_data(self):
        """CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            # CSV ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨
            from ...backtest.data.csv_data_loader import get_csv_loader

            csv_loader = get_csv_loader()

            # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            self.csv_data = csv_loader.load_multi_timeframe(
                symbol=self.symbol,
                timeframes=self.timeframes,
                start_date=self.backtest_start,
                end_date=self.backtest_end,
                limit=get_threshold("backtest.data_limit", 10000),  # ååˆ†ãªé‡ã‚’ç¢ºä¿
            )

            # è¨­å®šã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            main_timeframe = self.timeframes[0] if self.timeframes else "4h"

            if (
                not self.csv_data
                or main_timeframe not in self.csv_data
                or self.csv_data[main_timeframe].empty
            ):
                raise ValueError(f"ä¸»è¦ãƒ‡ãƒ¼ã‚¿ï¼ˆ{main_timeframe}ï¼‰ãŒä¸è¶³: {self.symbol}")

            # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
            self.total_data_points = len(self.csv_data[main_timeframe])

            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚’å‹•çš„ã«ç”Ÿæˆ
            timeframe_stats = []
            for tf in self.timeframes:
                count = len(self.csv_data.get(tf, []))
                timeframe_stats.append(f"{tf}:{count}ä»¶")

            self.logger.info(f"ğŸ“ˆ CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {', '.join(timeframe_stats)}")

        except Exception as e:
            self.logger.error(f"âŒ CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def _validate_data(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"""
        min_data_points = get_threshold("backtest.min_data_points", 50)

        if self.total_data_points < min_data_points:
            self.logger.warning(
                f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {self.total_data_points}ä»¶ " f"ï¼ˆæœ€å°{min_data_points}ä»¶å¿…è¦ï¼‰"
            )
            return False

        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
        main_timeframe = self.timeframes[0] if self.timeframes else "4h"
        main_data = self.csv_data[main_timeframe]
        if main_data.isnull().any().any():
            self.logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã«æ¬ æå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")

        if not main_data.index.is_monotonic_increasing:
            self.logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒæ™‚ç³»åˆ—é †åºã«ãªã£ã¦ã„ã¾ã›ã‚“")

        return True

    async def _run_time_series_backtest(self):
        """æ™‚ç³»åˆ—ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        main_timeframe = self.timeframes[0] if self.timeframes else "4h"
        main_data = self.csv_data[main_timeframe]

        # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã§å‡¦ç†
        for i in range(self.lookback_window, len(main_data)):
            self.data_index = i
            self.current_timestamp = main_data.index[i]

            # é€²æ—è¡¨ç¤º
            progress_interval = get_threshold("backtest.progress_interval", 50)
            if i % progress_interval == 0:
                progress = (i / len(main_data)) * 100
                self.logger.info(
                    f"ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé€²è¡Œä¸­: {progress:.1f}% "
                    f"({i}/{len(main_data)}) - {self.current_timestamp.strftime('%Y-%m-%d %H:%M')}"
                )

            # ç¾åœ¨æ™‚ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            await self._setup_current_market_data()

            # å–å¼•ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œï¼ˆæœ¬ç•ªã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            try:
                await self.orchestrator.run_trading_cycle()
                self.cycle_count += 1
                self.processed_timestamps.append(self.current_timestamp)

            except Exception as e:
                self.logger.warning(f"âš ï¸ å–å¼•ã‚µã‚¤ã‚¯ãƒ«ã‚¨ãƒ©ãƒ¼ ({self.current_timestamp}): {e}")
                continue

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå°‚ç”¨ã®é€²æ—ä¿å­˜ï¼ˆå®šæœŸçš„ï¼‰
            report_interval = get_threshold("backtest.report_interval", 100)
            if i % report_interval == 0:
                await self._save_progress_report()

    async def _setup_current_market_data(self):
        """ç¾åœ¨æ™‚ç‚¹ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ã‚’ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚åˆ»ã«è¨­å®š
        await self._set_simulated_time(self.current_timestamp)

        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        current_market_data = {}

        for timeframe, df in self.csv_data.items():
            if df.empty:
                continue

            # ç¾åœ¨æ™‚åˆ»ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼ˆãƒ«ãƒƒã‚¯ã‚¢ãƒ˜ãƒƒãƒ‰é˜²æ­¢ï¼‰
            available_data = df[df.index <= self.current_timestamp]

            if len(available_data) >= self.lookback_window:
                current_market_data[timeframe] = available_data.tail(self.lookback_window)
            else:
                current_market_data[timeframe] = available_data

        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
        self.orchestrator.data_service.set_backtest_data(current_market_data)

    async def _set_simulated_time(self, timestamp: datetime):
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚åˆ»è¨­å®š"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ç®¡ç†ã‚¯ãƒ©ã‚¹ãŒã‚ã‚Œã°è¨­å®š
        # ç¾åœ¨ã¯å®Ÿè£…ã›ãšã€å°†æ¥çš„ã«æ™‚åˆ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        pass

    async def _save_progress_report(self):
        """é€²æ—ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        try:
            progress_stats = {
                "current_timestamp": self.current_timestamp,
                "progress_percentage": (self.data_index / self.total_data_points) * 100,
                "cycles_completed": self.cycle_count,
                "processed_data_points": len(self.processed_timestamps),
            }

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ã‚¿ãƒ¼ã«é€²æ—ä¿å­˜
            await self.orchestrator.backtest_reporter.save_progress_report(progress_stats)

        except Exception as e:
            self.logger.warning(f"âš ï¸ é€²æ—ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    async def _generate_final_backtest_report(self):
        """æœ€çµ‚ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            # æœ€çµ‚çµ±è¨ˆåé›†
            final_stats = {
                "backtest_period": {
                    "start": self.backtest_start,
                    "end": self.backtest_end,
                    "duration_days": (self.backtest_end - self.backtest_start).days,
                },
                "data_processing": {
                    "total_data_points": self.total_data_points,
                    "processed_cycles": self.cycle_count,
                    "processed_timestamps": len(self.processed_timestamps),
                    "success_rate": len(self.processed_timestamps) / self.total_data_points * 100,
                },
                "timeframes": list(self.csv_data.keys()),
                "symbol": self.symbol,
            }

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ã‚¿ãƒ¼çµŒç”±ã§è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            await self.orchestrator.backtest_reporter.generate_backtest_report(
                final_stats, self.backtest_start, self.backtest_end
            )

        except Exception as e:
            self.logger.error(f"âŒ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    async def _save_error_report(self, error_message: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        try:
            context = {
                "backtest_runner": "Phase22_BacktestRunner",
                "current_timestamp": self.current_timestamp,
                "data_index": self.data_index,
                "cycle_count": self.cycle_count,
            }

            await self.orchestrator.backtest_reporter.save_error_report(error_message, context)

        except Exception as e:
            self.logger.warning(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
