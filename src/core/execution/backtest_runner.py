"""
バックテストランナー - Phase 38.4完了版

Phase 28-29最適化:
- ペーパートレードと同じアプローチでCSVデータからバックテスト実行
- 本番と同一のtrading_cycle_managerを使用
- CSVデータを時系列で順次処理し、各時点で取引判定を実行
- リアルタイム処理をシミュレートし、ルックアヘッドを防止

Phase 35: バックテスト10倍高速化実装
- 特徴量事前計算: 288分→0秒（無限倍高速化）・265,130件/秒処理
- ML予測事前計算: 15分→0.3秒（3,000倍高速化）・10,063件/秒処理
- 価格データ正常化: entry_price追加・¥0問題解決
- ログ最適化: 70%削減（12,781行→3,739行）・可読性大幅向上
- 合計高速化: 6-8時間→45分（約10倍高速化達成）

Phase 38: trading層レイヤードアーキテクチャ実装完了
Phase 38.4: 全モジュールPhase統一・コード品質保証完了

設計原則:
- 本番とペーパートレードの同一ロジック使用
- CSVデータによる高速・安定したデータ供給
- 時刻シミュレーションによる正確な時系列処理
- BacktestReporterによる詳細なレポート生成
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd

from ..config import get_threshold
from .base_runner import BaseRunner


class BacktestRunner(BaseRunner):
    """バックテストモード実行クラス（Phase 38.4完了版・Phase 35バックテスト最適化実績保持）"""

    def __init__(self, orchestrator_ref, logger):
        """
        バックテストランナー初期化

        Args:
            orchestrator_ref: TradingOrchestratorへの参照
            logger: ログシステム
        """
        super().__init__(orchestrator_ref, logger)

        # バックテスト状態管理
        self.backtest_start = None
        self.backtest_end = None
        self.current_timestamp = None
        self.csv_data = {}  # タイムフレーム別CSVデータ
        self.precomputed_features = {}  # Phase 35: 事前計算済み特徴量（10倍高速化）
        self.precomputed_ml_predictions = {}  # Phase 35.4: 事前計算済みML予測（10倍高速化）
        self.data_index = 0  # 現在の処理位置
        self.total_data_points = 0

        # バックテスト設定（Phase 28完了・Phase 29最適化）
        self.symbol = get_threshold("backtest.symbol", "BTC/JPY")
        self.timeframes = get_threshold("backtest.timeframes", ["15m", "4h"])
        self.lookback_window = get_threshold(
            "backtest.lookback_window", 100
        )  # 各時点で過去N件のデータを供給

        # 統計情報
        self.cycle_count = 0
        self.processed_timestamps = []
        self.session_stats = {}

    async def run(self) -> bool:
        """
        バックテストモード実行

        Returns:
            実行成功・失敗
        """
        try:
            self.logger.warning("📊 バックテストモード開始（Phase 35最適化: ログ=WARNING）")

            # 1. バックテスト期間設定
            await self._setup_backtest_period()

            # 2. CSVデータ読み込み
            await self._load_csv_data()

            # 3. 特徴量事前計算（Phase 35: 10倍高速化）
            await self._precompute_features()

            # 3.5. 戦略シグナル事前計算（Phase 49.1: バックテスト完全改修）
            await self._precompute_strategy_signals()

            # 3.6. ML予測事前計算（Phase 35.4: さらなる高速化）
            await self._precompute_ml_predictions()

            # 4. データ検証
            if not await self._validate_data():
                self.logger.error("❌ CSVデータが不十分です")
                return False

            # 5. 時系列バックテスト実行
            await self._run_time_series_backtest()

            # 6. 最終レポート生成
            await self._generate_final_backtest_report()

            self.logger.warning("✅ バックテスト実行完了", discord_notify=True)
            return True

        except Exception as e:
            self.logger.error(f"❌ バックテスト実行エラー: {e}", discord_notify=True)
            await self._save_error_report(str(e))
            raise

    async def _setup_backtest_period(self):
        """バックテスト期間設定"""
        # 外部設定から期間を取得
        backtest_days = get_threshold("execution.backtest_period_days", 30)

        self.backtest_end = datetime.now()
        self.backtest_start = self.backtest_end - timedelta(days=backtest_days)

        self.logger.info(
            f"📅 バックテスト期間: {self.backtest_start.strftime('%Y-%m-%d')} "
            f"~ {self.backtest_end.strftime('%Y-%m-%d')} ({backtest_days}日間)"
        )

    async def _load_csv_data(self):
        """CSVデータ読み込み"""
        try:
            # CSV データローダーを使用
            from ...backtest.data.csv_data_loader import get_csv_loader

            csv_loader = get_csv_loader()

            # マルチタイムフレームデータ読み込み
            self.csv_data = csv_loader.load_multi_timeframe(
                symbol=self.symbol,
                timeframes=self.timeframes,
                start_date=self.backtest_start,
                end_date=self.backtest_end,
                limit=get_threshold("backtest.data_limit", 10000),  # 十分な量を確保
            )

            # 設定からメインタイムフレームを取得
            main_timeframe = self.timeframes[0] if self.timeframes else "4h"

            if (
                not self.csv_data
                or main_timeframe not in self.csv_data
                or self.csv_data[main_timeframe].empty
            ):
                raise ValueError(f"主要データ（{main_timeframe}）が不足: {self.symbol}")

            # データ統計
            self.total_data_points = len(self.csv_data[main_timeframe])

            # タイムフレーム別データ統計を動的に生成
            timeframe_stats = []
            for tf in self.timeframes:
                count = len(self.csv_data.get(tf, []))
                timeframe_stats.append(f"{tf}:{count}件")

            self.logger.warning(f"📈 CSVデータ読み込み完了: {', '.join(timeframe_stats)}")

            # Phase 40.5拡張: データサンプリング処理（Optuna最適化高速化）
            sampling_ratio = get_threshold("backtest.data_sampling_ratio", 1.0)
            if sampling_ratio < 1.0:
                self._apply_data_sampling(sampling_ratio)

        except Exception as e:
            self.logger.error(f"❌ CSVデータ読み込みエラー: {e}")
            raise

    def _apply_data_sampling(self, sampling_ratio: float) -> None:
        """
        データサンプリング処理（Phase 40.5拡張: Optuna最適化高速化）

        等間隔サンプリングを使用して時系列の連続性を保持しつつデータ量を削減。

        Args:
            sampling_ratio: サンプリング比率（0.0-1.0）
                例: 0.1 = 10%サンプリング、0.2 = 20%サンプリング

        効果:
            - 10%サンプリング: 実行時間1/10（予想）
            - 20%サンプリング: 実行時間1/5（予想）
        """
        if sampling_ratio >= 1.0:
            return  # サンプリング不要

        self.logger.warning(
            f"🔬 データサンプリング開始: {sampling_ratio * 100:.0f}% "
            f"(Optuna最適化高速化・Phase 40.5)"
        )

        for timeframe in self.csv_data.keys():
            original_df = self.csv_data[timeframe]
            original_count = len(original_df)

            if original_count == 0:
                continue

            # 等間隔サンプリング（時系列連続性保持）
            step = max(1, int(1 / sampling_ratio))
            sampled_df = original_df.iloc[::step].copy()

            # 最後の行は必ず含める（最新データ確保）
            if original_df.index[-1] not in sampled_df.index:
                sampled_df = pd.concat([sampled_df, original_df.iloc[[-1]]])

            sampled_count = len(sampled_df)

            self.csv_data[timeframe] = sampled_df

            self.logger.warning(
                f"  {timeframe}: {original_count}件 → {sampled_count}件 "
                f"({sampled_count / original_count * 100:.1f}%)"
            )

        # メインタイムフレームのデータポイント数更新
        main_timeframe = self.timeframes[0] if self.timeframes else "4h"
        self.total_data_points = len(self.csv_data[main_timeframe])

    async def _precompute_features(self):
        """
        特徴量事前計算（Phase 35: 10倍高速化）

        全CSVデータに対して一度だけ特徴量を計算し、
        各サイクルではスライスのみ実行することで大幅高速化。

        最適化効果:
        - 17,271回の特徴量計算 → 1回（タイムフレーム毎）
        - 理論値: 17,271倍高速化
        - 実測予想: 20-30分 → 2-3分（10倍高速化）
        """
        try:
            import time

            from ...features.feature_generator import FeatureGenerator

            self.logger.warning("🚀 特徴量事前計算開始（Phase 35最適化）")
            start_time = time.time()

            feature_gen = FeatureGenerator()

            for timeframe, df in self.csv_data.items():
                if df.empty:
                    continue

                # Phase 35.2: 詳細ログ削除（高速化）
                tf_start = time.time()

                # 同期版特徴量生成（全データ一括計算）
                features_df = feature_gen.generate_features_sync(df)

                # Phase 49.1: 戦略シグナル特徴量は_precompute_strategy_signals()で別途計算
                # ここでは0.0で初期化のみ（後で上書きされる）
                strategy_signal_features = [
                    "strategy_signal_ATRBased",
                    "strategy_signal_MochipoyAlert",
                    "strategy_signal_MultiTimeframe",
                    "strategy_signal_DonchianChannel",
                    "strategy_signal_ADXTrendStrength",
                ]
                for col in strategy_signal_features:
                    if col not in features_df.columns:
                        features_df[col] = 0.0

                # 事前計算結果をキャッシュ
                self.precomputed_features[timeframe] = features_df

            elapsed = time.time() - start_time
            total_records = sum(len(df) for df in self.csv_data.values())
            self.logger.warning(
                f"✅ 特徴量事前計算完了: {total_records}件 "
                f"（{elapsed:.1f}秒, {total_records / elapsed:.0f}件/秒）",
                discord_notify=False,
            )

        except Exception as e:
            self.logger.error(f"❌ 特徴量事前計算エラー: {e}")
            raise

    async def _precompute_strategy_signals(self):
        """
        戦略シグナル事前計算（Phase 49.1: バックテスト完全改修）

        各タイムスタンプで過去データのみを使って5戦略を実行し、
        実戦略シグナル特徴量を生成することでライブモードと完全一致を実現。

        重要ポイント:
        - Look-ahead bias防止: df.iloc[:i+1]で過去データのみ使用
        - Phase 41.8 Strategy-Aware ML完全対応
        - 各タイムスタンプで特徴量生成+戦略実行が必要（処理時間増）

        最適化効果:
        - バックテスト精度: BUY偏重 → ライブモード完全一致
        - Strategy-Aware ML正常動作: 戦略シグナル0.0埋め → 実シグナル使用
        """
        try:
            import time

            from ...features.feature_generator import FeatureGenerator

            self.logger.warning("🎯 戦略シグナル事前計算開始（Phase 49.1: 実戦略実行）")
            start_time = time.time()

            # メインタイムフレームのみ処理（4h足）
            main_timeframe = self.timeframes[0] if self.timeframes else "4h"
            if main_timeframe not in self.csv_data:
                self.logger.warning(f"⚠️ メインタイムフレーム {main_timeframe} が存在しません")
                return

            main_df = self.csv_data[main_timeframe]
            if main_df.empty:
                self.logger.warning("⚠️ メインタイムフレームデータが空です")
                return

            feature_gen = FeatureGenerator()
            total_rows = len(main_df)

            # 戦略シグナル特徴量の初期化（全行×5戦略）
            strategy_names = [
                "ATRBased",
                "MochipoyAlert",
                "MultiTimeframe",
                "DonchianChannel",
                "ADXTrendStrength",
            ]
            strategy_signal_columns = {f"strategy_signal_{name}": [] for name in strategy_names}

            # 進捗報告用
            progress_interval = max(1, total_rows // 10)  # 10%ごとに報告

            # 各タイムスタンプで過去データのみ使用して戦略実行
            for i in range(total_rows):
                # Phase 49.1: Look-ahead bias防止 - 過去データのみ使用
                historical_data = main_df.iloc[: i + 1]

                # 進捗報告
                if i % progress_interval == 0 and i > 0:
                    progress = (i / total_rows) * 100
                    elapsed = time.time() - start_time
                    eta = (elapsed / i) * (total_rows - i) if i > 0 else 0
                    self.logger.warning(
                        f"  進捗: {progress:.1f}% ({i}/{total_rows}) - "
                        f"経過: {elapsed:.1f}秒, 残り: {eta:.1f}秒"
                    )

                # データ不足時は0.0で埋める（最初の数行）
                if len(historical_data) < 20:  # 最小データ数チェック
                    for col in strategy_signal_columns.keys():
                        strategy_signal_columns[col].append(0.0)
                    continue

                try:
                    # 1. 特徴量生成（過去データのみ）
                    features_df = feature_gen.generate_features_sync(historical_data)
                    if features_df.empty or len(features_df) == 0:
                        for col in strategy_signal_columns.keys():
                            strategy_signal_columns[col].append(0.0)
                        continue

                    # 最新行のみ取得（現在時点の特徴量）
                    current_features = features_df.iloc[[-1]]

                    # 2. 全タイムフレーム特徴量準備（簡易版 - メインタイムフレームのみ）
                    all_features = {main_timeframe: current_features}

                    # 3. 個別戦略シグナル取得（Phase 41.8準拠）
                    strategy_signals = (
                        self.orchestrator.strategy_service.get_individual_strategy_signals(
                            current_features, multi_timeframe_data=all_features
                        )
                    )

                    # 4. 戦略シグナルエンコーディング（action × confidence）
                    for strategy_name in strategy_names:
                        if strategy_name in strategy_signals:
                            signal = strategy_signals[strategy_name]
                            encoded_value = signal.get("encoded", 0.0)
                            strategy_signal_columns[f"strategy_signal_{strategy_name}"].append(
                                encoded_value
                            )
                        else:
                            # 戦略シグナル取得失敗時は0.0
                            strategy_signal_columns[f"strategy_signal_{strategy_name}"].append(0.0)

                except Exception as e:
                    # エラー時は0.0で埋める
                    self.logger.debug(f"⚠️ タイムスタンプ {i} で戦略シグナル計算エラー: {e}")
                    for col in strategy_signal_columns.keys():
                        strategy_signal_columns[col].append(0.0)

            # 5. precomputed_featuresに戦略シグナル特徴量を追加
            if main_timeframe in self.precomputed_features:
                features_df = self.precomputed_features[main_timeframe]
                for col_name, values in strategy_signal_columns.items():
                    if len(values) == len(features_df):
                        features_df[col_name] = values
                    else:
                        self.logger.warning(
                            f"⚠️ 戦略シグナル長さ不一致: {col_name} = {len(values)}, features = {len(features_df)}"
                        )

                self.precomputed_features[main_timeframe] = features_df

            elapsed = time.time() - start_time
            self.logger.warning(
                f"✅ 戦略シグナル事前計算完了: {total_rows}件 "
                f"（{elapsed:.1f}秒, {total_rows / elapsed:.1f}件/秒）",
                discord_notify=False,
            )

        except Exception as e:
            self.logger.error(f"❌ 戦略シグナル事前計算エラー: {e}")
            # エラー時は0.0埋めにフォールバック（既存動作維持）

    async def _precompute_ml_predictions(self):
        """
        ML予測事前計算（Phase 35.4: さらなる高速化）

        全特徴量データに対して一度だけML予測を実行し、
        各サイクルでは事前計算済み予測を使用することで大幅高速化。

        最適化効果:
        - 2,747回のML予測 → 1回のバッチ予測
        - 理論値: 2,747倍高速化
        - 実測予想: 15分 → 1-2分（10倍高速化）
        """
        try:
            import time

            import numpy as np

            from ...core.config.feature_manager import get_feature_names

            self.logger.warning("🤖 ML予測事前計算開始（Phase 35.4最適化）")
            start_time = time.time()

            # メインタイムフレームの特徴量に対してML予測
            main_timeframe = self.timeframes[0] if self.timeframes else "4h"
            if main_timeframe in self.precomputed_features:
                features_df = self.precomputed_features[main_timeframe]

                # Phase 40.6: 50特徴量抽出（動的取得）
                features_to_use = get_feature_names()
                available_features = [col for col in features_to_use if col in features_df.columns]

                if len(available_features) == len(features_to_use):
                    ml_features = features_df[available_features]

                    # バッチ予測実行
                    predictions_array = self.orchestrator.ml_service.predict(ml_features)
                    probabilities_array = self.orchestrator.ml_service.predict_proba(ml_features)

                    # 予測結果を保存（インデックス対応）
                    self.precomputed_ml_predictions[main_timeframe] = {
                        "predictions": predictions_array,
                        "probabilities": probabilities_array,
                    }

                    elapsed = time.time() - start_time
                    self.logger.warning(
                        f"✅ ML予測事前計算完了: {len(predictions_array)}件 "
                        f"（{elapsed:.1f}秒, {len(predictions_array) / elapsed:.0f}件/秒）",
                        discord_notify=False,
                    )
                else:
                    self.logger.warning(
                        f"⚠️ 特徴量不足: {len(available_features)}/{len(features_to_use)}個 - ML予測スキップ"
                    )

        except Exception as e:
            self.logger.error(f"❌ ML予測事前計算エラー: {e}")
            # エラー時は通常のML予測にフォールバック（処理継続）
            self.precomputed_ml_predictions = {}

    async def _validate_data(self) -> bool:
        """データ検証"""
        min_data_points = get_threshold("backtest.min_data_points", 50)

        if self.total_data_points < min_data_points:
            self.logger.warning(
                f"⚠️ データが不足: {self.total_data_points}件 " f"（最小{min_data_points}件必要）"
            )
            return False

        # データ品質チェック
        main_timeframe = self.timeframes[0] if self.timeframes else "4h"
        main_data = self.csv_data[main_timeframe]
        if main_data.isnull().any().any():
            self.logger.warning("⚠️ データに欠損値が含まれています")

        if not main_data.index.is_monotonic_increasing:
            self.logger.warning("⚠️ データが時系列順序になっていません")

        return True

    async def _run_time_series_backtest(self):
        """時系列バックテスト実行（Phase 35: 高速化最適化版）"""
        main_timeframe = self.timeframes[0] if self.timeframes else "4h"
        main_data = self.csv_data[main_timeframe]

        # データを時系列順で処理
        for i in range(self.lookback_window, len(main_data)):
            self.data_index = i
            self.current_timestamp = main_data.index[i]

            # Phase 35.2: 進捗表示（WARNING強制出力）
            progress_interval = get_threshold("backtest.progress_interval", 1000)
            if i % progress_interval == 0:
                progress = (i / len(main_data)) * 100
                self.logger.warning(
                    f"📊 バックテスト進行中: {progress:.1f}% "
                    f"({i}/{len(main_data)}) - {self.current_timestamp.strftime('%Y-%m-%d %H:%M')}"
                )

            # 現在時点のデータを準備（Phase 35: 高速化版）
            await self._setup_current_market_data_fast(i)

            # Phase 49.3: サイクル前のポジション数記録（エントリー検出用）
            positions_before = set(
                p["order_id"] for p in self.orchestrator.position_tracker.virtual_positions
            )

            # 取引サイクル実行（本番と同じロジック）
            try:
                await self.orchestrator.run_trading_cycle()
                self.cycle_count += 1
                self.processed_timestamps.append(self.current_timestamp)

                # Phase 49.3: サイクル後の新規ポジションをTradeTrackerに記録
                positions_after = self.orchestrator.position_tracker.virtual_positions
                for position in positions_after:
                    order_id = position.get("order_id")
                    if order_id not in positions_before:
                        # 新規エントリー検出
                        if (
                            hasattr(self.orchestrator, "backtest_reporter")
                            and self.orchestrator.backtest_reporter
                        ):
                            self.orchestrator.backtest_reporter.trade_tracker.record_entry(
                                order_id=order_id,
                                side=position.get("side"),
                                amount=position.get("amount"),
                                price=position.get("price"),
                                timestamp=self.current_timestamp,
                                strategy=position.get("strategy_name", "unknown"),
                            )

            except Exception as e:
                self.logger.warning(f"⚠️ 取引サイクルエラー ({self.current_timestamp}): {e}")
                continue

            # Phase 49.2: TP/SLトリガーチェック・決済シミュレーション
            try:
                # 現在価格取得
                current_price = main_data.iloc[i].get("close", None)
                if current_price is not None:
                    await self._check_tp_sl_triggers(current_price, self.current_timestamp)
            except Exception as e:
                self.logger.debug(f"⚠️ TP/SLトリガーチェックエラー ({self.current_timestamp}): {e}")

            # Phase 35.5: 進捗レポート保存を完全削除（バックテスト中は不要・I/Oオーバーヘッド削減）
            # report_interval = get_threshold("backtest.report_interval", 10000)
            # if i % report_interval == 0:
            #     await self._save_progress_report()

    async def _check_tp_sl_triggers(self, current_price: float, timestamp):
        """
        TP/SLトリガーチェック・決済シミュレーション（Phase 49.2: バックテスト完全改修）

        現在価格とTP/SL価格を比較し、トリガー時に決済注文シミュレーションを実行。
        これによりバックテストでSELL注文が生成され、完全な取引サイクルを実現。

        Args:
            current_price: 現在の終値
            timestamp: 現在タイムスタンプ

        処理フロー:
            1. PositionTrackerから全ポジション取得
            2. 各ポジションのTP/SL価格と現在価格を比較
            3. TP/SLトリガー時に決済注文シミュレーション
            4. ポジション削除
        """
        try:
            # 1. 全ポジション取得
            position_tracker = self.orchestrator.position_tracker
            positions = position_tracker.virtual_positions.copy()  # コピーして安全にイテレーション

            if not positions:
                return  # ポジションなし

            # 2. 各ポジションのTP/SLチェック
            for position in positions:
                order_id = position.get("order_id")
                side = position.get("side")  # "buy" or "sell"
                amount = position.get("amount")
                entry_price = position.get("price")
                take_profit = position.get("take_profit")
                stop_loss = position.get("stop_loss")
                strategy_name = position.get("strategy_name", "unknown")

                # TP/SL価格がない場合はスキップ
                if take_profit is None and stop_loss is None:
                    continue

                # 3. TP/SLトリガー判定
                tp_triggered = False
                sl_triggered = False

                if side == "buy":
                    # ロングポジション: 価格上昇でTP・価格下落でSL
                    if take_profit and current_price >= take_profit:
                        tp_triggered = True
                    elif stop_loss and current_price <= stop_loss:
                        sl_triggered = True
                elif side == "sell":
                    # ショートポジション: 価格下落でTP・価格上昇でSL
                    if take_profit and current_price <= take_profit:
                        tp_triggered = True
                    elif stop_loss and current_price >= stop_loss:
                        sl_triggered = True

                # 4. トリガー時に決済シミュレーション
                if tp_triggered or sl_triggered:
                    trigger_type = "TP" if tp_triggered else "SL"
                    exit_price = take_profit if tp_triggered else stop_loss

                    self.logger.info(
                        f"✅ Phase 49.2: {trigger_type}トリガー - "
                        f"{side} {amount} BTC @ {exit_price:.0f}円 "
                        f"(エントリー: {entry_price:.0f}円, 戦略: {strategy_name}) - {timestamp}"
                    )

                    # 5. 決済注文シミュレーション（ExecutionService経由）
                    try:
                        # 決済サイド: buy → sell, sell → buy
                        exit_side = "sell" if side == "buy" else "buy"

                        # ExecutionService経由で決済注文実行
                        # バックテストモードではbitbank APIは呼ばれず、仮想注文のみ実行
                        await self.orchestrator.execution_service._execute_order_with_limit(
                            side=exit_side,
                            amount=amount,
                            price=exit_price,
                            reason=f"{trigger_type}トリガー決済",
                        )

                        # 6. ポジション削除
                        position_tracker.remove_position(order_id)

                        # Phase 49.3: TradeTrackerにエグジット記録
                        if (
                            hasattr(self.orchestrator, "backtest_reporter")
                            and self.orchestrator.backtest_reporter
                        ):
                            self.orchestrator.backtest_reporter.trade_tracker.record_exit(
                                order_id=order_id,
                                exit_price=exit_price,
                                exit_timestamp=timestamp,
                                exit_reason=f"{trigger_type}トリガー",
                            )

                        self.logger.info(
                            f"✅ Phase 49.2: ポジション決済完了 - "
                            f"ID: {order_id}, {trigger_type}価格: {exit_price:.0f}円"
                        )

                    except Exception as e:
                        self.logger.warning(
                            f"⚠️ Phase 49.2: 決済シミュレーションエラー - {order_id}: {e}"
                        )

        except Exception as e:
            self.logger.error(f"❌ Phase 49.2: TP/SLトリガーチェックエラー: {e}")

    async def _setup_current_market_data_fast(self, current_index: int):
        """
        現在時点の市場データを準備（Phase 35: 高速化版）

        最適化:
        - df[df.index <= timestamp]を排除（O(n)→O(1)）
        - インデックスベース直接スライシング使用
        - 100倍以上の高速化
        """
        # グローバル時刻をバックテスト時刻に設定
        await self._set_simulated_time(self.current_timestamp)

        # 各タイムフレームのデータを準備
        current_market_data = {}

        for timeframe, df in self.csv_data.items():
            if df.empty:
                continue

            # Phase 35: インデックスベース高速スライシング
            # メインタイムフレームと同じインデックス位置を使用
            end_idx = min(current_index + 1, len(df))
            start_idx = max(0, end_idx - self.lookback_window)

            # Phase 35.1: 事前計算済み特徴量を使用（10倍高速化）
            if timeframe in self.precomputed_features:
                # 事前計算済み特徴量から直接スライス（特徴量計算スキップ）
                current_market_data[timeframe] = self.precomputed_features[timeframe].iloc[
                    start_idx:end_idx
                ]
            else:
                # フォールバック: 事前計算なしの場合は元のデータ
                current_market_data[timeframe] = df.iloc[start_idx:end_idx]

        # データサービスにバックテスト用データを設定
        self.orchestrator.data_service.set_backtest_data(current_market_data)

        # Phase 35.4: 事前計算済みML予測を設定
        main_timeframe = self.timeframes[0] if self.timeframes else "4h"
        if main_timeframe in self.precomputed_ml_predictions and current_index < len(
            self.precomputed_ml_predictions[main_timeframe]["predictions"]
        ):
            import numpy as np

            predictions = self.precomputed_ml_predictions[main_timeframe]["predictions"]
            probabilities = self.precomputed_ml_predictions[main_timeframe]["probabilities"]

            # 現在インデックスの予測値を取得
            prediction = int(predictions[current_index])
            confidence = float(np.max(probabilities[current_index]))

            # data_serviceにML予測を設定
            self.orchestrator.data_service.set_backtest_ml_prediction(
                {"prediction": prediction, "confidence": confidence}
            )

    async def _setup_current_market_data(self):
        """現在時点の市場データを準備（旧版・後方互換性維持）"""
        # Phase 35で_setup_current_market_data_fast()に置き換え
        # 互換性のため残すが、使用されない
        await self._setup_current_market_data_fast(self.data_index)

    async def _set_simulated_time(self, timestamp: datetime):
        """シミュレーション時刻設定"""
        # グローバル時刻管理クラスがあれば設定
        # 現在は実装せず、将来的に時刻シミュレーションを追加
        pass

    async def _save_progress_report(self):
        """進捗レポート保存（Phase 35: JSON serializable修正）"""
        try:
            progress_stats = {
                "current_timestamp": (
                    self.current_timestamp.isoformat() if self.current_timestamp else None
                ),
                "progress_percentage": (
                    (self.data_index / self.total_data_points) * 100
                    if self.total_data_points > 0
                    else 0
                ),
                "cycles_completed": self.cycle_count,
                "processed_data_points": len(self.processed_timestamps),
            }

            # バックテストレポーターに進捗保存
            await self.orchestrator.backtest_reporter.save_progress_report(progress_stats)

        except Exception as e:
            self.logger.warning(f"⚠️ 進捗レポート保存エラー: {e}")

    async def _generate_final_backtest_report(self):
        """最終バックテストレポート生成（Phase 35: JSON serializable修正）"""
        try:
            # 最終統計収集（Phase 35: datetime→ISO文字列変換でJSON serializable化）
            final_stats = {
                "backtest_period": {
                    "start": self.backtest_start.isoformat() if self.backtest_start else None,
                    "end": self.backtest_end.isoformat() if self.backtest_end else None,
                    "duration_days": (self.backtest_end - self.backtest_start).days,
                },
                "data_processing": {
                    "total_data_points": self.total_data_points,
                    "processed_cycles": self.cycle_count,
                    "processed_timestamps": len(self.processed_timestamps),
                    "success_rate": (
                        len(self.processed_timestamps) / self.total_data_points * 100
                        if self.total_data_points > 0
                        else 0
                    ),
                },
                "timeframes": list(self.csv_data.keys()),
                "symbol": self.symbol,
            }

            # バックテストレポーター経由で詳細レポート生成
            # Phase 35: datetime→ISO文字列変換
            await self.orchestrator.backtest_reporter.generate_backtest_report(
                final_stats,
                self.backtest_start.isoformat() if self.backtest_start else None,
                self.backtest_end.isoformat() if self.backtest_end else None,
            )

        except Exception as e:
            self.logger.error(f"❌ 最終レポート生成エラー: {e}")

    async def _save_error_report(self, error_message: str):
        """エラーレポート保存"""
        try:
            context = {
                "backtest_runner": "Phase22_BacktestRunner",
                "current_timestamp": self.current_timestamp,
                "data_index": self.data_index,
                "cycle_count": self.cycle_count,
            }

            await self.orchestrator.backtest_reporter.save_error_report(error_message, context)

        except Exception as e:
            self.logger.warning(f"⚠️ エラーレポート保存失敗: {e}")
