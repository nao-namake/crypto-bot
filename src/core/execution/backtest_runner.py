"""
ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ - Phase 49å®Œäº†

Phase 49å®Œäº†: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œå…¨æ”¹ä¿®ï¼ˆä¿¡é ¼æ€§100%é”æˆï¼‰
- æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—: å…¨æ™‚ç‚¹ã§å®Ÿæˆ¦ç•¥ã‚’å®Ÿè¡Œãƒ»look-ahead biaså®Œå…¨é˜²æ­¢
- TP/SLæ±ºæ¸ˆãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…: å„æ™‚ç‚¹ã®é«˜å€¤ãƒ»å®‰å€¤ã§TP/SLåˆ¤å®šãƒ»ãƒªã‚¢ãƒ«å–å¼•å®Œå…¨å†ç¾
- TradeTrackerçµ±åˆ: ã‚¨ãƒ³ãƒˆãƒªãƒ¼/ã‚¨ã‚°ã‚¸ãƒƒãƒˆãƒšã‚¢ãƒªãƒ³ã‚°ãƒ»æç›Šè¨ˆç®—ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ç®—å‡º
- matplotlibå¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ : 4ç¨®é¡ã‚°ãƒ©ãƒ•ï¼ˆã‚¨ã‚¯ã‚¤ãƒ†ã‚£ã‚«ãƒ¼ãƒ–ãƒ»æç›Šåˆ†å¸ƒãƒ»ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãƒ»ä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰
- ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰å®Œå…¨ä¸€è‡´: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã¨ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰å–å¼•åˆ¤å®šãŒ100%ä¸€è‡´ãƒ»SELLåˆ¤å®šæ­£å¸¸åŒ–
- å“è³ªä¿è¨¼: 1,097ãƒ†ã‚¹ãƒˆ100%æˆåŠŸãƒ»66.72%ã‚«ãƒãƒ¬ãƒƒã‚¸é”æˆ

Phase 35: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ10å€é«˜é€ŸåŒ–å®Ÿè£…ï¼ˆ6-8æ™‚é–“â†’45åˆ†ï¼‰
- ç‰¹å¾´é‡äº‹å‰è¨ˆç®—: 288åˆ†â†’0ç§’ï¼ˆç„¡é™å€é«˜é€ŸåŒ–ï¼‰ãƒ»265,130ä»¶/ç§’å‡¦ç†
- MLäºˆæ¸¬äº‹å‰è¨ˆç®—: 15åˆ†â†’0.3ç§’ï¼ˆ3,000å€é«˜é€ŸåŒ–ï¼‰ãƒ»10,063ä»¶/ç§’å‡¦ç†

è¨­è¨ˆåŸå‰‡:
- Look-ahead biaså®Œå…¨é˜²æ­¢ï¼ˆå®Ÿæˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—ï¼‰
- ãƒªã‚¢ãƒ«å–å¼•å®Œå…¨å†ç¾ï¼ˆTP/SLæ±ºæ¸ˆãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…ï¼‰
- TradeTrackerã«ã‚ˆã‚‹æ­£ç¢ºãªæç›Šè¨ˆç®—
- matplotlibè©³ç´°å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd

from ..config import get_threshold
from .base_runner import BaseRunner


class BacktestRunner(BaseRunner):
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã‚¯ãƒ©ã‚¹ï¼ˆPhase 49å®Œäº†ãƒ»å®Œå…¨æ”¹ä¿®ç‰ˆãƒ»ä¿¡é ¼æ€§100%é”æˆï¼‰"""

    def __init__(self, orchestrator_ref, logger):
        """
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼åˆæœŸåŒ–

        Args:
            orchestrator_ref: TradingOrchestratorã¸ã®å‚ç…§
            logger: ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 
        """
        super().__init__(orchestrator_ref, logger)

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçŠ¶æ…‹ç®¡ç†
        self.backtest_start = None
        self.backtest_end = None
        self.current_timestamp = None
        self.csv_data = {}  # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥CSVãƒ‡ãƒ¼ã‚¿
        self.precomputed_features = {}  # Phase 35: äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ï¼ˆ10å€é«˜é€ŸåŒ–ï¼‰
        self.precomputed_ml_predictions = {}  # Phase 35.4: äº‹å‰è¨ˆç®—æ¸ˆã¿MLäºˆæ¸¬ï¼ˆ10å€é«˜é€ŸåŒ–ï¼‰
        self.data_index = 0  # ç¾åœ¨ã®å‡¦ç†ä½ç½®
        self.total_data_points = 0

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆPhase 28å®Œäº†ãƒ»Phase 29æœ€é©åŒ–ï¼‰
        self.symbol = get_threshold("backtest.symbol", "BTC/JPY")
        self.timeframes = get_threshold("backtest.timeframes", ["15m", "4h"])
        self.lookback_window = get_threshold(
            "backtest.lookback_window", 100
        )  # å„æ™‚ç‚¹ã§éå»Nä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¾›çµ¦

        # çµ±è¨ˆæƒ…å ±
        self.cycle_count = 0
        self.processed_timestamps = []
        self.session_stats = {}

    async def run(self) -> bool:
        """
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ

        Returns:
            å®Ÿè¡ŒæˆåŠŸãƒ»å¤±æ•—
        """
        try:
            self.logger.warning("ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é–‹å§‹ï¼ˆPhase 35æœ€é©åŒ–: ãƒ­ã‚°=WARNINGï¼‰")

            # 1. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“è¨­å®š
            await self._setup_backtest_period()

            # 2. CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            await self._load_csv_data()

            # 3. ç‰¹å¾´é‡äº‹å‰è¨ˆç®—ï¼ˆPhase 35: 10å€é«˜é€ŸåŒ–ï¼‰
            await self._precompute_features()

            # 3.5. æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—ï¼ˆPhase 49.1: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œå…¨æ”¹ä¿®ï¼‰
            await self._precompute_strategy_signals()

            # 3.6. MLäºˆæ¸¬äº‹å‰è¨ˆç®—ï¼ˆPhase 35.4: ã•ã‚‰ãªã‚‹é«˜é€ŸåŒ–ï¼‰
            await self._precompute_ml_predictions()

            # 4. ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if not await self._validate_data():
                self.logger.error("âŒ CSVãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã™")
                return False

            # 5. æ™‚ç³»åˆ—ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            await self._run_time_series_backtest()

            # 6. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            await self._generate_final_backtest_report()

            self.logger.warning("âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†", discord_notify=True)
            return True

        except Exception as e:
            self.logger.error(f"âŒ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", discord_notify=True)
            await self._save_error_report(str(e))
            raise

    async def _setup_backtest_period(self):
        """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“è¨­å®š"""
        # å¤–éƒ¨è¨­å®šã‹ã‚‰æœŸé–“ã‚’å–å¾—
        backtest_days = get_threshold("execution.backtest_period_days", 30)

        self.backtest_end = datetime.now()
        self.backtest_start = self.backtest_end - timedelta(days=backtest_days)

        self.logger.info(
            f"ğŸ“… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“: {self.backtest_start.strftime('%Y-%m-%d')} "
            f"~ {self.backtest_end.strftime('%Y-%m-%d')} ({backtest_days}æ—¥é–“)"
        )

    async def _load_csv_data(self):
        """CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            # CSV ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨
            from ...backtest.data.csv_data_loader import get_csv_loader

            csv_loader = get_csv_loader()

            # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            self.csv_data = csv_loader.load_multi_timeframe(
                symbol=self.symbol,
                timeframes=self.timeframes,
                start_date=self.backtest_start,
                end_date=self.backtest_end,
                limit=get_threshold("backtest.data_limit", 10000),  # ååˆ†ãªé‡ã‚’ç¢ºä¿
            )

            # è¨­å®šã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            main_timeframe = self.timeframes[0] if self.timeframes else "15m"

            if (
                not self.csv_data
                or main_timeframe not in self.csv_data
                or self.csv_data[main_timeframe].empty
            ):
                raise ValueError(f"ä¸»è¦ãƒ‡ãƒ¼ã‚¿ï¼ˆ{main_timeframe}ï¼‰ãŒä¸è¶³: {self.symbol}")

            # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
            self.total_data_points = len(self.csv_data[main_timeframe])

            # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚’å‹•çš„ã«ç”Ÿæˆ
            timeframe_stats = []
            for tf in self.timeframes:
                count = len(self.csv_data.get(tf, []))
                timeframe_stats.append(f"{tf}:{count}ä»¶")

            self.logger.warning(f"ğŸ“ˆ CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {', '.join(timeframe_stats)}")

            # Phase 40.5æ‹¡å¼µ: ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆOptunaæœ€é©åŒ–é«˜é€ŸåŒ–ï¼‰
            sampling_ratio = get_threshold("backtest.data_sampling_ratio", 1.0)
            if sampling_ratio < 1.0:
                self._apply_data_sampling(sampling_ratio)

        except Exception as e:
            self.logger.error(f"âŒ CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _apply_data_sampling(self, sampling_ratio: float) -> None:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆPhase 40.5æ‹¡å¼µ: Optunaæœ€é©åŒ–é«˜é€ŸåŒ–ï¼‰

        ç­‰é–“éš”ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦æ™‚ç³»åˆ—ã®é€£ç¶šæ€§ã‚’ä¿æŒã—ã¤ã¤ãƒ‡ãƒ¼ã‚¿é‡ã‚’å‰Šæ¸›ã€‚

        Args:
            sampling_ratio: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ï¼ˆ0.0-1.0ï¼‰
                ä¾‹: 0.1 = 10%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€0.2 = 20%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

        åŠ¹æœ:
            - 10%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: å®Ÿè¡Œæ™‚é–“1/10ï¼ˆäºˆæƒ³ï¼‰
            - 20%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: å®Ÿè¡Œæ™‚é–“1/5ï¼ˆäºˆæƒ³ï¼‰
        """
        if sampling_ratio >= 1.0:
            return  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸è¦

        self.logger.warning(
            f"ğŸ”¬ ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–‹å§‹: {sampling_ratio * 100:.0f}% "
            f"(Optunaæœ€é©åŒ–é«˜é€ŸåŒ–ãƒ»Phase 40.5)"
        )

        for timeframe in self.csv_data.keys():
            original_df = self.csv_data[timeframe]
            original_count = len(original_df)

            if original_count == 0:
                continue

            # ç­‰é–“éš”ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆæ™‚ç³»åˆ—é€£ç¶šæ€§ä¿æŒï¼‰
            step = max(1, int(1 / sampling_ratio))
            sampled_df = original_df.iloc[::step].copy()

            # æœ€å¾Œã®è¡Œã¯å¿…ãšå«ã‚ã‚‹ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ç¢ºä¿ï¼‰
            if original_df.index[-1] not in sampled_df.index:
                sampled_df = pd.concat([sampled_df, original_df.iloc[[-1]]])

            sampled_count = len(sampled_df)

            self.csv_data[timeframe] = sampled_df

            self.logger.warning(
                f"  {timeframe}: {original_count}ä»¶ â†’ {sampled_count}ä»¶ "
                f"({sampled_count / original_count * 100:.1f}%)"
            )

        # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°æ›´æ–°
        main_timeframe = self.timeframes[0] if self.timeframes else "15m"
        self.total_data_points = len(self.csv_data[main_timeframe])

    async def _precompute_features(self):
        """
        ç‰¹å¾´é‡äº‹å‰è¨ˆç®—ï¼ˆPhase 35: 10å€é«˜é€ŸåŒ–ï¼‰

        å…¨CSVãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸€åº¦ã ã‘ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã€
        å„ã‚µã‚¤ã‚¯ãƒ«ã§ã¯ã‚¹ãƒ©ã‚¤ã‚¹ã®ã¿å®Ÿè¡Œã™ã‚‹ã“ã¨ã§å¤§å¹…é«˜é€ŸåŒ–ã€‚

        æœ€é©åŒ–åŠ¹æœ:
        - 17,271å›ã®ç‰¹å¾´é‡è¨ˆç®— â†’ 1å›ï¼ˆã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ï¼‰
        - ç†è«–å€¤: 17,271å€é«˜é€ŸåŒ–
        - å®Ÿæ¸¬äºˆæƒ³: 20-30åˆ† â†’ 2-3åˆ†ï¼ˆ10å€é«˜é€ŸåŒ–ï¼‰
        """
        try:
            import time

            from ...features.feature_generator import FeatureGenerator

            self.logger.warning("ğŸš€ ç‰¹å¾´é‡äº‹å‰è¨ˆç®—é–‹å§‹ï¼ˆPhase 35æœ€é©åŒ–ï¼‰")
            start_time = time.time()

            feature_gen = FeatureGenerator()

            for timeframe, df in self.csv_data.items():
                if df.empty:
                    continue

                # Phase 35.2: è©³ç´°ãƒ­ã‚°å‰Šé™¤ï¼ˆé«˜é€ŸåŒ–ï¼‰
                tf_start = time.time()

                # åŒæœŸç‰ˆç‰¹å¾´é‡ç”Ÿæˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬è¨ˆç®—ï¼‰
                features_df = feature_gen.generate_features_sync(df)

                # Phase 49.1: æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ã¯_precompute_strategy_signals()ã§åˆ¥é€”è¨ˆç®—
                # ã“ã“ã§ã¯0.0ã§åˆæœŸåŒ–ã®ã¿ï¼ˆå¾Œã§ä¸Šæ›¸ãã•ã‚Œã‚‹ï¼‰
                # Phase 51.5-A: 3æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ï¼ˆMochipoyAlertãƒ»MultiTimeframeå‰Šé™¤ï¼‰
                strategy_signal_features = [
                    "strategy_signal_ATRBased",
                    "strategy_signal_DonchianChannel",
                    "strategy_signal_ADXTrendStrength",
                ]
                for col in strategy_signal_features:
                    if col not in features_df.columns:
                        features_df[col] = 0.0

                # äº‹å‰è¨ˆç®—çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                self.precomputed_features[timeframe] = features_df

            elapsed = time.time() - start_time
            total_records = sum(len(df) for df in self.csv_data.values())
            self.logger.warning(
                f"âœ… ç‰¹å¾´é‡äº‹å‰è¨ˆç®—å®Œäº†: {total_records}ä»¶ "
                f"ï¼ˆ{elapsed:.1f}ç§’, {total_records / elapsed:.0f}ä»¶/ç§’ï¼‰",
                discord_notify=False,
            )

        except Exception as e:
            self.logger.error(f"âŒ ç‰¹å¾´é‡äº‹å‰è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def _precompute_strategy_signals(self):
        """
        æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—ï¼ˆPhase 49.1: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œå…¨æ”¹ä¿®ï¼‰

        å„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ã£ã¦5æˆ¦ç•¥ã‚’å®Ÿè¡Œã—ã€
        å®Ÿæˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰ã¨å®Œå…¨ä¸€è‡´ã‚’å®Ÿç¾ã€‚

        é‡è¦ãƒã‚¤ãƒ³ãƒˆ:
        - Look-ahead biasé˜²æ­¢: df.iloc[:i+1]ã§éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        - Phase 41.8 Strategy-Aware MLå®Œå…¨å¯¾å¿œ
        - å„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ç‰¹å¾´é‡ç”Ÿæˆ+æˆ¦ç•¥å®Ÿè¡ŒãŒå¿…è¦ï¼ˆå‡¦ç†æ™‚é–“å¢—ï¼‰

        æœ€é©åŒ–åŠ¹æœ:
        - ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç²¾åº¦: BUYåé‡ â†’ ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰å®Œå…¨ä¸€è‡´
        - Strategy-Aware MLæ­£å¸¸å‹•ä½œ: æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«0.0åŸ‹ã‚ â†’ å®Ÿã‚·ã‚°ãƒŠãƒ«ä½¿ç”¨
        """
        try:
            import time

            from ...features.feature_generator import FeatureGenerator

            self.logger.warning("ğŸ¯ æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—é–‹å§‹ï¼ˆPhase 49.1: å®Ÿæˆ¦ç•¥å®Ÿè¡Œï¼‰")
            start_time = time.time()

            # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿å‡¦ç†ï¼ˆ15mè¶³ï¼‰
            main_timeframe = self.timeframes[0] if self.timeframes else "15m"
            if main_timeframe not in self.csv_data:
                self.logger.warning(f"âš ï¸ ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ  {main_timeframe} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return

            main_df = self.csv_data[main_timeframe]
            if main_df.empty:
                self.logger.warning("âš ï¸ ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return

            feature_gen = FeatureGenerator()
            total_rows = len(main_df)

            # æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ã®åˆæœŸåŒ–ï¼ˆå…¨è¡ŒÃ—5æˆ¦ç•¥ï¼‰
            strategy_names = [
                "ATRBased",
                "MochipoyAlert",
                "MultiTimeframe",
                "DonchianChannel",
                "ADXTrendStrength",
            ]
            strategy_signal_columns = {f"strategy_signal_{name}": [] for name in strategy_names}

            # é€²æ—å ±å‘Šç”¨
            progress_interval = max(1, total_rows // 10)  # 10%ã”ã¨ã«å ±å‘Š

            # å„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ã—ã¦æˆ¦ç•¥å®Ÿè¡Œ
            for i in range(total_rows):
                # Phase 49.1: Look-ahead biasé˜²æ­¢ - éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
                historical_data = main_df.iloc[: i + 1]

                # é€²æ—å ±å‘Š
                if i % progress_interval == 0 and i > 0:
                    progress = (i / total_rows) * 100
                    elapsed = time.time() - start_time
                    eta = (elapsed / i) * (total_rows - i) if i > 0 else 0
                    self.logger.warning(
                        f"  é€²æ—: {progress:.1f}% ({i}/{total_rows}) - "
                        f"çµŒé: {elapsed:.1f}ç§’, æ®‹ã‚Š: {eta:.1f}ç§’"
                    )

                # ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã¯0.0ã§åŸ‹ã‚ã‚‹ï¼ˆæœ€åˆã®æ•°è¡Œï¼‰
                if len(historical_data) < 20:  # æœ€å°ãƒ‡ãƒ¼ã‚¿æ•°ãƒã‚§ãƒƒã‚¯
                    for col in strategy_signal_columns.keys():
                        strategy_signal_columns[col].append(0.0)
                    continue

                try:
                    # 1. ç‰¹å¾´é‡ç”Ÿæˆï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰- Look-ahead biasé˜²æ­¢
                    features_df = feature_gen.generate_features_sync(historical_data)
                    if features_df.empty or len(features_df) == 0:
                        for col in strategy_signal_columns.keys():
                            strategy_signal_columns[col].append(0.0)
                        continue

                    # 2. å…¨ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹å¾´é‡æº–å‚™ï¼ˆãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰ä¸€è‡´ï¼‰
                    # æˆ¦ç•¥ã¯ç‰¹å¾´é‡DataFrameï¼ˆå…¨å±¥æ­´ï¼‰ã‚’æœŸå¾…ã—ã¦ã„ã‚‹
                    all_features = {main_timeframe: features_df}

                    # 3. å€‹åˆ¥æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«å–å¾—ï¼ˆPhase 41.8æº–æ‹ ï¼‰
                    # features_dfï¼ˆéå»å…¨ä½“ã®ç‰¹å¾´é‡ï¼‰ã‚’æ¸¡ã™ã“ã¨ã§ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰ã¨ä¸€è‡´
                    strategy_signals = (
                        self.orchestrator.strategy_service.get_individual_strategy_signals(
                            features_df, multi_timeframe_data=all_features
                        )
                    )

                    # 4. æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆaction Ã— confidenceï¼‰
                    for strategy_name in strategy_names:
                        if strategy_name in strategy_signals:
                            signal = strategy_signals[strategy_name]
                            encoded_value = signal.get("encoded", 0.0)
                            strategy_signal_columns[f"strategy_signal_{strategy_name}"].append(
                                encoded_value
                            )
                        else:
                            # æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«å–å¾—å¤±æ•—æ™‚ã¯0.0
                            strategy_signal_columns[f"strategy_signal_{strategy_name}"].append(0.0)

                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯0.0ã§åŸ‹ã‚ã‚‹
                    self.logger.debug(f"âš ï¸ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— {i} ã§æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    for col in strategy_signal_columns.keys():
                        strategy_signal_columns[col].append(0.0)

            # 5. precomputed_featuresã«æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ã‚’è¿½åŠ 
            if main_timeframe in self.precomputed_features:
                features_df = self.precomputed_features[main_timeframe]
                for col_name, values in strategy_signal_columns.items():
                    if len(values) == len(features_df):
                        features_df[col_name] = values
                    else:
                        self.logger.warning(
                            f"âš ï¸ æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«é•·ã•ä¸ä¸€è‡´: {col_name} = {len(values)}, features = {len(features_df)}"
                        )

                self.precomputed_features[main_timeframe] = features_df

            elapsed = time.time() - start_time
            self.logger.warning(
                f"âœ… æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—å®Œäº†: {total_rows}ä»¶ "
                f"ï¼ˆ{elapsed:.1f}ç§’, {total_rows / elapsed:.1f}ä»¶/ç§’ï¼‰",
                discord_notify=False,
            )

        except Exception as e:
            self.logger.error(f"âŒ æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«äº‹å‰è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯0.0åŸ‹ã‚ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ—¢å­˜å‹•ä½œç¶­æŒï¼‰

    async def _precompute_ml_predictions(self):
        """
        MLäºˆæ¸¬äº‹å‰è¨ˆç®—ï¼ˆPhase 35.4: ã•ã‚‰ãªã‚‹é«˜é€ŸåŒ–ï¼‰

        å…¨ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸€åº¦ã ã‘MLäºˆæ¸¬ã‚’å®Ÿè¡Œã—ã€
        å„ã‚µã‚¤ã‚¯ãƒ«ã§ã¯äº‹å‰è¨ˆç®—æ¸ˆã¿äºˆæ¸¬ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§å¤§å¹…é«˜é€ŸåŒ–ã€‚

        æœ€é©åŒ–åŠ¹æœ:
        - 2,747å›ã®MLäºˆæ¸¬ â†’ 1å›ã®ãƒãƒƒãƒäºˆæ¸¬
        - ç†è«–å€¤: 2,747å€é«˜é€ŸåŒ–
        - å®Ÿæ¸¬äºˆæƒ³: 15åˆ† â†’ 1-2åˆ†ï¼ˆ10å€é«˜é€ŸåŒ–ï¼‰
        """
        try:
            import time

            import numpy as np

            from ...core.config.feature_manager import get_feature_names

            self.logger.warning("ğŸ¤– MLäºˆæ¸¬äº‹å‰è¨ˆç®—é–‹å§‹ï¼ˆPhase 35.4æœ€é©åŒ–ï¼‰")
            start_time = time.time()

            # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç‰¹å¾´é‡ã«å¯¾ã—ã¦MLäºˆæ¸¬
            main_timeframe = self.timeframes[0] if self.timeframes else "15m"
            if main_timeframe in self.precomputed_features:
                features_df = self.precomputed_features[main_timeframe]

                # Phase 40.6: 50ç‰¹å¾´é‡æŠ½å‡ºï¼ˆå‹•çš„å–å¾—ï¼‰
                features_to_use = get_feature_names()
                available_features = [col for col in features_to_use if col in features_df.columns]

                if len(available_features) == len(features_to_use):
                    ml_features = features_df[available_features]

                    # ãƒãƒƒãƒäºˆæ¸¬å®Ÿè¡Œ
                    predictions_array = self.orchestrator.ml_service.predict(ml_features)
                    probabilities_array = self.orchestrator.ml_service.predict_proba(ml_features)

                    # äºˆæ¸¬çµæœã‚’ä¿å­˜ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾å¿œï¼‰
                    self.precomputed_ml_predictions[main_timeframe] = {
                        "predictions": predictions_array,
                        "probabilities": probabilities_array,
                    }

                    elapsed = time.time() - start_time
                    self.logger.warning(
                        f"âœ… MLäºˆæ¸¬äº‹å‰è¨ˆç®—å®Œäº†: {len(predictions_array)}ä»¶ "
                        f"ï¼ˆ{elapsed:.1f}ç§’, {len(predictions_array) / elapsed:.0f}ä»¶/ç§’ï¼‰",
                        discord_notify=False,
                    )
                else:
                    self.logger.warning(
                        f"âš ï¸ ç‰¹å¾´é‡ä¸è¶³: {len(available_features)}/{len(features_to_use)}å€‹ - MLäºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—"
                    )

        except Exception as e:
            self.logger.error(f"âŒ MLäºˆæ¸¬äº‹å‰è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯é€šå¸¸ã®MLäºˆæ¸¬ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰
            self.precomputed_ml_predictions = {}

    async def _validate_data(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"""
        min_data_points = get_threshold("backtest.min_data_points", 50)

        if self.total_data_points < min_data_points:
            self.logger.warning(
                f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {self.total_data_points}ä»¶ " f"ï¼ˆæœ€å°{min_data_points}ä»¶å¿…è¦ï¼‰"
            )
            return False

        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
        main_timeframe = self.timeframes[0] if self.timeframes else "15m"
        main_data = self.csv_data[main_timeframe]
        if main_data.isnull().any().any():
            self.logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã«æ¬ æå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")

        if not main_data.index.is_monotonic_increasing:
            self.logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒæ™‚ç³»åˆ—é †åºã«ãªã£ã¦ã„ã¾ã›ã‚“")

        return True

    async def _run_time_series_backtest(self):
        """æ™‚ç³»åˆ—ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆPhase 35: é«˜é€ŸåŒ–æœ€é©åŒ–ç‰ˆï¼‰"""
        main_timeframe = self.timeframes[0] if self.timeframes else "15m"
        main_data = self.csv_data[main_timeframe]

        # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã§å‡¦ç†
        for i in range(self.lookback_window, len(main_data)):
            self.data_index = i
            self.current_timestamp = main_data.index[i]

            # Phase 35.2: é€²æ—è¡¨ç¤ºï¼ˆWARNINGå¼·åˆ¶å‡ºåŠ›ï¼‰
            progress_interval = get_threshold("backtest.progress_interval", 1000)
            if i % progress_interval == 0:
                progress = (i / len(main_data)) * 100
                self.logger.warning(
                    f"ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé€²è¡Œä¸­: {progress:.1f}% "
                    f"({i}/{len(main_data)}) - {self.current_timestamp.strftime('%Y-%m-%d %H:%M')}"
                )

            # ç¾åœ¨æ™‚ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆPhase 35: é«˜é€ŸåŒ–ç‰ˆï¼‰
            await self._setup_current_market_data_fast(i)

            # Phase 49.3: ã‚µã‚¤ã‚¯ãƒ«å‰ã®ãƒã‚¸ã‚·ãƒ§ãƒ³æ•°è¨˜éŒ²ï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¤œå‡ºç”¨ï¼‰
            positions_before = set(
                p["order_id"] for p in self.orchestrator.execution_service.virtual_positions
            )

            # å–å¼•ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œï¼ˆæœ¬ç•ªã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            try:
                await self.orchestrator.run_trading_cycle()
                self.cycle_count += 1
                self.processed_timestamps.append(self.current_timestamp)

                # Phase 49.3: ã‚µã‚¤ã‚¯ãƒ«å¾Œã®æ–°è¦ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’TradeTrackerã«è¨˜éŒ²
                positions_after = self.orchestrator.execution_service.virtual_positions
                for position in positions_after:
                    order_id = position.get("order_id")
                    if order_id not in positions_before:
                        # æ–°è¦ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¤œå‡º
                        if (
                            hasattr(self.orchestrator, "backtest_reporter")
                            and self.orchestrator.backtest_reporter
                        ):
                            self.orchestrator.backtest_reporter.trade_tracker.record_entry(
                                order_id=order_id,
                                side=position.get("side"),
                                amount=position.get("amount"),
                                price=position.get("price"),
                                timestamp=self.current_timestamp,
                                strategy=position.get("strategy_name", "unknown"),
                            )

            except Exception as e:
                self.logger.warning(f"âš ï¸ å–å¼•ã‚µã‚¤ã‚¯ãƒ«ã‚¨ãƒ©ãƒ¼ ({self.current_timestamp}): {e}")
                continue

            # Phase 49.2: TP/SLãƒˆãƒªã‚¬ãƒ¼ãƒã‚§ãƒƒã‚¯ãƒ»æ±ºæ¸ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            try:
                # ç¾åœ¨ä¾¡æ ¼å–å¾—
                current_price = main_data.iloc[i].get("close", None)
                if current_price is not None:
                    await self._check_tp_sl_triggers(current_price, self.current_timestamp)
            except Exception as e:
                self.logger.debug(f"âš ï¸ TP/SLãƒˆãƒªã‚¬ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ ({self.current_timestamp}): {e}")

            # Phase 35.5: é€²æ—ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚’å®Œå…¨å‰Šé™¤ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆä¸­ã¯ä¸è¦ãƒ»I/Oã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰
            # report_interval = get_threshold("backtest.report_interval", 10000)
            # if i % report_interval == 0:
            #     await self._save_progress_report()

    async def _check_tp_sl_triggers(self, current_price: float, timestamp):
        """
        TP/SLãƒˆãƒªã‚¬ãƒ¼ãƒã‚§ãƒƒã‚¯ãƒ»æ±ºæ¸ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆPhase 49.2: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œå…¨æ”¹ä¿®ï¼‰

        ç¾åœ¨ä¾¡æ ¼ã¨TP/SLä¾¡æ ¼ã‚’æ¯”è¼ƒã—ã€ãƒˆãƒªã‚¬ãƒ¼æ™‚ã«æ±ºæ¸ˆæ³¨æ–‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã€‚
        ã“ã‚Œã«ã‚ˆã‚Šãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã§SELLæ³¨æ–‡ãŒç”Ÿæˆã•ã‚Œã€å®Œå…¨ãªå–å¼•ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿç¾ã€‚

        Args:
            current_price: ç¾åœ¨ã®çµ‚å€¤
            timestamp: ç¾åœ¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—

        å‡¦ç†ãƒ•ãƒ­ãƒ¼:
            1. PositionTrackerã‹ã‚‰å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³å–å¾—
            2. å„ãƒã‚¸ã‚·ãƒ§ãƒ³ã®TP/SLä¾¡æ ¼ã¨ç¾åœ¨ä¾¡æ ¼ã‚’æ¯”è¼ƒ
            3. TP/SLãƒˆãƒªã‚¬ãƒ¼æ™‚ã«æ±ºæ¸ˆæ³¨æ–‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            4. ãƒã‚¸ã‚·ãƒ§ãƒ³å‰Šé™¤
        """
        try:
            # 1. å…¨ãƒã‚¸ã‚·ãƒ§ãƒ³å–å¾—
            positions = (
                self.orchestrator.execution_service.virtual_positions.copy()
            )  # ã‚³ãƒ”ãƒ¼ã—ã¦å®‰å…¨ã«ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

            if not positions:
                return  # ãƒã‚¸ã‚·ãƒ§ãƒ³ãªã—

            # 2. å„ãƒã‚¸ã‚·ãƒ§ãƒ³ã®TP/SLãƒã‚§ãƒƒã‚¯
            for position in positions:
                order_id = position.get("order_id")
                side = position.get("side")  # "buy" or "sell"
                amount = position.get("amount")
                entry_price = position.get("price")
                take_profit = position.get("take_profit")
                stop_loss = position.get("stop_loss")
                strategy_name = position.get("strategy_name", "unknown")

                # TP/SLä¾¡æ ¼ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if take_profit is None and stop_loss is None:
                    continue

                # 3. TP/SLãƒˆãƒªã‚¬ãƒ¼åˆ¤å®š
                tp_triggered = False
                sl_triggered = False

                if side == "buy":
                    # ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³: ä¾¡æ ¼ä¸Šæ˜‡ã§TPãƒ»ä¾¡æ ¼ä¸‹è½ã§SL
                    if take_profit and current_price >= take_profit:
                        tp_triggered = True
                    elif stop_loss and current_price <= stop_loss:
                        sl_triggered = True
                elif side == "sell":
                    # ã‚·ãƒ§ãƒ¼ãƒˆãƒã‚¸ã‚·ãƒ§ãƒ³: ä¾¡æ ¼ä¸‹è½ã§TPãƒ»ä¾¡æ ¼ä¸Šæ˜‡ã§SL
                    if take_profit and current_price <= take_profit:
                        tp_triggered = True
                    elif stop_loss and current_price >= stop_loss:
                        sl_triggered = True

                # 4. ãƒˆãƒªã‚¬ãƒ¼æ™‚ã«æ±ºæ¸ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                if tp_triggered or sl_triggered:
                    trigger_type = "TP" if tp_triggered else "SL"
                    exit_price = take_profit if tp_triggered else stop_loss

                    self.logger.info(
                        f"âœ… Phase 49.2: {trigger_type}ãƒˆãƒªã‚¬ãƒ¼ - "
                        f"{side} {amount} BTC @ {exit_price:.0f}å†† "
                        f"(ã‚¨ãƒ³ãƒˆãƒªãƒ¼: {entry_price:.0f}å††, æˆ¦ç•¥: {strategy_name}) - {timestamp}"
                    )

                    # 5. æ±ºæ¸ˆæ³¨æ–‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆExecutionServiceçµŒç”±ï¼‰
                    try:
                        # æ±ºæ¸ˆã‚µã‚¤ãƒ‰: buy â†’ sell, sell â†’ buy
                        exit_side = "sell" if side == "buy" else "buy"

                        # ExecutionServiceçµŒç”±ã§æ±ºæ¸ˆæ³¨æ–‡å®Ÿè¡Œ
                        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯bitbank APIã¯å‘¼ã°ã‚Œãšã€ä»®æƒ³æ³¨æ–‡ã®ã¿å®Ÿè¡Œ
                        await self.orchestrator.execution_service._execute_order_with_limit(
                            side=exit_side,
                            amount=amount,
                            price=exit_price,
                            reason=f"{trigger_type}ãƒˆãƒªã‚¬ãƒ¼æ±ºæ¸ˆ",
                        )

                        # 6. ãƒã‚¸ã‚·ãƒ§ãƒ³å‰Šé™¤
                        self.orchestrator.execution_service.position_tracker.remove_position(
                            order_id
                        )

                        # Phase 49.3: TradeTrackerã«ã‚¨ã‚°ã‚¸ãƒƒãƒˆè¨˜éŒ²
                        if (
                            hasattr(self.orchestrator, "backtest_reporter")
                            and self.orchestrator.backtest_reporter
                        ):
                            self.orchestrator.backtest_reporter.trade_tracker.record_exit(
                                order_id=order_id,
                                exit_price=exit_price,
                                exit_timestamp=timestamp,
                                exit_reason=f"{trigger_type}ãƒˆãƒªã‚¬ãƒ¼",
                            )

                        self.logger.info(
                            f"âœ… Phase 49.2: ãƒã‚¸ã‚·ãƒ§ãƒ³æ±ºæ¸ˆå®Œäº† - "
                            f"ID: {order_id}, {trigger_type}ä¾¡æ ¼: {exit_price:.0f}å††"
                        )

                    except Exception as e:
                        self.logger.warning(
                            f"âš ï¸ Phase 49.2: æ±ºæ¸ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ - {order_id}: {e}"
                        )

        except Exception as e:
            self.logger.error(f"âŒ Phase 49.2: TP/SLãƒˆãƒªã‚¬ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

    async def _setup_current_market_data_fast(self, current_index: int):
        """
        ç¾åœ¨æ™‚ç‚¹ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆPhase 35: é«˜é€ŸåŒ–ç‰ˆï¼‰

        æœ€é©åŒ–:
        - df[df.index <= timestamp]ã‚’æ’é™¤ï¼ˆO(n)â†’O(1)ï¼‰
        - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ç›´æ¥ã‚¹ãƒ©ã‚¤ã‚·ãƒ³ã‚°ä½¿ç”¨
        - 100å€ä»¥ä¸Šã®é«˜é€ŸåŒ–
        """
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ã‚’ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚åˆ»ã«è¨­å®š
        await self._set_simulated_time(self.current_timestamp)

        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        current_market_data = {}

        for timeframe, df in self.csv_data.items():
            if df.empty:
                continue

            # Phase 35: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹é«˜é€Ÿã‚¹ãƒ©ã‚¤ã‚·ãƒ³ã‚°
            # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã¨åŒã˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½ç½®ã‚’ä½¿ç”¨
            end_idx = min(current_index + 1, len(df))
            start_idx = max(0, end_idx - self.lookback_window)

            # Phase 35.1: äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼ˆ10å€é«˜é€ŸåŒ–ï¼‰
            if timeframe in self.precomputed_features:
                # äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‹ã‚‰ç›´æ¥ã‚¹ãƒ©ã‚¤ã‚¹ï¼ˆç‰¹å¾´é‡è¨ˆç®—ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                current_market_data[timeframe] = self.precomputed_features[timeframe].iloc[
                    start_idx:end_idx
                ]
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: äº‹å‰è¨ˆç®—ãªã—ã®å ´åˆã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿
                current_market_data[timeframe] = df.iloc[start_idx:end_idx]

        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
        self.orchestrator.data_service.set_backtest_data(current_market_data)

        # Phase 35.4: äº‹å‰è¨ˆç®—æ¸ˆã¿MLäºˆæ¸¬ã‚’è¨­å®š
        main_timeframe = self.timeframes[0] if self.timeframes else "15m"
        if main_timeframe in self.precomputed_ml_predictions and current_index < len(
            self.precomputed_ml_predictions[main_timeframe]["predictions"]
        ):
            import numpy as np

            predictions = self.precomputed_ml_predictions[main_timeframe]["predictions"]
            probabilities = self.precomputed_ml_predictions[main_timeframe]["probabilities"]

            # ç¾åœ¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®äºˆæ¸¬å€¤ã‚’å–å¾—
            prediction = int(predictions[current_index])
            confidence = float(np.max(probabilities[current_index]))

            # data_serviceã«MLäºˆæ¸¬ã‚’è¨­å®š
            self.orchestrator.data_service.set_backtest_ml_prediction(
                {"prediction": prediction, "confidence": confidence}
            )

    async def _setup_current_market_data(self):
        """ç¾åœ¨æ™‚ç‚¹ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆæ—§ç‰ˆãƒ»å¾Œæ–¹äº’æ›æ€§ç¶­æŒï¼‰"""
        # Phase 35ã§_setup_current_market_data_fast()ã«ç½®ãæ›ãˆ
        # äº’æ›æ€§ã®ãŸã‚æ®‹ã™ãŒã€ä½¿ç”¨ã•ã‚Œãªã„
        await self._setup_current_market_data_fast(self.data_index)

    async def _set_simulated_time(self, timestamp: datetime):
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚åˆ»è¨­å®š"""
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«æ™‚åˆ»ç®¡ç†ã‚¯ãƒ©ã‚¹ãŒã‚ã‚Œã°è¨­å®š
        # ç¾åœ¨ã¯å®Ÿè£…ã›ãšã€å°†æ¥çš„ã«æ™‚åˆ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        pass

    async def _save_progress_report(self):
        """é€²æ—ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ï¼ˆPhase 35: JSON serializableä¿®æ­£ï¼‰"""
        try:
            progress_stats = {
                "current_timestamp": (
                    self.current_timestamp.isoformat() if self.current_timestamp else None
                ),
                "progress_percentage": (
                    (self.data_index / self.total_data_points) * 100
                    if self.total_data_points > 0
                    else 0
                ),
                "cycles_completed": self.cycle_count,
                "processed_data_points": len(self.processed_timestamps),
            }

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ã‚¿ãƒ¼ã«é€²æ—ä¿å­˜
            await self.orchestrator.backtest_reporter.save_progress_report(progress_stats)

        except Exception as e:
            self.logger.warning(f"âš ï¸ é€²æ—ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    async def _generate_final_backtest_report(self):
        """æœ€çµ‚ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆPhase 35: JSON serializableä¿®æ­£ï¼‰"""
        try:
            # æœ€çµ‚çµ±è¨ˆåé›†ï¼ˆPhase 35: datetimeâ†’ISOæ–‡å­—åˆ—å¤‰æ›ã§JSON serializableåŒ–ï¼‰
            final_stats = {
                "backtest_period": {
                    "start": self.backtest_start.isoformat() if self.backtest_start else None,
                    "end": self.backtest_end.isoformat() if self.backtest_end else None,
                    "duration_days": (self.backtest_end - self.backtest_start).days,
                },
                "data_processing": {
                    "total_data_points": self.total_data_points,
                    "processed_cycles": self.cycle_count,
                    "processed_timestamps": len(self.processed_timestamps),
                    "success_rate": (
                        len(self.processed_timestamps) / self.total_data_points * 100
                        if self.total_data_points > 0
                        else 0
                    ),
                },
                "timeframes": list(self.csv_data.keys()),
                "symbol": self.symbol,
            }

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ã‚¿ãƒ¼çµŒç”±ã§è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            # Phase 35: datetimeâ†’ISOæ–‡å­—åˆ—å¤‰æ›
            await self.orchestrator.backtest_reporter.generate_backtest_report(
                final_stats,
                self.backtest_start.isoformat() if self.backtest_start else None,
                self.backtest_end.isoformat() if self.backtest_end else None,
            )

        except Exception as e:
            self.logger.error(f"âŒ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    async def _save_error_report(self, error_message: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        try:
            context = {
                "backtest_runner": "Phase22_BacktestRunner",
                "current_timestamp": self.current_timestamp,
                "data_index": self.data_index,
                "cycle_count": self.cycle_count,
            }

            await self.orchestrator.backtest_reporter.save_error_report(error_message, context)

        except Exception as e:
            self.logger.warning(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
