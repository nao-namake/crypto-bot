"""
ç‰¹å¾´é‡ç”Ÿæˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ  - Phase 18çµ±åˆç‰ˆ

TechnicalIndicatorsã€MarketAnomalyDetectorã€FeatureServiceAdapterã‚’
1ã¤ã®ã‚¯ãƒ©ã‚¹ã«çµ±åˆã—ã€é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šé™¤ã¨ä¿å®ˆæ€§å‘ä¸Šã‚’å®Ÿç¾ã€‚

97ç‰¹å¾´é‡ã‹ã‚‰12ç‰¹å¾´é‡ã¸ã®æ¥µé™æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ã€‚

çµ±åˆåŠ¹æœ:
- ãƒ•ã‚¡ã‚¤ãƒ«æ•°å‰Šæ¸›: 3â†’1ï¼ˆ67%å‰Šæ¸›ï¼‰
- ã‚³ãƒ¼ãƒ‰è¡Œæ•°å‰Šæ¸›: 461è¡Œâ†’ç´„250è¡Œï¼ˆ46%å‰Šæ¸›ï¼‰
- é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šé™¤: _handle_nan_valuesã€loggeråˆæœŸåŒ–ç­‰
- ç®¡ç†ç°¡ç´ åŒ–: ç‰¹å¾´é‡å‡¦ç†ã®å®Œå…¨ä¸€å…ƒåŒ–

Phase 18çµ±åˆå®Ÿè£…æ—¥: 2025å¹´8æœˆ31æ—¥.
"""

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from ..core.config import get_anomaly_config

# Phase 19: ç‰¹å¾´é‡å®šç¾©ä¸€å…ƒåŒ–ï¼ˆfeature_managerã‹ã‚‰å–å¾—ï¼‰
from ..core.config.feature_manager import get_feature_categories, get_feature_names
from ..core.exceptions import DataProcessingError
from ..core.logger import CryptoBotLogger, get_logger

# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆä¸€å…ƒåŒ–å¯¾å¿œï¼‰
OPTIMIZED_FEATURES = get_feature_names()

# ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªï¼ˆä¸€å…ƒåŒ–å¯¾å¿œï¼‰
FEATURE_CATEGORIES = get_feature_categories()


class FeatureGenerator:
    """
    çµ±åˆç‰¹å¾´é‡ç”Ÿæˆã‚¯ãƒ©ã‚¹ - Phase 19çµ±åˆç‰ˆ

    ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã€ç•°å¸¸æ¤œçŸ¥ã€ç‰¹å¾´é‡ã‚µãƒ¼ãƒ“ã‚¹æ©Ÿèƒ½ã‚’
    1ã¤ã®ã‚¯ãƒ©ã‚¹ã«çµ±åˆã—ã€12ç‰¹å¾´é‡ç”Ÿæˆã‚’åŠ¹ç‡çš„ã«æä¾›ã€‚

    ä¸»è¦æ©Ÿèƒ½:
    - ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ç”Ÿæˆï¼ˆ6å€‹ï¼‰
    - ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ç”Ÿæˆï¼ˆ3å€‹ï¼‰
    - åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ3å€‹ï¼‰
    - çµ±åˆå“è³ªç®¡ç†ã¨12ç‰¹å¾´é‡ç¢ºèª
    """

    def __init__(self, lookback_period: Optional[int] = None) -> None:
        """
        åˆæœŸåŒ–

        Args:
            lookback_period: ç•°å¸¸æ¤œçŸ¥ã®å‚ç…§æœŸé–“
        """
        self.logger = get_logger()
        self.lookback_period = lookback_period or get_anomaly_config(
            "spike_detection.lookback_period", 20
        )
        self.computed_features = set()

    async def generate_features(self, market_data: Dict[str, Any]) -> pd.DataFrame:
        """
        çµ±åˆç‰¹å¾´é‡ç”Ÿæˆå‡¦ç†ï¼ˆ12ç‰¹å¾´é‡ç¢ºèªæ©Ÿèƒ½ä»˜ãï¼‰

        Args:
            market_data: å¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrame ã¾ãŸã¯ dictï¼‰

        Returns:
            12ç‰¹å¾´é‡ã‚’å«ã‚€DataFrame
        """
        try:
            # DataFrameã«å¤‰æ›
            result_df = self._convert_to_dataframe(market_data)

            self.logger.info("ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹ - 12ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ")
            self.computed_features.clear()

            # å¿…è¦åˆ—ãƒã‚§ãƒƒã‚¯
            self._validate_required_columns(result_df)

            # ğŸ”¹ åŸºæœ¬ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ3å€‹ï¼‰
            result_df = self._generate_basic_features(result_df)

            # ğŸ”¹ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’ç”Ÿæˆï¼ˆ6å€‹ï¼‰
            result_df = self._generate_technical_indicators(result_df)

            # ğŸ”¹ ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ã‚’ç”Ÿæˆï¼ˆ3å€‹ï¼‰
            result_df = self._generate_anomaly_indicators(result_df)

            # ğŸ”¹ NaNå€¤å‡¦ç†ï¼ˆçµ±åˆç‰ˆï¼‰
            result_df = self._handle_nan_values(result_df)

            # ğŸ¯ 12ç‰¹å¾´é‡å®Œå…¨ç¢ºèªãƒ»æ¤œè¨¼
            self._validate_feature_generation(result_df)

            # DataFrameã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆæˆ¦ç•¥ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
            return result_df

        except Exception as e:
            self.logger.error(f"çµ±åˆç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise DataProcessingError(f"ç‰¹å¾´é‡ç”Ÿæˆå¤±æ•—: {e}")

    def _convert_to_dataframe(self, market_data: Dict[str, Any]) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›ï¼ˆã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸å¯¾å¿œï¼‰"""
        if isinstance(market_data, pd.DataFrame):
            return market_data.copy()
        elif isinstance(market_data, dict):
            try:
                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸ã®å ´åˆï¼ˆãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ï¼‰
                # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ : 4hï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰, 15mï¼ˆã‚µãƒ–ï¼‰
                timeframe_keys = ["4h", "15m"]  # å„ªå…ˆé †ä½é †
                for tf in timeframe_keys:
                    if tf in market_data and isinstance(market_data[tf], pd.DataFrame):
                        self.logger.info(f"ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸ã‹ã‚‰ãƒ¡ã‚¤ãƒ³æ™‚ç³»åˆ—å–å¾—: {tf}")
                        return market_data[tf].copy()

                # é€šå¸¸ã®è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã®å ´åˆï¼ˆOHLCVå½¢å¼ç­‰ï¼‰
                # å…¨ã¦ã®å€¤ãŒã‚¹ã‚«ãƒ©ãƒ¼ã‹ãƒªã‚¹ãƒˆã‹ã‚’ãƒã‚§ãƒƒã‚¯
                if all(
                    isinstance(v, (int, float, str)) or (isinstance(v, list) and len(v) > 0)
                    for v in market_data.values()
                ):
                    return pd.DataFrame(market_data)

                # ãã®ä»–ã®æ§‹é€ ã®è¾æ›¸
                self.logger.warning(f"è¤‡é›‘ãªè¾æ›¸æ§‹é€ ã‚’æ¤œå‡º: keys={list(market_data.keys())}")
                return pd.DataFrame(market_data)

            except (ValueError, KeyError, TypeError) as e:
                self.logger.error(
                    f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ - æ§‹é€ : {type(market_data)}, ã‚­ãƒ¼: {list(market_data.keys()) if hasattr(market_data, 'keys') else 'N/A'}"
                )
                raise DataProcessingError(f"Dictâ†’DataFrameå¤‰æ›ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚¨ãƒ©ãƒ¼: {e}")
            except (MemoryError, OverflowError) as e:
                raise DataProcessingError(f"Dictâ†’DataFrameå¤‰æ›ã‚µã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
            except Exception as e:
                raise DataProcessingError(f"Dictâ†’DataFrameå¤‰æ›äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            raise ValueError(f"Unsupported market_data type: {type(market_data)}")

    def _validate_required_columns(self, df: pd.DataFrame) -> None:
        """å¿…è¦åˆ—ã®å­˜åœ¨ç¢ºèª"""
        required_cols = ["open", "high", "low", "close", "volume"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise DataProcessingError(f"å¿…è¦åˆ—ãŒä¸è¶³: {missing_cols}")

    def _generate_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ3å€‹ï¼‰"""
        result_df = df.copy()

        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾ï¼ˆclose, volumeï¼‰
        basic_features = []
        if "close" in result_df.columns:
            basic_features.append("close")
        if "volume" in result_df.columns:
            basic_features.append("volume")

        # returns_1ã‚’è¨ˆç®—
        if "close" in result_df.columns:
            result_df["returns_1"] = result_df["close"].pct_change(1, fill_method=None)
            result_df["returns_1"] = result_df["returns_1"].fillna(0)
            basic_features.append("returns_1")

        self.computed_features.update(basic_features)
        self.logger.debug(f"åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(basic_features)}å€‹")
        return result_df

    def _generate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ç”Ÿæˆï¼ˆ6å€‹ï¼‰"""
        result_df = df.copy()

        # RSI 14æœŸé–“
        result_df["rsi_14"] = self._calculate_rsi(result_df["close"])
        self.computed_features.add("rsi_14")

        # MACDï¼ˆãƒ©ã‚¤ãƒ³ã¨ã‚·ã‚°ãƒŠãƒ«ä¸¡æ–¹ç”Ÿæˆï¼‰
        macd_line, macd_signal = self._calculate_macd(result_df["close"])
        result_df["macd"] = macd_line
        result_df["macd_signal"] = macd_signal
        self.computed_features.add("macd")
        self.computed_features.add("macd_signal")

        # ATR 14æœŸé–“
        result_df["atr_14"] = self._calculate_atr(result_df)
        self.computed_features.add("atr_14")

        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä½ç½®
        result_df["bb_position"] = self._calculate_bb_position(result_df["close"])
        self.computed_features.add("bb_position")

        # EMA 20æœŸé–“ãƒ»50æœŸé–“
        result_df["ema_20"] = result_df["close"].ewm(span=20, adjust=False).mean()
        result_df["ema_50"] = result_df["close"].ewm(span=50, adjust=False).mean()
        self.computed_features.update(["ema_20", "ema_50"])

        self.logger.debug(f"ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ç”Ÿæˆå®Œäº†: 6å€‹")
        return result_df

    def _generate_anomaly_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ç”Ÿæˆï¼ˆ3å€‹ï¼‰"""
        result_df = df.copy()

        # Z-Score
        result_df["zscore"] = self._calculate_zscore(result_df["close"])
        self.computed_features.add("zscore")

        # å‡ºæ¥é«˜æ¯”ç‡
        result_df["volume_ratio"] = self._calculate_volume_ratio(result_df["volume"])
        self.computed_features.add("volume_ratio")

        self.logger.debug(f"ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ç”Ÿæˆå®Œäº†: 2å€‹")
        return result_df

    def _calculate_rsi(self, close: pd.Series, period: int = 14) -> pd.Series:
        """RSIè¨ˆç®—"""
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period, min_periods=1).mean()
        rs = gain / (loss + 1e-8)
        return 100 - (100 / (1 + rs))

    def _calculate_macd(self, close: pd.Series) -> tuple:
        """MACDè¨ˆç®—ï¼ˆMACDãƒ©ã‚¤ãƒ³ã¨ã‚·ã‚°ãƒŠãƒ«ãƒ©ã‚¤ãƒ³ã‚’è¿”ã™ï¼‰"""
        exp1 = close.ewm(span=12, adjust=False).mean()
        exp2 = close.ewm(span=26, adjust=False).mean()
        macd_line = exp1 - exp2
        macd_signal = macd_line.ewm(span=9, adjust=False).mean()
        return macd_line, macd_signal

    def _calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """ATRè¨ˆç®—"""
        high_low = df["high"] - df["low"]
        high_close = np.abs(df["high"] - df["close"].shift())
        low_close = np.abs(df["low"] - df["close"].shift())
        true_range = np.maximum(high_low, np.maximum(high_close, low_close))
        return true_range.rolling(window=period, min_periods=1).mean()

    def _calculate_bb_position(self, close: pd.Series, period: int = 20) -> pd.Series:
        """ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä½ç½®è¨ˆç®—"""
        bb_middle = close.rolling(window=period, min_periods=1).mean()
        bb_std_dev = close.rolling(window=period, min_periods=1).std()
        bb_upper = bb_middle + (bb_std_dev * 2)
        bb_lower = bb_middle - (bb_std_dev * 2)
        return (close - bb_lower) / (bb_upper - bb_lower + 1e-8)

    def _calculate_zscore(self, close: pd.Series, period: Optional[int] = None) -> pd.Series:
        """Z-Scoreè¨ˆç®—"""
        try:
            if period is None:
                period = get_anomaly_config("zscore.calculation_period", 20)
            rolling_mean = close.rolling(window=period, min_periods=1).mean()
            rolling_std = close.rolling(window=period, min_periods=1).std()
            return (close - rolling_mean) / (rolling_std + 1e-8)
        except Exception as e:
            self.logger.error(f"Z-Scoreè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.Series(np.zeros(len(close)), index=close.index)

    def _calculate_volume_ratio(self, volume: pd.Series, period: Optional[int] = None) -> pd.Series:
        """å‡ºæ¥é«˜æ¯”ç‡è¨ˆç®—"""
        try:
            if period is None:
                period = get_anomaly_config("volume_ratio.calculation_period", 20)
            volume_avg = volume.rolling(window=period, min_periods=1).mean()
            return volume / (volume_avg + 1e-8)
        except Exception as e:
            self.logger.error(f"å‡ºæ¥é«˜æ¯”ç‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.Series(np.zeros(len(volume)), index=volume.index)

    # Phase 19: market_stressç‰¹å¾´é‡å‰Šé™¤ï¼ˆ12ç‰¹å¾´é‡çµ±ä¸€ï¼‰
    # def _calculate_market_stress(self, df: pd.DataFrame) -> pd.Series:
    #     """å¸‚å ´ã‚¹ãƒˆãƒ¬ã‚¹åº¦æŒ‡æ¨™è¨ˆç®—ï¼ˆçµ±åˆç•°å¸¸æŒ‡æ¨™ï¼‰"""

    def _normalize(self, series: pd.Series) -> pd.Series:
        """0-1ç¯„å›²ã«æ­£è¦åŒ–"""
        try:
            # å¤–ã‚Œå€¤å‡¦ç†ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
            outlier_clip_quantile = get_anomaly_config("normalization.outlier_clip_quantile", 0.95)
            upper_bound = series.quantile(outlier_clip_quantile)
            clipped_series = np.clip(series, 0, upper_bound)

            # 0-1æ­£è¦åŒ–
            min_val = clipped_series.min()
            max_val = clipped_series.max()

            if max_val - min_val == 0:
                return pd.Series(np.zeros(len(series)), index=series.index)

            return (clipped_series - min_val) / (max_val - min_val)

        except Exception:
            return pd.Series(np.zeros(len(series)), index=series.index)

    def _handle_nan_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """NaNå€¤å‡¦ç†ï¼ˆçµ±åˆç‰ˆï¼‰"""
        for feature in self.computed_features:
            if feature in df.columns:
                df[feature] = df[feature].ffill().bfill().fillna(0)
        return df

    def _validate_feature_generation(self, df: pd.DataFrame) -> None:
        """12ç‰¹å¾´é‡å®Œå…¨ç¢ºèªãƒ»æ¤œè¨¼"""
        generated_features = [col for col in OPTIMIZED_FEATURES if col in df.columns]
        missing_features = [col for col in OPTIMIZED_FEATURES if col not in df.columns]

        # ğŸš¨ çµ±åˆãƒ­ã‚°å‡ºåŠ›
        self.logger.info(
            f"ç‰¹å¾´é‡ç”Ÿæˆå®Œäº† - ç·æ•°: {len(generated_features)}/{len(OPTIMIZED_FEATURES)}å€‹",
            extra_data={
                "basic_features": len(
                    [f for f in ["close", "volume", "returns_1"] if f in df.columns]
                ),
                "technical_features": len(
                    [
                        f
                        for f in [
                            "rsi_14",
                            "macd",
                            "atr_14",
                            "bb_position",
                            "ema_20",
                            "ema_50",
                        ]
                        if f in df.columns
                    ]
                ),
                "anomaly_features": len([f for f in ["zscore", "volume_ratio"] if f in df.columns]),
                "generated_features": generated_features,
                "missing_features": missing_features,
                "total_expected": len(OPTIMIZED_FEATURES),
                "success": len(generated_features) == len(OPTIMIZED_FEATURES),
            },
        )

        # âš ï¸ ä¸è¶³ç‰¹å¾´é‡ã®è­¦å‘Š
        if missing_features:
            self.logger.warning(
                f"ğŸš¨ ç‰¹å¾´é‡ä¸è¶³æ¤œå‡º: {missing_features} ({len(missing_features)}å€‹ä¸è¶³)"
            )
        else:
            self.logger.info("âœ… 12ç‰¹å¾´é‡å®Œå…¨ç”ŸæˆæˆåŠŸ")

    def generate_features_sync(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        åŒæœŸç‰¹å¾´é‡ç”Ÿæˆï¼ˆå¾Œæ–¹äº’æ›æ€§ç”¨ï¼‰

        Phase 18çµ±åˆã«ã‚ˆã‚Šã€ãƒ†ã‚¹ãƒˆã¨ã®äº’æ›æ€§ã®ãŸã‚åŒæœŸç‰ˆã‚’æä¾›ã€‚
        DataFrameå…¥åŠ›ãƒ»DataFrameå‡ºåŠ›ã§ã€ç•°å¸¸æ¤œçŸ¥ç‰¹å¾´é‡ã®ã¿ç”Ÿæˆã€‚

        Args:
            df: OHLCVãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        Returns:
            ç‰¹å¾´é‡è¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        # å¿…è¦åˆ—ã®ãƒã‚§ãƒƒã‚¯ï¼ˆOHLCVå…¨ã¦å¿…è¦ï¼‰
        required_columns = ["open", "high", "low", "close", "volume"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            from src.core.exceptions import DataProcessingError

            raise DataProcessingError(f"å¿…è¦åˆ—ãŒä¸è¶³: {missing_columns}")

        # ç°¡æ˜“ç‰ˆï¼šmarket_stressç‰¹å¾´é‡ã®ã¿ç”Ÿæˆ
        result_df = df.copy()

        # åŠ¹æœçš„ãªlookback_periodã‚’æ±ºå®šï¼ˆæœ€å°3ã€æœ€å¤§ã¯ãƒ‡ãƒ¼ã‚¿é•·ã®80%ï¼‰
        effective_lookback = min(self.lookback_period, max(3, int(len(df) * 0.8)))

        # å‡ºæ¥é«˜ç•°å¸¸æ¤œçŸ¥ (volume_ratio)
        if "volume" in df.columns:
            if len(df) >= 2:
                rolling_mean = df["volume"].rolling(window=effective_lookback, min_periods=1).mean()
                volume_ratio = df["volume"] / rolling_mean.fillna(df["volume"].mean())
                result_df["volume_ratio"] = volume_ratio.fillna(1.0)
            else:
                result_df["volume_ratio"] = 1.0

        # ä¾¡æ ¼Z-Score (zscore)
        if "close" in df.columns:
            if len(df) >= 2:
                rolling_mean = df["close"].rolling(window=effective_lookback, min_periods=1).mean()
                rolling_std = df["close"].rolling(window=effective_lookback, min_periods=1).std()
                zscore = (df["close"] - rolling_mean) / rolling_std.fillna(
                    1.0
                )  # std=0ã®å ´åˆã¯1.0ã§é™¤ç®—
                result_df["zscore"] = zscore.fillna(0.0)
            else:
                result_df["zscore"] = 0.0

        # Phase 19: market_stresså‰Šé™¤ï¼ˆ12ç‰¹å¾´é‡çµ±ä¸€ï¼‰
        # å¸‚å ´ã‚¹ãƒˆãƒ¬ã‚¹ (market_stress) - çµ±åˆæŒ‡æ¨™ - å‰Šé™¤æ¸ˆã¿

        # computed_featuresã‚’æ›´æ–°ï¼ˆmarket_stressé™¤å¤–ï¼‰
        self.computed_features.update(["volume_ratio", "zscore"])

        return result_df

    def get_feature_info(self) -> Dict[str, Any]:
        """ç‰¹å¾´é‡æƒ…å ±å–å¾—"""
        return {
            "total_features": len(self.computed_features),
            "computed_features": sorted(list(self.computed_features)),
            "feature_categories": FEATURE_CATEGORIES,
            "optimized_features": OPTIMIZED_FEATURES,
            "parameters": {"lookback_period": self.lookback_period},
            "feature_descriptions": {
                "close": "çµ‚å€¤ï¼ˆåŸºæº–ä¾¡æ ¼ï¼‰",
                "volume": "å‡ºæ¥é«˜ï¼ˆå¸‚å ´æ´»å‹•åº¦ï¼‰",
                "returns_1": "1æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆçŸ­æœŸãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼‰",
                "rsi_14": "RSIï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒœãƒ¼ãƒˆãƒ»ã‚½ãƒ¼ãƒ«ãƒ‰åˆ¤å®šï¼‰",
                "macd": "MACDï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã‚·ã‚°ãƒŠãƒ«ï¼‰",
                "macd_signal": "MACDã‚·ã‚°ãƒŠãƒ«ï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼‰",
                "atr_14": "ATRï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¸¬å®šï¼‰",
                "bb_position": "ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä½ç½®ï¼ˆä¾¡æ ¼ä½ç½®ï¼‰",
                "ema_20": "EMAçŸ­æœŸï¼ˆçŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰",
                "ema_50": "EMAä¸­æœŸï¼ˆä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰",
                "volume_ratio": "å‡ºæ¥é«˜æ¯”ç‡ï¼ˆå‡ºæ¥é«˜ç•°å¸¸æ¤œçŸ¥ï¼‰",
                "zscore": "ä¾¡æ ¼Z-Scoreï¼ˆæ¨™æº–åŒ–ä¾¡æ ¼ä½ç½®ï¼‰",
            },
        }


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
TechnicalIndicators = FeatureGenerator
MarketAnomalyDetector = FeatureGenerator
FeatureServiceAdapter = FeatureGenerator

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒªã‚¹ãƒˆ
__all__ = [
    "FeatureGenerator",
    "TechnicalIndicators",
    "MarketAnomalyDetector",
    "FeatureServiceAdapter",
    "OPTIMIZED_FEATURES",
    "FEATURE_CATEGORIES",
]
