"""
ç‰¹å¾´é‡ç”Ÿæˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ 

æœ€çµ‚æ›´æ–°: 2025/11/16 (Phase 52.4-B)

TechnicalIndicatorsã€MarketAnomalyDetectorã€FeatureServiceAdapterã‚’
1ã¤ã®ã‚¯ãƒ©ã‚¹ã«çµ±åˆã—ã€é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šé™¤ã¨ä¿å®ˆæ€§å‘ä¸Šã‚’å®Ÿç¾ã€‚

é–‹ç™ºå±¥æ­´:
- Phase 52.4-B (2025/11/16): ã‚³ãƒ¼ãƒ‰æ•´ç†ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçµ±ä¸€å®Œäº†ãƒ»ç‰¹å¾´é‡æ•°ã‚³ãƒ¡ãƒ³ãƒˆä¿®æ­£
- Phase 51.7 Day 7 (2025/11/07): 6æˆ¦ç•¥çµ±åˆãƒ»55ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ç¢ºç«‹
- Phase 51.7 Day 2 (2025/11/07): Feature Importanceåˆ†æã«åŸºã¥ãæœ€é©åŒ–
- Phase 50.9 (2025/11/01): å¤–éƒ¨APIå®Œå…¨å‰Šé™¤ãƒ»ã‚·ãƒ³ãƒ—ãƒ«è¨­è¨ˆå›å¸°
- Phase 50.2 (2025/10/28): æ™‚é–“çš„ç‰¹å¾´é‡æ‹¡å¼µï¼ˆå¸‚å ´ã‚»ãƒƒã‚·ãƒ§ãƒ³+å‘¨æœŸæ€§è¿½åŠ ï¼‰
- Phase 50.1 (2025/10/27): ç¢ºå®Ÿãªç‰¹å¾´é‡ç”Ÿæˆå®Ÿè£…ï¼ˆstrategy_signals=Noneæ™‚ã‚‚0åŸ‹ã‚ï¼‰
- Phase 41 (2025/10/17): Strategy-Aware MLå®Ÿè£…ãƒ»æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«è¿½åŠ 
- Phase 40.6 (2025/10/15): Feature Engineeringæ‹¡å¼µï¼ˆLag/Rolling/Interaction/Timeï¼‰
- Phase 38.4 (2025/10/13): 97â†’15ç‰¹å¾´é‡æœ€é©åŒ–

çµ±åˆåŠ¹æœ:
- ãƒ•ã‚¡ã‚¤ãƒ«æ•°å‰Šæ¸›: 3â†’1ï¼ˆ67%å‰Šæ¸›ï¼‰
- ã‚³ãƒ¼ãƒ‰è¡Œæ•°å‰Šæ¸›: 461è¡Œâ†’ç´„250è¡Œï¼ˆ46%å‰Šé™¤ï¼‰
- é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šé™¤: _handle_nan_valuesã€loggeråˆæœŸåŒ–ç­‰
- ç®¡ç†ç°¡ç´ åŒ–: ç‰¹å¾´é‡å‡¦ç†ã®å®Œå…¨ä¸€å…ƒåŒ–
"""

import os
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from ..core.config import get_anomaly_config

# Phase 38.4: ç‰¹å¾´é‡å®šç¾©ä¸€å…ƒåŒ–ï¼ˆfeature_managerã‹ã‚‰å–å¾—ï¼‰
from ..core.config.feature_manager import (
    get_feature_categories,
    get_feature_count,
    get_feature_names,
)
from ..core.exceptions import DataProcessingError
from ..core.logger import CryptoBotLogger, get_logger

# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆä¸€å…ƒåŒ–å¯¾å¿œï¼‰
OPTIMIZED_FEATURES = get_feature_names()

# ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªï¼ˆä¸€å…ƒåŒ–å¯¾å¿œï¼‰
FEATURE_CATEGORIES = get_feature_categories()

# ========================================
# ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šæ•°
# ========================================
# Phase 52.4-B: Magic numberæŠ½å‡º

# RSI
RSI_PERIOD = 14

# MACD
MACD_FAST_PERIOD = 12
MACD_SLOW_PERIOD = 26
MACD_SIGNAL_PERIOD = 9

# ATR
ATR_PERIOD = 14

# Bollinger Bands
BB_PERIOD = 20
BB_STD_MULTIPLIER = 2

# EMA
EMA_SHORT_PERIOD = 20
EMA_LONG_PERIOD = 50

# Donchian Channel
DONCHIAN_PERIOD = 20

# ADX
ADX_PERIOD = 14

# Stochastic Oscillator
STOCHASTIC_PERIOD = 14
STOCHASTIC_SMOOTH_K = 3
STOCHASTIC_SMOOTH_D = 3

# Volume EMA
VOLUME_EMA_PERIOD = 20

# Lag features
LAG_PERIODS_CLOSE = [1, 2, 3, 10]
LAG_PERIODS_VOLUME = [1, 2, 3]
LAG_PERIODS_INDICATOR = [1]  # RSI, MACD

# Rolling statistics
ROLLING_WINDOWS_MA = [10, 20]
ROLLING_WINDOWS_STD = [5, 10, 20]

# Market hours (JST)
MARKET_OPEN_HOUR = 9
MARKET_CLOSE_HOUR = 15
EUROPE_SESSION_START = 16
EUROPE_SESSION_END_HOUR = 23
EUROPE_SESSION_EARLY_HOUR = 1

# Numerical stability
EPSILON = 1e-8

# Cyclic encoding
HOURS_PER_DAY = 24
DAYS_PER_WEEK = 7


class FeatureGenerator:
    """
    çµ±åˆç‰¹å¾´é‡ç”Ÿæˆã‚¯ãƒ©ã‚¹

    æœ€çµ‚æ›´æ–°: 2025/11/16 (Phase 52.4-B)

    ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã€ç•°å¸¸æ¤œçŸ¥ã€ç‰¹å¾´é‡ã‚µãƒ¼ãƒ“ã‚¹æ©Ÿèƒ½ã‚’
    1ã¤ã®ã‚¯ãƒ©ã‚¹ã«çµ±åˆã—ã€55ç‰¹å¾´é‡ã‚’ç¢ºå®Ÿã«ç”Ÿæˆã€‚

    ä¸»è¦æ©Ÿèƒ½:
    - åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ2å€‹ï¼‰
    - ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ç”Ÿæˆï¼ˆ17å€‹ï¼šRSI, MACDæ‹¡å¼µ, ATR, BBæ‹¡å¼µ, EMA, Donchian, ADX, Stochasticç­‰ï¼‰
    - ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ç”Ÿæˆï¼ˆ1å€‹ï¼šVolume Ratioï¼‰
    - ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ9å€‹ï¼šClose/Volume/RSI/MACD lagï¼‰
    - ç§»å‹•çµ±è¨ˆé‡ç”Ÿæˆï¼ˆ5å€‹ï¼šMA, Stdï¼‰
    - äº¤äº’ä½œç”¨ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ5å€‹ï¼šRSIÃ—ATR, MACDÃ—Volumeç­‰ï¼‰
    - æ™‚é–“ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ7å€‹ï¼šHour, Day, å¸‚å ´ã‚»ãƒƒã‚·ãƒ§ãƒ³, å‘¨æœŸæ€§ï¼‰
    - æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ6å€‹ï¼šæˆ¦ç•¥åˆ¤æ–­ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰
    - çµ±åˆå“è³ªç®¡ç†ã¨ç‰¹å¾´é‡ç¢ºèªï¼ˆå¿…ãš55ç‰¹å¾´é‡ï¼‰

    ç‰¹å¾´é‡æœ€é©åŒ–:
    - 55ç‰¹å¾´é‡å›ºå®šï¼ˆ49åŸºæœ¬+6æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ï¼‰
    - Feature Importanceåˆ†æã«åŸºã¥ãæœ€é©åŒ–
    - 6æˆ¦ç•¥å¯¾å¿œï¼ˆStochastic, MACDæ‹¡å¼µ, BBæ‹¡å¼µç­‰ï¼‰
    - ã‚·ã‚¹ãƒ†ãƒ ç²¾åº¦å‘ä¸Šãƒ»ä¿å®ˆæ€§å‘ä¸Š

    ä¿¡é ¼æ€§ä¿è¨¼:
    - å¿…ãšå›ºå®šæ•°ç”Ÿæˆï¼ˆstrategy_signals=Noneæ™‚ã‚‚0.0åŸ‹ã‚ï¼‰
    - å¾Œã‹ã‚‰è¿½åŠ ã—ãªã„è¨­è¨ˆ
    - MLäºˆæ¸¬ã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼ˆç‰¹å¾´é‡æ•°ä¸ä¸€è‡´è§£æ¶ˆï¼‰
    """

    def __init__(self, lookback_period: Optional[int] = None) -> None:
        """
        åˆæœŸåŒ–

        Args:
            lookback_period: ç•°å¸¸æ¤œçŸ¥ã®å‚ç…§æœŸé–“
        """
        self.logger = get_logger()
        self.lookback_period = lookback_period or get_anomaly_config(
            "spike_detection.lookback_period", 20
        )
        self.computed_features = set()

    async def generate_features(
        self,
        market_data: Dict[str, Any],
        strategy_signals: Optional[Dict[str, Dict[str, float]]] = None,
    ) -> pd.DataFrame:
        """
        çµ±åˆç‰¹å¾´é‡ç”Ÿæˆå‡¦ç†

        Args:
            market_data: å¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆDataFrame ã¾ãŸã¯ dictï¼‰
            strategy_signals: æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«è¾æ›¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ç‰¹å¾´é‡ã‚’å«ã‚€DataFrameï¼ˆ55ç‰¹å¾´é‡å›ºå®šï¼‰

        Raises:
            DataProcessingError: ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼

        Note:
            - Phase 52.4-B: 55ç‰¹å¾´é‡å›ºå®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆ49åŸºæœ¬+6æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ï¼‰
            - ç¢ºå®Ÿãªç‰¹å¾´é‡ç”Ÿæˆï¼ˆstrategy_signals=Noneæ™‚ã‚‚6å€‹ã‚’0åŸ‹ã‚ï¼‰
            - ä¿¡é ¼æ€§å‘ä¸Š: å¾Œã‹ã‚‰è¿½åŠ ã›ãšã€ç”Ÿæˆæ™‚ã«å…¨ç‰¹å¾´é‡ç¢ºå®š
        """
        try:
            # DataFrameã«å¤‰æ›
            result_df = self._convert_to_dataframe(market_data)

            # Phase 52.4-B: ç‰¹å¾´é‡æ•°ä¸€å…ƒç®¡ç†ï¼ˆfeature_order.jsonã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰
            target_features = get_feature_count()
            self.logger.info(
                f"ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹ - Phase 52.4-B: {target_features}ç‰¹å¾´é‡å›ºå®šã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¸€å…ƒç®¡ç†ï¼‰"
            )
            self.computed_features.clear()

            # å¿…è¦åˆ—ãƒã‚§ãƒƒã‚¯
            self._validate_required_columns(result_df)

            # ğŸ”¹ åŸºæœ¬ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ2å€‹ï¼‰
            result_df = self._generate_basic_features(result_df)

            # ğŸ”¹ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’ç”Ÿæˆï¼ˆ17å€‹ï¼‰
            result_df = self._generate_technical_indicators(result_df)

            # ğŸ”¹ ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ã‚’ç”Ÿæˆï¼ˆ1å€‹ï¼‰
            result_df = self._generate_anomaly_indicators(result_df)

            # ğŸ”¹ ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ9å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_lag_features(result_df)

            # ğŸ”¹ ç§»å‹•çµ±è¨ˆé‡ã‚’ç”Ÿæˆï¼ˆ5å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_rolling_statistics(result_df)

            # ğŸ”¹ äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ5å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_interaction_features(result_df)

            # ğŸ”¹ æ™‚é–“ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ7å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_time_features(result_df)

            # ğŸ”¹ æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆ6å€‹ï¼‰- Phase 52.4-B: å¿…ãšè¿½åŠ ï¼ˆNoneã®å ´åˆã¯0åŸ‹ã‚ï¼‰
            result_df = self._add_strategy_signal_features(result_df, strategy_signals)

            # ğŸ”¹ NaNå€¤å‡¦ç†ï¼ˆçµ±åˆç‰ˆï¼‰
            result_df = self._handle_nan_values(result_df)

            # ğŸ¯ ç‰¹å¾´é‡å®Œå…¨ç¢ºèªãƒ»æ¤œè¨¼ï¼ˆ55ç‰¹å¾´é‡å›ºå®šï¼‰
            self._validate_feature_generation(result_df, expected_count=target_features)

            # DataFrameã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆæˆ¦ç•¥ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
            return result_df

        except Exception as e:
            self.logger.error(f"çµ±åˆç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise DataProcessingError(f"ç‰¹å¾´é‡ç”Ÿæˆå¤±æ•—: {e}")

    def generate_features_sync(
        self,
        df: pd.DataFrame,
        strategy_signals: Optional[Dict[str, Dict[str, float]]] = None,
    ) -> pd.DataFrame:
        """
        åŒæœŸç‰ˆç‰¹å¾´é‡ç”Ÿæˆï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆäº‹å‰è¨ˆç®—ç”¨ï¼‰

        Args:
            df: OHLCVãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€DataFrame
            strategy_signals: æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«è¾æ›¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ç‰¹å¾´é‡ã‚’å«ã‚€DataFrameï¼ˆå¿…ãš55ç‰¹å¾´é‡ï¼‰

        Note:
            - Phase 52.4-B: 55ç‰¹å¾´é‡å›ºå®šã‚·ã‚¹ãƒ†ãƒ 
            - ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®äº‹å‰è¨ˆç®—ã§ä½¿ç”¨ï¼ˆasyncãªã—ã§ä¸€æ‹¬è¨ˆç®—ï¼‰
            - ç¢ºå®Ÿãªç‰¹å¾´é‡ç”Ÿæˆï¼ˆstrategy_signals=Noneæ™‚ã‚‚6å€‹ã‚’0åŸ‹ã‚ï¼‰
        """
        try:
            result_df = df.copy()

            # å¿…è¦åˆ—ãƒã‚§ãƒƒã‚¯
            self._validate_required_columns(result_df)

            # åŸºæœ¬ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ2å€‹ï¼‰
            result_df = self._generate_basic_features(result_df)

            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’ç”Ÿæˆï¼ˆ17å€‹ï¼‰
            result_df = self._generate_technical_indicators(result_df)

            # ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ã‚’ç”Ÿæˆï¼ˆ1å€‹ï¼‰
            result_df = self._generate_anomaly_indicators(result_df)

            # ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ9å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_lag_features(result_df)

            # ç§»å‹•çµ±è¨ˆé‡ã‚’ç”Ÿæˆï¼ˆ5å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_rolling_statistics(result_df)

            # äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ5å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_interaction_features(result_df)

            # æ™‚é–“ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’ç”Ÿæˆï¼ˆ7å€‹ï¼‰- Phase 52.4-B
            result_df = self._generate_time_features(result_df)

            # æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆ6å€‹ï¼‰- Phase 52.4-Bï¼ˆNoneã®å ´åˆã¯0åŸ‹ã‚ï¼‰
            result_df = self._add_strategy_signal_features(result_df, strategy_signals)

            # NaNå€¤å‡¦ç†ï¼ˆçµ±åˆç‰ˆï¼‰
            result_df = self._handle_nan_values(result_df)

            return result_df

        except Exception as e:
            self.logger.error(f"åŒæœŸç‰ˆç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise DataProcessingError(f"åŒæœŸç‰ˆç‰¹å¾´é‡ç”Ÿæˆå¤±æ•—: {e}")

    def _convert_to_dataframe(self, market_data: Dict[str, Any]) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›ï¼ˆã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸å¯¾å¿œï¼‰"""
        if isinstance(market_data, pd.DataFrame):
            return market_data.copy()
        elif isinstance(market_data, dict):
            try:
                # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸ã®å ´åˆï¼ˆãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ï¼‰
                # è¨­å®šã‹ã‚‰å„ªå…ˆé †ä½ä»˜ãã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                from ..core.config import get_data_config

                timeframe_keys = get_data_config("timeframes", ["4h", "15m"])  # è¨­å®šåŒ–å¯¾å¿œ
                for tf in timeframe_keys:
                    if tf in market_data and isinstance(market_data[tf], pd.DataFrame):
                        self.logger.info(f"ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸ã‹ã‚‰ãƒ¡ã‚¤ãƒ³æ™‚ç³»åˆ—å–å¾—: {tf}")
                        return market_data[tf].copy()

                # é€šå¸¸ã®è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã®å ´åˆï¼ˆOHLCVå½¢å¼ç­‰ï¼‰
                # å…¨ã¦ã®å€¤ãŒã‚¹ã‚«ãƒ©ãƒ¼ã‹ãƒªã‚¹ãƒˆã‹ã‚’ãƒã‚§ãƒƒã‚¯
                if all(
                    isinstance(v, (int, float, str)) or (isinstance(v, list) and len(v) > 0)
                    for v in market_data.values()
                ):
                    return pd.DataFrame(market_data)

                # ãã®ä»–ã®æ§‹é€ ã®è¾æ›¸
                self.logger.warning(f"è¤‡é›‘ãªè¾æ›¸æ§‹é€ ã‚’æ¤œå‡º: keys={list(market_data.keys())}")
                return pd.DataFrame(market_data)

            except (ValueError, KeyError, TypeError) as e:
                self.logger.error(
                    f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ - æ§‹é€ : {type(market_data)}, ã‚­ãƒ¼: {list(market_data.keys()) if hasattr(market_data, 'keys') else 'N/A'}"
                )
                raise DataProcessingError(f"Dictâ†’DataFrameå¤‰æ›ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚¨ãƒ©ãƒ¼: {e}")
            except (MemoryError, OverflowError) as e:
                raise DataProcessingError(f"Dictâ†’DataFrameå¤‰æ›ã‚µã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
            except Exception as e:
                raise DataProcessingError(f"Dictâ†’DataFrameå¤‰æ›äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            raise ValueError(f"Unsupported market_data type: {type(market_data)}")

    def _validate_required_columns(self, df: pd.DataFrame) -> None:
        """å¿…è¦åˆ—ã®å­˜åœ¨ç¢ºèª"""
        required_cols = ["open", "high", "low", "close", "volume"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise DataProcessingError(f"å¿…è¦åˆ—ãŒä¸è¶³: {missing_cols}")

    def _generate_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆï¼ˆ2å€‹ï¼‰"""
        result_df = df.copy()

        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾ï¼ˆclose, volumeï¼‰
        basic_features = []
        if "close" in result_df.columns:
            basic_features.append("close")
        if "volume" in result_df.columns:
            basic_features.append("volume")

        self.computed_features.update(basic_features)
        self.logger.debug(f"åŸºæœ¬ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(basic_features)}å€‹")
        return result_df

    def _generate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ç”Ÿæˆï¼ˆ17å€‹ï¼‰"""
        result_df = df.copy()

        # RSI 14æœŸé–“
        result_df["rsi_14"] = self._calculate_rsi(result_df["close"])
        self.computed_features.add("rsi_14")

        # MACDæ‹¡å¼µï¼ˆãƒ©ã‚¤ãƒ³ãƒ»ã‚·ã‚°ãƒŠãƒ«ãƒ»ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”Ÿæˆï¼‰
        macd_line, macd_signal = self._calculate_macd(result_df["close"])
        result_df["macd"] = macd_line
        result_df["macd_signal"] = macd_signal
        result_df["macd_histogram"] = macd_line - macd_signal
        self.computed_features.update(["macd", "macd_signal", "macd_histogram"])

        # ATR 14æœŸé–“
        result_df["atr_14"] = self._calculate_atr(result_df)
        self.computed_features.add("atr_14")

        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰æ‹¡å¼µï¼ˆä¸Šé™ãƒ»ä¸‹é™ãƒ»ä½ç½®ï¼‰
        bb_upper, bb_lower, bb_position = self._calculate_bb_bands(result_df["close"])
        result_df["bb_upper"] = bb_upper
        result_df["bb_lower"] = bb_lower
        result_df["bb_position"] = bb_position
        self.computed_features.update(["bb_upper", "bb_lower", "bb_position"])

        # EMA 2æœ¬
        result_df["ema_20"] = result_df["close"].ewm(span=EMA_SHORT_PERIOD, adjust=False).mean()
        result_df["ema_50"] = result_df["close"].ewm(span=EMA_LONG_PERIOD, adjust=False).mean()
        self.computed_features.update(["ema_20", "ema_50"])

        # Donchian ChannelæŒ‡æ¨™ï¼ˆ3å€‹ï¼‰
        donchian_high, donchian_low, channel_position = self._calculate_donchian_channel(result_df)
        result_df["donchian_high_20"] = donchian_high
        result_df["donchian_low_20"] = donchian_low
        result_df["channel_position"] = channel_position
        self.computed_features.update(["donchian_high_20", "donchian_low_20", "channel_position"])

        # ADXæŒ‡æ¨™ï¼ˆ3å€‹ï¼‰
        adx, plus_di, minus_di = self._calculate_adx_indicators(result_df)
        result_df["adx_14"] = adx
        result_df["plus_di_14"] = plus_di
        result_df["minus_di_14"] = minus_di
        self.computed_features.update(["adx_14", "plus_di_14", "minus_di_14"])

        # Stochastic Oscillatorï¼ˆ2å€‹ï¼‰
        stoch_k, stoch_d = self._calculate_stochastic(result_df)
        result_df["stoch_k"] = stoch_k
        result_df["stoch_d"] = stoch_d
        self.computed_features.update(["stoch_k", "stoch_d"])

        # å‡ºæ¥é«˜EMA
        result_df["volume_ema"] = self._calculate_volume_ema(result_df["volume"])
        self.computed_features.add("volume_ema")

        # ATRæ¯”ç‡ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ­£è¦åŒ–ï¼‰
        result_df["atr_ratio"] = self._calculate_atr_ratio(result_df)
        self.computed_features.add("atr_ratio")

        self.logger.debug("ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ç”Ÿæˆå®Œäº†: 17å€‹")
        return result_df

    def _generate_anomaly_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ç”Ÿæˆï¼ˆ1å€‹ï¼‰"""
        result_df = df.copy()

        # å‡ºæ¥é«˜æ¯”ç‡
        result_df["volume_ratio"] = self._calculate_volume_ratio(result_df["volume"])
        self.computed_features.add("volume_ratio")

        self.logger.debug("ç•°å¸¸æ¤œçŸ¥æŒ‡æ¨™ç”Ÿæˆå®Œäº†: 1å€‹")
        return result_df

    def _generate_lag_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆï¼ˆéå»NæœŸé–“ã®å€¤ãƒ»9å€‹ï¼‰"""
        result_df = df.copy()

        # Close lag features
        for lag in LAG_PERIODS_CLOSE:
            result_df[f"close_lag_{lag}"] = result_df["close"].shift(lag)
            self.computed_features.add(f"close_lag_{lag}")

        # Volume lag features
        for lag in LAG_PERIODS_VOLUME:
            result_df[f"volume_lag_{lag}"] = result_df["volume"].shift(lag)
            self.computed_features.add(f"volume_lag_{lag}")

        # RSI lag feature
        if "rsi_14" in result_df.columns:
            for lag in LAG_PERIODS_INDICATOR:
                result_df[f"rsi_lag_{lag}"] = result_df["rsi_14"].shift(lag)
                self.computed_features.add(f"rsi_lag_{lag}")

        # MACD lag feature
        if "macd" in result_df.columns:
            for lag in LAG_PERIODS_INDICATOR:
                result_df[f"macd_lag_{lag}"] = result_df["macd"].shift(lag)
                self.computed_features.add(f"macd_lag_{lag}")

        self.logger.debug("ãƒ©ã‚°ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: 9å€‹")
        return result_df

    def _generate_rolling_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç§»å‹•çµ±è¨ˆé‡ç”Ÿæˆï¼ˆRolling Statisticsãƒ»5å€‹ï¼‰"""
        result_df = df.copy()

        # Moving Average
        for window in ROLLING_WINDOWS_MA:
            result_df[f"close_ma_{window}"] = (
                result_df["close"].rolling(window=window, min_periods=1).mean()
            )
            self.computed_features.add(f"close_ma_{window}")

        # Standard Deviation
        for window in ROLLING_WINDOWS_STD:
            result_df[f"close_std_{window}"] = (
                result_df["close"].rolling(window=window, min_periods=1).std()
            )
            self.computed_features.add(f"close_std_{window}")

        self.logger.debug("ç§»å‹•çµ±è¨ˆé‡ç”Ÿæˆå®Œäº†: 5å€‹")
        return result_df

    def _generate_interaction_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """äº¤äº’ä½œç”¨ç‰¹å¾´é‡ç”Ÿæˆï¼ˆFeature Interactionsãƒ»5å€‹ï¼‰"""
        result_df = df.copy()

        # RSI Ã— ATR
        if "rsi_14" in result_df.columns and "atr_14" in result_df.columns:
            result_df["rsi_x_atr"] = result_df["rsi_14"] * result_df["atr_14"]
            self.computed_features.add("rsi_x_atr")

        # MACD Ã— Volume
        if "macd" in result_df.columns and "volume" in result_df.columns:
            result_df["macd_x_volume"] = result_df["macd"] * result_df["volume"]
            self.computed_features.add("macd_x_volume")

        # BB Position Ã— Volume Ratio
        if "bb_position" in result_df.columns and "volume_ratio" in result_df.columns:
            result_df["bb_position_x_volume_ratio"] = (
                result_df["bb_position"] * result_df["volume_ratio"]
            )
            self.computed_features.add("bb_position_x_volume_ratio")

        # Close Ã— ATR
        if "close" in result_df.columns and "atr_14" in result_df.columns:
            result_df["close_x_atr"] = result_df["close"] * result_df["atr_14"]
            self.computed_features.add("close_x_atr")

        # Volume Ã— BB Position
        if "volume" in result_df.columns and "bb_position" in result_df.columns:
            result_df["volume_x_bb_position"] = result_df["volume"] * result_df["bb_position"]
            self.computed_features.add("volume_x_bb_position")

        self.logger.debug("äº¤äº’ä½œç”¨ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: 5å€‹")
        return result_df

    def _generate_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ™‚é–“ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ç”Ÿæˆï¼ˆTime-based Featuresãƒ»7å€‹ï¼‰"""
        result_df = df.copy()

        # indexã¾ãŸã¯timestampåˆ—ã‹ã‚‰æ—¥æ™‚æƒ…å ±ã‚’æŠ½å‡º
        if isinstance(result_df.index, pd.DatetimeIndex):
            dt_index = result_df.index
        elif "timestamp" in result_df.columns:
            dt_index = pd.to_datetime(result_df["timestamp"])
        else:
            # æ—¥æ™‚æƒ…å ±ãŒãªã„å ´åˆã¯ã‚¼ãƒ­åŸ‹ã‚ï¼ˆ7ç‰¹å¾´é‡ï¼‰
            self.logger.warning("æ—¥æ™‚æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ™‚é–“ç‰¹å¾´é‡ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ç”Ÿæˆã—ã¾ã™")
            result_df["hour"] = 0
            result_df["day_of_week"] = 0
            result_df["is_market_open_hour"] = 0
            result_df["is_europe_session"] = 0
            result_df["hour_cos"] = 1.0
            result_df["day_sin"] = 0.0
            result_df["day_cos"] = 1.0
            self.computed_features.update(
                [
                    "hour",
                    "day_of_week",
                    "is_market_open_hour",
                    "is_europe_session",
                    "hour_cos",
                    "day_sin",
                    "day_cos",
                ]
            )
            return result_df

        # Hour (0-23)
        result_df["hour"] = dt_index.hour
        self.computed_features.add("hour")

        # Day of week (0-6)
        result_df["day_of_week"] = dt_index.dayofweek
        self.computed_features.add("day_of_week")

        # Is market open hour (JST market hours)
        result_df["is_market_open_hour"] = (
            (dt_index.hour >= MARKET_OPEN_HOUR) & (dt_index.hour <= MARKET_CLOSE_HOUR)
        ).astype(int)
        self.computed_features.add("is_market_open_hour")

        # æ¬§å·å¸‚å ´ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆæ—¥ã‚’ã¾ãŸãå‡¦ç†ï¼‰
        result_df["is_europe_session"] = (
            ((dt_index.hour >= EUROPE_SESSION_START) & (dt_index.hour <= EUROPE_SESSION_END_HOUR))
            | (dt_index.hour < EUROPE_SESSION_EARLY_HOUR)
        ).astype(int)
        self.computed_features.add("is_europe_session")

        # æ™‚åˆ»ã®å‘¨æœŸæ€§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        result_df["hour_cos"] = np.cos(2 * np.pi * dt_index.hour / HOURS_PER_DAY)
        self.computed_features.add("hour_cos")

        # æ›œæ—¥ã®å‘¨æœŸæ€§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        result_df["day_sin"] = np.sin(2 * np.pi * dt_index.dayofweek / DAYS_PER_WEEK)
        result_df["day_cos"] = np.cos(2 * np.pi * dt_index.dayofweek / DAYS_PER_WEEK)
        self.computed_features.add("day_sin")
        self.computed_features.add("day_cos")

        self.logger.debug("æ™‚é–“ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: 7å€‹")
        return result_df

    def _get_strategy_signal_feature_names(self) -> Dict[str, str]:
        """
        æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡åã‚’å‹•çš„å–å¾—ï¼ˆè¨­å®šé§†å‹•å‹ï¼‰

        strategies.yamlã‹ã‚‰æˆ¦ç•¥ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ã€ç‰¹å¾´é‡åè¾æ›¸ã‚’ç”Ÿæˆã€‚
        ã“ã‚Œã«ã‚ˆã‚Šã€æˆ¦ç•¥è¿½åŠ æ™‚ã«ä¿®æ­£ãŒä¸è¦ã«ãªã‚‹ã€‚

        Returns:
            æˆ¦ç•¥åã‚’ã‚­ãƒ¼ã¨ã—ãŸç‰¹å¾´é‡åè¾æ›¸
            ä¾‹: {"ATRBased": "strategy_signal_ATRBased", ...}
        """
        from ..strategies.strategy_loader import StrategyLoader

        loader = StrategyLoader()
        strategies_data = loader.load_strategies()
        return {
            s["metadata"]["name"]: f"strategy_signal_{s['metadata']['name']}"
            for s in strategies_data
        }

    def _add_strategy_signal_features(
        self, df: pd.DataFrame, strategy_signals: Optional[Dict[str, Dict[str, float]]] = None
    ) -> pd.DataFrame:
        """
        æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡è¿½åŠ ï¼ˆStrategy Signalsãƒ»è¨­å®šé§†å‹•å‹ãƒ»å¿…ãšè¿½åŠ ï¼‰

        Args:
            df: ç‰¹å¾´é‡DataFrame
            strategy_signals: æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«è¾æ›¸ï¼ˆStrategyManager.get_individual_strategy_signals()ã®æˆ»ã‚Šå€¤ï¼‰
                ä¾‹: {
                    "ATRBased": {"action": "buy", "confidence": 0.678, "encoded": 0.678},
                    "DonchianChannel": {"action": "sell", "confidence": 0.729, "encoded": -0.729},
                    ...
                }

        Returns:
            æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrameï¼ˆstrategies.yamlã‹ã‚‰å‹•çš„å–å¾—ï¼‰

        Note:
            - Phase 52.4-B: 6æˆ¦ç•¥çµ±åˆãƒ»è¨­å®šé§†å‹•å‹ï¼ˆstrategies.yamlã‹ã‚‰å‹•çš„èª­ã¿è¾¼ã¿ï¼‰
            - ç¢ºå®Ÿãªç‰¹å¾´é‡ç”Ÿæˆï¼ˆstrategy_signals=Noneæ™‚ã‚‚0.0ã§è¿½åŠ ï¼‰
            - MLãŒæˆ¦ç•¥ã®å°‚é–€çŸ¥è­˜ã‚’å­¦ç¿’å¯èƒ½ã«
            - ä¿¡é ¼æ€§å‘ä¸Š: æˆ¦ç•¥æ•°åˆ†å¿…ãšè¿½åŠ ï¼ˆå¾Œã‹ã‚‰è¿½åŠ ã—ãªã„ï¼‰
        """
        result_df = df.copy()

        # å„æˆ¦ç•¥ã®ã‚·ã‚°ãƒŠãƒ«ã‚’ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ ï¼ˆ6æˆ¦ç•¥ãƒ»è¨­å®šé§†å‹•å‹ï¼‰
        strategy_internal_names = self._get_strategy_signal_feature_names()
        num_strategies = len(strategy_internal_names)

        added_count = 0

        # strategy_signals=Noneã®å ´åˆã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆ0åŸ‹ã‚ï¼‰
        if not strategy_signals:
            self.logger.debug(
                f"æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡: strategy_signalsæœªæä¾› â†’ {num_strategies}å€‹ã‚’0.0ã§ç”Ÿæˆï¼ˆç¢ºå®Ÿï¼‰"
            )
            # å…¨æˆ¦ç•¥ã‚’0.0ã§è¿½åŠ 
            for internal_name, feature_name in strategy_internal_names.items():
                result_df[feature_name] = 0.0
                self.computed_features.add(feature_name)
            self.logger.debug(f"æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {num_strategies}å€‹ï¼ˆ0åŸ‹ã‚ï¼‰")
            return result_df

        # strategy_signalsãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆ
        for internal_name, feature_name in strategy_internal_names.items():
            if internal_name in strategy_signals:
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿å€¤ã‚’ä½¿ç”¨ï¼ˆbuy=+1, hold=0, sell=-1 Ã— confidenceï¼‰
                encoded_value = strategy_signals[internal_name].get("encoded", 0.0)

                # DataFrameã®æœ€å¾Œã®è¡Œã«å€¤ã‚’è¿½åŠ 
                result_df[feature_name] = encoded_value
                self.computed_features.add(feature_name)
                added_count += 1
            else:
                # æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ãŒãªã„å ´åˆã¯0ã§è£œå®Œ
                result_df[feature_name] = 0.0
                self.computed_features.add(feature_name)
                self.logger.debug(f"æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ä¸è¶³: {internal_name} â†’ 0.0ã§è£œå®Œ")

        self.logger.debug(f"æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {added_count}/{num_strategies}å€‹")
        return result_df

    def _calculate_rsi(self, close: pd.Series, period: int = RSI_PERIOD) -> pd.Series:
        """RSIè¨ˆç®—"""
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period, min_periods=1).mean()
        rs = gain / (loss + EPSILON)
        return 100 - (100 / (1 + rs))

    def _calculate_macd(self, close: pd.Series) -> tuple:
        """MACDè¨ˆç®—ï¼ˆMACDãƒ©ã‚¤ãƒ³ã¨ã‚·ã‚°ãƒŠãƒ«ãƒ©ã‚¤ãƒ³ã‚’è¿”ã™ï¼‰"""
        ema_fast = close.ewm(span=MACD_FAST_PERIOD, adjust=False).mean()
        ema_slow = close.ewm(span=MACD_SLOW_PERIOD, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        macd_signal = macd_line.ewm(span=MACD_SIGNAL_PERIOD, adjust=False).mean()
        return macd_line, macd_signal

    def _calculate_atr(self, df: pd.DataFrame, period: int = ATR_PERIOD) -> pd.Series:
        """ATRè¨ˆç®—"""
        high_low = df["high"] - df["low"]
        high_close = np.abs(df["high"] - df["close"].shift())
        low_close = np.abs(df["low"] - df["close"].shift())
        true_range = np.maximum(high_low, np.maximum(high_close, low_close))
        return true_range.rolling(window=period, min_periods=1).mean()

    def _calculate_bb_bands(self, close: pd.Series, period: int = BB_PERIOD) -> tuple:
        """ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰æ‹¡å¼µï¼ˆä¸Šé™ãƒ»ä¸‹é™ãƒ»ä½ç½®ã‚’è¿”ã™ï¼‰"""
        bb_middle = close.rolling(window=period, min_periods=1).mean()
        bb_std_dev = close.rolling(window=period, min_periods=1).std()
        bb_upper = bb_middle + (bb_std_dev * BB_STD_MULTIPLIER)
        bb_lower = bb_middle - (bb_std_dev * BB_STD_MULTIPLIER)
        bb_position = (close - bb_lower) / (bb_upper - bb_lower + EPSILON)
        return bb_upper, bb_lower, bb_position

    def _calculate_stochastic(
        self, df: pd.DataFrame, period: int = STOCHASTIC_PERIOD, smooth_k: int = STOCHASTIC_SMOOTH_K
    ) -> tuple:
        """Stochastic Oscillatorè¨ˆç®— (%K, %D)"""
        low_min = df["low"].rolling(window=period, min_periods=1).min()
        high_max = df["high"].rolling(window=period, min_periods=1).max()

        # %Kè¨ˆç®—ï¼ˆFast %Kï¼‰
        stoch_k_fast = 100 * (df["close"] - low_min) / (high_max - low_min + EPSILON)

        # %K smoothingï¼ˆSlow %Kï¼‰
        stoch_k = stoch_k_fast.rolling(window=smooth_k, min_periods=1).mean()

        # %Dè¨ˆç®—ï¼ˆ%Kã®3æœŸé–“SMAï¼‰
        stoch_d = stoch_k.rolling(window=STOCHASTIC_SMOOTH_D, min_periods=1).mean()

        return stoch_k, stoch_d

    def _calculate_volume_ema(
        self, volume: pd.Series, period: int = VOLUME_EMA_PERIOD
    ) -> pd.Series:
        """å‡ºæ¥é«˜EMAè¨ˆç®—"""
        return volume.ewm(span=period, adjust=False).mean()

    def _calculate_atr_ratio(self, df: pd.DataFrame) -> pd.Series:
        """ATR/Closeæ¯”ç‡è¨ˆç®—ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ­£è¦åŒ–ï¼‰"""
        return df["atr_14"] / (df["close"] + EPSILON)

    def _calculate_volume_ratio(self, volume: pd.Series, period: Optional[int] = None) -> pd.Series:
        """å‡ºæ¥é«˜æ¯”ç‡è¨ˆç®—"""
        try:
            if period is None:
                period = get_anomaly_config("volume_ratio.calculation_period", VOLUME_EMA_PERIOD)
            volume_avg = volume.rolling(window=period, min_periods=1).mean()
            return volume / (volume_avg + EPSILON)
        except Exception as e:
            self.logger.error(f"å‡ºæ¥é«˜æ¯”ç‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.Series(np.zeros(len(volume)), index=volume.index)

    def _normalize(self, series: pd.Series) -> pd.Series:
        """0-1ç¯„å›²ã«æ­£è¦åŒ–"""
        try:
            # å¤–ã‚Œå€¤å‡¦ç†ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
            outlier_clip_quantile = get_anomaly_config("normalization.outlier_clip_quantile", 0.95)
            upper_bound = series.quantile(outlier_clip_quantile)
            clipped_series = np.clip(series, 0, upper_bound)

            # 0-1æ­£è¦åŒ–
            min_val = clipped_series.min()
            max_val = clipped_series.max()

            if max_val - min_val == 0:
                return pd.Series(np.zeros(len(series)), index=series.index)

            return (clipped_series - min_val) / (max_val - min_val)

        except Exception:
            return pd.Series(np.zeros(len(series)), index=series.index)

    def _calculate_donchian_channel(self, df: pd.DataFrame, period: int = DONCHIAN_PERIOD) -> tuple:
        """
        Donchian Channelè¨ˆç®—

        Args:
            df: OHLCV DataFrame
            period: è¨ˆç®—æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: DONCHIAN_PERIODï¼‰

        Returns:
            (donchian_high, donchian_low, channel_position)
        """
        try:
            high = df["high"]
            low = df["low"]
            close = df["close"]

            # æœŸé–“ã®æœ€é«˜å€¤ãƒ»æœ€å®‰å€¤
            donchian_high = high.rolling(window=period, min_periods=1).max()
            donchian_low = low.rolling(window=period, min_periods=1).min()

            # ãƒãƒ£ãƒãƒ«å†…ä½ç½®è¨ˆç®—ï¼ˆ0-1ï¼‰
            channel_width = donchian_high - donchian_low
            channel_position = (close - donchian_low) / (channel_width + EPSILON)

            # NaNå€¤ã‚’é©åˆ‡ãªå€¤ã§è£œå®Œ
            donchian_high = donchian_high.bfill().fillna(high.iloc[0])
            donchian_low = donchian_low.bfill().fillna(low.iloc[0])
            channel_position = channel_position.fillna(0.5)  # ä¸­å¤®å€¤ã§è£œå®Œ

            return donchian_high, donchian_low, channel_position

        except Exception as e:
            self.logger.error(f"Donchian Channelè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            zeros = pd.Series(np.zeros(len(df)), index=df.index)
            half_ones = pd.Series(np.full(len(df), 0.5), index=df.index)
            return zeros, zeros, half_ones

    def _calculate_adx_indicators(self, df: pd.DataFrame, period: int = ADX_PERIOD) -> tuple:
        """
        ADXæŒ‡æ¨™è¨ˆç®—ï¼ˆADXã€+DIã€-DIï¼‰

        Args:
            df: OHLCV DataFrame
            period: è¨ˆç®—æœŸé–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ADX_PERIODï¼‰

        Returns:
            (adx, plus_di, minus_di)
        """
        try:
            high = df["high"]
            low = df["low"]
            close = df["close"]

            # True Rangeè¨ˆç®—
            tr1 = high - low
            tr2 = np.abs(high - close.shift(1))
            tr3 = np.abs(low - close.shift(1))
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

            # Directional Movementè¨ˆç®—
            plus_dm = (high - high.shift(1)).where((high - high.shift(1)) > (low.shift(1) - low), 0)
            minus_dm = (low.shift(1) - low).where((low.shift(1) - low) > (high - high.shift(1)), 0)
            plus_dm = plus_dm.where(plus_dm > 0, 0)
            minus_dm = minus_dm.where(minus_dm > 0, 0)

            # Smoothed True Range ã¨ Directional Movement
            atr = tr.rolling(window=period, min_periods=1).mean()
            plus_dm_smooth = plus_dm.rolling(window=period, min_periods=1).mean()
            minus_dm_smooth = minus_dm.rolling(window=period, min_periods=1).mean()

            # Directional Indicators
            plus_di = 100 * plus_dm_smooth / (atr + EPSILON)
            minus_di = 100 * minus_dm_smooth / (atr + EPSILON)

            # Directional Index
            dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di + EPSILON)

            # ADX (Average Directional Index)
            adx = dx.rolling(window=period, min_periods=1).mean()

            # NaNå€¤è£œå®Œ
            adx = adx.bfill().fillna(0)
            plus_di = plus_di.bfill().fillna(0)
            minus_di = minus_di.bfill().fillna(0)

            return adx, plus_di, minus_di

        except Exception as e:
            self.logger.error(f"ADXæŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            zeros = pd.Series(np.zeros(len(df)), index=df.index)
            return zeros, zeros, zeros

    def _handle_nan_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """NaNå€¤å‡¦ç†ï¼ˆçµ±åˆç‰ˆï¼‰"""
        for feature in self.computed_features:
            if feature in df.columns:
                # pandas 2.xäº’æ›æ€§: ãƒã‚§ãƒ¼ãƒ³ä»£å…¥ã‚’2è¡Œã«åˆ†å‰²
                df[feature] = df[feature].ffill().bfill()
                df[feature] = df[feature].fillna(0)
        return df

    def _validate_feature_generation(
        self, df: pd.DataFrame, expected_count: Optional[int] = None
    ) -> None:
        """
        ç‰¹å¾´é‡å®Œå…¨ç¢ºèªãƒ»æ¤œè¨¼

        Args:
            df: æ¤œè¨¼å¯¾è±¡DataFrame
            expected_count: æœŸå¾…ç‰¹å¾´é‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: get_feature_count()ã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰
        """
        if expected_count is None:
            expected_count = get_feature_count()
        generated_features = [col for col in OPTIMIZED_FEATURES if col in df.columns]
        missing_features = [col for col in OPTIMIZED_FEATURES if col not in df.columns]

        total_generated = len(generated_features)

        # çµ±åˆãƒ­ã‚°å‡ºåŠ›
        self.logger.info(
            f"ç‰¹å¾´é‡ç”Ÿæˆå®Œäº† - ç·æ•°: {total_generated}/{expected_count}å€‹",
            extra_data={
                "basic_features": len([f for f in ["close", "volume"] if f in df.columns]),
                "technical_features": len(
                    [
                        f
                        for f in [
                            "rsi_14",
                            "macd",
                            "macd_signal",
                            "macd_histogram",
                            "atr_14",
                            "bb_upper",
                            "bb_lower",
                            "bb_position",
                            "ema_50",
                            "donchian_low_20",
                            "channel_position",
                            "adx_14",
                            "plus_di_14",
                            "minus_di_14",
                            "stoch_k",
                            "stoch_d",
                            "volume_ema",
                            "atr_ratio",
                        ]
                        if f in df.columns
                    ]
                ),
                "anomaly_features": len([f for f in ["volume_ratio"] if f in df.columns]),
                "lag_features": len([f for f in df.columns if "lag" in f]),
                "rolling_features": len(
                    [f for f in df.columns if any(kw in f for kw in ["_ma_", "_std_"])]
                ),
                "interaction_features": len([f for f in df.columns if "_x_" in f]),
                "time_features": len(
                    [
                        f
                        for f in [
                            "hour",
                            "day_of_week",
                            "is_market_open_hour",
                            "is_europe_session",
                            "hour_cos",
                            "day_sin",
                            "day_cos",
                        ]
                        if f in df.columns
                    ]
                ),
                "generated_features": generated_features,
                "missing_features": missing_features,
                "total_expected": expected_count,
                "success": total_generated >= expected_count,
            },
        )

        # ä¸è¶³ç‰¹å¾´é‡ã®è­¦å‘Š
        if missing_features:
            self.logger.warning(
                f"ğŸš¨ ç‰¹å¾´é‡ä¸è¶³æ¤œå‡º: {missing_features} ({len(missing_features)}å€‹ä¸è¶³)"
            )

        # ç‰¹å¾´é‡å®Œå…¨ç”Ÿæˆç¢ºèª
        if total_generated == expected_count:
            self.logger.info(f"âœ… {expected_count}ç‰¹å¾´é‡å®Œå…¨ç”ŸæˆæˆåŠŸ")

    def get_feature_info(self) -> Dict[str, Any]:
        """ç‰¹å¾´é‡æƒ…å ±å–å¾—"""
        return {
            "total_features": len(self.computed_features),
            "computed_features": sorted(list(self.computed_features)),
            "feature_categories": FEATURE_CATEGORIES,
            "optimized_features": OPTIMIZED_FEATURES,
            "parameters": {"lookback_period": self.lookback_period},
            "feature_descriptions": {
                "close": "çµ‚å€¤ï¼ˆåŸºæº–ä¾¡æ ¼ï¼‰",
                "volume": "å‡ºæ¥é«˜ï¼ˆå¸‚å ´æ´»å‹•åº¦ï¼‰",
                "rsi_14": "RSIï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒœãƒ¼ãƒˆãƒ»ã‚½ãƒ¼ãƒ«ãƒ‰åˆ¤å®šï¼‰",
                "macd": "MACDï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã‚·ã‚°ãƒŠãƒ«ï¼‰",
                "atr_14": "ATRï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¸¬å®šï¼‰",
                "bb_position": "ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä½ç½®ï¼ˆä¾¡æ ¼ä½ç½®ï¼‰",
                "ema_20": "EMAçŸ­æœŸï¼ˆçŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰",
                "ema_50": "EMAä¸­æœŸï¼ˆä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰",
                "donchian_high_20": "Donchian Channelä¸Šé™ï¼ˆ20æœŸé–“æœ€é«˜å€¤ï¼‰",
                "donchian_low_20": "Donchian Channelä¸‹é™ï¼ˆ20æœŸé–“æœ€å®‰å€¤ï¼‰",
                "channel_position": "ãƒãƒ£ãƒãƒ«å†…ä½ç½®ï¼ˆ0-1æ­£è¦åŒ–ä½ç½®ï¼‰",
                "adx_14": "ADXï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦æŒ‡æ¨™ï¼‰",
                "plus_di_14": "+DIï¼ˆä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘æ€§ï¼‰",
                "minus_di_14": "-DIï¼ˆä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘æ€§ï¼‰",
                "volume_ratio": "å‡ºæ¥é«˜æ¯”ç‡ï¼ˆå‡ºæ¥é«˜ç•°å¸¸æ¤œçŸ¥ï¼‰",
            },
        }


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒªã‚¹ãƒˆ
__all__ = [
    "FeatureGenerator",
    "OPTIMIZED_FEATURES",
    "FEATURE_CATEGORIES",
]
