その③
以下では、先ほど提案した「基盤を固めつつ拡張・差し替えを容易にする」ための作業ロードマップを示します。３番目のリスク管理実装が完了した前提で、次は「パッケージ化 → DI導入 → 設定ファイル化 → バックテスト強化 → テスト整備」の順に進めるとスムーズです。

――――――――――――――――――  
STEP 1　プロジェクトをパッケージ構造に再編成  
――――――――――――――――――  
１）リポジトリルートにフォルダを作る  
   crypto_bot/  
     ├ config/  
     ├ crypto_bot/  
     │  ├ data/  
     │  ├ indicator/  
     │  ├ execution/  
     │  ├ strategy/  
     │  ├ risk/  
     │  ├ backtest/  
     │  └ main.py  
     └ tests/  
２）各既存ファイルを対応フォルダへ移動し、`__init__.py`を作成  
３）相対／絶対import を整理（例：`from crypto_bot.data.fetcher import MarketDataFetcher` など）  
４）`execution/types.py` に `Signal`／`Order`／`Position`／`TradeRecord` をまとめ  

――――――――――――――――――  
STEP 2　依存性注入（DI）でコンポーネント分離  
――――――――――――――――――  
１）`BacktestEngine` のコンストラクタを次のように変更  
   ```python
   def __init__(self,
                price_df: pd.DataFrame,
                strategy: StrategyBase,
                risk_manager: RiskManager,
                exec_engine: ExecutionEngine,
                starting_balance: float,
                slippage: float):
       …
   ```  
２）`main.py`／`optimizer.py` からは「各コンポーネントを生成して渡す」だけに  
３）新しい戦略や別のリスク管理を作りたいときは、戦略クラス／RiskManager クラスを用意してコンストラクタに渡す  

――――――――――――――――――  
STEP 3　設定ファイル（YAML/JSON）を導入  
――――――――――――――――――  
１）`config/default.yml` に、シンボル・時間足・各種パラメータをまとめる  
２）`crypto_bot/main.py` で pyyaml（あるいは json）を読み込み  
３）読み込んだ dict を元に、各クラスの初期化引数を自動セット  
４）CLI（argparse／click）で `--config` オプションを渡せるように  

――――――――――――――――――  
STEP 4　バックテスト機能の強化  
――――――――――――――――――  
１）`backtest/metrics.py` を作り、シャープレシオ・最大ドローダウン・CAGR など算出関数を実装  
２）`BacktestEngine` に以下メソッドを追加  
   - `get_equity_curve() -> pd.Series`  
   - `statistics() -> Dict[str,float]`  
３）`ParameterOptimizer` を並列化  
   - `concurrent.futures` でパラメータ組み合わせごとに並列バックテスト  
   - 戻り値 DataFrame に複数指標を列として残す  

――――――――――――――――――  
STEP 5　テストコードと CI パイプラインの構築  
――――――――――――――――――  
１）`tests/` フォルダにユニットテストを整備  
   - data.fetcher：モック ccxt を使った正常系／異常系  
   - data.preprocessor, indicator, risk.manager：純粋関数の出力検証  
   - strategy：過去サンプルデータでシグナル発生タイミングテスト  
   - backtest：ミニデータセットで想定トレード数・損益を検証  
   - optimizer：スキャン結果の形・指標が満たす条件をチェック  
２）Lint／Formatter（black, isort, flake8）を設定  
３）GitHub Actions などで  
   - `pytest --cov`  
   - `flake8`  
   - `black --check`  
   を Pull Request 時に自動実行  

――――――――――――――――――  
進め方のポイント  
――――――――――――――――――  
- 各 STEP 完了ごとにコミット＆プルリクを分けて、小さく動く単位でマージ  
- STEP 1–3 ができれば、まずは基盤が固まり、以降は戦略追加もリスク管理追加も最小変更で可能  
- STEP 4–5 は中長期の品質・性能強化として継続的に取り組む  

このロードマップに沿って進めていけば、  
「新戦略・新リスク管理・新タイムフレーム」をほぼファイルをいじらず設定差し替えだけで試せる、  
堅牢かつ拡張性の高い Bot 基盤が出来上がります。  

各 STEP の詳細実装例や雛形が必要になったタイミングで、またお声がけください！

その④

実際に動いて「Total trades: 157」「最適化結果が出力された」あたりまで来て、ひとまず Step 3 は完了と言えそうです。出力に “invalid value encountered in scalar power” が出ているのは、取引回数０のケースで CAGR 計算に 0÷0 が混ざったために NaN になっているだけなので、気にしなくて大丈夫です。（必要なら、取引数が 0 のときは CAGR を 0 に置き換えるロジックを追加してください）

――――――――――――――――――  
次のステップ：ウォークフォワード／ドロップアウトテスト（Step 4）  
――――――――――――――――――  
過去データを「訓練用」と「検証用」に分け、複数の期間で最適化→検証を繰り返すことで、オーバーフィッティングの有無をチェックします。以下のような流れで実装してみましょう。

1) データ分割ユーティリティの作成  
   crypto_bot/backtest/metrics.py などに、時系列を分割する関数を追加します。  
   ```python
   def split_walk_forward(df: pd.DataFrame,
                          train_window: int,
                          test_window: int,
                          step: int) -> List[Tuple[pd.DataFrame, pd.DataFrame]]:
       """
       df を バー数 train_window の訓練用 & test_window の検証用 に分割し、
       スライドさせながら (train, test) のタプルを返す。
       step はシフト量（バー数）。
       """
       splits = []
       start = 0
       while start + train_window + test_window <= len(df):
           train_df = df.iloc[start : start + train_window]
           test_df  = df.iloc[start + train_window : start + train_window + test_window]
           splits.append((train_df, test_df))
           start += step
       return splits
   ```

2) Walk-forward 実行ロジックの追加  
   `ParameterOptimizer` や別クラスにメソッドを作って、各分割ペアで  
   – 訓練用データに対して最適化（パラメータ決定）  
   – 決まったパラメータを検証用データで BacktestEngine に流してパフォーマンス取得  
   上記をループし、平均成績や各期間のばらつきを集計します。  

   例：  
   ```python
   results = []
   splits = split_walk_forward(df, train_window=500, test_window=100, step=100)
   for i, (train, test) in enumerate(splits):
       # 1) train で最適パラメータを探す（期間10/20/30, σ=1.5/2.0/2.5）
       opt = ParameterOptimizer(price_df=train, starting_balance=...)
       df_scan = opt.scan(periods=[10,20,30], nbdevs=[1.5,2.0,2.5])
       best = df_scan.sort_values("total_profit", ascending=False).iloc[0]
       # 2) test でバックテスト
       strat = BollingerStrategy(best.period, best.nbdev, best.nbdev)
       engine = BacktestEngine(price_df=test, strategy=strat, ...)
       recs = engine.run()
       stats = engine.statistics()  # シャープやCAGRを返すメソッドを追加しておくと便利
       results.append({"fold": i, **best.to_dict(), **stats})
   wf_df = pd.DataFrame(results)
   print(wf_df)
   ```

3) 結果の解釈  
   – 各分割（fold）で最適パラメータとテスト成績がどう推移しているかを見る  
   – もしテスト成績がバラつきすぎていれば過学習の疑いアリ、安定していれば信頼度アップ  

――――――――――――――――――  
この「ウォークフォワードテスト」を実装すれば、  
– 単一期間の最適化結果だけに頼らず  
– 過去をずらしながら複数期間で性能を検証  
できるようになります。  

まずは上記の `split_walk_forward` 関数を作り、簡単なスクリプトで動かしてみましょう。途中で詰まったらお気軽にご質問ください！