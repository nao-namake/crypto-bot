# =============================================================================
# .github/workflows/ci.yml
#   - Push / PR æ™‚ã« Lintãƒ»Formatãƒ»UnitTestï¼ˆcoverageï¼‰ã‚’å®Ÿè¡Œ
#   - Bybit Testnet ç”¨ E2E ãƒ†ã‚¹ãƒˆï¼ˆAPI ã‚­ãƒ¼ãŒç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰
#   - Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ“ãƒ«ãƒ‰ & Artifact Registry ã¸ã®ãƒ—ãƒƒã‚·ãƒ¥
#   - GCP Cloud Run ã¸ã®è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆTerraformä½¿ç”¨ï¼‰
# =============================================================================
name: CI

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
jobs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  test:
    name: Unit Tests
    runs-on: ubuntu-latest

    # Bitbankæœ¬ç•ªé‹ç”¨ã«æœ€é©åŒ– - Python 3.11ã®ã¿ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    strategy:
      matrix:
        python-version: ['3.11']

    # Codecov ç”¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äº‹å‰ã«ç’°å¢ƒå¤‰æ•°ã¸æµã—è¾¼ã‚“ã§ãŠã
    env:
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

    steps:
      - uses: actions/checkout@v4
        # ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements/*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
        # Phase 12.5: çµ±ä¸€ä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ»requirements/ãƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œ

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
        # matrix ã§æŒ‡å®šã—ãŸ Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements/dev.txt
        # Phase 12.5: çµ±ä¸€ä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ»requirements/dev.txtä½¿ç”¨

      - name: Run quality checks & tests
        run: |
          echo ">>> Running full quality checks"
          bash scripts/checks.sh
        # scripts/checks.sh ã«æ›¸ã‹ã‚ŒãŸ flake8/isort/black/pytestï¼‹coverage ã‚³ãƒãƒ³ãƒ‰ã‚’ä¸€æ‹¬å®Ÿè¡Œ

      - name: Generate pre-computed cache
        run: |
          echo ">>> Phase 12.3: Generating pre-computed cache"
          python scripts/pre_compute_data.py || echo "âš ï¸ Pre-computation failed but continuing"
          if [ -d "cache" ]; then
            echo "âœ… Cache generated successfully: $(ls -la cache/)"
          else
            echo "âš ï¸ Cache directory not found"
          fi
        # Phase 12.3: äº‹å‰è¨ˆç®—ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆå¤±æ•—ã—ã¦ã‚‚CIã‚’åœæ­¢ã—ãªã„ï¼‰

      - name: Validate production environment dependencies
        run: |
          echo ">>> Phase 12.5: Validating production dependencies"
          echo "ğŸ“‹ Testing production base dependencies import"
          python -c "
          import sys
          failed_imports = []
          base_modules = ['numpy', 'pandas', 'sklearn', 'joblib', 'requests', 'ccxt', 'dotenv', 'fastapi', 'uvicorn', 'yaml', 'tenacity']
          for module in base_modules:
              try:
                  __import__(module)
                  print(f'âœ… {module}')
              except ImportError as e:
                  failed_imports.append(f'{module}: {e}')
                  print(f'âŒ {module}: {e}')
          if failed_imports:
              print(f'\\nğŸš¨ Failed imports: {len(failed_imports)}')
              for failure in failed_imports:
                  print(f'   - {failure}')
              sys.exit(1)
          else:
              print(f'\\nğŸ‰ All {len(base_modules)} base dependencies imported successfully')
          "
        # Phase 12.5: æœ¬ç•ªç’°å¢ƒä¾å­˜é–¢ä¿‚æ¤œè¨¼ãƒ»importå¤±æ•—æ—©æœŸæ¤œå‡º

      - name: Test production Docker environment
        run: |
          echo ">>> Phase 12.5: Testing production Docker build and import"
          echo "ğŸ³ Building production Docker image..."
          docker build -f docker/Dockerfile -t crypto-bot-prod-test .
          echo "ğŸ“¦ Testing production environment import..."
          docker run --rm crypto-bot-prod-test python -c "
          import crypto_bot
          print('âœ… Production Docker import test passed')
          print('ğŸ¯ Environment parity verified: Local â‰ˆ CI â‰ˆ Production')
          "
        # Phase 12.5: æœ¬ç•ªDockerç’°å¢ƒãƒ†ã‚¹ãƒˆãƒ»tenacityãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å•é¡Œé¡ä¼¼ã‚¨ãƒ©ãƒ¼é˜²æ­¢

      - name: Run Phase C1 integration tests
        run: |
          echo ">>> Running Phase C1 integration tests"
          if [ -f "tests/integration/test_phase_c1_integration.py" ]; then
            python tests/integration/test_phase_c1_integration.py || echo "âš ï¸ Phase C1 integration tests failed but continuing"
          else
            echo "âš ï¸ Phase C1 integration tests not found - skipping"
          fi
        # Phase C1çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå¤±æ•—ã—ã¦ã‚‚CIã‚’åœæ­¢ã—ãªã„ï¼‰

      - name: Run Phase C2 integration tests
        run: |
          echo ">>> Running Phase C2 integration tests"
          if [ -f "tests/integration/test_phase_c2_integration.py" ]; then
            python tests/integration/test_phase_c2_integration.py || echo "âš ï¸ Phase C2 integration tests failed but continuing"
          else
            echo "âš ï¸ Phase C2 integration tests not found - skipping"
          fi
        # Phase C2çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå¤±æ•—ã—ã¦ã‚‚CIã‚’åœæ­¢ã—ãªã„ï¼‰

      - name: Upload coverage to Codecov
        if: ${{ env.CODECOV_TOKEN != '' }}
        uses: codecov/codecov-action@v4.5.0
        with:
          token: ${{ env.CODECOV_TOKEN }}
        # CODECOV_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã° coverage ã‚’ Codecov ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Bybit Testnet E2E ãƒ†ã‚¹ãƒˆ - Bitbankæœ¬ç•ªé‹ç”¨ã®ãŸã‚é™¤å¤–
  # å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•å®Ÿè¡Œå¯èƒ½
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  docker-build:
    name: Build & Test Docker Image
    needs: test
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')) ||
      startsWith(github.ref, 'refs/tags/v') ||
      (github.event_name == 'workflow_dispatch')
    permissions:
      contents: read
      id-token: write

    # Docker build and test environment
    env:
      IMAGE_NAME: crypto-bot

    steps:
      - uses: actions/checkout@v4
        # ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ

      - name: Create CI cache directory with minimal data
        run: |
          echo "ğŸ”§ Creating cache directory with minimal initial data for CI..."
          mkdir -p cache
          
          # æœ€å°é™ã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½œæˆï¼ˆCIã§ã¯APIèªè¨¼ã§ããªã„ãŸã‚ï¼‰
          python -c "
import pickle
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# CIç”¨ã®æœ€å°é™åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆ300ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰
now = pd.Timestamp.now(tz='UTC')
timestamps = pd.date_range(end=now, periods=300, freq='1H', tz='UTC')

# ãƒ€ãƒŸãƒ¼OHLCVãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
data = {
    'open': np.random.uniform(5000000, 5100000, 300),
    'high': np.random.uniform(5050000, 5150000, 300),
    'low': np.random.uniform(4950000, 5050000, 300),
    'close': np.random.uniform(5000000, 5100000, 300),
    'volume': np.random.uniform(100, 1000, 300)
}
df = pd.DataFrame(data, index=timestamps)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã—ã¦ä¿å­˜
cache_data = {
    'data': df,
    'metadata': {
        'generated': datetime.utcnow().isoformat(),
        'environment': 'CI',
        'records': len(df)
    }
}

with open('cache/initial_data.pkl', 'wb') as f:
    pickle.dump(cache_data, f)

print(f'âœ… Created initial data cache with {len(df)} records')
"
          
          # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
          echo '{"generated": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "environment": "CI", "records": 300}' > cache/initial_data_metadata.json
          
          echo "âœ… CI cache directory created with initial data"
          ls -la cache/
        # CIç’°å¢ƒç”¨ã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½œæˆ

      - name: Prepare model files for CI
        run: |
          echo "ğŸ¤– Preparing model files for CI environment..."
          mkdir -p models/production
          
          # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€CIç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆ
          if [ ! -f "models/production/model.pkl" ]; then
            echo "âš ï¸ Model file not found, creating minimal model for CI..."
            python -c "
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier

# CIç”¨ã®æœ€å°é™ã®ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
model = RandomForestClassifier(n_estimators=10, random_state=42)
# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
X_dummy = np.random.randn(100, 97)  # 97ç‰¹å¾´é‡
y_dummy = np.random.randint(0, 2, 100)
model.fit(X_dummy, y_dummy)

# TradingEnsembleClassifierå½¢å¼ã§ãƒ©ãƒƒãƒ—
class TradingEnsembleClassifier:
    def __init__(self):
        self.models_ = {'rf': model}
        self.is_fitted = True
        self.n_features_ = 97
    
    def predict_proba(self, X):
        return model.predict_proba(X)
    
    def predict(self, X):
        return model.predict(X)

ensemble = TradingEnsembleClassifier()

# ä¿å­˜
with open('models/production/model.pkl', 'wb') as f:
    pickle.dump(ensemble, f)
print('âœ… CI dummy model created successfully')
"
          else
            echo "âœ… Model file already exists"
          fi
          
          # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
          if [ ! -f "models/production/model_metadata.json" ]; then
            echo '{"version": "CI", "features": 97, "created": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}' > models/production/model_metadata.json
          fi
          
          echo "ğŸ“Š Model files prepared:"
          ls -la models/production/
        # CIç’°å¢ƒç”¨ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          platforms: linux/amd64
        # Docker Buildx ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (AMD64å°‚ç”¨)

      # ---------- Authenticate to GCP for Artifact Registry ----------
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_DEPLOYER_SA }}
          access_token_lifetime: 7200s
          access_token_scopes: |
            https://www.googleapis.com/auth/cloud-platform
            https://www.googleapis.com/auth/devstorage.read_write
            https://www.googleapis.com/auth/artifactregistry.repositories.uploadArtifacts

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure docker for Artifact Registry
        run: gcloud --quiet auth configure-docker asia-northeast1-docker.pkg.dev

      - name: Create Artifact Registry repository if not exists
        run: |
          echo "Checking if Artifact Registry repository exists..."
          if ! gcloud artifacts repositories describe crypto-bot-repo --location=asia-northeast1 --format="value(name)" 2>/dev/null; then
            echo "Creating Artifact Registry repository..."
            gcloud artifacts repositories create crypto-bot-repo \
              --repository-format=docker \
              --location=asia-northeast1 \
              --description="Docker repository for crypto-bot application"
          else
            echo "Artifact Registry repository already exists"
          fi

      # ---------- Build & push to Artifact Registry ----------
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/Dockerfile
          push: true
          load: false
          platforms: linux/amd64
          provenance: false
          tags: |
            asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:latest
            asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1
      
      - name: Test Docker image
        run: |
          IMAGE_TAG="asia-northeast1-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/crypto-bot-repo/crypto-bot:${{ github.sha }}"
          docker pull "${IMAGE_TAG}"
          docker run --rm "${IMAGE_TAG}" python -c "import crypto_bot; print('Docker import test passed')"
          
          # Test API server only mode for CI (no live trading due to missing model)
          docker run -d --name test-container -p 8080:8080 -e CI=true -e API_ONLY_MODE=true "${IMAGE_TAG}"
          echo "Waiting for API server to start..."
          sleep 15
          
          # Test API server health
          if curl -f http://localhost:8080/health; then
            echo "âœ… API server health check passed"
          else
            echo "âŒ API server health check failed"
            echo "Container logs:"
            docker logs test-container
            exit 1
          fi
          
          # Test additional endpoints
          if curl -f http://localhost:8080/healthz; then
            echo "âœ… Healthz endpoint check passed"
          else
            echo "âŒ Healthz endpoint check failed"
            docker logs test-container
            exit 1
          fi
          
          docker stop test-container
          docker rm test-container
          echo "âœ… Docker image tests passed successfully"
          echo "ğŸ“‹ Note: Live trading mode requires trained ML model (not available in CI)"


  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Development Environment Deploy (develop branch and PRs)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  terraform-deploy-dev:
    name: Deploy to Development
    needs: docker-build
    runs-on: ubuntu-latest
    if: |
      (github.ref == 'refs/heads/develop' && github.event_name == 'push') ||
      (github.event_name == 'pull_request' && github.base_ref == 'develop') ||
      (github.event_name == 'workflow_dispatch')
    permissions:
      contents: read
      id-token: write
    env:
      # Docker image pushed in the previous job
      IMAGE_NAME: ghcr.io/${{ github.repository_owner }}/crypto-bot
      # GCP project (secret)
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}

      # Development environment specific settings
      TF_VAR_artifact_registry_repo: "crypto-bot-repo"
      TF_VAR_service_name: "crypto-bot-dev"
      TF_VAR_image_name: "crypto-bot"
      TF_VAR_mode: "paper"
      TF_VAR_alert_email: ${{ secrets.ALERT_EMAIL }}
      TF_VAR_github_repo: "nao-namake/crypto-bot"
      TF_VAR_project_number: ${{ secrets.GCP_PROJECT_NUMBER }}
      TF_VAR_deployer_sa: ${{ secrets.GCP_DEPLOYER_SA }}
      # Paper modeã«ã¯å®Ÿéš›ã®APIã‚­ãƒ¼ã¯ä¸è¦ãªã®ã§ç©ºæ–‡å­—åˆ—ã‚’è¨­å®š
      TF_VAR_bitbank_api_key: ""
      TF_VAR_bitbank_api_secret: ""

      # ----- Terraform variables -----
      TF_VAR_project_id: ${{ secrets.GCP_PROJECT_ID }}
      TF_VAR_region: "asia-northeast1"
      TF_VAR_image_tag: "${{ github.sha }}"
      TF_ENV_DIR: "infra/envs/dev"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---------- Authenticate to GCP via Workload Identity Federation ----------
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_DEPLOYER_SA }}
          access_token_lifetime: 7200s
          access_token_scopes: |
            https://www.googleapis.com/auth/cloud-platform
            https://www.googleapis.com/auth/devstorage.read_write
            https://www.googleapis.com/auth/artifactregistry.repositories.uploadArtifacts

      - name: Set up gcloud for Development
        uses: google-github-actions/setup-gcloud@v2

      # ---------- Terraform ----------
      - name: Set up Terraform for Development
        uses: hashicorp/setup-terraform@v3.1.1
        with:
          terraform_version: 1.8.5

      - name: Terraform Init (Development)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} init -upgrade

      - name: Terraform Plan (Development)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} plan -input=false

      - name: Terraform Apply (Development)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} apply -auto-approve -input=false

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Production Environment Deploy (main branch only)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  terraform-deploy-prod:
    name: Deploy to Production
    needs: docker-build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    permissions:
      contents: read
      id-token: write
    env:
      # Docker image pushed in the previous job
      IMAGE_NAME: ghcr.io/${{ github.repository_owner }}/crypto-bot
      # GCP project (secret)
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}

      # Production environment specific settings
      TF_VAR_artifact_registry_repo: "crypto-bot-repo"
      TF_VAR_service_name: "crypto-bot-service-prod"
      TF_VAR_image_name: "crypto-bot"
      TF_VAR_mode: "live"
      TF_VAR_alert_email: ${{ secrets.ALERT_EMAIL }}
      TF_VAR_github_repo: "nao-namake/crypto-bot"
      TF_VAR_project_number: ${{ secrets.GCP_PROJECT_NUMBER }}
      TF_VAR_deployer_sa: ${{ secrets.GCP_DEPLOYER_SA }}

      # ----- Terraform variables -----
      TF_VAR_project_id: ${{ secrets.GCP_PROJECT_ID }}
      TF_VAR_region: "asia-northeast1"
      TF_VAR_image_tag: "${{ github.sha }}"
      TF_VAR_bitbank_api_key: ${{ secrets.BITBANK_API_KEY }}
      TF_VAR_bitbank_api_secret: ${{ secrets.BITBANK_API_SECRET }}
      TF_ENV_DIR: "infra/envs/prod"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---------- Authenticate to GCP via Workload Identity Federation ----------
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_DEPLOYER_SA }}
          access_token_lifetime: 7200s
          access_token_scopes: |
            https://www.googleapis.com/auth/cloud-platform
            https://www.googleapis.com/auth/devstorage.read_write
            https://www.googleapis.com/auth/artifactregistry.repositories.uploadArtifacts

      - name: Set up gcloud for Production
        uses: google-github-actions/setup-gcloud@v2

      # ---------- Terraform ----------
      - name: Set up Terraform for Production
        uses: hashicorp/setup-terraform@v3.1.1
        with:
          terraform_version: 1.8.5

      - name: Prepare Production Data Cache
        env:
          BITBANK_API_KEY: ${{ secrets.BITBANK_API_KEY }}
          BITBANK_API_SECRET: ${{ secrets.BITBANK_API_SECRET }}
        run: |
          echo "ğŸ“Š Preparing production data cache..."
          
          # Try to fetch real data for production
          if [[ -n "$BITBANK_API_KEY" ]] && [[ -n "$BITBANK_API_SECRET" ]]; then
            echo "ğŸ”„ Fetching real market data for production cache..."
            python scripts/prepare_initial_data.py || {
              echo "âš ï¸ Failed to fetch real data, using minimal cache"
              python scripts/create_minimal_cache.py || echo "âš ï¸ Minimal cache creation also failed"
            }
          else
            echo "âš ï¸ API credentials not available, creating minimal cache..."
            python scripts/create_minimal_cache.py || echo "âš ï¸ Minimal cache creation failed"
          fi
          
          # Verify cache was created
          if [ -f "cache/initial_data.pkl" ]; then
            echo "âœ… Production cache prepared successfully"
            ls -la cache/
          else
            echo "âš ï¸ Cache file not found, deployment may have issues"
          fi

      - name: Terraform Init (Production)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} init -upgrade

      - name: Terraform Plan (Production)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} plan -input=false

      - name: Terraform Apply (Production)
        run: terraform -chdir=${{ env.TF_ENV_DIR }} apply -auto-approve -input=false

      # ---------- Post-deployment verification ----------
      - name: Verify Production Deployment
        run: |
          echo "ğŸ” Verifying production deployment..."
          sleep 30  # Wait for service to fully start
          
          # Check service health
          echo "ğŸ“Š Checking service health..."
          HEALTH_RESPONSE=$(curl -s https://crypto-bot-service-prod-lufv3saz7q-an.a.run.app/health || echo "failed")
          
          if [[ "$HEALTH_RESPONSE" == *"healthy"* ]]; then
            echo "âœ… Service is healthy: $HEALTH_RESPONSE"
          else
            echo "âš ï¸ Service health check failed or returned unexpected response"
            echo "Response: $HEALTH_RESPONSE"
          fi
          
          # Check for critical errors in logs
          echo "ğŸ“ Checking for critical errors in recent logs..."
          gcloud logging read "resource.type=cloud_run_revision AND severity>=ERROR AND timestamp>=\"$(date -u -d '5 minutes ago' '+%Y-%m-%dT%H:%M:%S')Z\"" --limit=10 --format=json | jq -r '.[] | "\(.timestamp): \(.textPayload // .jsonPayload.message)"' || echo "No recent errors found"
          
          # Verify main loop is running
          echo "ğŸ”„ Checking if main trading loop started..."
          LOOP_CHECK=$(gcloud logging read "resource.type=cloud_run_revision AND textPayload:\"LOOP-ITER\" AND timestamp>=\"$(date -u -d '5 minutes ago' '+%Y-%m-%dT%H:%M:%S')Z\"" --limit=1 --format=json | jq -r '.[] | .textPayload' || echo "")
          
          if [[ -n "$LOOP_CHECK" ]]; then
            echo "âœ… Main trading loop is running"
          else
            echo "âš ï¸ Main trading loop not detected yet (this may be normal if deployment just completed)"
          fi
          
          echo "ğŸ“Š Deployment verification complete"

